/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
10/21/2021 14:00:28 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, beam_size=5, config_name='', dev_filename='../../data/unique/split/large/src-val.txt,../../data/unique/split/large/tgt-val.txt', do_eval=True, do_lower_case=False, do_test=False, do_train=True, eval_batch_size=4, eval_steps=1000, gradient_accumulation_steps=1, learning_rate=5e-05, load_model_path=None, local_rank=-1, max_grad_norm=1.0, max_source_length=510, max_steps=-1, max_target_length=510, model_name_or_path='../../codebert-base', model_type='roberta', no_cuda=False, num_train_epochs=3.0, output_dir='saved_models/codebert/unique/large', seed=42, test_filename=None, tokenizer_name='roberta-base', train_batch_size=4, train_filename='../../data/unique/split/large/src-train.txt,../../data/unique/split/large/tgt-train.txt', train_steps=50000, warmup_steps=0, weight_decay=0.0)
10/21/2021 14:00:28 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False
10/21/2021 14:00:28 - INFO - transformers.configuration_utils -   loading configuration file ../../codebert-base/config.json
10/21/2021 14:00:28 - INFO - transformers.configuration_utils -   Model config RobertaConfig {
  "architectures": [
    "RobertaModel"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "eos_token_id": 2,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 514,
  "model_type": "roberta",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "output_past": true,
  "pad_token_id": 1,
  "type_vocab_size": 1,
  "vocab_size": 50265
}

10/21/2021 14:00:28 - INFO - transformers.tokenization_utils_base -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at /home/mahim/.cache/torch/transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/21/2021 14:00:28 - INFO - transformers.tokenization_utils_base -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at /home/mahim/.cache/torch/transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/21/2021 14:00:28 - INFO - transformers.modeling_utils -   loading weights file ../../codebert-base/pytorch_model.bin
10/21/2021 14:00:34 - INFO - transformers.modeling_utils -   All model checkpoint weights were used when initializing RobertaModel.

10/21/2021 14:00:34 - INFO - transformers.modeling_utils -   All the weights of RobertaModel were initialized from the model checkpoint at ../../codebert-base.
If your task is similar to the task the model of the ckeckpoint was trained on, you can already use RobertaModel for predictions without further training.
10/21/2021 14:00:38 - INFO - __main__ -   *** Example ***
10/21/2021 14:00:38 - INFO - __main__ -   idx: 0
10/21/2021 14:00:38 - INFO - __main__ -   source_tokens: ['<s>', 'e', '.', 'get', 'Cache', 'H', 'its', '()', '</s>']
10/21/2021 14:00:38 - INFO - __main__ -   source_ids: 0 242 4 6460 48572 725 2629 43048 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
10/21/2021 14:00:38 - INFO - __main__ -   source_mask: 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
10/21/2021 14:00:38 - INFO - __main__ -   target_tokens: ['<s>', 'e', '.', 'get', 'Cache', 'Miss', 'es', '()', '</s>']
10/21/2021 14:00:38 - INFO - __main__ -   target_ids: 0 242 4 6460 48572 22885 293 43048 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
10/21/2021 14:00:38 - INFO - __main__ -   target_mask: 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
10/21/2021 14:00:42 - INFO - __main__ -   *** Example ***
10/21/2021 14:00:42 - INFO - __main__ -   idx: 5000
10/21/2021 14:00:42 - INFO - __main__ -   source_tokens: ['<s>', 'LOG', '.', 'is', 'Debug', 'Enabled', '()', '_&&', '_instruction', '_instance', 'of', '_Control', 'Transfer', 'Inst', 'ruction', '_&&', '_after', '.', 'length', '_==', '_0', '</s>']
10/21/2021 14:00:42 - INFO - __main__ -   source_ids: 0 45403 4 354 49714 48582 43048 48200 15741 4327 1116 6007 46552 23754 31470 48200 71 4 16096 45994 321 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
10/21/2021 14:00:42 - INFO - __main__ -   source_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
10/21/2021 14:00:42 - INFO - __main__ -   target_tokens: ['<s>', 'LOG', '.', 'is', 'Debug', 'Enabled', '()', '_&&', '_!', '(', 'ps', 'i', 'Block', '_instance', 'of', '_P', 'si', 'Code', 'Frag', 'ment', ')', '_&&', '_instruction', '_instance', 'of', '_Control', 'Transfer', 'Inst', 'ruction', '&&', '_after', '.', 'length', '_==', '_0', '</s>']
10/21/2021 14:00:42 - INFO - __main__ -   target_ids: 0 45403 4 354 49714 48582 43048 48200 27785 1640 3275 118 38866 4327 1116 221 11000 41555 47881 1757 43 48200 15741 4327 1116 6007 46552 23754 31470 49145 71 4 16096 45994 321 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
10/21/2021 14:00:42 - INFO - __main__ -   target_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
10/21/2021 14:00:45 - INFO - __main__ -   *** Example ***
10/21/2021 14:00:45 - INFO - __main__ -   idx: 10000
10/21/2021 14:00:45 - INFO - __main__ -   source_tokens: ['<s>', 'assert', 'Left', 'Right', 'Category', '(', '12', ',', 'category', '2', 'c', ')', '</s>']
10/21/2021 14:00:45 - INFO - __main__ -   source_ids: 0 46346 39961 13984 46308 1640 1092 6 42747 176 438 43 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
10/21/2021 14:00:45 - INFO - __main__ -   source_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
10/21/2021 14:00:45 - INFO - __main__ -   target_tokens: ['<s>', 'assert', 'Left', 'Right', 'Category', '(', '11', ',', 'category', '2', 'c', ')', '</s>']
10/21/2021 14:00:45 - INFO - __main__ -   target_ids: 0 46346 39961 13984 46308 1640 1225 6 42747 176 438 43 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
10/21/2021 14:00:45 - INFO - __main__ -   target_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
10/21/2021 14:00:48 - INFO - __main__ -   *** Example ***
10/21/2021 14:00:48 - INFO - __main__ -   idx: 15000
10/21/2021 14:00:48 - INFO - __main__ -   source_tokens: ['<s>', '!', 'is', 'Part', 'ial', 'Update', '</s>']
10/21/2021 14:00:48 - INFO - __main__ -   source_ids: 0 328 354 4741 2617 39962 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
10/21/2021 14:00:48 - INFO - __main__ -   source_mask: 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
10/21/2021 14:00:48 - INFO - __main__ -   target_tokens: ['<s>', '!', 'is', 'Part', 'ial', 'Update', '_||', '_id', '.', 'views', '_==', '_null', '</s>']
10/21/2021 14:00:48 - INFO - __main__ -   target_ids: 0 328 354 4741 2617 39962 45056 13561 4 39281 45994 23796 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
10/21/2021 14:00:48 - INFO - __main__ -   target_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
10/21/2021 14:00:52 - INFO - __main__ -   ***** Running training *****
10/21/2021 14:00:52 - INFO - __main__ -     Num examples = 19590
10/21/2021 14:00:52 - INFO - __main__ -     Batch size = 4
10/21/2021 14:00:52 - INFO - __main__ -     Num epoch = 10
10/21/2021 14:01:45 - INFO - __main__ -     step 100 loss 7.2653
10/21/2021 14:02:38 - INFO - __main__ -     step 200 loss 6.7444
10/21/2021 14:03:31 - INFO - __main__ -     step 300 loss 6.3853
10/21/2021 14:04:25 - INFO - __main__ -     step 400 loss 6.121
10/21/2021 14:05:18 - INFO - __main__ -     step 500 loss 5.9333
10/21/2021 14:06:12 - INFO - __main__ -     step 600 loss 5.7526
10/21/2021 14:07:06 - INFO - __main__ -     step 700 loss 5.6023
10/21/2021 14:07:59 - INFO - __main__ -     step 800 loss 5.469
10/21/2021 14:08:53 - INFO - __main__ -     step 900 loss 5.3334
10/21/2021 14:09:46 - INFO - __main__ -   Here1
10/21/2021 14:09:46 - INFO - __main__ -   Here3
10/21/2021 14:09:48 - INFO - __main__ -   
***** Running evaluation *****
10/21/2021 14:09:48 - INFO - __main__ -     Num examples = 2449
10/21/2021 14:09:48 - INFO - __main__ -     Batch size = 4
10/21/2021 14:11:25 - INFO - __main__ -     eval_ppl = 53.8267
10/21/2021 14:11:25 - INFO - __main__ -     global_step = 1000
10/21/2021 14:11:25 - INFO - __main__ -     train_loss = 5.208
10/21/2021 14:11:25 - INFO - __main__ -     ********************
10/21/2021 14:11:27 - INFO - __main__ -     Best ppl:53.8267
10/21/2021 14:11:27 - INFO - __main__ -     ********************
10/21/2021 14:11:29 - INFO - __main__ -   Here5
10/21/2021 14:11:29 - INFO - __main__ -   Here5.5
10/21/2021 14:46:57 - INFO - __main__ -   Here6
10/21/2021 14:46:57 - INFO - __main__ -     bleu-4 = 0.75 
10/21/2021 14:46:57 - INFO - __main__ -     xMatch = 0.5 
10/21/2021 14:46:57 - INFO - __main__ -     ********************
10/21/2021 14:46:57 - INFO - __main__ -     Best bleu:0.75
10/21/2021 14:46:57 - INFO - __main__ -     ********************
10/21/2021 14:46:59 - INFO - __main__ -     step 1000 loss 3.4392
10/21/2021 14:47:53 - INFO - __main__ -     step 1100 loss 3.9109
10/21/2021 14:48:46 - INFO - __main__ -     step 1200 loss 3.8545
10/21/2021 14:49:40 - INFO - __main__ -     step 1300 loss 3.7861
10/21/2021 14:50:34 - INFO - __main__ -     step 1400 loss 3.6819
10/21/2021 14:51:28 - INFO - __main__ -     step 1500 loss 3.5694
10/21/2021 14:52:22 - INFO - __main__ -     step 1600 loss 3.4846
10/21/2021 14:53:15 - INFO - __main__ -     step 1700 loss 3.4101
10/21/2021 14:54:09 - INFO - __main__ -     step 1800 loss 3.3342
10/21/2021 14:55:03 - INFO - __main__ -     step 1900 loss 3.2443
10/21/2021 14:55:56 - INFO - __main__ -   Here1
10/21/2021 14:55:56 - INFO - __main__ -   Here2
10/21/2021 14:55:56 - INFO - __main__ -   
***** Running evaluation *****
10/21/2021 14:55:56 - INFO - __main__ -     Num examples = 2449
10/21/2021 14:55:56 - INFO - __main__ -     Batch size = 4
10/21/2021 14:57:34 - INFO - __main__ -     eval_ppl = 13.17774
10/21/2021 14:57:34 - INFO - __main__ -     global_step = 2000
10/21/2021 14:57:34 - INFO - __main__ -     train_loss = 3.1786
10/21/2021 14:57:34 - INFO - __main__ -     ********************
10/21/2021 14:57:38 - INFO - __main__ -     Best ppl:13.17774
10/21/2021 14:57:38 - INFO - __main__ -     ********************
10/21/2021 14:57:43 - INFO - __main__ -   Here4
10/21/2021 14:57:43 - INFO - __main__ -   Here5.5
10/21/2021 15:39:16 - INFO - __main__ -   Here6
10/21/2021 15:39:16 - INFO - __main__ -     bleu-4 = 2.15 
10/21/2021 15:39:16 - INFO - __main__ -     xMatch = 0.8 
10/21/2021 15:39:16 - INFO - __main__ -     ********************
10/21/2021 15:39:16 - INFO - __main__ -     Best bleu:2.15
10/21/2021 15:39:16 - INFO - __main__ -     ********************
10/21/2021 15:39:20 - INFO - __main__ -     step 2000 loss 3.8338
10/21/2021 15:40:14 - INFO - __main__ -     step 2100 loss 2.4615
10/21/2021 15:41:08 - INFO - __main__ -     step 2200 loss 2.3244
10/21/2021 15:42:03 - INFO - __main__ -     step 2300 loss 2.2874
10/21/2021 15:42:57 - INFO - __main__ -     step 2400 loss 2.3026
10/21/2021 15:43:51 - INFO - __main__ -     step 2500 loss 2.2651
10/21/2021 15:44:45 - INFO - __main__ -     step 2600 loss 2.2572
10/21/2021 15:45:39 - INFO - __main__ -     step 2700 loss 2.2415
10/21/2021 15:46:34 - INFO - __main__ -     step 2800 loss 2.2182
10/21/2021 15:47:28 - INFO - __main__ -     step 2900 loss 2.2113
10/21/2021 15:48:21 - INFO - __main__ -   Here1
10/21/2021 15:48:21 - INFO - __main__ -   Here2
10/21/2021 15:48:21 - INFO - __main__ -   
***** Running evaluation *****
10/21/2021 15:48:21 - INFO - __main__ -     Num examples = 2449
10/21/2021 15:48:21 - INFO - __main__ -     Batch size = 4
10/21/2021 15:50:00 - INFO - __main__ -     eval_ppl = 7.329
10/21/2021 15:50:00 - INFO - __main__ -     global_step = 3000
10/21/2021 15:50:00 - INFO - __main__ -     train_loss = 2.1836
10/21/2021 15:50:00 - INFO - __main__ -     ********************
10/21/2021 15:50:04 - INFO - __main__ -     Best ppl:7.329
10/21/2021 15:50:04 - INFO - __main__ -     ********************
10/21/2021 15:50:09 - INFO - __main__ -   Here4
10/21/2021 15:50:09 - INFO - __main__ -   Here5.5
10/21/2021 16:12:50 - INFO - __main__ -   Here6
10/21/2021 16:12:50 - INFO - __main__ -     bleu-4 = 7.44 
10/21/2021 16:12:50 - INFO - __main__ -     xMatch = 1.5 
10/21/2021 16:12:50 - INFO - __main__ -     ********************
10/21/2021 16:12:50 - INFO - __main__ -     Best bleu:7.44
10/21/2021 16:12:50 - INFO - __main__ -     ********************
10/21/2021 16:12:54 - INFO - __main__ -     step 3000 loss 1.2887
10/21/2021 16:13:48 - INFO - __main__ -     step 3100 loss 1.9573
10/21/2021 16:14:42 - INFO - __main__ -     step 3200 loss 1.9045
10/21/2021 16:15:37 - INFO - __main__ -     step 3300 loss 1.884
10/21/2021 16:16:31 - INFO - __main__ -     step 3400 loss 1.8488
10/21/2021 16:17:25 - INFO - __main__ -     step 3500 loss 1.8653
10/21/2021 16:18:20 - INFO - __main__ -     step 3600 loss 1.8478
10/21/2021 16:19:14 - INFO - __main__ -     step 3700 loss 1.8414
10/21/2021 16:20:08 - INFO - __main__ -     step 3800 loss 1.8252
10/21/2021 16:21:03 - INFO - __main__ -     step 3900 loss 1.8071
10/21/2021 16:21:57 - INFO - __main__ -   Here1
10/21/2021 16:21:57 - INFO - __main__ -   Here2
10/21/2021 16:21:57 - INFO - __main__ -   
***** Running evaluation *****
10/21/2021 16:21:57 - INFO - __main__ -     Num examples = 2449
10/21/2021 16:21:57 - INFO - __main__ -     Batch size = 4
10/21/2021 16:23:35 - INFO - __main__ -     eval_ppl = 5.3798
10/21/2021 16:23:35 - INFO - __main__ -     global_step = 4000
10/21/2021 16:23:35 - INFO - __main__ -     train_loss = 1.7949
10/21/2021 16:23:35 - INFO - __main__ -     ********************
10/21/2021 16:23:40 - INFO - __main__ -     Best ppl:5.3798
10/21/2021 16:23:40 - INFO - __main__ -     ********************
10/21/2021 16:23:45 - INFO - __main__ -   Here4
10/21/2021 16:23:45 - INFO - __main__ -   Here5.5
10/21/2021 16:50:00 - INFO - __main__ -   Here6
10/21/2021 16:50:00 - INFO - __main__ -     bleu-4 = 12.0 
10/21/2021 16:50:00 - INFO - __main__ -     xMatch = 4.3 
10/21/2021 16:50:00 - INFO - __main__ -     ********************
10/21/2021 16:50:00 - INFO - __main__ -     Best bleu:12.0
10/21/2021 16:50:00 - INFO - __main__ -     ********************
10/21/2021 16:50:04 - INFO - __main__ -     step 4000 loss 1.2201
10/21/2021 16:50:58 - INFO - __main__ -     step 4100 loss 1.6327
10/21/2021 16:51:52 - INFO - __main__ -     step 4200 loss 1.5842
10/21/2021 16:52:46 - INFO - __main__ -     step 4300 loss 1.565
10/21/2021 16:53:41 - INFO - __main__ -     step 4400 loss 1.5651
10/21/2021 16:54:35 - INFO - __main__ -     step 4500 loss 1.5626
10/21/2021 16:55:29 - INFO - __main__ -     step 4600 loss 1.5464
10/21/2021 16:56:23 - INFO - __main__ -     step 4700 loss 1.5295
10/21/2021 16:57:17 - INFO - __main__ -     step 4800 loss 1.5304
10/21/2021 16:58:11 - INFO - __main__ -     step 4900 loss 1.5251
10/21/2021 16:59:05 - INFO - __main__ -   Here1
10/21/2021 16:59:05 - INFO - __main__ -   Here2
10/21/2021 16:59:05 - INFO - __main__ -   
***** Running evaluation *****
10/21/2021 16:59:05 - INFO - __main__ -     Num examples = 2449
10/21/2021 16:59:05 - INFO - __main__ -     Batch size = 4
10/21/2021 17:00:43 - INFO - __main__ -     eval_ppl = 4.64091
10/21/2021 17:00:43 - INFO - __main__ -     global_step = 5000
10/21/2021 17:00:43 - INFO - __main__ -     train_loss = 1.5257
10/21/2021 17:00:43 - INFO - __main__ -     ********************
10/21/2021 17:00:46 - INFO - __main__ -     Best ppl:4.64091
10/21/2021 17:00:46 - INFO - __main__ -     ********************
10/21/2021 17:00:49 - INFO - __main__ -   Here4
10/21/2021 17:00:49 - INFO - __main__ -   Here5.5
10/21/2021 17:17:08 - INFO - __main__ -   Here6
10/21/2021 17:17:08 - INFO - __main__ -     bleu-4 = 13.13 
10/21/2021 17:17:08 - INFO - __main__ -     xMatch = 4.1 
10/21/2021 17:17:08 - INFO - __main__ -     ********************
10/21/2021 17:17:08 - INFO - __main__ -     Best bleu:13.13
10/21/2021 17:17:08 - INFO - __main__ -     ********************
10/21/2021 17:17:12 - INFO - __main__ -     step 5000 loss 1.2185
10/21/2021 17:18:06 - INFO - __main__ -     step 5100 loss 1.4203
10/21/2021 17:19:00 - INFO - __main__ -     step 5200 loss 1.4235
10/21/2021 17:19:55 - INFO - __main__ -     step 5300 loss 1.3763
10/21/2021 17:20:49 - INFO - __main__ -     step 5400 loss 1.4006
10/21/2021 17:21:43 - INFO - __main__ -     step 5500 loss 1.3913
10/21/2021 17:22:38 - INFO - __main__ -     step 5600 loss 1.3811
10/21/2021 17:23:31 - INFO - __main__ -     step 5700 loss 1.3698
10/21/2021 17:24:25 - INFO - __main__ -     step 5800 loss 1.3717
10/21/2021 17:25:19 - INFO - __main__ -     step 5900 loss 1.3564
10/21/2021 17:26:13 - INFO - __main__ -   Here1
10/21/2021 17:26:13 - INFO - __main__ -   Here2
10/21/2021 17:26:13 - INFO - __main__ -   
***** Running evaluation *****
10/21/2021 17:26:13 - INFO - __main__ -     Num examples = 2449
10/21/2021 17:26:13 - INFO - __main__ -     Batch size = 4
10/21/2021 17:27:51 - INFO - __main__ -     eval_ppl = 3.90684
10/21/2021 17:27:51 - INFO - __main__ -     global_step = 6000
10/21/2021 17:27:51 - INFO - __main__ -     train_loss = 1.3532
10/21/2021 17:27:51 - INFO - __main__ -     ********************
10/21/2021 17:27:55 - INFO - __main__ -     Best ppl:3.90684
10/21/2021 17:27:55 - INFO - __main__ -     ********************
10/21/2021 17:27:58 - INFO - __main__ -   Here4
10/21/2021 17:27:58 - INFO - __main__ -   Here5.5
10/21/2021 17:44:08 - INFO - __main__ -   Here6
10/21/2021 17:44:08 - INFO - __main__ -     bleu-4 = 19.25 
10/21/2021 17:44:08 - INFO - __main__ -     xMatch = 5.6 
10/21/2021 17:44:08 - INFO - __main__ -     ********************
10/21/2021 17:44:08 - INFO - __main__ -     Best bleu:19.25
10/21/2021 17:44:08 - INFO - __main__ -     ********************
10/21/2021 17:44:12 - INFO - __main__ -     step 6000 loss 1.4681
10/21/2021 17:45:06 - INFO - __main__ -     step 6100 loss 1.4038
10/21/2021 17:46:00 - INFO - __main__ -     step 6200 loss 1.3827
10/21/2021 17:46:54 - INFO - __main__ -     step 6300 loss 1.3503
10/21/2021 17:47:48 - INFO - __main__ -     step 6400 loss 1.3409
10/21/2021 17:48:42 - INFO - __main__ -     step 6500 loss 1.3168
10/21/2021 17:49:36 - INFO - __main__ -     step 6600 loss 1.2943
10/21/2021 17:50:30 - INFO - __main__ -     step 6700 loss 1.2718
10/21/2021 17:51:24 - INFO - __main__ -     step 6800 loss 1.2505
10/21/2021 17:52:19 - INFO - __main__ -     step 6900 loss 1.2446
10/21/2021 17:53:13 - INFO - __main__ -   Here1
10/21/2021 17:53:13 - INFO - __main__ -   Here2
10/21/2021 17:53:13 - INFO - __main__ -   
***** Running evaluation *****
10/21/2021 17:53:13 - INFO - __main__ -     Num examples = 2449
10/21/2021 17:53:13 - INFO - __main__ -     Batch size = 4
10/21/2021 17:54:51 - INFO - __main__ -     eval_ppl = 3.67613
10/21/2021 17:54:51 - INFO - __main__ -     global_step = 7000
10/21/2021 17:54:51 - INFO - __main__ -     train_loss = 1.2396
10/21/2021 17:54:51 - INFO - __main__ -     ********************
10/21/2021 17:54:54 - INFO - __main__ -     Best ppl:3.67613
10/21/2021 17:54:54 - INFO - __main__ -     ********************
10/21/2021 17:54:57 - INFO - __main__ -   Here4
10/21/2021 17:54:57 - INFO - __main__ -   Here5.5
10/21/2021 18:13:44 - INFO - __main__ -   Here6
10/21/2021 18:13:44 - INFO - __main__ -     bleu-4 = 20.47 
10/21/2021 18:13:44 - INFO - __main__ -     xMatch = 7.5 
10/21/2021 18:13:44 - INFO - __main__ -     ********************
10/21/2021 18:13:44 - INFO - __main__ -     Best bleu:20.47
10/21/2021 18:13:44 - INFO - __main__ -     ********************
10/21/2021 18:13:48 - INFO - __main__ -     step 7000 loss 1.1941
10/21/2021 18:14:43 - INFO - __main__ -     step 7100 loss 1.0401
10/21/2021 18:15:37 - INFO - __main__ -     step 7200 loss 1.0371
10/21/2021 18:16:31 - INFO - __main__ -     step 7300 loss 1.0786
10/21/2021 18:17:25 - INFO - __main__ -     step 7400 loss 1.0936
10/21/2021 18:18:20 - INFO - __main__ -     step 7500 loss 1.1072
10/21/2021 18:19:14 - INFO - __main__ -     step 7600 loss 1.1129
10/21/2021 18:20:09 - INFO - __main__ -     step 7700 loss 1.1158
10/21/2021 18:21:03 - INFO - __main__ -     step 7800 loss 1.1278
10/21/2021 18:21:58 - INFO - __main__ -     step 7900 loss 1.1201
10/21/2021 18:22:52 - INFO - __main__ -   Here1
10/21/2021 18:22:52 - INFO - __main__ -   Here2
10/21/2021 18:22:52 - INFO - __main__ -   
***** Running evaluation *****
10/21/2021 18:22:52 - INFO - __main__ -     Num examples = 2449
10/21/2021 18:22:52 - INFO - __main__ -     Batch size = 4
10/21/2021 18:24:31 - INFO - __main__ -     eval_ppl = 3.25764
10/21/2021 18:24:31 - INFO - __main__ -     global_step = 8000
10/21/2021 18:24:31 - INFO - __main__ -     train_loss = 1.1157
10/21/2021 18:24:31 - INFO - __main__ -     ********************
10/21/2021 18:24:34 - INFO - __main__ -     Best ppl:3.25764
10/21/2021 18:24:34 - INFO - __main__ -     ********************
10/21/2021 18:24:37 - INFO - __main__ -   Here4
10/21/2021 18:24:37 - INFO - __main__ -   Here5.5
10/21/2021 18:37:34 - INFO - __main__ -   Here6
10/21/2021 18:37:34 - INFO - __main__ -     bleu-4 = 26.61 
10/21/2021 18:37:34 - INFO - __main__ -     xMatch = 6.6 
10/21/2021 18:37:34 - INFO - __main__ -     ********************
10/21/2021 18:37:34 - INFO - __main__ -     Best bleu:26.61
10/21/2021 18:37:34 - INFO - __main__ -     ********************
10/21/2021 18:37:38 - INFO - __main__ -     step 8000 loss 0.8153
10/21/2021 18:38:33 - INFO - __main__ -     step 8100 loss 1.0656
10/21/2021 18:39:27 - INFO - __main__ -     step 8200 loss 1.0776
10/21/2021 18:40:22 - INFO - __main__ -     step 8300 loss 1.0647
10/21/2021 18:41:16 - INFO - __main__ -     step 8400 loss 1.0824
10/21/2021 18:42:11 - INFO - __main__ -     step 8500 loss 1.0822
10/21/2021 18:43:05 - INFO - __main__ -     step 8600 loss 1.0851
10/21/2021 18:44:00 - INFO - __main__ -     step 8700 loss 1.0819
10/21/2021 18:44:54 - INFO - __main__ -     step 8800 loss 1.0751
10/21/2021 18:45:48 - INFO - __main__ -     step 8900 loss 1.0783
10/21/2021 18:46:42 - INFO - __main__ -   Here1
10/21/2021 18:46:42 - INFO - __main__ -   Here2
10/21/2021 18:46:42 - INFO - __main__ -   
***** Running evaluation *****
10/21/2021 18:46:42 - INFO - __main__ -     Num examples = 2449
10/21/2021 18:46:42 - INFO - __main__ -     Batch size = 4
10/21/2021 18:48:21 - INFO - __main__ -     eval_ppl = 3.10118
10/21/2021 18:48:21 - INFO - __main__ -     global_step = 9000
10/21/2021 18:48:21 - INFO - __main__ -     train_loss = 1.0693
10/21/2021 18:48:21 - INFO - __main__ -     ********************
10/21/2021 18:48:25 - INFO - __main__ -     Best ppl:3.10118
10/21/2021 18:48:25 - INFO - __main__ -     ********************
10/21/2021 18:48:29 - INFO - __main__ -   Here4
10/21/2021 18:48:29 - INFO - __main__ -   Here5.5
10/21/2021 18:59:00 - INFO - __main__ -   Here6
10/21/2021 18:59:00 - INFO - __main__ -     bleu-4 = 27.92 
10/21/2021 18:59:00 - INFO - __main__ -     xMatch = 9.4 
10/21/2021 18:59:00 - INFO - __main__ -     ********************
10/21/2021 18:59:00 - INFO - __main__ -     Best bleu:27.92
10/21/2021 18:59:00 - INFO - __main__ -     ********************
10/21/2021 18:59:04 - INFO - __main__ -     step 9000 loss 0.735
10/21/2021 18:59:58 - INFO - __main__ -     step 9100 loss 0.9966
10/21/2021 19:00:52 - INFO - __main__ -     step 9200 loss 0.9841
10/21/2021 19:01:46 - INFO - __main__ -     step 9300 loss 0.9911
10/21/2021 19:02:41 - INFO - __main__ -     step 9400 loss 0.9969
10/21/2021 19:03:35 - INFO - __main__ -     step 9500 loss 0.9801
10/21/2021 19:04:29 - INFO - __main__ -     step 9600 loss 0.9715
10/21/2021 19:05:23 - INFO - __main__ -     step 9700 loss 0.9708
10/21/2021 19:06:16 - INFO - __main__ -     step 9800 loss 0.9715
10/21/2021 19:07:10 - INFO - __main__ -     step 9900 loss 0.9813
10/21/2021 19:08:04 - INFO - __main__ -   Here1
10/21/2021 19:08:04 - INFO - __main__ -   Here2
10/21/2021 19:08:04 - INFO - __main__ -   
***** Running evaluation *****
10/21/2021 19:08:04 - INFO - __main__ -     Num examples = 2449
10/21/2021 19:08:04 - INFO - __main__ -     Batch size = 4
10/21/2021 19:09:43 - INFO - __main__ -     eval_ppl = 3.02951
10/21/2021 19:09:43 - INFO - __main__ -     global_step = 10000
10/21/2021 19:09:43 - INFO - __main__ -     train_loss = 0.975
10/21/2021 19:09:43 - INFO - __main__ -     ********************
10/21/2021 19:09:47 - INFO - __main__ -     Best ppl:3.02951
10/21/2021 19:09:47 - INFO - __main__ -     ********************
10/21/2021 19:09:50 - INFO - __main__ -   Here4
10/21/2021 19:09:50 - INFO - __main__ -   Here5.5
10/21/2021 19:21:23 - INFO - __main__ -   Here6
10/21/2021 19:21:23 - INFO - __main__ -     bleu-4 = 28.45 
10/21/2021 19:21:23 - INFO - __main__ -     xMatch = 8.1 
10/21/2021 19:21:23 - INFO - __main__ -     ********************
10/21/2021 19:21:23 - INFO - __main__ -     Best bleu:28.45
10/21/2021 19:21:23 - INFO - __main__ -     ********************
10/21/2021 19:21:27 - INFO - __main__ -     step 10000 loss 1.3156
10/21/2021 19:22:22 - INFO - __main__ -     step 10100 loss 0.9782
10/21/2021 19:23:16 - INFO - __main__ -     step 10200 loss 0.9236
10/21/2021 19:24:10 - INFO - __main__ -     step 10300 loss 0.943
10/21/2021 19:25:04 - INFO - __main__ -     step 10400 loss 0.9402
10/21/2021 19:25:58 - INFO - __main__ -     step 10500 loss 0.9385
10/21/2021 19:26:52 - INFO - __main__ -     step 10600 loss 0.9285
10/21/2021 19:27:46 - INFO - __main__ -     step 10700 loss 0.9348
10/21/2021 19:28:40 - INFO - __main__ -     step 10800 loss 0.9235
10/21/2021 19:29:34 - INFO - __main__ -     step 10900 loss 0.9263
10/21/2021 19:30:28 - INFO - __main__ -   Here1
10/21/2021 19:30:28 - INFO - __main__ -   Here2
10/21/2021 19:30:28 - INFO - __main__ -   
***** Running evaluation *****
10/21/2021 19:30:28 - INFO - __main__ -     Num examples = 2449
10/21/2021 19:30:28 - INFO - __main__ -     Batch size = 4
10/21/2021 19:32:07 - INFO - __main__ -     eval_ppl = 2.92529
10/21/2021 19:32:07 - INFO - __main__ -     global_step = 11000
10/21/2021 19:32:07 - INFO - __main__ -     train_loss = 0.9334
10/21/2021 19:32:07 - INFO - __main__ -     ********************
10/21/2021 19:32:10 - INFO - __main__ -     Best ppl:2.92529
10/21/2021 19:32:10 - INFO - __main__ -     ********************
10/21/2021 19:32:13 - INFO - __main__ -   Here4
10/21/2021 19:32:13 - INFO - __main__ -   Here5.5
10/21/2021 19:41:21 - INFO - __main__ -   Here6
10/21/2021 19:41:21 - INFO - __main__ -     bleu-4 = 26.7 
10/21/2021 19:41:21 - INFO - __main__ -     xMatch = 9.0 
10/21/2021 19:41:21 - INFO - __main__ -     ********************
10/21/2021 19:41:21 - INFO - __main__ -     step 11000 loss 0.373
10/21/2021 19:42:16 - INFO - __main__ -     step 11100 loss 0.9151
10/21/2021 19:43:10 - INFO - __main__ -     step 11200 loss 0.8978
10/21/2021 19:44:04 - INFO - __main__ -     step 11300 loss 0.909
10/21/2021 19:44:58 - INFO - __main__ -     step 11400 loss 0.8974
10/21/2021 19:45:52 - INFO - __main__ -     step 11500 loss 0.8904
10/21/2021 19:46:47 - INFO - __main__ -     step 11600 loss 0.8783
10/21/2021 19:47:41 - INFO - __main__ -     step 11700 loss 0.8654
10/21/2021 19:48:35 - INFO - __main__ -     step 11800 loss 0.8636
10/21/2021 19:49:29 - INFO - __main__ -     step 11900 loss 0.8643
10/21/2021 19:50:23 - INFO - __main__ -   Here1
10/21/2021 19:50:23 - INFO - __main__ -   Here2
10/21/2021 19:50:23 - INFO - __main__ -   
***** Running evaluation *****
10/21/2021 19:50:23 - INFO - __main__ -     Num examples = 2449
10/21/2021 19:50:23 - INFO - __main__ -     Batch size = 4
10/21/2021 19:52:01 - INFO - __main__ -     eval_ppl = 2.84567
10/21/2021 19:52:01 - INFO - __main__ -     global_step = 12000
10/21/2021 19:52:01 - INFO - __main__ -     train_loss = 0.85
10/21/2021 19:52:01 - INFO - __main__ -     ********************
10/21/2021 19:52:05 - INFO - __main__ -     Best ppl:2.84567
10/21/2021 19:52:05 - INFO - __main__ -     ********************
10/21/2021 19:52:09 - INFO - __main__ -   Here4
10/21/2021 19:52:09 - INFO - __main__ -   Here5.5
10/21/2021 20:02:35 - INFO - __main__ -   Here6
10/21/2021 20:02:35 - INFO - __main__ -     bleu-4 = 29.97 
10/21/2021 20:02:35 - INFO - __main__ -     xMatch = 11.0 
10/21/2021 20:02:35 - INFO - __main__ -     ********************
10/21/2021 20:02:35 - INFO - __main__ -     Best bleu:29.97
10/21/2021 20:02:35 - INFO - __main__ -     ********************
10/21/2021 20:02:39 - INFO - __main__ -     step 12000 loss 1.8181
10/21/2021 20:03:34 - INFO - __main__ -     step 12100 loss 0.7526
10/21/2021 20:04:28 - INFO - __main__ -     step 12200 loss 0.7927
10/21/2021 20:05:22 - INFO - __main__ -     step 12300 loss 0.7923
10/21/2021 20:06:16 - INFO - __main__ -     step 12400 loss 0.8039
10/21/2021 20:07:11 - INFO - __main__ -     step 12500 loss 0.8011
10/21/2021 20:08:05 - INFO - __main__ -     step 12600 loss 0.8069
10/21/2021 20:09:00 - INFO - __main__ -     step 12700 loss 0.8121
10/21/2021 20:09:54 - INFO - __main__ -     step 12800 loss 0.8021
10/21/2021 20:10:48 - INFO - __main__ -     step 12900 loss 0.8016
10/21/2021 20:11:42 - INFO - __main__ -   Here1
10/21/2021 20:11:42 - INFO - __main__ -   Here2
10/21/2021 20:11:42 - INFO - __main__ -   
***** Running evaluation *****
10/21/2021 20:11:42 - INFO - __main__ -     Num examples = 2449
10/21/2021 20:11:42 - INFO - __main__ -     Batch size = 4
10/21/2021 20:13:21 - INFO - __main__ -     eval_ppl = 2.75608
10/21/2021 20:13:21 - INFO - __main__ -     global_step = 13000
10/21/2021 20:13:21 - INFO - __main__ -     train_loss = 0.7983
10/21/2021 20:13:21 - INFO - __main__ -     ********************
10/21/2021 20:13:24 - INFO - __main__ -     Best ppl:2.75608
10/21/2021 20:13:24 - INFO - __main__ -     ********************
10/21/2021 20:13:27 - INFO - __main__ -   Here4
10/21/2021 20:13:27 - INFO - __main__ -   Here5.5
10/21/2021 20:24:22 - INFO - __main__ -   Here6
10/21/2021 20:24:22 - INFO - __main__ -     bleu-4 = 33.58 
10/21/2021 20:24:22 - INFO - __main__ -     xMatch = 10.9 
10/21/2021 20:24:22 - INFO - __main__ -     ********************
10/21/2021 20:24:22 - INFO - __main__ -     Best bleu:33.58
10/21/2021 20:24:22 - INFO - __main__ -     ********************
10/21/2021 20:24:26 - INFO - __main__ -     step 13000 loss 0.7977
10/21/2021 20:25:21 - INFO - __main__ -     step 13100 loss 0.7964
10/21/2021 20:26:15 - INFO - __main__ -     step 13200 loss 0.7881
10/21/2021 20:27:10 - INFO - __main__ -     step 13300 loss 0.8036
10/21/2021 20:28:04 - INFO - __main__ -     step 13400 loss 0.7973
10/21/2021 20:28:59 - INFO - __main__ -     step 13500 loss 0.8002
10/21/2021 20:29:53 - INFO - __main__ -     step 13600 loss 0.7969
10/21/2021 20:30:47 - INFO - __main__ -     step 13700 loss 0.788
10/21/2021 20:31:42 - INFO - __main__ -     step 13800 loss 0.7891
10/21/2021 20:32:36 - INFO - __main__ -     step 13900 loss 0.7847
10/21/2021 20:33:30 - INFO - __main__ -   Here1
10/21/2021 20:33:30 - INFO - __main__ -   Here2
10/21/2021 20:33:30 - INFO - __main__ -   
***** Running evaluation *****
10/21/2021 20:33:30 - INFO - __main__ -     Num examples = 2449
10/21/2021 20:33:30 - INFO - __main__ -     Batch size = 4
10/21/2021 20:35:09 - INFO - __main__ -     eval_ppl = 2.77786
10/21/2021 20:35:09 - INFO - __main__ -     global_step = 14000
10/21/2021 20:35:09 - INFO - __main__ -     train_loss = 0.7829
10/21/2021 20:35:09 - INFO - __main__ -     ********************
10/21/2021 20:35:12 - INFO - __main__ -   Here4
10/21/2021 20:35:12 - INFO - __main__ -   Here5.5
10/21/2021 20:48:23 - INFO - __main__ -   Here6
10/21/2021 20:48:23 - INFO - __main__ -     bleu-4 = 30.27 
10/21/2021 20:48:23 - INFO - __main__ -     xMatch = 9.8 
10/21/2021 20:48:23 - INFO - __main__ -     ********************
10/21/2021 20:48:24 - INFO - __main__ -     step 14000 loss 1.3506
10/21/2021 20:49:18 - INFO - __main__ -     step 14100 loss 0.7302
10/21/2021 20:50:13 - INFO - __main__ -     step 14200 loss 0.7272
10/21/2021 20:51:07 - INFO - __main__ -     step 14300 loss 0.7312
10/21/2021 20:52:01 - INFO - __main__ -     step 14400 loss 0.7193
10/21/2021 20:52:55 - INFO - __main__ -     step 14500 loss 0.7108
10/21/2021 20:53:50 - INFO - __main__ -     step 14600 loss 0.7135
10/21/2021 20:54:44 - INFO - __main__ -     step 14700 loss 0.7174
10/21/2021 20:55:38 - INFO - __main__ -     step 14800 loss 0.722
10/21/2021 20:56:32 - INFO - __main__ -     step 14900 loss 0.7194
10/21/2021 20:57:26 - INFO - __main__ -   Here1
10/21/2021 20:57:26 - INFO - __main__ -   Here2
10/21/2021 20:57:26 - INFO - __main__ -   
***** Running evaluation *****
10/21/2021 20:57:26 - INFO - __main__ -     Num examples = 2449
10/21/2021 20:57:26 - INFO - __main__ -     Batch size = 4
10/21/2021 20:59:04 - INFO - __main__ -     eval_ppl = 2.61614
10/21/2021 20:59:04 - INFO - __main__ -     global_step = 15000
10/21/2021 20:59:04 - INFO - __main__ -     train_loss = 0.7186
10/21/2021 20:59:04 - INFO - __main__ -     ********************
10/21/2021 20:59:08 - INFO - __main__ -     Best ppl:2.61614
10/21/2021 20:59:08 - INFO - __main__ -     ********************
10/21/2021 20:59:11 - INFO - __main__ -   Here4
10/21/2021 20:59:11 - INFO - __main__ -   Here5.5
10/21/2021 21:08:05 - INFO - __main__ -   Here6
10/21/2021 21:08:05 - INFO - __main__ -     bleu-4 = 32.4 
10/21/2021 21:08:05 - INFO - __main__ -     xMatch = 12.7 
10/21/2021 21:08:05 - INFO - __main__ -     ********************
10/21/2021 21:08:05 - INFO - __main__ -     step 15000 loss 0.9595
10/21/2021 21:08:59 - INFO - __main__ -     step 15100 loss 0.6472
10/21/2021 21:09:54 - INFO - __main__ -     step 15200 loss 0.6895
10/21/2021 21:10:48 - INFO - __main__ -     step 15300 loss 0.6876
10/21/2021 21:11:42 - INFO - __main__ -     step 15400 loss 0.6841
10/21/2021 21:12:36 - INFO - __main__ -     step 15500 loss 0.6785
10/21/2021 21:13:30 - INFO - __main__ -     step 15600 loss 0.6876
10/21/2021 21:14:25 - INFO - __main__ -     step 15700 loss 0.674
10/21/2021 21:15:19 - INFO - __main__ -     step 15800 loss 0.6767
10/21/2021 21:16:13 - INFO - __main__ -     step 15900 loss 0.6828
10/21/2021 21:17:07 - INFO - __main__ -   Here1
10/21/2021 21:17:07 - INFO - __main__ -   Here2
10/21/2021 21:17:07 - INFO - __main__ -   
***** Running evaluation *****
10/21/2021 21:17:07 - INFO - __main__ -     Num examples = 2449
10/21/2021 21:17:07 - INFO - __main__ -     Batch size = 4
10/21/2021 21:18:45 - INFO - __main__ -     eval_ppl = 2.6018
10/21/2021 21:18:45 - INFO - __main__ -     global_step = 16000
10/21/2021 21:18:45 - INFO - __main__ -     train_loss = 0.6824
10/21/2021 21:18:45 - INFO - __main__ -     ********************
10/21/2021 21:18:49 - INFO - __main__ -     Best ppl:2.6018
10/21/2021 21:18:49 - INFO - __main__ -     ********************
10/21/2021 21:18:52 - INFO - __main__ -   Here4
10/21/2021 21:18:52 - INFO - __main__ -   Here5.5
10/21/2021 21:27:33 - INFO - __main__ -   Here6
10/21/2021 21:27:34 - INFO - __main__ -     bleu-4 = 35.04 
10/21/2021 21:27:34 - INFO - __main__ -     xMatch = 12.5 
10/21/2021 21:27:34 - INFO - __main__ -     ********************
10/21/2021 21:27:34 - INFO - __main__ -     Best bleu:35.04
10/21/2021 21:27:34 - INFO - __main__ -     ********************
10/21/2021 21:27:38 - INFO - __main__ -     step 16000 loss 2.2137
10/21/2021 21:28:32 - INFO - __main__ -     step 16100 loss 0.6425
10/21/2021 21:29:27 - INFO - __main__ -     step 16200 loss 0.667
10/21/2021 21:30:21 - INFO - __main__ -     step 16300 loss 0.6543
10/21/2021 21:31:16 - INFO - __main__ -     step 16400 loss 0.655
10/21/2021 21:32:10 - INFO - __main__ -     step 16500 loss 0.6458
10/21/2021 21:33:05 - INFO - __main__ -     step 16600 loss 0.639
10/21/2021 21:33:59 - INFO - __main__ -     step 16700 loss 0.6375
10/21/2021 21:34:53 - INFO - __main__ -     step 16800 loss 0.6395
10/21/2021 21:35:48 - INFO - __main__ -     step 16900 loss 0.6323
10/21/2021 21:36:42 - INFO - __main__ -   Here1
10/21/2021 21:36:42 - INFO - __main__ -   Here2
10/21/2021 21:36:42 - INFO - __main__ -   
***** Running evaluation *****
10/21/2021 21:36:42 - INFO - __main__ -     Num examples = 2449
10/21/2021 21:36:42 - INFO - __main__ -     Batch size = 4
10/21/2021 21:38:20 - INFO - __main__ -     eval_ppl = 2.55231
10/21/2021 21:38:20 - INFO - __main__ -     global_step = 17000
10/21/2021 21:38:20 - INFO - __main__ -     train_loss = 0.6243
10/21/2021 21:38:20 - INFO - __main__ -     ********************
10/21/2021 21:38:25 - INFO - __main__ -     Best ppl:2.55231
10/21/2021 21:38:25 - INFO - __main__ -     ********************
10/21/2021 21:38:28 - INFO - __main__ -   Here4
10/21/2021 21:38:28 - INFO - __main__ -   Here5.5
10/21/2021 21:47:33 - INFO - __main__ -   Here6
10/21/2021 21:47:33 - INFO - __main__ -     bleu-4 = 35.04 
10/21/2021 21:47:33 - INFO - __main__ -     xMatch = 14.3 
10/21/2021 21:47:33 - INFO - __main__ -     ********************
10/21/2021 21:47:33 - INFO - __main__ -     step 17000 loss 0.7989
10/21/2021 21:48:27 - INFO - __main__ -     step 17100 loss 0.6048
10/21/2021 21:49:22 - INFO - __main__ -     step 17200 loss 0.6071
10/21/2021 21:50:16 - INFO - __main__ -     step 17300 loss 0.612
10/21/2021 21:51:10 - INFO - __main__ -     step 17400 loss 0.6047
10/21/2021 21:52:05 - INFO - __main__ -     step 17500 loss 0.6088
10/21/2021 21:52:59 - INFO - __main__ -     step 17600 loss 0.6088
10/21/2021 21:53:54 - INFO - __main__ -     step 17700 loss 0.5985
10/21/2021 21:54:48 - INFO - __main__ -     step 17800 loss 0.5944
10/21/2021 21:55:43 - INFO - __main__ -     step 17900 loss 0.593
10/21/2021 21:56:38 - INFO - __main__ -   Here1
10/21/2021 21:56:38 - INFO - __main__ -   Here2
10/21/2021 21:56:38 - INFO - __main__ -   
***** Running evaluation *****
10/21/2021 21:56:38 - INFO - __main__ -     Num examples = 2449
10/21/2021 21:56:38 - INFO - __main__ -     Batch size = 4
10/21/2021 21:58:16 - INFO - __main__ -     eval_ppl = 2.53485
10/21/2021 21:58:16 - INFO - __main__ -     global_step = 18000
10/21/2021 21:58:16 - INFO - __main__ -     train_loss = 0.5933
10/21/2021 21:58:16 - INFO - __main__ -     ********************
10/21/2021 21:58:21 - INFO - __main__ -     Best ppl:2.53485
10/21/2021 21:58:21 - INFO - __main__ -     ********************
10/21/2021 21:58:24 - INFO - __main__ -   Here4
10/21/2021 21:58:24 - INFO - __main__ -   Here5.5
10/21/2021 22:08:43 - INFO - __main__ -   Here6
10/21/2021 22:08:43 - INFO - __main__ -     bleu-4 = 35.61 
10/21/2021 22:08:43 - INFO - __main__ -     xMatch = 13.0 
10/21/2021 22:08:43 - INFO - __main__ -     ********************
10/21/2021 22:08:43 - INFO - __main__ -     Best bleu:35.61
10/21/2021 22:08:43 - INFO - __main__ -     ********************
10/21/2021 22:08:47 - INFO - __main__ -     step 18000 loss 0.1257
10/21/2021 22:09:41 - INFO - __main__ -     step 18100 loss 0.5922
10/21/2021 22:10:36 - INFO - __main__ -     step 18200 loss 0.6065
10/21/2021 22:11:30 - INFO - __main__ -     step 18300 loss 0.6001
10/21/2021 22:12:25 - INFO - __main__ -     step 18400 loss 0.593
10/21/2021 22:13:19 - INFO - __main__ -     step 18500 loss 0.5886
10/21/2021 22:14:14 - INFO - __main__ -     step 18600 loss 0.5851
10/21/2021 22:15:08 - INFO - __main__ -     step 18700 loss 0.5884
10/21/2021 22:16:02 - INFO - __main__ -     step 18800 loss 0.5834
10/21/2021 22:16:57 - INFO - __main__ -     step 18900 loss 0.5803
10/21/2021 22:17:51 - INFO - __main__ -   Here1
10/21/2021 22:17:51 - INFO - __main__ -   Here2
10/21/2021 22:17:51 - INFO - __main__ -   
***** Running evaluation *****
10/21/2021 22:17:51 - INFO - __main__ -     Num examples = 2449
10/21/2021 22:17:51 - INFO - __main__ -     Batch size = 4
10/21/2021 22:19:29 - INFO - __main__ -     eval_ppl = 2.51508
10/21/2021 22:19:29 - INFO - __main__ -     global_step = 19000
10/21/2021 22:19:29 - INFO - __main__ -     train_loss = 0.5757
10/21/2021 22:19:29 - INFO - __main__ -     ********************
10/21/2021 22:19:33 - INFO - __main__ -     Best ppl:2.51508
10/21/2021 22:19:33 - INFO - __main__ -     ********************
10/21/2021 22:19:36 - INFO - __main__ -   Here4
10/21/2021 22:19:36 - INFO - __main__ -   Here5.5
10/21/2021 22:29:14 - INFO - __main__ -   Here6
10/21/2021 22:29:14 - INFO - __main__ -     bleu-4 = 35.11 
10/21/2021 22:29:14 - INFO - __main__ -     xMatch = 11.9 
10/21/2021 22:29:14 - INFO - __main__ -     ********************
10/21/2021 22:29:14 - INFO - __main__ -     step 19000 loss 0.6176
10/21/2021 22:30:08 - INFO - __main__ -     step 19100 loss 0.5592
10/21/2021 22:31:03 - INFO - __main__ -     step 19200 loss 0.5633
10/21/2021 22:31:57 - INFO - __main__ -     step 19300 loss 0.5484
10/21/2021 22:32:52 - INFO - __main__ -     step 19400 loss 0.5358
10/21/2021 22:33:46 - INFO - __main__ -     step 19500 loss 0.5368
10/21/2021 22:34:40 - INFO - __main__ -     step 19600 loss 0.5394
10/21/2021 22:35:34 - INFO - __main__ -     step 19700 loss 0.5449
10/21/2021 22:36:29 - INFO - __main__ -     step 19800 loss 0.5422
10/21/2021 22:37:23 - INFO - __main__ -     step 19900 loss 0.5416
10/21/2021 22:38:17 - INFO - __main__ -   Here1
10/21/2021 22:38:17 - INFO - __main__ -   Here2
10/21/2021 22:38:17 - INFO - __main__ -   
***** Running evaluation *****
10/21/2021 22:38:17 - INFO - __main__ -     Num examples = 2449
10/21/2021 22:38:17 - INFO - __main__ -     Batch size = 4
10/21/2021 22:39:56 - INFO - __main__ -     eval_ppl = 2.44093
10/21/2021 22:39:56 - INFO - __main__ -     global_step = 20000
10/21/2021 22:39:56 - INFO - __main__ -     train_loss = 0.5373
10/21/2021 22:39:56 - INFO - __main__ -     ********************
10/21/2021 22:40:01 - INFO - __main__ -     Best ppl:2.44093
10/21/2021 22:40:01 - INFO - __main__ -     ********************
10/21/2021 22:40:05 - INFO - __main__ -   Here4
10/21/2021 22:40:05 - INFO - __main__ -   Here5.5
10/21/2021 22:50:04 - INFO - __main__ -   Here6
10/21/2021 22:50:04 - INFO - __main__ -     bleu-4 = 38.13 
10/21/2021 22:50:04 - INFO - __main__ -     xMatch = 15.9 
10/21/2021 22:50:04 - INFO - __main__ -     ********************
10/21/2021 22:50:04 - INFO - __main__ -     Best bleu:38.13
10/21/2021 22:50:04 - INFO - __main__ -     ********************
10/21/2021 22:50:09 - INFO - __main__ -     step 20000 loss 0.3058
10/21/2021 22:51:04 - INFO - __main__ -     step 20100 loss 0.5656
10/21/2021 22:51:58 - INFO - __main__ -     step 20200 loss 0.5492
10/21/2021 22:52:53 - INFO - __main__ -     step 20300 loss 0.5404
10/21/2021 22:53:47 - INFO - __main__ -     step 20400 loss 0.5299
10/21/2021 22:54:41 - INFO - __main__ -     step 20500 loss 0.5361
10/21/2021 22:55:36 - INFO - __main__ -     step 20600 loss 0.5245
10/21/2021 22:56:30 - INFO - __main__ -     step 20700 loss 0.5267
10/21/2021 22:57:24 - INFO - __main__ -     step 20800 loss 0.5285
10/21/2021 22:58:19 - INFO - __main__ -     step 20900 loss 0.5264
10/21/2021 22:59:13 - INFO - __main__ -   Here1
10/21/2021 22:59:13 - INFO - __main__ -   Here2
10/21/2021 22:59:13 - INFO - __main__ -   
***** Running evaluation *****
10/21/2021 22:59:13 - INFO - __main__ -     Num examples = 2449
10/21/2021 22:59:13 - INFO - __main__ -     Batch size = 4
10/21/2021 23:00:51 - INFO - __main__ -     eval_ppl = 2.421
10/21/2021 23:00:51 - INFO - __main__ -     global_step = 21000
10/21/2021 23:00:51 - INFO - __main__ -     train_loss = 0.5208
10/21/2021 23:00:51 - INFO - __main__ -     ********************
10/21/2021 23:00:55 - INFO - __main__ -     Best ppl:2.421
10/21/2021 23:00:55 - INFO - __main__ -     ********************
10/21/2021 23:00:58 - INFO - __main__ -   Here4
10/21/2021 23:00:58 - INFO - __main__ -   Here5.5
10/21/2021 23:09:18 - INFO - __main__ -   Here6
10/21/2021 23:09:18 - INFO - __main__ -     bleu-4 = 38.33 
10/21/2021 23:09:18 - INFO - __main__ -     xMatch = 16.1 
10/21/2021 23:09:18 - INFO - __main__ -     ********************
10/21/2021 23:09:18 - INFO - __main__ -     Best bleu:38.33
10/21/2021 23:09:18 - INFO - __main__ -     ********************
10/21/2021 23:09:22 - INFO - __main__ -     step 21000 loss 0.2661
10/21/2021 23:10:16 - INFO - __main__ -     step 21100 loss 0.505
10/21/2021 23:11:11 - INFO - __main__ -     step 21200 loss 0.4931
10/21/2021 23:12:05 - INFO - __main__ -     step 21300 loss 0.4955
10/21/2021 23:12:59 - INFO - __main__ -     step 21400 loss 0.4865
10/21/2021 23:13:53 - INFO - __main__ -     step 21500 loss 0.482
10/21/2021 23:14:48 - INFO - __main__ -     step 21600 loss 0.4795
10/21/2021 23:15:42 - INFO - __main__ -     step 21700 loss 0.4823
10/21/2021 23:16:36 - INFO - __main__ -     step 21800 loss 0.4755
10/21/2021 23:17:31 - INFO - __main__ -     step 21900 loss 0.4686
10/21/2021 23:18:25 - INFO - __main__ -   Here1
10/21/2021 23:18:25 - INFO - __main__ -   Here2
10/21/2021 23:18:25 - INFO - __main__ -   
***** Running evaluation *****
10/21/2021 23:18:25 - INFO - __main__ -     Num examples = 2449
10/21/2021 23:18:25 - INFO - __main__ -     Batch size = 4
10/21/2021 23:20:03 - INFO - __main__ -     eval_ppl = 2.46558
10/21/2021 23:20:03 - INFO - __main__ -     global_step = 22000
10/21/2021 23:20:03 - INFO - __main__ -     train_loss = 0.467
10/21/2021 23:20:03 - INFO - __main__ -     ********************
10/21/2021 23:20:07 - INFO - __main__ -   Here4
10/21/2021 23:20:07 - INFO - __main__ -   Here5.5
10/21/2021 23:28:31 - INFO - __main__ -   Here6
10/21/2021 23:28:31 - INFO - __main__ -     bleu-4 = 37.22 
10/21/2021 23:28:31 - INFO - __main__ -     xMatch = 14.3 
10/21/2021 23:28:31 - INFO - __main__ -     ********************
10/21/2021 23:28:31 - INFO - __main__ -     step 22000 loss 0.3425
10/21/2021 23:29:25 - INFO - __main__ -     step 22100 loss 0.447
10/21/2021 23:30:20 - INFO - __main__ -     step 22200 loss 0.4574
10/21/2021 23:31:14 - INFO - __main__ -     step 22300 loss 0.4513
10/21/2021 23:32:08 - INFO - __main__ -     step 22400 loss 0.4571
10/21/2021 23:33:02 - INFO - __main__ -     step 22500 loss 0.4602
10/21/2021 23:33:56 - INFO - __main__ -     step 22600 loss 0.4494
10/21/2021 23:34:50 - INFO - __main__ -     step 22700 loss 0.4461
10/21/2021 23:35:44 - INFO - __main__ -     step 22800 loss 0.4425
10/21/2021 23:36:37 - INFO - __main__ -     step 22900 loss 0.4423
10/21/2021 23:37:31 - INFO - __main__ -   Here1
10/21/2021 23:37:31 - INFO - __main__ -   Here2
10/21/2021 23:37:31 - INFO - __main__ -   
***** Running evaluation *****
10/21/2021 23:37:31 - INFO - __main__ -     Num examples = 2449
10/21/2021 23:37:31 - INFO - __main__ -     Batch size = 4
10/21/2021 23:39:09 - INFO - __main__ -     eval_ppl = 2.40974
10/21/2021 23:39:09 - INFO - __main__ -     global_step = 23000
10/21/2021 23:39:09 - INFO - __main__ -     train_loss = 0.4426
10/21/2021 23:39:09 - INFO - __main__ -     ********************
10/21/2021 23:39:13 - INFO - __main__ -     Best ppl:2.40974
10/21/2021 23:39:13 - INFO - __main__ -     ********************
10/21/2021 23:39:17 - INFO - __main__ -   Here4
10/21/2021 23:39:17 - INFO - __main__ -   Here5.5
10/21/2021 23:47:15 - INFO - __main__ -   Here6
10/21/2021 23:47:15 - INFO - __main__ -     bleu-4 = 40.98 
10/21/2021 23:47:15 - INFO - __main__ -     xMatch = 14.9 
10/21/2021 23:47:15 - INFO - __main__ -     ********************
10/21/2021 23:47:15 - INFO - __main__ -     Best bleu:40.98
10/21/2021 23:47:15 - INFO - __main__ -     ********************
10/21/2021 23:47:20 - INFO - __main__ -     step 23000 loss 0.3218
10/21/2021 23:48:14 - INFO - __main__ -     step 23100 loss 0.4804
10/21/2021 23:49:09 - INFO - __main__ -     step 23200 loss 0.4587
10/21/2021 23:50:03 - INFO - __main__ -     step 23300 loss 0.4482
10/21/2021 23:50:57 - INFO - __main__ -     step 23400 loss 0.4406
10/21/2021 23:51:51 - INFO - __main__ -     step 23500 loss 0.4373
10/21/2021 23:52:45 - INFO - __main__ -     step 23600 loss 0.437
10/21/2021 23:53:39 - INFO - __main__ -     step 23700 loss 0.4323
10/21/2021 23:54:33 - INFO - __main__ -     step 23800 loss 0.4306
10/21/2021 23:55:27 - INFO - __main__ -     step 23900 loss 0.4241
10/21/2021 23:56:21 - INFO - __main__ -   Here1
10/21/2021 23:56:21 - INFO - __main__ -   Here2
10/21/2021 23:56:21 - INFO - __main__ -   
***** Running evaluation *****
10/21/2021 23:56:21 - INFO - __main__ -     Num examples = 2449
10/21/2021 23:56:21 - INFO - __main__ -     Batch size = 4
10/21/2021 23:57:59 - INFO - __main__ -     eval_ppl = 2.38912
10/21/2021 23:57:59 - INFO - __main__ -     global_step = 24000
10/21/2021 23:57:59 - INFO - __main__ -     train_loss = 0.424
10/21/2021 23:57:59 - INFO - __main__ -     ********************
10/21/2021 23:58:03 - INFO - __main__ -     Best ppl:2.38912
10/21/2021 23:58:03 - INFO - __main__ -     ********************
10/21/2021 23:58:07 - INFO - __main__ -   Here4
10/21/2021 23:58:07 - INFO - __main__ -   Here5.5
10/22/2021 00:06:23 - INFO - __main__ -   Here6
10/22/2021 00:06:23 - INFO - __main__ -     bleu-4 = 36.79 
10/22/2021 00:06:23 - INFO - __main__ -     xMatch = 16.3 
10/22/2021 00:06:23 - INFO - __main__ -     ********************
10/22/2021 00:06:23 - INFO - __main__ -     step 24000 loss 0.4059
10/22/2021 00:07:18 - INFO - __main__ -     step 24100 loss 0.4101
10/22/2021 00:08:12 - INFO - __main__ -     step 24200 loss 0.4068
10/22/2021 00:09:06 - INFO - __main__ -     step 24300 loss 0.4
10/22/2021 00:10:01 - INFO - __main__ -     step 24400 loss 0.4042
10/22/2021 00:10:55 - INFO - __main__ -     step 24500 loss 0.4066
10/22/2021 00:11:49 - INFO - __main__ -     step 24600 loss 0.4092
10/22/2021 00:12:43 - INFO - __main__ -     step 24700 loss 0.4076
10/22/2021 00:13:37 - INFO - __main__ -     step 24800 loss 0.4062
10/22/2021 00:14:31 - INFO - __main__ -     step 24900 loss 0.4024
10/22/2021 00:15:25 - INFO - __main__ -   Here1
10/22/2021 00:15:25 - INFO - __main__ -   Here2
10/22/2021 00:15:25 - INFO - __main__ -   
***** Running evaluation *****
10/22/2021 00:15:25 - INFO - __main__ -     Num examples = 2449
10/22/2021 00:15:25 - INFO - __main__ -     Batch size = 4
10/22/2021 00:17:03 - INFO - __main__ -     eval_ppl = 2.36297
10/22/2021 00:17:03 - INFO - __main__ -     global_step = 25000
10/22/2021 00:17:03 - INFO - __main__ -     train_loss = 0.4054
10/22/2021 00:17:03 - INFO - __main__ -     ********************
10/22/2021 00:17:07 - INFO - __main__ -     Best ppl:2.36297
10/22/2021 00:17:07 - INFO - __main__ -     ********************
10/22/2021 00:17:10 - INFO - __main__ -   Here4
10/22/2021 00:17:10 - INFO - __main__ -   Here5.5
10/22/2021 00:27:10 - INFO - __main__ -   Here6
10/22/2021 00:27:10 - INFO - __main__ -     bleu-4 = 42.0 
10/22/2021 00:27:10 - INFO - __main__ -     xMatch = 17.2 
10/22/2021 00:27:10 - INFO - __main__ -     ********************
10/22/2021 00:27:10 - INFO - __main__ -     Best bleu:42.0
10/22/2021 00:27:10 - INFO - __main__ -     ********************
10/22/2021 00:27:15 - INFO - __main__ -     step 25000 loss 0.294
10/22/2021 00:28:09 - INFO - __main__ -     step 25100 loss 0.3913
10/22/2021 00:29:03 - INFO - __main__ -     step 25200 loss 0.3853
10/22/2021 00:29:57 - INFO - __main__ -     step 25300 loss 0.38
10/22/2021 00:30:51 - INFO - __main__ -     step 25400 loss 0.3927
10/22/2021 00:31:46 - INFO - __main__ -     step 25500 loss 0.3851
10/22/2021 00:32:40 - INFO - __main__ -     step 25600 loss 0.3861
10/22/2021 00:33:34 - INFO - __main__ -     step 25700 loss 0.3869
10/22/2021 00:34:28 - INFO - __main__ -     step 25800 loss 0.3861
10/22/2021 00:35:22 - INFO - __main__ -     step 25900 loss 0.3813
10/22/2021 00:36:17 - INFO - __main__ -   Here1
10/22/2021 00:36:17 - INFO - __main__ -   Here2
10/22/2021 00:36:17 - INFO - __main__ -   
***** Running evaluation *****
10/22/2021 00:36:17 - INFO - __main__ -     Num examples = 2449
10/22/2021 00:36:17 - INFO - __main__ -     Batch size = 4
10/22/2021 00:37:55 - INFO - __main__ -     eval_ppl = 2.38832
10/22/2021 00:37:55 - INFO - __main__ -     global_step = 26000
10/22/2021 00:37:55 - INFO - __main__ -     train_loss = 0.3799
10/22/2021 00:37:55 - INFO - __main__ -     ********************
10/22/2021 00:37:58 - INFO - __main__ -   Here4
10/22/2021 00:37:58 - INFO - __main__ -   Here5.5
10/22/2021 00:46:56 - INFO - __main__ -   Here6
10/22/2021 00:46:56 - INFO - __main__ -     bleu-4 = 41.98 
10/22/2021 00:46:56 - INFO - __main__ -     xMatch = 16.8 
10/22/2021 00:46:56 - INFO - __main__ -     ********************
10/22/2021 00:46:56 - INFO - __main__ -     step 26000 loss 0.1187
10/22/2021 00:47:50 - INFO - __main__ -     step 26100 loss 0.3477
10/22/2021 00:48:44 - INFO - __main__ -     step 26200 loss 0.3659
10/22/2021 00:49:38 - INFO - __main__ -     step 26300 loss 0.3522
10/22/2021 00:50:32 - INFO - __main__ -     step 26400 loss 0.3515
10/22/2021 00:51:27 - INFO - __main__ -     step 26500 loss 0.3487
10/22/2021 00:52:21 - INFO - __main__ -     step 26600 loss 0.3506
10/22/2021 00:53:14 - INFO - __main__ -     step 26700 loss 0.346
10/22/2021 00:54:09 - INFO - __main__ -     step 26800 loss 0.3415
10/22/2021 00:55:02 - INFO - __main__ -     step 26900 loss 0.3411
10/22/2021 00:55:56 - INFO - __main__ -   Here1
10/22/2021 00:55:56 - INFO - __main__ -   Here2
10/22/2021 00:55:56 - INFO - __main__ -   
***** Running evaluation *****
10/22/2021 00:55:56 - INFO - __main__ -     Num examples = 2449
10/22/2021 00:55:56 - INFO - __main__ -     Batch size = 4
10/22/2021 00:57:34 - INFO - __main__ -     eval_ppl = 2.36568
10/22/2021 00:57:34 - INFO - __main__ -     global_step = 27000
10/22/2021 00:57:34 - INFO - __main__ -     train_loss = 0.3411
10/22/2021 00:57:34 - INFO - __main__ -     ********************
10/22/2021 00:57:38 - INFO - __main__ -   Here4
10/22/2021 00:57:38 - INFO - __main__ -   Here5.5
10/22/2021 01:05:38 - INFO - __main__ -   Here6
10/22/2021 01:05:38 - INFO - __main__ -     bleu-4 = 41.43 
10/22/2021 01:05:38 - INFO - __main__ -     xMatch = 16.9 
10/22/2021 01:05:38 - INFO - __main__ -     ********************
10/22/2021 01:05:38 - INFO - __main__ -     step 27000 loss 0.6625
10/22/2021 01:06:33 - INFO - __main__ -     step 27100 loss 0.3468
10/22/2021 01:07:27 - INFO - __main__ -     step 27200 loss 0.3307
10/22/2021 01:08:21 - INFO - __main__ -     step 27300 loss 0.3377
10/22/2021 01:09:16 - INFO - __main__ -     step 27400 loss 0.3365
10/22/2021 01:10:10 - INFO - __main__ -     step 27500 loss 0.3301
10/22/2021 01:11:04 - INFO - __main__ -     step 27600 loss 0.3251
10/22/2021 01:11:58 - INFO - __main__ -     step 27700 loss 0.3238
10/22/2021 01:12:52 - INFO - __main__ -     step 27800 loss 0.3243
10/22/2021 01:13:47 - INFO - __main__ -     step 27900 loss 0.3244
10/22/2021 01:14:41 - INFO - __main__ -   Here1
10/22/2021 01:14:41 - INFO - __main__ -   Here2
10/22/2021 01:14:41 - INFO - __main__ -   
***** Running evaluation *****
10/22/2021 01:14:41 - INFO - __main__ -     Num examples = 2449
10/22/2021 01:14:41 - INFO - __main__ -     Batch size = 4
10/22/2021 01:16:19 - INFO - __main__ -     eval_ppl = 2.36719
10/22/2021 01:16:19 - INFO - __main__ -     global_step = 28000
10/22/2021 01:16:19 - INFO - __main__ -     train_loss = 0.3282
10/22/2021 01:16:19 - INFO - __main__ -     ********************
10/22/2021 01:16:23 - INFO - __main__ -   Here4
10/22/2021 01:16:23 - INFO - __main__ -   Here5.5
10/22/2021 01:26:09 - INFO - __main__ -   Here6
10/22/2021 01:26:09 - INFO - __main__ -     bleu-4 = 44.38 
10/22/2021 01:26:09 - INFO - __main__ -     xMatch = 17.8 
10/22/2021 01:26:09 - INFO - __main__ -     ********************
10/22/2021 01:26:09 - INFO - __main__ -     Best bleu:44.38
10/22/2021 01:26:09 - INFO - __main__ -     ********************
10/22/2021 01:26:14 - INFO - __main__ -     step 28000 loss 0.2109
10/22/2021 01:27:08 - INFO - __main__ -     step 28100 loss 0.3298
10/22/2021 01:28:02 - INFO - __main__ -     step 28200 loss 0.3192
10/22/2021 01:28:56 - INFO - __main__ -     step 28300 loss 0.3145
10/22/2021 01:29:51 - INFO - __main__ -     step 28400 loss 0.3133
10/22/2021 01:30:45 - INFO - __main__ -     step 28500 loss 0.3124
10/22/2021 01:31:39 - INFO - __main__ -     step 28600 loss 0.3112
10/22/2021 01:32:33 - INFO - __main__ -     step 28700 loss 0.3121
10/22/2021 01:33:27 - INFO - __main__ -     step 28800 loss 0.3067
10/22/2021 01:34:21 - INFO - __main__ -     step 28900 loss 0.307
10/22/2021 01:35:15 - INFO - __main__ -   Here1
10/22/2021 01:35:15 - INFO - __main__ -   Here2
10/22/2021 01:35:15 - INFO - __main__ -   
***** Running evaluation *****
10/22/2021 01:35:15 - INFO - __main__ -     Num examples = 2449
10/22/2021 01:35:15 - INFO - __main__ -     Batch size = 4
10/22/2021 01:36:53 - INFO - __main__ -     eval_ppl = 2.37893
10/22/2021 01:36:53 - INFO - __main__ -     global_step = 29000
10/22/2021 01:36:53 - INFO - __main__ -     train_loss = 0.3054
10/22/2021 01:36:53 - INFO - __main__ -     ********************
10/22/2021 01:36:59 - INFO - __main__ -   Here4
10/22/2021 01:36:59 - INFO - __main__ -   Here5.5
10/22/2021 01:44:26 - INFO - __main__ -   Here6
10/22/2021 01:44:26 - INFO - __main__ -     bleu-4 = 42.14 
10/22/2021 01:44:26 - INFO - __main__ -     xMatch = 18.2 
10/22/2021 01:44:26 - INFO - __main__ -     ********************
10/22/2021 01:44:26 - INFO - __main__ -     step 29000 loss 0.1789
10/22/2021 01:45:20 - INFO - __main__ -     step 29100 loss 0.2931
10/22/2021 01:46:14 - INFO - __main__ -     step 29200 loss 0.2843
10/22/2021 01:47:08 - INFO - __main__ -     step 29300 loss 0.2911
10/22/2021 01:48:01 - INFO - __main__ -     step 29400 loss 0.2973
10/22/2021 01:48:55 - INFO - __main__ -     step 29500 loss 0.2998
10/22/2021 01:49:49 - INFO - __main__ -     step 29600 loss 0.2984
10/22/2021 01:50:43 - INFO - __main__ -     step 29700 loss 0.2967
10/22/2021 01:51:37 - INFO - __main__ -     step 29800 loss 0.2956
10/22/2021 01:52:31 - INFO - __main__ -     step 29900 loss 0.2961
10/22/2021 01:53:25 - INFO - __main__ -   Here1
10/22/2021 01:53:25 - INFO - __main__ -   Here2
10/22/2021 01:53:25 - INFO - __main__ -   
***** Running evaluation *****
10/22/2021 01:53:25 - INFO - __main__ -     Num examples = 2449
10/22/2021 01:53:25 - INFO - __main__ -     Batch size = 4
10/22/2021 01:55:03 - INFO - __main__ -     eval_ppl = 2.35012
10/22/2021 01:55:03 - INFO - __main__ -     global_step = 30000
10/22/2021 01:55:03 - INFO - __main__ -     train_loss = 0.2954
10/22/2021 01:55:03 - INFO - __main__ -     ********************
10/22/2021 01:55:06 - INFO - __main__ -     Best ppl:2.35012
10/22/2021 01:55:06 - INFO - __main__ -     ********************
10/22/2021 01:55:10 - INFO - __main__ -   Here4
10/22/2021 01:55:10 - INFO - __main__ -   Here5.5
10/22/2021 02:03:03 - INFO - __main__ -   Here6
10/22/2021 02:03:03 - INFO - __main__ -     bleu-4 = 41.29 
10/22/2021 02:03:03 - INFO - __main__ -     xMatch = 18.6 
10/22/2021 02:03:03 - INFO - __main__ -     ********************
10/22/2021 02:03:03 - INFO - __main__ -     step 30000 loss 0.3575
10/22/2021 02:03:57 - INFO - __main__ -     step 30100 loss 0.2747
10/22/2021 02:04:51 - INFO - __main__ -     step 30200 loss 0.2732
10/22/2021 02:05:45 - INFO - __main__ -     step 30300 loss 0.2892
10/22/2021 02:06:40 - INFO - __main__ -     step 30400 loss 0.2822
10/22/2021 02:07:34 - INFO - __main__ -     step 30500 loss 0.2826
10/22/2021 02:08:28 - INFO - __main__ -     step 30600 loss 0.2834
10/22/2021 02:09:23 - INFO - __main__ -     step 30700 loss 0.2836
10/22/2021 02:10:17 - INFO - __main__ -     step 30800 loss 0.28
10/22/2021 02:11:12 - INFO - __main__ -     step 30900 loss 0.2788
10/22/2021 02:12:06 - INFO - __main__ -   Here1
10/22/2021 02:12:06 - INFO - __main__ -   Here2
10/22/2021 02:12:06 - INFO - __main__ -   
***** Running evaluation *****
10/22/2021 02:12:06 - INFO - __main__ -     Num examples = 2449
10/22/2021 02:12:06 - INFO - __main__ -     Batch size = 4
10/22/2021 02:13:44 - INFO - __main__ -     eval_ppl = 2.3844
10/22/2021 02:13:44 - INFO - __main__ -     global_step = 31000
10/22/2021 02:13:44 - INFO - __main__ -     train_loss = 0.2775
10/22/2021 02:13:44 - INFO - __main__ -     ********************
10/22/2021 02:13:48 - INFO - __main__ -   Here4
10/22/2021 02:13:48 - INFO - __main__ -   Here5.5
10/22/2021 02:22:33 - INFO - __main__ -   Here6
10/22/2021 02:22:33 - INFO - __main__ -     bleu-4 = 45.47 
10/22/2021 02:22:33 - INFO - __main__ -     xMatch = 19.1 
10/22/2021 02:22:33 - INFO - __main__ -     ********************
10/22/2021 02:22:33 - INFO - __main__ -     Best bleu:45.47
10/22/2021 02:22:33 - INFO - __main__ -     ********************
10/22/2021 02:22:38 - INFO - __main__ -     step 31000 loss 0.0424
10/22/2021 02:23:32 - INFO - __main__ -     step 31100 loss 0.2838
10/22/2021 02:24:26 - INFO - __main__ -     step 31200 loss 0.262
10/22/2021 02:25:21 - INFO - __main__ -     step 31300 loss 0.261
10/22/2021 02:26:15 - INFO - __main__ -     step 31400 loss 0.2632
10/22/2021 02:27:10 - INFO - __main__ -     step 31500 loss 0.2643
10/22/2021 02:28:04 - INFO - __main__ -     step 31600 loss 0.26
10/22/2021 02:28:59 - INFO - __main__ -     step 31700 loss 0.2573
10/22/2021 02:29:53 - INFO - __main__ -     step 31800 loss 0.2561
10/22/2021 02:30:47 - INFO - __main__ -     step 31900 loss 0.2559
10/22/2021 02:31:41 - INFO - __main__ -   Here1
10/22/2021 02:31:41 - INFO - __main__ -   Here2
10/22/2021 02:31:41 - INFO - __main__ -   
***** Running evaluation *****
10/22/2021 02:31:41 - INFO - __main__ -     Num examples = 2449
10/22/2021 02:31:41 - INFO - __main__ -     Batch size = 4
10/22/2021 02:33:20 - INFO - __main__ -     eval_ppl = 2.35411
10/22/2021 02:33:20 - INFO - __main__ -     global_step = 32000
10/22/2021 02:33:20 - INFO - __main__ -     train_loss = 0.2565
10/22/2021 02:33:20 - INFO - __main__ -     ********************
10/22/2021 02:33:24 - INFO - __main__ -   Here4
10/22/2021 02:33:24 - INFO - __main__ -   Here5.5
10/22/2021 02:41:26 - INFO - __main__ -   Here6
10/22/2021 02:41:26 - INFO - __main__ -     bleu-4 = 43.84 
10/22/2021 02:41:26 - INFO - __main__ -     xMatch = 18.7 
10/22/2021 02:41:26 - INFO - __main__ -     ********************
10/22/2021 02:41:27 - INFO - __main__ -     step 32000 loss 0.3766
10/22/2021 02:42:21 - INFO - __main__ -     step 32100 loss 0.2453
10/22/2021 02:43:15 - INFO - __main__ -     step 32200 loss 0.2509
10/22/2021 02:44:09 - INFO - __main__ -     step 32300 loss 0.2527
10/22/2021 02:45:03 - INFO - __main__ -     step 32400 loss 0.2465
10/22/2021 02:45:57 - INFO - __main__ -     step 32500 loss 0.2442
10/22/2021 02:46:51 - INFO - __main__ -     step 32600 loss 0.2433
10/22/2021 02:47:46 - INFO - __main__ -     step 32700 loss 0.2416
10/22/2021 02:48:40 - INFO - __main__ -     step 32800 loss 0.2435
10/22/2021 02:49:34 - INFO - __main__ -     step 32900 loss 0.2467
10/22/2021 02:50:28 - INFO - __main__ -   Here1
10/22/2021 02:50:28 - INFO - __main__ -   Here2
10/22/2021 02:50:28 - INFO - __main__ -   
***** Running evaluation *****
10/22/2021 02:50:28 - INFO - __main__ -     Num examples = 2449
10/22/2021 02:50:28 - INFO - __main__ -     Batch size = 4
10/22/2021 02:52:06 - INFO - __main__ -     eval_ppl = 2.36684
10/22/2021 02:52:06 - INFO - __main__ -     global_step = 33000
10/22/2021 02:52:06 - INFO - __main__ -     train_loss = 0.2458
10/22/2021 02:52:06 - INFO - __main__ -     ********************
10/22/2021 02:52:10 - INFO - __main__ -   Here4
10/22/2021 02:52:10 - INFO - __main__ -   Here5.5
10/22/2021 03:01:22 - INFO - __main__ -   Here6
10/22/2021 03:01:22 - INFO - __main__ -     bleu-4 = 47.07 
10/22/2021 03:01:22 - INFO - __main__ -     xMatch = 19.7 
10/22/2021 03:01:22 - INFO - __main__ -     ********************
10/22/2021 03:01:22 - INFO - __main__ -     Best bleu:47.07
10/22/2021 03:01:22 - INFO - __main__ -     ********************
10/22/2021 03:01:29 - INFO - __main__ -     step 33000 loss 0.1739
10/22/2021 03:02:24 - INFO - __main__ -     step 33100 loss 0.2294
10/22/2021 03:03:18 - INFO - __main__ -     step 33200 loss 0.2273
10/22/2021 03:04:12 - INFO - __main__ -     step 33300 loss 0.2269
10/22/2021 03:05:06 - INFO - __main__ -     step 33400 loss 0.2264
10/22/2021 03:06:00 - INFO - __main__ -     step 33500 loss 0.2262
10/22/2021 03:06:54 - INFO - __main__ -     step 33600 loss 0.227
10/22/2021 03:07:49 - INFO - __main__ -     step 33700 loss 0.2228
10/22/2021 03:08:43 - INFO - __main__ -     step 33800 loss 0.2236
10/22/2021 03:09:37 - INFO - __main__ -     step 33900 loss 0.2216
10/22/2021 03:10:31 - INFO - __main__ -   Here1
10/22/2021 03:10:31 - INFO - __main__ -   Here2
10/22/2021 03:10:31 - INFO - __main__ -   
***** Running evaluation *****
10/22/2021 03:10:31 - INFO - __main__ -     Num examples = 2449
10/22/2021 03:10:31 - INFO - __main__ -     Batch size = 4
10/22/2021 03:12:09 - INFO - __main__ -     eval_ppl = 2.37305
10/22/2021 03:12:09 - INFO - __main__ -     global_step = 34000
10/22/2021 03:12:09 - INFO - __main__ -     train_loss = 0.2213
10/22/2021 03:12:09 - INFO - __main__ -     ********************
10/22/2021 03:12:13 - INFO - __main__ -   Here4
10/22/2021 03:12:13 - INFO - __main__ -   Here5.5
10/22/2021 03:21:00 - INFO - __main__ -   Here6
10/22/2021 03:21:00 - INFO - __main__ -     bleu-4 = 46.4 
10/22/2021 03:21:00 - INFO - __main__ -     xMatch = 19.2 
10/22/2021 03:21:00 - INFO - __main__ -     ********************
10/22/2021 03:21:00 - INFO - __main__ -     step 34000 loss 0.6924
10/22/2021 03:21:54 - INFO - __main__ -     step 34100 loss 0.196
10/22/2021 03:22:48 - INFO - __main__ -     step 34200 loss 0.2105
10/22/2021 03:23:42 - INFO - __main__ -     step 34300 loss 0.2169
10/22/2021 03:24:36 - INFO - __main__ -     step 34400 loss 0.2179
10/22/2021 03:25:30 - INFO - __main__ -     step 34500 loss 0.2181
10/22/2021 03:26:24 - INFO - __main__ -     step 34600 loss 0.217
10/22/2021 03:27:18 - INFO - __main__ -     step 34700 loss 0.2187
10/22/2021 03:28:12 - INFO - __main__ -     step 34800 loss 0.2199
10/22/2021 03:29:06 - INFO - __main__ -     step 34900 loss 0.2208
10/22/2021 03:30:00 - INFO - __main__ -   Here1
10/22/2021 03:30:00 - INFO - __main__ -   Here2
10/22/2021 03:30:00 - INFO - __main__ -   
***** Running evaluation *****
10/22/2021 03:30:00 - INFO - __main__ -     Num examples = 2449
10/22/2021 03:30:00 - INFO - __main__ -     Batch size = 4
10/22/2021 03:31:38 - INFO - __main__ -     eval_ppl = 2.31532
10/22/2021 03:31:38 - INFO - __main__ -     global_step = 35000
10/22/2021 03:31:38 - INFO - __main__ -     train_loss = 0.2186
10/22/2021 03:31:38 - INFO - __main__ -     ********************
10/22/2021 03:31:41 - INFO - __main__ -     Best ppl:2.31532
10/22/2021 03:31:41 - INFO - __main__ -     ********************
10/22/2021 03:31:46 - INFO - __main__ -   Here4
10/22/2021 03:31:46 - INFO - __main__ -   Here5.5
10/22/2021 03:39:50 - INFO - __main__ -   Here6
10/22/2021 03:39:50 - INFO - __main__ -     bleu-4 = 46.45 
10/22/2021 03:39:50 - INFO - __main__ -     xMatch = 19.2 
10/22/2021 03:39:50 - INFO - __main__ -     ********************
10/22/2021 03:39:50 - INFO - __main__ -     step 35000 loss 0.1207
10/22/2021 03:40:44 - INFO - __main__ -     step 35100 loss 0.1955
10/22/2021 03:41:38 - INFO - __main__ -     step 35200 loss 0.2144
10/22/2021 03:42:32 - INFO - __main__ -     step 35300 loss 0.2099
10/22/2021 03:43:27 - INFO - __main__ -     step 35400 loss 0.2129
10/22/2021 03:44:21 - INFO - __main__ -     step 35500 loss 0.2136
10/22/2021 03:45:15 - INFO - __main__ -     step 35600 loss 0.214
10/22/2021 03:46:09 - INFO - __main__ -     step 35700 loss 0.2092
10/22/2021 03:47:04 - INFO - __main__ -     step 35800 loss 0.2064
10/22/2021 03:47:58 - INFO - __main__ -     step 35900 loss 0.2051
10/22/2021 03:48:52 - INFO - __main__ -   Here1
10/22/2021 03:48:52 - INFO - __main__ -   Here2
10/22/2021 03:48:52 - INFO - __main__ -   
***** Running evaluation *****
10/22/2021 03:48:52 - INFO - __main__ -     Num examples = 2449
10/22/2021 03:48:52 - INFO - __main__ -     Batch size = 4
10/22/2021 03:50:30 - INFO - __main__ -     eval_ppl = 2.33441
10/22/2021 03:50:30 - INFO - __main__ -     global_step = 36000
10/22/2021 03:50:30 - INFO - __main__ -     train_loss = 0.2065
10/22/2021 03:50:30 - INFO - __main__ -     ********************
10/22/2021 03:50:35 - INFO - __main__ -   Here4
10/22/2021 03:50:35 - INFO - __main__ -   Here5.5
10/22/2021 03:58:41 - INFO - __main__ -   Here6
10/22/2021 03:58:41 - INFO - __main__ -     bleu-4 = 47.58 
10/22/2021 03:58:41 - INFO - __main__ -     xMatch = 20.5 
10/22/2021 03:58:41 - INFO - __main__ -     ********************
10/22/2021 03:58:41 - INFO - __main__ -     Best bleu:47.58
10/22/2021 03:58:41 - INFO - __main__ -     ********************
10/22/2021 03:58:47 - INFO - __main__ -     step 36000 loss 0.1115
10/22/2021 03:59:41 - INFO - __main__ -     step 36100 loss 0.1745
10/22/2021 04:00:36 - INFO - __main__ -     step 36200 loss 0.1769
10/22/2021 04:01:30 - INFO - __main__ -     step 36300 loss 0.1824
10/22/2021 04:02:25 - INFO - __main__ -     step 36400 loss 0.1855
10/22/2021 04:03:19 - INFO - __main__ -     step 36500 loss 0.1847
10/22/2021 04:04:13 - INFO - __main__ -     step 36600 loss 0.1838
10/22/2021 04:05:08 - INFO - __main__ -     step 36700 loss 0.1855
10/22/2021 04:06:02 - INFO - __main__ -     step 36800 loss 0.1855
10/22/2021 04:06:56 - INFO - __main__ -     step 36900 loss 0.1858
10/22/2021 04:07:50 - INFO - __main__ -   Here1
10/22/2021 04:07:50 - INFO - __main__ -   Here2
10/22/2021 04:07:50 - INFO - __main__ -   
***** Running evaluation *****
10/22/2021 04:07:50 - INFO - __main__ -     Num examples = 2449
10/22/2021 04:07:50 - INFO - __main__ -     Batch size = 4
10/22/2021 04:09:28 - INFO - __main__ -     eval_ppl = 2.33238
10/22/2021 04:09:28 - INFO - __main__ -     global_step = 37000
10/22/2021 04:09:28 - INFO - __main__ -     train_loss = 0.1849
10/22/2021 04:09:28 - INFO - __main__ -     ********************
10/22/2021 04:09:32 - INFO - __main__ -   Here4
10/22/2021 04:09:32 - INFO - __main__ -   Here5.5
10/22/2021 04:17:56 - INFO - __main__ -   Here6
10/22/2021 04:17:56 - INFO - __main__ -     bleu-4 = 46.43 
10/22/2021 04:17:56 - INFO - __main__ -     xMatch = 20.0 
10/22/2021 04:17:56 - INFO - __main__ -     ********************
10/22/2021 04:17:57 - INFO - __main__ -     step 37000 loss 0.1424
10/22/2021 04:18:52 - INFO - __main__ -     step 37100 loss 0.1904
10/22/2021 04:19:46 - INFO - __main__ -     step 37200 loss 0.19
10/22/2021 04:20:41 - INFO - __main__ -     step 37300 loss 0.1863
10/22/2021 04:21:35 - INFO - __main__ -     step 37400 loss 0.1849
10/22/2021 04:22:29 - INFO - __main__ -     step 37500 loss 0.1822
10/22/2021 04:23:23 - INFO - __main__ -     step 37600 loss 0.1811
10/22/2021 04:24:18 - INFO - __main__ -     step 37700 loss 0.1801
10/22/2021 04:25:12 - INFO - __main__ -     step 37800 loss 0.1827
10/22/2021 04:26:06 - INFO - __main__ -     step 37900 loss 0.1826
10/22/2021 04:27:00 - INFO - __main__ -   Here1
10/22/2021 04:27:00 - INFO - __main__ -   Here2
10/22/2021 04:27:00 - INFO - __main__ -   
***** Running evaluation *****
10/22/2021 04:27:00 - INFO - __main__ -     Num examples = 2449
10/22/2021 04:27:00 - INFO - __main__ -     Batch size = 4
10/22/2021 04:28:38 - INFO - __main__ -     eval_ppl = 2.34047
10/22/2021 04:28:38 - INFO - __main__ -     global_step = 38000
10/22/2021 04:28:38 - INFO - __main__ -     train_loss = 0.181
10/22/2021 04:28:38 - INFO - __main__ -     ********************
10/22/2021 04:28:43 - INFO - __main__ -   Here4
10/22/2021 04:28:43 - INFO - __main__ -   Here5.5
10/22/2021 04:36:49 - INFO - __main__ -   Here6
10/22/2021 04:36:49 - INFO - __main__ -     bleu-4 = 48.52 
10/22/2021 04:36:49 - INFO - __main__ -     xMatch = 20.9 
10/22/2021 04:36:49 - INFO - __main__ -     ********************
10/22/2021 04:36:49 - INFO - __main__ -     Best bleu:48.52
10/22/2021 04:36:49 - INFO - __main__ -     ********************
10/22/2021 04:36:53 - INFO - __main__ -     step 38000 loss 0.0575
10/22/2021 04:37:47 - INFO - __main__ -     step 38100 loss 0.1653
10/22/2021 04:38:41 - INFO - __main__ -     step 38200 loss 0.172
10/22/2021 04:39:36 - INFO - __main__ -     step 38300 loss 0.1716
10/22/2021 04:40:31 - INFO - __main__ -     step 38400 loss 0.1708
10/22/2021 04:41:25 - INFO - __main__ -     step 38500 loss 0.1718
10/22/2021 04:42:20 - INFO - __main__ -     step 38600 loss 0.1671
10/22/2021 04:43:14 - INFO - __main__ -     step 38700 loss 0.1677
10/22/2021 04:44:09 - INFO - __main__ -     step 38800 loss 0.1659
10/22/2021 04:45:03 - INFO - __main__ -     step 38900 loss 0.1655
10/22/2021 04:45:57 - INFO - __main__ -   Here1
10/22/2021 04:45:57 - INFO - __main__ -   Here2
10/22/2021 04:45:57 - INFO - __main__ -   
***** Running evaluation *****
10/22/2021 04:45:57 - INFO - __main__ -     Num examples = 2449
10/22/2021 04:45:57 - INFO - __main__ -     Batch size = 4
10/22/2021 04:47:35 - INFO - __main__ -     eval_ppl = 2.35336
10/22/2021 04:47:35 - INFO - __main__ -     global_step = 39000
10/22/2021 04:47:35 - INFO - __main__ -     train_loss = 0.1632
10/22/2021 04:47:35 - INFO - __main__ -     ********************
10/22/2021 04:47:39 - INFO - __main__ -   Here4
10/22/2021 04:47:39 - INFO - __main__ -   Here5.5
10/22/2021 04:55:35 - INFO - __main__ -   Here6
10/22/2021 04:55:35 - INFO - __main__ -     bleu-4 = 48.51 
10/22/2021 04:55:35 - INFO - __main__ -     xMatch = 20.2 
10/22/2021 04:55:35 - INFO - __main__ -     ********************
10/22/2021 04:55:35 - INFO - __main__ -     step 39000 loss 0.1584
10/22/2021 04:56:29 - INFO - __main__ -     step 39100 loss 0.1659
10/22/2021 04:57:23 - INFO - __main__ -     step 39200 loss 0.1754
10/22/2021 04:58:17 - INFO - __main__ -     step 39300 loss 0.1728
10/22/2021 04:59:11 - INFO - __main__ -     step 39400 loss 0.1725
10/22/2021 05:00:05 - INFO - __main__ -     step 39500 loss 0.1697
10/22/2021 05:00:59 - INFO - __main__ -     step 39600 loss 0.1697
10/22/2021 05:01:54 - INFO - __main__ -     step 39700 loss 0.1693
10/22/2021 05:02:48 - INFO - __main__ -     step 39800 loss 0.1703
10/22/2021 05:03:42 - INFO - __main__ -     step 39900 loss 0.1672
10/22/2021 05:04:36 - INFO - __main__ -   Here1
10/22/2021 05:04:36 - INFO - __main__ -   Here2
10/22/2021 05:04:36 - INFO - __main__ -   
***** Running evaluation *****
10/22/2021 05:04:36 - INFO - __main__ -     Num examples = 2449
10/22/2021 05:04:36 - INFO - __main__ -     Batch size = 4
10/22/2021 05:06:14 - INFO - __main__ -     eval_ppl = 2.3175
10/22/2021 05:06:14 - INFO - __main__ -     global_step = 40000
10/22/2021 05:06:14 - INFO - __main__ -     train_loss = 0.1651
10/22/2021 05:06:14 - INFO - __main__ -     ********************
10/22/2021 05:06:18 - INFO - __main__ -   Here4
10/22/2021 05:06:18 - INFO - __main__ -   Here5.5
10/22/2021 05:14:13 - INFO - __main__ -   Here6
10/22/2021 05:14:13 - INFO - __main__ -     bleu-4 = 46.43 
10/22/2021 05:14:13 - INFO - __main__ -     xMatch = 20.9 
10/22/2021 05:14:13 - INFO - __main__ -     ********************
10/22/2021 05:14:13 - INFO - __main__ -     step 40000 loss 0.3002
10/22/2021 05:15:07 - INFO - __main__ -     step 40100 loss 0.1816
10/22/2021 05:16:02 - INFO - __main__ -     step 40200 loss 0.1626
10/22/2021 05:16:56 - INFO - __main__ -     step 40300 loss 0.1675
10/22/2021 05:17:50 - INFO - __main__ -     step 40400 loss 0.1666
10/22/2021 05:18:45 - INFO - __main__ -     step 40500 loss 0.1635
10/22/2021 05:19:39 - INFO - __main__ -     step 40600 loss 0.1583
10/22/2021 05:20:33 - INFO - __main__ -     step 40700 loss 0.1561
10/22/2021 05:21:27 - INFO - __main__ -     step 40800 loss 0.1543
10/22/2021 05:22:21 - INFO - __main__ -     step 40900 loss 0.1551
10/22/2021 05:23:15 - INFO - __main__ -   Here1
10/22/2021 05:23:15 - INFO - __main__ -   Here2
10/22/2021 05:23:15 - INFO - __main__ -   
***** Running evaluation *****
10/22/2021 05:23:15 - INFO - __main__ -     Num examples = 2449
10/22/2021 05:23:15 - INFO - __main__ -     Batch size = 4
10/22/2021 05:24:53 - INFO - __main__ -     eval_ppl = 2.33031
10/22/2021 05:24:53 - INFO - __main__ -     global_step = 41000
10/22/2021 05:24:53 - INFO - __main__ -     train_loss = 0.1524
10/22/2021 05:24:53 - INFO - __main__ -     ********************
10/22/2021 05:24:58 - INFO - __main__ -   Here4
10/22/2021 05:24:58 - INFO - __main__ -   Here5.5
10/22/2021 05:32:59 - INFO - __main__ -   Here6
10/22/2021 05:32:59 - INFO - __main__ -     bleu-4 = 47.95 
10/22/2021 05:32:59 - INFO - __main__ -     xMatch = 21.4 
10/22/2021 05:32:59 - INFO - __main__ -     ********************
10/22/2021 05:33:00 - INFO - __main__ -     step 41000 loss 0.035
10/22/2021 05:33:54 - INFO - __main__ -     step 41100 loss 0.1408
10/22/2021 05:34:48 - INFO - __main__ -     step 41200 loss 0.1427
10/22/2021 05:35:42 - INFO - __main__ -     step 41300 loss 0.1442
10/22/2021 05:36:36 - INFO - __main__ -     step 41400 loss 0.1409
10/22/2021 05:37:30 - INFO - __main__ -     step 41500 loss 0.1407
10/22/2021 05:38:24 - INFO - __main__ -     step 41600 loss 0.1417
10/22/2021 05:39:18 - INFO - __main__ -     step 41700 loss 0.1406
10/22/2021 05:40:12 - INFO - __main__ -     step 41800 loss 0.1412
10/22/2021 05:41:06 - INFO - __main__ -     step 41900 loss 0.1408
10/22/2021 05:42:00 - INFO - __main__ -   Here1
10/22/2021 05:42:00 - INFO - __main__ -   Here2
10/22/2021 05:42:00 - INFO - __main__ -   
***** Running evaluation *****
10/22/2021 05:42:00 - INFO - __main__ -     Num examples = 2449
10/22/2021 05:42:00 - INFO - __main__ -     Batch size = 4
10/22/2021 05:43:38 - INFO - __main__ -     eval_ppl = 2.34256
10/22/2021 05:43:38 - INFO - __main__ -     global_step = 42000
10/22/2021 05:43:38 - INFO - __main__ -     train_loss = 0.1404
10/22/2021 05:43:38 - INFO - __main__ -     ********************
10/22/2021 05:43:42 - INFO - __main__ -   Here4
10/22/2021 05:43:42 - INFO - __main__ -   Here5.5
10/22/2021 05:51:21 - INFO - __main__ -   Here6
10/22/2021 05:51:21 - INFO - __main__ -     bleu-4 = 49.03 
10/22/2021 05:51:21 - INFO - __main__ -     xMatch = 21.1 
10/22/2021 05:51:21 - INFO - __main__ -     ********************
10/22/2021 05:51:21 - INFO - __main__ -     Best bleu:49.03
10/22/2021 05:51:21 - INFO - __main__ -     ********************
10/22/2021 05:51:25 - INFO - __main__ -     step 42000 loss 0.2558
10/22/2021 05:52:19 - INFO - __main__ -     step 42100 loss 0.1477
10/22/2021 05:53:13 - INFO - __main__ -     step 42200 loss 0.1385
10/22/2021 05:54:07 - INFO - __main__ -     step 42300 loss 0.1355
10/22/2021 05:55:01 - INFO - __main__ -     step 42400 loss 0.1326
10/22/2021 05:55:54 - INFO - __main__ -     step 42500 loss 0.1322
10/22/2021 05:56:49 - INFO - __main__ -     step 42600 loss 0.1329
10/22/2021 05:57:43 - INFO - __main__ -     step 42700 loss 0.1359
10/22/2021 05:58:37 - INFO - __main__ -     step 42800 loss 0.1364
10/22/2021 05:59:31 - INFO - __main__ -     step 42900 loss 0.1351
10/22/2021 06:00:25 - INFO - __main__ -   Here1
10/22/2021 06:00:25 - INFO - __main__ -   Here2
10/22/2021 06:00:25 - INFO - __main__ -   
***** Running evaluation *****
10/22/2021 06:00:25 - INFO - __main__ -     Num examples = 2449
10/22/2021 06:00:25 - INFO - __main__ -     Batch size = 4
10/22/2021 06:02:03 - INFO - __main__ -     eval_ppl = 2.35439
10/22/2021 06:02:03 - INFO - __main__ -     global_step = 43000
10/22/2021 06:02:03 - INFO - __main__ -     train_loss = 0.1339
10/22/2021 06:02:03 - INFO - __main__ -     ********************
10/22/2021 06:02:07 - INFO - __main__ -   Here4
10/22/2021 06:02:07 - INFO - __main__ -   Here5.5
10/22/2021 06:09:54 - INFO - __main__ -   Here6
10/22/2021 06:09:54 - INFO - __main__ -     bleu-4 = 49.02 
10/22/2021 06:09:54 - INFO - __main__ -     xMatch = 20.9 
10/22/2021 06:09:54 - INFO - __main__ -     ********************
10/22/2021 06:09:54 - INFO - __main__ -     step 43000 loss 0.0723
10/22/2021 06:10:48 - INFO - __main__ -     step 43100 loss 0.1301
10/22/2021 06:11:42 - INFO - __main__ -     step 43200 loss 0.1306
10/22/2021 06:12:36 - INFO - __main__ -     step 43300 loss 0.1291
10/22/2021 06:13:30 - INFO - __main__ -     step 43400 loss 0.1296
10/22/2021 06:14:24 - INFO - __main__ -     step 43500 loss 0.1248
10/22/2021 06:15:17 - INFO - __main__ -     step 43600 loss 0.1262
10/22/2021 06:16:11 - INFO - __main__ -     step 43700 loss 0.1254
10/22/2021 06:17:05 - INFO - __main__ -     step 43800 loss 0.1256
10/22/2021 06:17:59 - INFO - __main__ -     step 43900 loss 0.1237
10/22/2021 06:18:53 - INFO - __main__ -   Here1
10/22/2021 06:18:53 - INFO - __main__ -   Here2
10/22/2021 06:18:53 - INFO - __main__ -   
***** Running evaluation *****
10/22/2021 06:18:53 - INFO - __main__ -     Num examples = 2449
10/22/2021 06:18:53 - INFO - __main__ -     Batch size = 4
10/22/2021 06:20:31 - INFO - __main__ -     eval_ppl = 2.3333
10/22/2021 06:20:31 - INFO - __main__ -     global_step = 44000
10/22/2021 06:20:31 - INFO - __main__ -     train_loss = 0.1241
10/22/2021 06:20:31 - INFO - __main__ -     ********************
10/22/2021 06:20:35 - INFO - __main__ -   Here4
10/22/2021 06:20:35 - INFO - __main__ -   Here5.5
10/22/2021 06:28:07 - INFO - __main__ -   Here6
10/22/2021 06:28:07 - INFO - __main__ -     bleu-4 = 49.62 
10/22/2021 06:28:07 - INFO - __main__ -     xMatch = 22.0 
10/22/2021 06:28:07 - INFO - __main__ -     ********************
10/22/2021 06:28:07 - INFO - __main__ -     Best bleu:49.62
10/22/2021 06:28:07 - INFO - __main__ -     ********************
10/22/2021 06:28:12 - INFO - __main__ -     step 44000 loss 0.0421
10/22/2021 06:29:06 - INFO - __main__ -     step 44100 loss 0.1332
10/22/2021 06:30:00 - INFO - __main__ -     step 44200 loss 0.1284
10/22/2021 06:30:54 - INFO - __main__ -     step 44300 loss 0.1288
10/22/2021 06:31:48 - INFO - __main__ -     step 44400 loss 0.1276
10/22/2021 06:32:43 - INFO - __main__ -     step 44500 loss 0.1262
10/22/2021 06:33:37 - INFO - __main__ -     step 44600 loss 0.1271
10/22/2021 06:34:31 - INFO - __main__ -     step 44700 loss 0.1279
10/22/2021 06:35:25 - INFO - __main__ -     step 44800 loss 0.1257
10/22/2021 06:36:20 - INFO - __main__ -     step 44900 loss 0.1255
10/22/2021 06:37:14 - INFO - __main__ -   Here1
10/22/2021 06:37:14 - INFO - __main__ -   Here2
10/22/2021 06:37:14 - INFO - __main__ -   
***** Running evaluation *****
10/22/2021 06:37:14 - INFO - __main__ -     Num examples = 2449
10/22/2021 06:37:14 - INFO - __main__ -     Batch size = 4
10/22/2021 06:38:52 - INFO - __main__ -     eval_ppl = 2.32544
10/22/2021 06:38:52 - INFO - __main__ -     global_step = 45000
10/22/2021 06:38:52 - INFO - __main__ -     train_loss = 0.1268
10/22/2021 06:38:52 - INFO - __main__ -     ********************
10/22/2021 06:38:56 - INFO - __main__ -   Here4
10/22/2021 06:38:56 - INFO - __main__ -   Here5.5
10/22/2021 06:46:56 - INFO - __main__ -   Here6
10/22/2021 06:46:56 - INFO - __main__ -     bleu-4 = 48.75 
10/22/2021 06:46:56 - INFO - __main__ -     xMatch = 21.5 
10/22/2021 06:46:56 - INFO - __main__ -     ********************
10/22/2021 06:46:57 - INFO - __main__ -     step 45000 loss 0.2062
10/22/2021 06:47:51 - INFO - __main__ -     step 45100 loss 0.1126
10/22/2021 06:48:45 - INFO - __main__ -     step 45200 loss 0.1234
10/22/2021 06:49:40 - INFO - __main__ -     step 45300 loss 0.1256
10/22/2021 06:50:34 - INFO - __main__ -     step 45400 loss 0.1248
10/22/2021 06:51:28 - INFO - __main__ -     step 45500 loss 0.1201
10/22/2021 06:52:23 - INFO - __main__ -     step 45600 loss 0.1175
10/22/2021 06:53:17 - INFO - __main__ -     step 45700 loss 0.1164
10/22/2021 06:54:11 - INFO - __main__ -     step 45800 loss 0.1179
10/22/2021 06:55:05 - INFO - __main__ -     step 45900 loss 0.1159
10/22/2021 06:55:59 - INFO - __main__ -   Here1
10/22/2021 06:55:59 - INFO - __main__ -   Here2
10/22/2021 06:55:59 - INFO - __main__ -   
***** Running evaluation *****
10/22/2021 06:55:59 - INFO - __main__ -     Num examples = 2449
10/22/2021 06:55:59 - INFO - __main__ -     Batch size = 4
10/22/2021 06:57:37 - INFO - __main__ -     eval_ppl = 2.33027
10/22/2021 06:57:37 - INFO - __main__ -     global_step = 46000
10/22/2021 06:57:37 - INFO - __main__ -     train_loss = 0.1159
10/22/2021 06:57:37 - INFO - __main__ -     ********************
10/22/2021 06:57:43 - INFO - __main__ -   Here4
10/22/2021 06:57:43 - INFO - __main__ -   Here5.5
10/22/2021 07:05:10 - INFO - __main__ -   Here6
10/22/2021 07:05:10 - INFO - __main__ -     bleu-4 = 49.83 
10/22/2021 07:05:10 - INFO - __main__ -     xMatch = 22.9 
10/22/2021 07:05:10 - INFO - __main__ -     ********************
10/22/2021 07:05:10 - INFO - __main__ -     Best bleu:49.83
10/22/2021 07:05:10 - INFO - __main__ -     ********************
10/22/2021 07:05:15 - INFO - __main__ -     step 46000 loss 0.1379
10/22/2021 07:06:09 - INFO - __main__ -     step 46100 loss 0.1112
10/22/2021 07:07:04 - INFO - __main__ -     step 46200 loss 0.1127
10/22/2021 07:07:58 - INFO - __main__ -     step 46300 loss 0.11
10/22/2021 07:08:52 - INFO - __main__ -     step 46400 loss 0.1091
10/22/2021 07:09:46 - INFO - __main__ -     step 46500 loss 0.11
10/22/2021 07:10:40 - INFO - __main__ -     step 46600 loss 0.1094
10/22/2021 07:11:34 - INFO - __main__ -     step 46700 loss 0.1098
10/22/2021 07:12:28 - INFO - __main__ -     step 46800 loss 0.1102
10/22/2021 07:13:23 - INFO - __main__ -     step 46900 loss 0.1106
10/22/2021 07:14:17 - INFO - __main__ -   Here1
10/22/2021 07:14:17 - INFO - __main__ -   Here2
10/22/2021 07:14:17 - INFO - __main__ -   
***** Running evaluation *****
10/22/2021 07:14:17 - INFO - __main__ -     Num examples = 2449
10/22/2021 07:14:17 - INFO - __main__ -     Batch size = 4
10/22/2021 07:15:55 - INFO - __main__ -     eval_ppl = 2.31387
10/22/2021 07:15:55 - INFO - __main__ -     global_step = 47000
10/22/2021 07:15:55 - INFO - __main__ -     train_loss = 0.1108
10/22/2021 07:15:55 - INFO - __main__ -     ********************
10/22/2021 07:16:00 - INFO - __main__ -     Best ppl:2.31387
10/22/2021 07:16:00 - INFO - __main__ -     ********************
10/22/2021 07:16:05 - INFO - __main__ -   Here4
10/22/2021 07:16:05 - INFO - __main__ -   Here5.5
10/22/2021 07:23:42 - INFO - __main__ -   Here6
10/22/2021 07:23:42 - INFO - __main__ -     bleu-4 = 49.46 
10/22/2021 07:23:42 - INFO - __main__ -     xMatch = 22.9 
10/22/2021 07:23:42 - INFO - __main__ -     ********************
10/22/2021 07:23:42 - INFO - __main__ -     step 47000 loss 0.0554
10/22/2021 07:24:36 - INFO - __main__ -     step 47100 loss 0.1051
10/22/2021 07:25:30 - INFO - __main__ -     step 47200 loss 0.1088
10/22/2021 07:26:24 - INFO - __main__ -     step 47300 loss 0.1038
10/22/2021 07:27:18 - INFO - __main__ -     step 47400 loss 0.1029
10/22/2021 07:28:12 - INFO - __main__ -     step 47500 loss 0.1036
10/22/2021 07:29:06 - INFO - __main__ -     step 47600 loss 0.1082
10/22/2021 07:30:00 - INFO - __main__ -     step 47700 loss 0.1083
10/22/2021 07:30:54 - INFO - __main__ -     step 47800 loss 0.1073
10/22/2021 07:31:48 - INFO - __main__ -     step 47900 loss 0.1067
10/22/2021 07:32:42 - INFO - __main__ -   Here1
10/22/2021 07:32:42 - INFO - __main__ -   Here2
10/22/2021 07:32:42 - INFO - __main__ -   
***** Running evaluation *****
10/22/2021 07:32:42 - INFO - __main__ -     Num examples = 2449
10/22/2021 07:32:42 - INFO - __main__ -     Batch size = 4
10/22/2021 07:34:20 - INFO - __main__ -     eval_ppl = 2.34042
10/22/2021 07:34:20 - INFO - __main__ -     global_step = 48000
10/22/2021 07:34:20 - INFO - __main__ -     train_loss = 0.1065
10/22/2021 07:34:20 - INFO - __main__ -     ********************
10/22/2021 07:34:24 - INFO - __main__ -   Here4
10/22/2021 07:34:24 - INFO - __main__ -   Here5.5
10/22/2021 07:41:49 - INFO - __main__ -   Here6
10/22/2021 07:41:49 - INFO - __main__ -     bleu-4 = 49.22 
10/22/2021 07:41:49 - INFO - __main__ -     xMatch = 22.1 
10/22/2021 07:41:49 - INFO - __main__ -     ********************
10/22/2021 07:41:49 - INFO - __main__ -     step 48000 loss 0.0667
10/22/2021 07:42:43 - INFO - __main__ -     step 48100 loss 0.1061
10/22/2021 07:43:37 - INFO - __main__ -     step 48200 loss 0.1036
10/22/2021 07:44:31 - INFO - __main__ -     step 48300 loss 0.1049
10/22/2021 07:45:25 - INFO - __main__ -     step 48400 loss 0.0995
10/22/2021 07:46:19 - INFO - __main__ -     step 48500 loss 0.0997
10/22/2021 07:47:13 - INFO - __main__ -     step 48600 loss 0.0997
10/22/2021 07:48:07 - INFO - __main__ -     step 48700 loss 0.0997
10/22/2021 07:49:01 - INFO - __main__ -     step 48800 loss 0.0982
10/22/2021 07:49:55 - INFO - __main__ -     step 48900 loss 0.0985
10/22/2021 07:50:47 - INFO - __main__ -   Here1
10/22/2021 07:50:47 - INFO - __main__ -   Here2
10/22/2021 07:50:47 - INFO - __main__ -   
***** Running evaluation *****
10/22/2021 07:50:47 - INFO - __main__ -     Num examples = 2449
10/22/2021 07:50:47 - INFO - __main__ -     Batch size = 4
10/22/2021 07:52:25 - INFO - __main__ -     eval_ppl = 2.31945
10/22/2021 07:52:25 - INFO - __main__ -     global_step = 49000
10/22/2021 07:52:25 - INFO - __main__ -     train_loss = 0.1005
10/22/2021 07:52:25 - INFO - __main__ -     ********************
10/22/2021 07:52:29 - INFO - __main__ -   Here4
10/22/2021 07:52:29 - INFO - __main__ -   Here5.5
10/22/2021 08:00:08 - INFO - __main__ -   Here6
10/22/2021 08:00:08 - INFO - __main__ -     bleu-4 = 49.82 
10/22/2021 08:00:08 - INFO - __main__ -     xMatch = 22.9 
10/22/2021 08:00:08 - INFO - __main__ -     ********************
10/22/2021 08:00:08 - INFO - __main__ -     step 49000 loss 0.0297
10/22/2021 08:01:02 - INFO - __main__ -     step 49100 loss 0.0998
10/22/2021 08:01:56 - INFO - __main__ -     step 49200 loss 0.1051
10/22/2021 08:02:50 - INFO - __main__ -     step 49300 loss 0.1028
10/22/2021 08:03:44 - INFO - __main__ -     step 49400 loss 0.1048
10/22/2021 08:04:39 - INFO - __main__ -     step 49500 loss 0.1049
10/22/2021 08:05:33 - INFO - __main__ -     step 49600 loss 0.1063
10/22/2021 08:06:27 - INFO - __main__ -     step 49700 loss 0.104
10/22/2021 08:07:21 - INFO - __main__ -     step 49800 loss 0.1034
10/22/2021 08:08:15 - INFO - __main__ -     step 49900 loss 0.1059
10/22/2021 08:09:09 - INFO - __main__ -   Here1
10/22/2021 08:09:09 - INFO - __main__ -   Here2
10/22/2021 08:09:09 - INFO - __main__ -   
***** Running evaluation *****
10/22/2021 08:09:09 - INFO - __main__ -     Num examples = 2449
10/22/2021 08:09:09 - INFO - __main__ -     Batch size = 4
10/22/2021 08:10:47 - INFO - __main__ -     eval_ppl = 2.31853
10/22/2021 08:10:47 - INFO - __main__ -     global_step = 50000
10/22/2021 08:10:47 - INFO - __main__ -     train_loss = 0.1046
10/22/2021 08:10:47 - INFO - __main__ -     ********************
10/22/2021 08:10:51 - INFO - __main__ -   Here4
10/22/2021 08:10:51 - INFO - __main__ -   Here5.5
10/22/2021 08:18:32 - INFO - __main__ -   Here6
10/22/2021 08:18:32 - INFO - __main__ -     bleu-4 = 49.82 
10/22/2021 08:18:32 - INFO - __main__ -     xMatch = 23.1 
10/22/2021 08:18:32 - INFO - __main__ -     ********************
10/22/2021 08:18:32 - INFO - __main__ -     step 50000 loss 0.1589
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
10/22/2021 18:15:58 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, beam_size=5, config_name='', dev_filename='../../data/unique/split/large/src-val.txt,../../data/unique/split/large/tgt-val.txt', do_eval=False, do_lower_case=False, do_test=True, do_train=False, eval_batch_size=128, eval_steps=-1, gradient_accumulation_steps=1, learning_rate=5e-05, load_model_path='saved_models/codebert/unique/large/checkpoint-best-ppl/pytorch_model.bin', local_rank=-1, max_grad_norm=1.0, max_source_length=510, max_steps=-1, max_target_length=510, model_name_or_path='../../codebert-base', model_type='roberta', no_cuda=False, num_train_epochs=3.0, output_dir='saved_models/codebert/unique/large', seed=42, test_filename='../../data/unique/split/large/src-test.txt,../../data/unique/split/large/tgt-test.txt', tokenizer_name='roberta-base', train_batch_size=8, train_filename=None, train_steps=-1, warmup_steps=0, weight_decay=0.0)
10/22/2021 18:15:58 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False
10/22/2021 18:15:58 - INFO - transformers.configuration_utils -   loading configuration file ../../codebert-base/config.json
10/22/2021 18:15:58 - INFO - transformers.configuration_utils -   Model config RobertaConfig {
  "architectures": [
    "RobertaModel"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "eos_token_id": 2,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 514,
  "model_type": "roberta",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "output_past": true,
  "pad_token_id": 1,
  "type_vocab_size": 1,
  "vocab_size": 50265
}

10/22/2021 18:15:58 - INFO - transformers.tokenization_utils_base -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at /home/mahim/.cache/torch/transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b
10/22/2021 18:15:58 - INFO - transformers.tokenization_utils_base -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at /home/mahim/.cache/torch/transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
10/22/2021 18:15:58 - INFO - transformers.modeling_utils -   loading weights file ../../codebert-base/pytorch_model.bin
10/22/2021 18:16:05 - INFO - transformers.modeling_utils -   All model checkpoint weights were used when initializing RobertaModel.

10/22/2021 18:16:05 - INFO - transformers.modeling_utils -   All the weights of RobertaModel were initialized from the model checkpoint at ../../codebert-base.
If your task is similar to the task the model of the ckeckpoint was trained on, you can already use RobertaModel for predictions without further training.
10/22/2021 18:16:06 - INFO - __main__ -   reload model from saved_models/codebert/unique/large/checkpoint-best-ppl/pytorch_model.bin
10/22/2021 18:16:10 - INFO - __main__ -   Running Test
10/22/2021 18:16:10 - INFO - __main__ -   Test file: ../../data/unique/split/large/src-val.txt,../../data/unique/split/large/tgt-val.txt

  0%|          | 0/20 [00:00<?, ?it/s]
  5%|▌         | 1/20 [01:03<20:05, 63.43s/it]
 10%|█         | 2/20 [01:57<17:22, 57.90s/it]
 15%|█▌        | 3/20 [02:39<14:21, 50.67s/it]
 20%|██        | 4/20 [03:51<15:43, 58.99s/it]
 25%|██▌       | 5/20 [04:56<15:19, 61.27s/it]
 30%|███       | 6/20 [05:59<14:26, 61.90s/it]
 35%|███▌      | 7/20 [07:00<13:18, 61.42s/it]
 40%|████      | 8/20 [07:52<11:43, 58.62s/it]
 45%|████▌     | 9/20 [08:54<10:54, 59.46s/it]
 50%|█████     | 10/20 [09:57<10:08, 60.81s/it]
 55%|█████▌    | 11/20 [11:00<09:12, 61.36s/it]
 60%|██████    | 12/20 [12:13<08:38, 64.80s/it]
 65%|██████▌   | 13/20 [12:52<06:38, 56.97s/it]
 70%|███████   | 14/20 [13:35<05:16, 52.80s/it]
 75%|███████▌  | 15/20 [14:22<04:15, 51.03s/it]
 80%|████████  | 16/20 [16:04<04:25, 66.45s/it]
 85%|████████▌ | 17/20 [17:05<03:14, 64.88s/it]
 90%|█████████ | 18/20 [17:55<02:00, 60.30s/it]
 95%|█████████▌| 19/20 [19:05<01:03, 63.31s/it]
100%|██████████| 20/20 [19:10<00:00, 45.81s/it]
100%|██████████| 20/20 [19:10<00:00, 57.53s/it]
10/22/2021 18:35:23 - INFO - __main__ -     bleu-4 = 53.04 
10/22/2021 18:35:23 - INFO - __main__ -     xMatch = 22.0498 
10/22/2021 18:35:23 - INFO - __main__ -     ********************
10/22/2021 18:35:23 - INFO - __main__ -   Test file: ../../data/unique/split/large/src-test.txt,../../data/unique/split/large/tgt-test.txt

  0%|          | 0/20 [00:00<?, ?it/s]
  5%|▌         | 1/20 [00:41<13:01, 41.14s/it]
 10%|█         | 2/20 [01:24<12:48, 42.68s/it]
 15%|█▌        | 3/20 [02:11<12:34, 44.40s/it]
 20%|██        | 4/20 [03:09<13:15, 49.72s/it]
 25%|██▌       | 5/20 [04:06<13:05, 52.36s/it]
 30%|███       | 6/20 [04:51<11:39, 49.94s/it]
 35%|███▌      | 7/20 [05:37<10:34, 48.78s/it]
 40%|████      | 8/20 [08:09<16:16, 81.41s/it]
 45%|████▌     | 9/20 [09:22<14:26, 78.80s/it]
 50%|█████     | 10/20 [10:05<11:19, 67.96s/it]
 55%|█████▌    | 11/20 [11:21<10:33, 70.43s/it]
 60%|██████    | 12/20 [12:53<10:14, 76.77s/it]
 65%|██████▌   | 13/20 [14:52<10:28, 89.75s/it]
 70%|███████   | 14/20 [16:31<09:14, 92.38s/it]
 75%|███████▌  | 15/20 [17:38<07:03, 84.74s/it]
 80%|████████  | 16/20 [18:25<04:54, 73.51s/it]
 85%|████████▌ | 17/20 [19:10<03:14, 64.88s/it]
 90%|█████████ | 18/20 [19:57<01:59, 59.61s/it]
 95%|█████████▌| 19/20 [20:41<00:54, 54.91s/it]
100%|██████████| 20/20 [20:47<00:00, 40.02s/it]
100%|██████████| 20/20 [20:47<00:00, 62.36s/it]
10/22/2021 18:56:12 - INFO - __main__ -     bleu-4 = 58.47 
10/22/2021 18:56:12 - INFO - __main__ -     xMatch = 20.0898 
10/22/2021 18:56:12 - INFO - __main__ -     ********************
