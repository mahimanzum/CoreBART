Source: source Target: target
2021-10-22 21:54:36 | INFO | fairseq_cli.train | Namespace(activation_fn='gelu', adam_betas='(0.9, 0.98)', adam_eps=1e-06, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='mbart_base', attention_dropout=0.1, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_suffix='', clip_norm=0.0, cpu=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='../processed_data/large/data-bin', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', decoder_attention_heads=12, decoder_embed_dim=768, decoder_embed_path=None, decoder_ffn_embed_dim=3072, decoder_input_dim=768, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=True, decoder_normalize_before=False, decoder_output_dim=768, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', dropout=0.1, empty_cache_freq=0, encoder_attention_heads=12, encoder_embed_dim=768, encoder_embed_path=None, encoder_ffn_embed_dim=3072, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=False, end_learning_rate=0.0, eval_bleu=True, eval_bleu_args='{"beam": 5}', eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.1, langs='java,python,en_XX', layernorm_embedding=True, left_pad_source='True', left_pad_target='False', load_alignments=False, localsgd_frequency=3, log_format='json', log_interval=100, lr=[5e-05], lr_scheduler='polynomial_decay', max_epoch=30, max_sentences=8, max_sentences_valid=8, max_source_positions=1024, max_target_positions=1024, max_tokens=None, max_tokens_valid=None, max_update=100000, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=-1.0, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_workers=1, optimizer='adam', optimizer_overrides='{}', patience=10, pooler_activation_fn='tanh', pooler_dropout=0.0, power=1.0, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, relu_dropout=0.0, required_batch_size_multiple=8, reset_dataloader=True, reset_lr_scheduler=True, reset_meters=True, reset_optimizer=True, restore_file='../plbart/checkpoint_11_100000.pt', save_dir='../models/large', save_interval=1, save_interval_updates=0, seed=1234, sentence_avg=False, share_all_embeddings=True, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='source', stop_time_hours=0, target_lang='target', task='translation_without_lang_token', tensorboard_logdir='', threshold_loss_scale=None, tokenizer=None, total_num_update=1000000, tpu=False, train_subset='train', truncate_source=True, update_freq=[2], upsample_primary=1, use_bmuf=False, use_old_adam=False, user_dir='../user_dir', valid_subset='valid', validate_interval=1, warmup_updates=500, weight_decay=0.0)
2021-10-22 21:54:37 | INFO | fairseq.tasks.translation | [source] dictionary: 50001 types
2021-10-22 21:54:37 | INFO | fairseq.tasks.translation | [target] dictionary: 50001 types
2021-10-22 21:54:37 | INFO | fairseq.data.data_utils | loaded 2449 examples from: ../processed_data/large/data-bin/valid.source-target.source
2021-10-22 21:54:37 | INFO | fairseq.data.data_utils | loaded 2449 examples from: ../processed_data/large/data-bin/valid.source-target.target
2021-10-22 21:54:37 | INFO | fairseq.tasks.translation | ../processed_data/large/data-bin valid source-target 2449 examples
2021-10-22 21:54:42 | INFO | fairseq_cli.train | BARTModel(
  (encoder): TransformerEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(50005, 768, padding_idx=1)
    (embed_positions): LearnedPositionalEmbedding(1026, 768, padding_idx=1)
    (layernorm_embedding): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(50005, 768, padding_idx=1)
    (embed_positions): LearnedPositionalEmbedding(1026, 768, padding_idx=1)
    (layernorm_embedding): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=768, out_features=50005, bias=False)
  )
  (classification_heads): ModuleDict()
)
2021-10-22 21:54:42 | INFO | fairseq_cli.train | model mbart_base, criterion LabelSmoothedCrossEntropyCriterion
2021-10-22 21:54:42 | INFO | fairseq_cli.train | num. model params: 139220736 (num. trained: 139220736)
2021-10-22 21:54:46 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight
2021-10-22 21:54:46 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight
2021-10-22 21:54:46 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2021-10-22 21:54:46 | INFO | fairseq.utils | rank   0: capabilities =  6.1  ; total memory = 12.000 GB ; name = GRID P40-12Q                            
2021-10-22 21:54:46 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2021-10-22 21:54:46 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2021-10-22 21:54:46 | INFO | fairseq_cli.train | max tokens per GPU = None and max sentences per GPU = 8
2021-10-22 21:54:50 | INFO | fairseq.trainer | loaded checkpoint ../plbart/checkpoint_11_100000.pt (epoch 11 @ 0 updates)
2021-10-22 21:54:50 | INFO | fairseq.optim.adam | using FusedAdam
2021-10-22 21:54:50 | INFO | fairseq.trainer | loading train data for epoch 1
2021-10-22 21:54:50 | INFO | fairseq.data.data_utils | loaded 19590 examples from: ../processed_data/large/data-bin/train.source-target.source
2021-10-22 21:54:50 | INFO | fairseq.data.data_utils | loaded 19590 examples from: ../processed_data/large/data-bin/train.source-target.target
2021-10-22 21:54:50 | INFO | fairseq.tasks.translation | ../processed_data/large/data-bin train source-target 19590 examples
2021-10-22 21:54:51 | INFO | fairseq_cli.train | begin training epoch 1
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
2021-10-22 21:55:10 | INFO | train_inner | {"epoch": 1, "update": 0.082, "loss": "5.671", "nll_loss": "3.598", "ppl": "12.11", "wps": "2808.5", "ups": "5.26", "wpb": "532.4", "bsz": "16", "num_updates": "100", "lr": "1e-05", "gnorm": "29.166", "train_wall": "19", "wall": "25"}
2021-10-22 21:55:30 | INFO | train_inner | {"epoch": 1, "update": 0.163, "loss": "3.729", "nll_loss": "1.776", "ppl": "3.42", "wps": "2820.3", "ups": "5.08", "wpb": "554.8", "bsz": "16", "num_updates": "200", "lr": "2e-05", "gnorm": "6.488", "train_wall": "19", "wall": "44"}
2021-10-22 21:55:50 | INFO | train_inner | {"epoch": 1, "update": 0.245, "loss": "3.226", "nll_loss": "1.3", "ppl": "2.46", "wps": "2877.9", "ups": "4.9", "wpb": "586.8", "bsz": "16", "num_updates": "300", "lr": "3e-05", "gnorm": "3.884", "train_wall": "20", "wall": "65"}
2021-10-22 21:56:11 | INFO | train_inner | {"epoch": 1, "update": 0.327, "loss": "3.062", "nll_loss": "1.157", "ppl": "2.23", "wps": "2554.7", "ups": "4.91", "wpb": "520.6", "bsz": "16", "num_updates": "400", "lr": "4e-05", "gnorm": "3.45", "train_wall": "20", "wall": "85"}
2021-10-22 21:56:34 | INFO | train_inner | {"epoch": 1, "update": 0.408, "loss": "2.83", "nll_loss": "0.926", "ppl": "1.9", "wps": "2721.5", "ups": "4.35", "wpb": "626.1", "bsz": "16", "num_updates": "500", "lr": "5e-05", "gnorm": "2.486", "train_wall": "23", "wall": "108"}
2021-10-22 21:56:56 | INFO | train_inner | {"epoch": 1, "update": 0.49, "loss": "2.862", "nll_loss": "0.971", "ppl": "1.96", "wps": "2706.5", "ups": "4.47", "wpb": "605", "bsz": "16", "num_updates": "600", "lr": "4.9995e-05", "gnorm": "2.598", "train_wall": "22", "wall": "131"}
2021-10-22 21:57:17 | INFO | train_inner | {"epoch": 1, "update": 0.571, "loss": "2.848", "nll_loss": "0.964", "ppl": "1.95", "wps": "2890.1", "ups": "4.74", "wpb": "609.2", "bsz": "16", "num_updates": "700", "lr": "4.999e-05", "gnorm": "2.685", "train_wall": "21", "wall": "152"}
2021-10-22 21:57:37 | INFO | train_inner | {"epoch": 1, "update": 0.653, "loss": "2.788", "nll_loss": "0.907", "ppl": "1.88", "wps": "3052.9", "ups": "5.06", "wpb": "603.8", "bsz": "16", "num_updates": "800", "lr": "4.9985e-05", "gnorm": "2.519", "train_wall": "20", "wall": "171"}
2021-10-22 21:57:58 | INFO | train_inner | {"epoch": 1, "update": 0.735, "loss": "2.796", "nll_loss": "0.922", "ppl": "1.89", "wps": "2958", "ups": "4.76", "wpb": "621.8", "bsz": "16", "num_updates": "900", "lr": "4.998e-05", "gnorm": "2.48", "train_wall": "21", "wall": "192"}
2021-10-22 21:58:18 | INFO | train_inner | {"epoch": 1, "update": 0.816, "loss": "2.77", "nll_loss": "0.897", "ppl": "1.86", "wps": "2738", "ups": "4.88", "wpb": "561.4", "bsz": "16", "num_updates": "1000", "lr": "4.9975e-05", "gnorm": "2.401", "train_wall": "20", "wall": "213"}
2021-10-22 21:58:41 | INFO | train_inner | {"epoch": 1, "update": 0.898, "loss": "2.639", "nll_loss": "0.754", "ppl": "1.69", "wps": "2751.5", "ups": "4.5", "wpb": "611.7", "bsz": "16", "num_updates": "1100", "lr": "4.997e-05", "gnorm": "2.119", "train_wall": "22", "wall": "235"}
2021-10-22 21:59:02 | INFO | train_inner | {"epoch": 1, "update": 0.98, "loss": "2.674", "nll_loss": "0.798", "ppl": "1.74", "wps": "2915", "ups": "4.6", "wpb": "633.5", "bsz": "16", "num_updates": "1200", "lr": "4.9965e-05", "gnorm": "2.229", "train_wall": "21", "wall": "257"}
2021-10-22 21:59:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-22 22:02:20 | INFO | valid | {"epoch": 1, "valid_loss": "2.731", "valid_nll_loss": "0.734", "valid_ppl": "1.66", "valid_bleu": "51.73", "valid_wps": "452.3", "valid_wpb": "281.5", "valid_bsz": "8", "valid_num_updates": "1225"}
2021-10-22 22:02:20 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-22 22:02:29 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/large/checkpoint_best.pt (epoch 1 @ 1225 updates, score 51.73) (writing took 8.88256751501467 seconds)
2021-10-22 22:02:29 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2021-10-22 22:02:29 | INFO | train | {"epoch": 1, "train_loss": "3.12", "train_nll_loss": "1.212", "train_ppl": "2.32", "train_wps": "1569.3", "train_ups": "2.67", "train_wpb": "586.8", "train_bsz": "16", "train_num_updates": "1225", "train_lr": "4.99637e-05", "train_gnorm": "5.153", "train_train_wall": "254", "train_wall": "464"}
2021-10-22 22:02:29 | INFO | fairseq_cli.train | begin training epoch 1
2021-10-22 22:02:45 | INFO | train_inner | {"epoch": 2, "update": 1.061, "loss": "2.64", "nll_loss": "0.759", "ppl": "1.69", "wps": "280.8", "ups": "0.45", "wpb": "626.1", "bsz": "15.9", "num_updates": "1300", "lr": "4.996e-05", "gnorm": "2.268", "train_wall": "21", "wall": "480"}
2021-10-22 22:03:05 | INFO | train_inner | {"epoch": 2, "update": 1.143, "loss": "2.634", "nll_loss": "0.758", "ppl": "1.69", "wps": "3165.5", "ups": "5.02", "wpb": "631", "bsz": "16", "num_updates": "1400", "lr": "4.9955e-05", "gnorm": "2.364", "train_wall": "20", "wall": "500"}
2021-10-22 22:03:25 | INFO | train_inner | {"epoch": 2, "update": 1.224, "loss": "2.66", "nll_loss": "0.787", "ppl": "1.73", "wps": "2832.5", "ups": "5.21", "wpb": "543.6", "bsz": "16", "num_updates": "1500", "lr": "4.995e-05", "gnorm": "2.175", "train_wall": "19", "wall": "519"}
2021-10-22 22:03:46 | INFO | train_inner | {"epoch": 2, "update": 1.306, "loss": "2.649", "nll_loss": "0.777", "ppl": "1.71", "wps": "2621.8", "ups": "4.76", "wpb": "551.1", "bsz": "16", "num_updates": "1600", "lr": "4.9945e-05", "gnorm": "2.256", "train_wall": "21", "wall": "540"}
2021-10-22 22:04:06 | INFO | train_inner | {"epoch": 2, "update": 1.388, "loss": "2.601", "nll_loss": "0.728", "ppl": "1.66", "wps": "2755.5", "ups": "4.8", "wpb": "573.7", "bsz": "16", "num_updates": "1700", "lr": "4.994e-05", "gnorm": "1.952", "train_wall": "21", "wall": "561"}
2021-10-22 22:04:28 | INFO | train_inner | {"epoch": 2, "update": 1.469, "loss": "2.571", "nll_loss": "0.694", "ppl": "1.62", "wps": "2992", "ups": "4.62", "wpb": "647.4", "bsz": "16", "num_updates": "1800", "lr": "4.9935e-05", "gnorm": "1.916", "train_wall": "21", "wall": "582"}
2021-10-22 22:04:48 | INFO | train_inner | {"epoch": 2, "update": 1.551, "loss": "2.643", "nll_loss": "0.776", "ppl": "1.71", "wps": "2584", "ups": "5.01", "wpb": "515.5", "bsz": "16", "num_updates": "1900", "lr": "4.993e-05", "gnorm": "2.259", "train_wall": "20", "wall": "602"}
2021-10-22 22:05:08 | INFO | train_inner | {"epoch": 2, "update": 1.633, "loss": "2.707", "nll_loss": "0.849", "ppl": "1.8", "wps": "2518", "ups": "4.9", "wpb": "514.4", "bsz": "16", "num_updates": "2000", "lr": "4.9925e-05", "gnorm": "2.279", "train_wall": "20", "wall": "623"}
2021-10-22 22:05:30 | INFO | train_inner | {"epoch": 2, "update": 1.714, "loss": "2.546", "nll_loss": "0.67", "ppl": "1.59", "wps": "2939.5", "ups": "4.71", "wpb": "623.5", "bsz": "16", "num_updates": "2100", "lr": "4.992e-05", "gnorm": "2.009", "train_wall": "21", "wall": "644"}
2021-10-22 22:05:52 | INFO | train_inner | {"epoch": 2, "update": 1.796, "loss": "2.553", "nll_loss": "0.682", "ppl": "1.6", "wps": "3071.7", "ups": "4.45", "wpb": "689.7", "bsz": "16", "num_updates": "2200", "lr": "4.9915e-05", "gnorm": "2.059", "train_wall": "22", "wall": "666"}
2021-10-22 22:06:15 | INFO | train_inner | {"epoch": 2, "update": 1.878, "loss": "2.561", "nll_loss": "0.69", "ppl": "1.61", "wps": "2753.3", "ups": "4.4", "wpb": "625.6", "bsz": "16", "num_updates": "2300", "lr": "4.991e-05", "gnorm": "2.206", "train_wall": "22", "wall": "689"}
2021-10-22 22:06:35 | INFO | train_inner | {"epoch": 2, "update": 1.959, "loss": "2.622", "nll_loss": "0.761", "ppl": "1.69", "wps": "2693.4", "ups": "4.97", "wpb": "542.1", "bsz": "16", "num_updates": "2400", "lr": "4.9905e-05", "gnorm": "2.028", "train_wall": "20", "wall": "709"}
2021-10-22 22:06:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-22 22:10:00 | INFO | valid | {"epoch": 2, "valid_loss": "2.656", "valid_nll_loss": "0.648", "valid_ppl": "1.57", "valid_bleu": "49.91", "valid_wps": "442.2", "valid_wpb": "281.5", "valid_bsz": "8", "valid_num_updates": "2450", "valid_best_bleu": "51.73"}
2021-10-22 22:10:00 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-22 22:10:07 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/large/checkpoint_last.pt (epoch 2 @ 2450 updates, score 49.91) (writing took 6.4929039349080995 seconds)
2021-10-22 22:10:07 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2021-10-22 22:10:07 | INFO | train | {"epoch": 2, "train_loss": "2.61", "train_nll_loss": "0.739", "train_ppl": "1.67", "train_wps": "1570.5", "train_ups": "2.68", "train_wpb": "586.8", "train_bsz": "16", "train_num_updates": "2450", "train_lr": "4.99025e-05", "train_gnorm": "2.138", "train_train_wall": "253", "train_wall": "921"}
2021-10-22 22:10:07 | INFO | fairseq_cli.train | begin training epoch 2
2021-10-22 22:10:17 | INFO | train_inner | {"epoch": 3, "update": 2.041, "loss": "2.564", "nll_loss": "0.694", "ppl": "1.62", "wps": "224", "ups": "0.45", "wpb": "497.2", "bsz": "15.9", "num_updates": "2500", "lr": "4.98999e-05", "gnorm": "1.999", "train_wall": "19", "wall": "931"}
2021-10-22 22:10:37 | INFO | train_inner | {"epoch": 3, "update": 2.122, "loss": "2.496", "nll_loss": "0.618", "ppl": "1.54", "wps": "2809.1", "ups": "5", "wpb": "561.3", "bsz": "16", "num_updates": "2600", "lr": "4.98949e-05", "gnorm": "2.193", "train_wall": "20", "wall": "951"}
2021-10-22 22:10:59 | INFO | train_inner | {"epoch": 3, "update": 2.204, "loss": "2.484", "nll_loss": "0.606", "ppl": "1.52", "wps": "2595.2", "ups": "4.59", "wpb": "565", "bsz": "16", "num_updates": "2700", "lr": "4.98899e-05", "gnorm": "1.928", "train_wall": "22", "wall": "973"}
2021-10-22 22:11:20 | INFO | train_inner | {"epoch": 3, "update": 2.286, "loss": "2.527", "nll_loss": "0.654", "ppl": "1.57", "wps": "2942.1", "ups": "4.75", "wpb": "619.1", "bsz": "16", "num_updates": "2800", "lr": "4.98849e-05", "gnorm": "2.208", "train_wall": "21", "wall": "994"}
2021-10-22 22:11:39 | INFO | train_inner | {"epoch": 3, "update": 2.367, "loss": "2.526", "nll_loss": "0.654", "ppl": "1.57", "wps": "2685.4", "ups": "5.1", "wpb": "526.5", "bsz": "16", "num_updates": "2900", "lr": "4.98799e-05", "gnorm": "2.287", "train_wall": "19", "wall": "1014"}
2021-10-22 22:12:00 | INFO | train_inner | {"epoch": 3, "update": 2.449, "loss": "2.509", "nll_loss": "0.635", "ppl": "1.55", "wps": "3030.4", "ups": "4.75", "wpb": "637.6", "bsz": "16", "num_updates": "3000", "lr": "4.98749e-05", "gnorm": "2.022", "train_wall": "21", "wall": "1035"}
2021-10-22 22:12:21 | INFO | train_inner | {"epoch": 3, "update": 2.531, "loss": "2.504", "nll_loss": "0.63", "ppl": "1.55", "wps": "2601.6", "ups": "4.94", "wpb": "526.8", "bsz": "16", "num_updates": "3100", "lr": "4.98699e-05", "gnorm": "2.168", "train_wall": "20", "wall": "1055"}
2021-10-22 22:12:42 | INFO | train_inner | {"epoch": 3, "update": 2.612, "loss": "2.486", "nll_loss": "0.612", "ppl": "1.53", "wps": "2900.8", "ups": "4.72", "wpb": "614.3", "bsz": "16", "num_updates": "3200", "lr": "4.98649e-05", "gnorm": "2.091", "train_wall": "21", "wall": "1076"}
2021-10-22 22:13:02 | INFO | train_inner | {"epoch": 3, "update": 2.694, "loss": "2.525", "nll_loss": "0.656", "ppl": "1.58", "wps": "2758.4", "ups": "4.85", "wpb": "568.7", "bsz": "16", "num_updates": "3300", "lr": "4.98599e-05", "gnorm": "1.873", "train_wall": "20", "wall": "1097"}
2021-10-22 22:13:23 | INFO | train_inner | {"epoch": 3, "update": 2.776, "loss": "2.622", "nll_loss": "0.764", "ppl": "1.7", "wps": "2824.5", "ups": "4.93", "wpb": "572.8", "bsz": "16", "num_updates": "3400", "lr": "4.98549e-05", "gnorm": "2.237", "train_wall": "20", "wall": "1117"}
2021-10-22 22:13:45 | INFO | train_inner | {"epoch": 3, "update": 2.857, "loss": "2.448", "nll_loss": "0.572", "ppl": "1.49", "wps": "3033.3", "ups": "4.55", "wpb": "666.6", "bsz": "16", "num_updates": "3500", "lr": "4.98499e-05", "gnorm": "1.743", "train_wall": "22", "wall": "1139"}
2021-10-22 22:14:06 | INFO | train_inner | {"epoch": 3, "update": 2.939, "loss": "2.51", "nll_loss": "0.64", "ppl": "1.56", "wps": "2960.2", "ups": "4.77", "wpb": "620.4", "bsz": "16", "num_updates": "3600", "lr": "4.98449e-05", "gnorm": "2.228", "train_wall": "21", "wall": "1160"}
2021-10-22 22:14:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-22 22:17:39 | INFO | valid | {"epoch": 3, "valid_loss": "2.615", "valid_nll_loss": "0.622", "valid_ppl": "1.54", "valid_bleu": "51.82", "valid_wps": "439.6", "valid_wpb": "281.5", "valid_bsz": "8", "valid_num_updates": "3675", "valid_best_bleu": "51.82"}
2021-10-22 22:17:39 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-22 22:17:59 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/large/checkpoint_best.pt (epoch 3 @ 3675 updates, score 51.82) (writing took 20.341830197023228 seconds)
2021-10-22 22:17:59 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2021-10-22 22:17:59 | INFO | train | {"epoch": 3, "train_loss": "2.511", "train_nll_loss": "0.639", "train_ppl": "1.56", "train_wps": "1522.1", "train_ups": "2.59", "train_wpb": "586.8", "train_bsz": "16", "train_num_updates": "3675", "train_lr": "4.98412e-05", "train_gnorm": "2.076", "train_train_wall": "252", "train_wall": "1394"}
2021-10-22 22:17:59 | INFO | fairseq_cli.train | begin training epoch 3
2021-10-22 22:18:04 | INFO | train_inner | {"epoch": 4, "update": 3.02, "loss": "2.481", "nll_loss": "0.61", "ppl": "1.53", "wps": "238.2", "ups": "0.42", "wpb": "568.3", "bsz": "15.9", "num_updates": "3700", "lr": "4.98399e-05", "gnorm": "2.013", "train_wall": "21", "wall": "1399"}
2021-10-22 22:18:25 | INFO | train_inner | {"epoch": 4, "update": 3.102, "loss": "2.478", "nll_loss": "0.602", "ppl": "1.52", "wps": "2616.1", "ups": "4.76", "wpb": "549.5", "bsz": "16", "num_updates": "3800", "lr": "4.98349e-05", "gnorm": "2.045", "train_wall": "21", "wall": "1420"}
2021-10-22 22:18:47 | INFO | train_inner | {"epoch": 4, "update": 3.184, "loss": "2.48", "nll_loss": "0.605", "ppl": "1.52", "wps": "2699", "ups": "4.64", "wpb": "581.8", "bsz": "16", "num_updates": "3900", "lr": "4.98299e-05", "gnorm": "2.071", "train_wall": "21", "wall": "1441"}
2021-10-22 22:19:09 | INFO | train_inner | {"epoch": 4, "update": 3.265, "loss": "2.399", "nll_loss": "0.517", "ppl": "1.43", "wps": "2612.2", "ups": "4.44", "wpb": "588.4", "bsz": "16", "num_updates": "4000", "lr": "4.98249e-05", "gnorm": "2.112", "train_wall": "22", "wall": "1464"}
2021-10-22 22:19:29 | INFO | train_inner | {"epoch": 4, "update": 3.347, "loss": "2.385", "nll_loss": "0.501", "ppl": "1.42", "wps": "3165", "ups": "4.98", "wpb": "636.1", "bsz": "16", "num_updates": "4100", "lr": "4.98199e-05", "gnorm": "1.799", "train_wall": "20", "wall": "1484"}
2021-10-22 22:19:51 | INFO | train_inner | {"epoch": 4, "update": 3.429, "loss": "2.421", "nll_loss": "0.544", "ppl": "1.46", "wps": "3110.5", "ups": "4.65", "wpb": "668.8", "bsz": "16", "num_updates": "4200", "lr": "4.98149e-05", "gnorm": "1.869", "train_wall": "21", "wall": "1505"}
2021-10-22 22:20:11 | INFO | train_inner | {"epoch": 4, "update": 3.51, "loss": "2.441", "nll_loss": "0.566", "ppl": "1.48", "wps": "2796.7", "ups": "4.94", "wpb": "566.5", "bsz": "16", "num_updates": "4300", "lr": "4.98099e-05", "gnorm": "1.992", "train_wall": "20", "wall": "1525"}
2021-10-22 22:20:33 | INFO | train_inner | {"epoch": 4, "update": 3.592, "loss": "2.51", "nll_loss": "0.642", "ppl": "1.56", "wps": "2528", "ups": "4.49", "wpb": "563", "bsz": "16", "num_updates": "4400", "lr": "4.98049e-05", "gnorm": "2.115", "train_wall": "22", "wall": "1548"}
2021-10-22 22:20:52 | INFO | train_inner | {"epoch": 4, "update": 3.673, "loss": "2.453", "nll_loss": "0.579", "ppl": "1.49", "wps": "2811", "ups": "5.27", "wpb": "533.7", "bsz": "16", "num_updates": "4500", "lr": "4.97999e-05", "gnorm": "1.913", "train_wall": "19", "wall": "1567"}
2021-10-22 22:21:13 | INFO | train_inner | {"epoch": 4, "update": 3.755, "loss": "2.484", "nll_loss": "0.614", "ppl": "1.53", "wps": "2617.8", "ups": "4.85", "wpb": "539.5", "bsz": "16", "num_updates": "4600", "lr": "4.97949e-05", "gnorm": "2.185", "train_wall": "20", "wall": "1587"}
2021-10-22 22:21:34 | INFO | train_inner | {"epoch": 4, "update": 3.837, "loss": "2.439", "nll_loss": "0.565", "ppl": "1.48", "wps": "2870.4", "ups": "4.74", "wpb": "605.3", "bsz": "16", "num_updates": "4700", "lr": "4.97899e-05", "gnorm": "1.984", "train_wall": "21", "wall": "1608"}
2021-10-22 22:21:54 | INFO | train_inner | {"epoch": 4, "update": 3.918, "loss": "2.441", "nll_loss": "0.567", "ppl": "1.48", "wps": "2700.5", "ups": "4.88", "wpb": "552.8", "bsz": "16", "num_updates": "4800", "lr": "4.97849e-05", "gnorm": "2.092", "train_wall": "20", "wall": "1629"}
2021-10-22 22:22:17 | INFO | train_inner | {"epoch": 4, "update": 4.0, "loss": "2.406", "nll_loss": "0.53", "ppl": "1.44", "wps": "2990.9", "ups": "4.46", "wpb": "671.2", "bsz": "15.9", "num_updates": "4900", "lr": "4.97799e-05", "gnorm": "1.79", "train_wall": "22", "wall": "1651"}
2021-10-22 22:22:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-22 22:25:43 | INFO | valid | {"epoch": 4, "valid_loss": "2.601", "valid_nll_loss": "0.612", "valid_ppl": "1.53", "valid_bleu": "53.4", "valid_wps": "420.7", "valid_wpb": "281.5", "valid_bsz": "8", "valid_num_updates": "4900", "valid_best_bleu": "53.4"}
2021-10-22 22:25:43 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-22 22:26:08 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/large/checkpoint_best.pt (epoch 4 @ 4900 updates, score 53.4) (writing took 25.746513472055085 seconds)
2021-10-22 22:26:08 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2021-10-22 22:26:08 | INFO | train | {"epoch": 4, "train_loss": "2.443", "train_nll_loss": "0.567", "train_ppl": "1.48", "train_wps": "1468.9", "train_ups": "2.5", "train_wpb": "586.8", "train_bsz": "16", "train_num_updates": "4900", "train_lr": "4.97799e-05", "train_gnorm": "1.998", "train_train_wall": "255", "train_wall": "1883"}
2021-10-22 22:26:08 | INFO | fairseq_cli.train | begin training epoch 4
2021-10-22 22:26:31 | INFO | train_inner | {"epoch": 5, "update": 4.082, "loss": "2.359", "nll_loss": "0.474", "ppl": "1.39", "wps": "242.1", "ups": "0.39", "wpb": "614.3", "bsz": "16", "num_updates": "5000", "lr": "4.97749e-05", "gnorm": "1.801", "train_wall": "22", "wall": "1905"}
2021-10-22 22:26:52 | INFO | train_inner | {"epoch": 5, "update": 4.163, "loss": "2.398", "nll_loss": "0.515", "ppl": "1.43", "wps": "2521.4", "ups": "4.68", "wpb": "539.2", "bsz": "16", "num_updates": "5100", "lr": "4.97699e-05", "gnorm": "2.032", "train_wall": "21", "wall": "1926"}
2021-10-22 22:27:12 | INFO | train_inner | {"epoch": 5, "update": 4.245, "loss": "2.403", "nll_loss": "0.522", "ppl": "1.44", "wps": "2687.6", "ups": "4.94", "wpb": "544", "bsz": "16", "num_updates": "5200", "lr": "4.97649e-05", "gnorm": "1.908", "train_wall": "20", "wall": "1947"}
2021-10-22 22:27:35 | INFO | train_inner | {"epoch": 5, "update": 4.327, "loss": "2.364", "nll_loss": "0.479", "ppl": "1.39", "wps": "2826.7", "ups": "4.46", "wpb": "633.8", "bsz": "16", "num_updates": "5300", "lr": "4.97599e-05", "gnorm": "2.384", "train_wall": "22", "wall": "1969"}
2021-10-22 22:27:56 | INFO | train_inner | {"epoch": 5, "update": 4.408, "loss": "2.405", "nll_loss": "0.527", "ppl": "1.44", "wps": "2768", "ups": "4.59", "wpb": "603.3", "bsz": "16", "num_updates": "5400", "lr": "4.97549e-05", "gnorm": "1.906", "train_wall": "22", "wall": "1991"}
2021-10-22 22:28:17 | INFO | train_inner | {"epoch": 5, "update": 4.49, "loss": "2.409", "nll_loss": "0.53", "ppl": "1.44", "wps": "2499.1", "ups": "4.96", "wpb": "504", "bsz": "16", "num_updates": "5500", "lr": "4.97499e-05", "gnorm": "2.235", "train_wall": "20", "wall": "2011"}
2021-10-22 22:28:36 | INFO | train_inner | {"epoch": 5, "update": 4.571, "loss": "2.362", "nll_loss": "0.479", "ppl": "1.39", "wps": "2983.2", "ups": "5.09", "wpb": "585.8", "bsz": "16", "num_updates": "5600", "lr": "4.97449e-05", "gnorm": "1.969", "train_wall": "19", "wall": "2031"}
2021-10-22 22:28:57 | INFO | train_inner | {"epoch": 5, "update": 4.653, "loss": "2.388", "nll_loss": "0.51", "ppl": "1.42", "wps": "2831.5", "ups": "4.86", "wpb": "583", "bsz": "16", "num_updates": "5700", "lr": "4.97399e-05", "gnorm": "1.951", "train_wall": "20", "wall": "2051"}
2021-10-22 22:29:18 | INFO | train_inner | {"epoch": 5, "update": 4.735, "loss": "2.391", "nll_loss": "0.512", "ppl": "1.43", "wps": "2718", "ups": "4.72", "wpb": "576.1", "bsz": "16", "num_updates": "5800", "lr": "4.97349e-05", "gnorm": "1.934", "train_wall": "21", "wall": "2073"}
2021-10-22 22:29:39 | INFO | train_inner | {"epoch": 5, "update": 4.816, "loss": "2.38", "nll_loss": "0.5", "ppl": "1.41", "wps": "3080.9", "ups": "4.73", "wpb": "651.3", "bsz": "16", "num_updates": "5900", "lr": "4.97299e-05", "gnorm": "2.132", "train_wall": "21", "wall": "2094"}
2021-10-22 22:29:59 | INFO | train_inner | {"epoch": 5, "update": 4.898, "loss": "2.386", "nll_loss": "0.509", "ppl": "1.42", "wps": "2846.8", "ups": "4.94", "wpb": "576.5", "bsz": "16", "num_updates": "6000", "lr": "4.97249e-05", "gnorm": "2.062", "train_wall": "20", "wall": "2114"}
2021-10-22 22:30:20 | INFO | train_inner | {"epoch": 5, "update": 4.98, "loss": "2.4", "nll_loss": "0.523", "ppl": "1.44", "wps": "2801.2", "ups": "4.85", "wpb": "577.7", "bsz": "16", "num_updates": "6100", "lr": "4.97199e-05", "gnorm": "1.88", "train_wall": "20", "wall": "2135"}
2021-10-22 22:30:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-22 22:34:07 | INFO | valid | {"epoch": 5, "valid_loss": "2.59", "valid_nll_loss": "0.603", "valid_ppl": "1.52", "valid_bleu": "54.31", "valid_wps": "392", "valid_wpb": "281.5", "valid_bsz": "8", "valid_num_updates": "6125", "valid_best_bleu": "54.31"}
2021-10-22 22:34:07 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-22 22:34:33 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/large/checkpoint_best.pt (epoch 5 @ 6125 updates, score 54.31) (writing took 26.7076648339862 seconds)
2021-10-22 22:34:33 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2021-10-22 22:34:33 | INFO | train | {"epoch": 5, "train_loss": "2.386", "train_nll_loss": "0.506", "train_ppl": "1.42", "train_wps": "1423.6", "train_ups": "2.43", "train_wpb": "586.8", "train_bsz": "16", "train_num_updates": "6125", "train_lr": "4.97186e-05", "train_gnorm": "2.01", "train_train_wall": "254", "train_wall": "2388"}
2021-10-22 22:34:33 | INFO | fairseq_cli.train | begin training epoch 5
2021-10-22 22:34:50 | INFO | train_inner | {"epoch": 6, "update": 5.061, "loss": "2.353", "nll_loss": "0.467", "ppl": "1.38", "wps": "230.8", "ups": "0.37", "wpb": "621.9", "bsz": "15.9", "num_updates": "6200", "lr": "4.97149e-05", "gnorm": "1.914", "train_wall": "22", "wall": "2404"}
2021-10-22 22:35:11 | INFO | train_inner | {"epoch": 6, "update": 5.143, "loss": "2.342", "nll_loss": "0.455", "ppl": "1.37", "wps": "2781.2", "ups": "4.57", "wpb": "608.2", "bsz": "16", "num_updates": "6300", "lr": "4.97099e-05", "gnorm": "1.969", "train_wall": "22", "wall": "2426"}
2021-10-22 22:35:33 | INFO | train_inner | {"epoch": 6, "update": 5.224, "loss": "2.305", "nll_loss": "0.415", "ppl": "1.33", "wps": "2821.9", "ups": "4.67", "wpb": "604.4", "bsz": "16", "num_updates": "6400", "lr": "4.97049e-05", "gnorm": "1.791", "train_wall": "21", "wall": "2447"}
2021-10-22 22:35:53 | INFO | train_inner | {"epoch": 6, "update": 5.306, "loss": "2.39", "nll_loss": "0.507", "ppl": "1.42", "wps": "2443", "ups": "4.9", "wpb": "498.1", "bsz": "16", "num_updates": "6500", "lr": "4.96998e-05", "gnorm": "2.136", "train_wall": "20", "wall": "2468"}
2021-10-22 22:36:15 | INFO | train_inner | {"epoch": 6, "update": 5.388, "loss": "2.312", "nll_loss": "0.424", "ppl": "1.34", "wps": "2989.9", "ups": "4.61", "wpb": "648", "bsz": "16", "num_updates": "6600", "lr": "4.96948e-05", "gnorm": "2.206", "train_wall": "21", "wall": "2489"}
2021-10-22 22:36:36 | INFO | train_inner | {"epoch": 6, "update": 5.469, "loss": "2.326", "nll_loss": "0.439", "ppl": "1.36", "wps": "2756.2", "ups": "4.78", "wpb": "576.2", "bsz": "16", "num_updates": "6700", "lr": "4.96898e-05", "gnorm": "2.031", "train_wall": "21", "wall": "2510"}
2021-10-22 22:36:56 | INFO | train_inner | {"epoch": 6, "update": 5.551, "loss": "2.326", "nll_loss": "0.44", "ppl": "1.36", "wps": "2762.9", "ups": "4.95", "wpb": "557.8", "bsz": "16", "num_updates": "6800", "lr": "4.96848e-05", "gnorm": "1.728", "train_wall": "20", "wall": "2530"}
2021-10-22 22:37:17 | INFO | train_inner | {"epoch": 6, "update": 5.633, "loss": "2.372", "nll_loss": "0.489", "ppl": "1.4", "wps": "2789.3", "ups": "4.73", "wpb": "589.8", "bsz": "16", "num_updates": "6900", "lr": "4.96798e-05", "gnorm": "2.092", "train_wall": "21", "wall": "2552"}
2021-10-22 22:37:41 | INFO | train_inner | {"epoch": 6, "update": 5.714, "loss": "2.341", "nll_loss": "0.459", "ppl": "1.37", "wps": "2863.6", "ups": "4.28", "wpb": "669.4", "bsz": "16", "num_updates": "7000", "lr": "4.96748e-05", "gnorm": "1.912", "train_wall": "23", "wall": "2575"}
2021-10-22 22:38:01 | INFO | train_inner | {"epoch": 6, "update": 5.796, "loss": "2.362", "nll_loss": "0.48", "ppl": "1.4", "wps": "2640.6", "ups": "4.96", "wpb": "532.8", "bsz": "16", "num_updates": "7100", "lr": "4.96698e-05", "gnorm": "2.07", "train_wall": "20", "wall": "2595"}
2021-10-22 22:38:23 | INFO | train_inner | {"epoch": 6, "update": 5.878, "loss": "2.304", "nll_loss": "0.419", "ppl": "1.34", "wps": "2996.9", "ups": "4.53", "wpb": "662.1", "bsz": "16", "num_updates": "7200", "lr": "4.96648e-05", "gnorm": "1.88", "train_wall": "22", "wall": "2617"}
2021-10-22 22:38:44 | INFO | train_inner | {"epoch": 6, "update": 5.959, "loss": "2.401", "nll_loss": "0.522", "ppl": "1.44", "wps": "2381.2", "ups": "4.64", "wpb": "512.7", "bsz": "16", "num_updates": "7300", "lr": "4.96598e-05", "gnorm": "2.064", "train_wall": "21", "wall": "2639"}
2021-10-22 22:38:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-22 22:42:19 | INFO | valid | {"epoch": 6, "valid_loss": "2.586", "valid_nll_loss": "0.611", "valid_ppl": "1.53", "valid_bleu": "54.18", "valid_wps": "425", "valid_wpb": "281.5", "valid_bsz": "8", "valid_num_updates": "7350", "valid_best_bleu": "54.31"}
2021-10-22 22:42:19 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-22 22:42:26 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/large/checkpoint_last.pt (epoch 6 @ 7350 updates, score 54.18) (writing took 6.438910318072885 seconds)
2021-10-22 22:42:26 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2021-10-22 22:42:26 | INFO | train | {"epoch": 6, "train_loss": "2.34", "train_nll_loss": "0.455", "train_ppl": "1.37", "train_wps": "1522.3", "train_ups": "2.59", "train_wpb": "586.8", "train_bsz": "16", "train_num_updates": "7350", "train_lr": "4.96573e-05", "train_gnorm": "1.986", "train_train_wall": "259", "train_wall": "2860"}
2021-10-22 22:42:26 | INFO | fairseq_cli.train | begin training epoch 6
2021-10-22 22:42:36 | INFO | train_inner | {"epoch": 7, "update": 6.041, "loss": "2.302", "nll_loss": "0.414", "ppl": "1.33", "wps": "263.6", "ups": "0.43", "wpb": "611", "bsz": "15.9", "num_updates": "7400", "lr": "4.96548e-05", "gnorm": "2.016", "train_wall": "21", "wall": "2871"}
2021-10-22 22:42:57 | INFO | train_inner | {"epoch": 7, "update": 6.122, "loss": "2.271", "nll_loss": "0.378", "ppl": "1.3", "wps": "2634.6", "ups": "4.78", "wpb": "551.2", "bsz": "16", "num_updates": "7500", "lr": "4.96498e-05", "gnorm": "1.853", "train_wall": "21", "wall": "2892"}
2021-10-22 22:43:17 | INFO | train_inner | {"epoch": 7, "update": 6.204, "loss": "2.321", "nll_loss": "0.429", "ppl": "1.35", "wps": "2498.7", "ups": "4.96", "wpb": "503.4", "bsz": "16", "num_updates": "7600", "lr": "4.96448e-05", "gnorm": "2.317", "train_wall": "20", "wall": "2912"}
2021-10-22 22:43:38 | INFO | train_inner | {"epoch": 7, "update": 6.286, "loss": "2.339", "nll_loss": "0.451", "ppl": "1.37", "wps": "2610.8", "ups": "4.83", "wpb": "540.8", "bsz": "16", "num_updates": "7700", "lr": "4.96398e-05", "gnorm": "2.386", "train_wall": "20", "wall": "2932"}
2021-10-22 22:44:01 | INFO | train_inner | {"epoch": 7, "update": 6.367, "loss": "2.277", "nll_loss": "0.386", "ppl": "1.31", "wps": "2686.4", "ups": "4.33", "wpb": "621", "bsz": "16", "num_updates": "7800", "lr": "4.96348e-05", "gnorm": "1.818", "train_wall": "23", "wall": "2956"}
2021-10-22 22:44:24 | INFO | train_inner | {"epoch": 7, "update": 6.449, "loss": "2.269", "nll_loss": "0.379", "ppl": "1.3", "wps": "2838.1", "ups": "4.39", "wpb": "646.5", "bsz": "16", "num_updates": "7900", "lr": "4.96298e-05", "gnorm": "1.736", "train_wall": "23", "wall": "2978"}
2021-10-22 22:44:45 | INFO | train_inner | {"epoch": 7, "update": 6.531, "loss": "2.288", "nll_loss": "0.398", "ppl": "1.32", "wps": "2860.6", "ups": "4.8", "wpb": "595.5", "bsz": "16", "num_updates": "8000", "lr": "4.96248e-05", "gnorm": "1.871", "train_wall": "21", "wall": "2999"}
2021-10-22 22:45:06 | INFO | train_inner | {"epoch": 7, "update": 6.612, "loss": "2.292", "nll_loss": "0.403", "ppl": "1.32", "wps": "3312.3", "ups": "4.65", "wpb": "713", "bsz": "16", "num_updates": "8100", "lr": "4.96198e-05", "gnorm": "1.856", "train_wall": "21", "wall": "3021"}
2021-10-22 22:45:28 | INFO | train_inner | {"epoch": 7, "update": 6.694, "loss": "2.309", "nll_loss": "0.423", "ppl": "1.34", "wps": "2839.7", "ups": "4.6", "wpb": "617.2", "bsz": "16", "num_updates": "8200", "lr": "4.96148e-05", "gnorm": "1.855", "train_wall": "21", "wall": "3042"}
2021-10-22 22:45:48 | INFO | train_inner | {"epoch": 7, "update": 6.776, "loss": "2.317", "nll_loss": "0.43", "ppl": "1.35", "wps": "2748.6", "ups": "4.95", "wpb": "555.7", "bsz": "16", "num_updates": "8300", "lr": "4.96098e-05", "gnorm": "2.1", "train_wall": "20", "wall": "3063"}
2021-10-22 22:46:09 | INFO | train_inner | {"epoch": 7, "update": 6.857, "loss": "2.31", "nll_loss": "0.424", "ppl": "1.34", "wps": "2843.7", "ups": "4.8", "wpb": "592.1", "bsz": "16", "num_updates": "8400", "lr": "4.96048e-05", "gnorm": "2.068", "train_wall": "21", "wall": "3083"}
2021-10-22 22:46:29 | INFO | train_inner | {"epoch": 7, "update": 6.939, "loss": "2.294", "nll_loss": "0.405", "ppl": "1.32", "wps": "2596.6", "ups": "4.95", "wpb": "524.6", "bsz": "16", "num_updates": "8500", "lr": "4.95998e-05", "gnorm": "2.089", "train_wall": "20", "wall": "3104"}
2021-10-22 22:46:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-22 22:50:14 | INFO | valid | {"epoch": 7, "valid_loss": "2.612", "valid_nll_loss": "0.63", "valid_ppl": "1.55", "valid_bleu": "54.12", "valid_wps": "413.4", "valid_wpb": "281.5", "valid_bsz": "8", "valid_num_updates": "8575", "valid_best_bleu": "54.31"}
2021-10-22 22:50:14 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-22 22:50:21 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/large/checkpoint_last.pt (epoch 7 @ 8575 updates, score 54.12) (writing took 6.673499078024179 seconds)
2021-10-22 22:50:21 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2021-10-22 22:50:21 | INFO | train | {"epoch": 7, "train_loss": "2.299", "train_nll_loss": "0.41", "train_ppl": "1.33", "train_wps": "1512", "train_ups": "2.58", "train_wpb": "586.8", "train_bsz": "16", "train_num_updates": "8575", "train_lr": "4.9596e-05", "train_gnorm": "2.007", "train_train_wall": "256", "train_wall": "3335"}
2021-10-22 22:50:21 | INFO | fairseq_cli.train | begin training epoch 7
2021-10-22 22:50:26 | INFO | train_inner | {"epoch": 8, "update": 7.02, "loss": "2.304", "nll_loss": "0.415", "ppl": "1.33", "wps": "231", "ups": "0.42", "wpb": "547.5", "bsz": "15.9", "num_updates": "8600", "lr": "4.95948e-05", "gnorm": "2.033", "train_wall": "21", "wall": "3341"}
2021-10-22 22:50:49 | INFO | train_inner | {"epoch": 8, "update": 7.102, "loss": "2.256", "nll_loss": "0.361", "ppl": "1.28", "wps": "2928", "ups": "4.46", "wpb": "656", "bsz": "16", "num_updates": "8700", "lr": "4.95898e-05", "gnorm": "2.001", "train_wall": "22", "wall": "3363"}
2021-10-22 22:51:11 | INFO | train_inner | {"epoch": 8, "update": 7.184, "loss": "2.239", "nll_loss": "0.342", "ppl": "1.27", "wps": "2926.4", "ups": "4.45", "wpb": "657.4", "bsz": "16", "num_updates": "8800", "lr": "4.95848e-05", "gnorm": "1.79", "train_wall": "22", "wall": "3386"}
2021-10-22 22:51:32 | INFO | train_inner | {"epoch": 8, "update": 7.265, "loss": "2.248", "nll_loss": "0.354", "ppl": "1.28", "wps": "2594.4", "ups": "4.86", "wpb": "533.8", "bsz": "16", "num_updates": "8900", "lr": "4.95798e-05", "gnorm": "1.945", "train_wall": "20", "wall": "3406"}
2021-10-22 22:51:53 | INFO | train_inner | {"epoch": 8, "update": 7.347, "loss": "2.264", "nll_loss": "0.371", "ppl": "1.29", "wps": "2596.2", "ups": "4.74", "wpb": "548.1", "bsz": "16", "num_updates": "9000", "lr": "4.95748e-05", "gnorm": "1.894", "train_wall": "21", "wall": "3427"}
2021-10-22 22:52:13 | INFO | train_inner | {"epoch": 8, "update": 7.429, "loss": "2.249", "nll_loss": "0.355", "ppl": "1.28", "wps": "2809.6", "ups": "4.83", "wpb": "581.4", "bsz": "16", "num_updates": "9100", "lr": "4.95698e-05", "gnorm": "2.103", "train_wall": "20", "wall": "3448"}
2021-10-22 22:52:34 | INFO | train_inner | {"epoch": 8, "update": 7.51, "loss": "2.291", "nll_loss": "0.4", "ppl": "1.32", "wps": "2826", "ups": "4.98", "wpb": "567.5", "bsz": "16", "num_updates": "9200", "lr": "4.95648e-05", "gnorm": "2.155", "train_wall": "20", "wall": "3468"}
2021-10-22 22:52:52 | INFO | train_inner | {"epoch": 8, "update": 7.592, "loss": "2.266", "nll_loss": "0.373", "ppl": "1.29", "wps": "2876.3", "ups": "5.45", "wpb": "527.7", "bsz": "16", "num_updates": "9300", "lr": "4.95598e-05", "gnorm": "2.155", "train_wall": "18", "wall": "3486"}
2021-10-22 22:53:13 | INFO | train_inner | {"epoch": 8, "update": 7.673, "loss": "2.307", "nll_loss": "0.418", "ppl": "1.34", "wps": "2725.8", "ups": "4.76", "wpb": "572.1", "bsz": "16", "num_updates": "9400", "lr": "4.95548e-05", "gnorm": "1.893", "train_wall": "21", "wall": "3507"}
2021-10-22 22:53:33 | INFO | train_inner | {"epoch": 8, "update": 7.755, "loss": "2.269", "nll_loss": "0.376", "ppl": "1.3", "wps": "2822.9", "ups": "4.98", "wpb": "567.4", "bsz": "16", "num_updates": "9500", "lr": "4.95498e-05", "gnorm": "1.915", "train_wall": "20", "wall": "3527"}
2021-10-22 22:53:56 | INFO | train_inner | {"epoch": 8, "update": 7.837, "loss": "2.25", "nll_loss": "0.359", "ppl": "1.28", "wps": "2894.2", "ups": "4.3", "wpb": "673.7", "bsz": "16", "num_updates": "9600", "lr": "4.95448e-05", "gnorm": "1.919", "train_wall": "23", "wall": "3551"}
2021-10-22 22:54:18 | INFO | train_inner | {"epoch": 8, "update": 7.918, "loss": "2.262", "nll_loss": "0.371", "ppl": "1.29", "wps": "2716.6", "ups": "4.7", "wpb": "578.3", "bsz": "16", "num_updates": "9700", "lr": "4.95398e-05", "gnorm": "1.947", "train_wall": "21", "wall": "3572"}
2021-10-22 22:54:39 | INFO | train_inner | {"epoch": 8, "update": 8.0, "loss": "2.285", "nll_loss": "0.397", "ppl": "1.32", "wps": "2770.9", "ups": "4.63", "wpb": "598.4", "bsz": "15.9", "num_updates": "9800", "lr": "4.95348e-05", "gnorm": "2.38", "train_wall": "21", "wall": "3594"}
2021-10-22 22:54:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-22 22:58:02 | INFO | valid | {"epoch": 8, "valid_loss": "2.623", "valid_nll_loss": "0.642", "valid_ppl": "1.56", "valid_bleu": "53.08", "valid_wps": "427.1", "valid_wpb": "281.5", "valid_bsz": "8", "valid_num_updates": "9800", "valid_best_bleu": "54.31"}
2021-10-22 22:58:02 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-22 22:58:08 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/large/checkpoint_last.pt (epoch 8 @ 9800 updates, score 53.08) (writing took 6.69190263596829 seconds)
2021-10-22 22:58:08 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2021-10-22 22:58:08 | INFO | train | {"epoch": 8, "train_loss": "2.265", "train_nll_loss": "0.372", "train_ppl": "1.29", "train_wps": "1537.5", "train_ups": "2.62", "train_wpb": "586.8", "train_bsz": "16", "train_num_updates": "9800", "train_lr": "4.95348e-05", "train_gnorm": "2.003", "train_train_wall": "255", "train_wall": "3803"}
2021-10-22 22:58:08 | INFO | fairseq_cli.train | begin training epoch 8
2021-10-22 22:58:29 | INFO | train_inner | {"epoch": 9, "update": 8.082, "loss": "2.213", "nll_loss": "0.313", "ppl": "1.24", "wps": "256.8", "ups": "0.44", "wpb": "589.6", "bsz": "16", "num_updates": "9900", "lr": "4.95298e-05", "gnorm": "1.88", "train_wall": "20", "wall": "3823"}
2021-10-22 22:58:49 | INFO | train_inner | {"epoch": 9, "update": 8.163, "loss": "2.237", "nll_loss": "0.339", "ppl": "1.27", "wps": "2820", "ups": "4.84", "wpb": "583", "bsz": "16", "num_updates": "10000", "lr": "4.95248e-05", "gnorm": "2.128", "train_wall": "20", "wall": "3844"}
2021-10-22 22:59:08 | INFO | train_inner | {"epoch": 9, "update": 8.245, "loss": "2.261", "nll_loss": "0.363", "ppl": "1.29", "wps": "2547.9", "ups": "5.43", "wpb": "469.3", "bsz": "16", "num_updates": "10100", "lr": "4.95198e-05", "gnorm": "2.041", "train_wall": "18", "wall": "3862"}
2021-10-22 22:59:28 | INFO | train_inner | {"epoch": 9, "update": 8.327, "loss": "2.219", "nll_loss": "0.322", "ppl": "1.25", "wps": "3142.2", "ups": "4.87", "wpb": "645", "bsz": "16", "num_updates": "10200", "lr": "4.95148e-05", "gnorm": "1.778", "train_wall": "20", "wall": "3883"}
2021-10-22 22:59:48 | INFO | train_inner | {"epoch": 9, "update": 8.408, "loss": "2.245", "nll_loss": "0.348", "ppl": "1.27", "wps": "2752.1", "ups": "5.21", "wpb": "528", "bsz": "16", "num_updates": "10300", "lr": "4.95098e-05", "gnorm": "2.055", "train_wall": "19", "wall": "3902"}
2021-10-22 23:00:08 | INFO | train_inner | {"epoch": 9, "update": 8.49, "loss": "2.25", "nll_loss": "0.355", "ppl": "1.28", "wps": "2477.4", "ups": "4.86", "wpb": "509.9", "bsz": "16", "num_updates": "10400", "lr": "4.95048e-05", "gnorm": "2.051", "train_wall": "20", "wall": "3923"}
2021-10-22 23:00:30 | INFO | train_inner | {"epoch": 9, "update": 8.571, "loss": "2.236", "nll_loss": "0.341", "ppl": "1.27", "wps": "2591.5", "ups": "4.55", "wpb": "569.9", "bsz": "16", "num_updates": "10500", "lr": "4.94997e-05", "gnorm": "1.895", "train_wall": "22", "wall": "3945"}
2021-10-22 23:00:53 | INFO | train_inner | {"epoch": 9, "update": 8.653, "loss": "2.221", "nll_loss": "0.327", "ppl": "1.25", "wps": "2840.2", "ups": "4.38", "wpb": "648.8", "bsz": "16", "num_updates": "10600", "lr": "4.94947e-05", "gnorm": "1.775", "train_wall": "23", "wall": "3967"}
2021-10-22 23:01:14 | INFO | train_inner | {"epoch": 9, "update": 8.735, "loss": "2.238", "nll_loss": "0.344", "ppl": "1.27", "wps": "3174.7", "ups": "4.66", "wpb": "681.5", "bsz": "16", "num_updates": "10700", "lr": "4.94897e-05", "gnorm": "1.766", "train_wall": "21", "wall": "3989"}
2021-10-22 23:01:36 | INFO | train_inner | {"epoch": 9, "update": 8.816, "loss": "2.258", "nll_loss": "0.364", "ppl": "1.29", "wps": "2870.6", "ups": "4.56", "wpb": "629.9", "bsz": "16", "num_updates": "10800", "lr": "4.94847e-05", "gnorm": "1.965", "train_wall": "22", "wall": "4011"}
2021-10-22 23:01:57 | INFO | train_inner | {"epoch": 9, "update": 8.898, "loss": "2.241", "nll_loss": "0.347", "ppl": "1.27", "wps": "2825.9", "ups": "4.89", "wpb": "578", "bsz": "16", "num_updates": "10900", "lr": "4.94797e-05", "gnorm": "1.951", "train_wall": "20", "wall": "4031"}
2021-10-22 23:02:18 | INFO | train_inner | {"epoch": 9, "update": 8.98, "loss": "2.226", "nll_loss": "0.332", "ppl": "1.26", "wps": "2911.6", "ups": "4.66", "wpb": "624.2", "bsz": "16", "num_updates": "11000", "lr": "4.94747e-05", "gnorm": "1.916", "train_wall": "21", "wall": "4053"}
2021-10-22 23:02:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-22 23:05:48 | INFO | valid | {"epoch": 9, "valid_loss": "2.627", "valid_nll_loss": "0.663", "valid_ppl": "1.58", "valid_bleu": "54.98", "valid_wps": "423.4", "valid_wpb": "281.5", "valid_bsz": "8", "valid_num_updates": "11025", "valid_best_bleu": "54.98"}
2021-10-22 23:05:48 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-22 23:06:08 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/large/checkpoint_best.pt (epoch 9 @ 11025 updates, score 54.98) (writing took 20.251891484949738 seconds)
2021-10-22 23:06:08 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2021-10-22 23:06:08 | INFO | train | {"epoch": 9, "train_loss": "2.237", "train_nll_loss": "0.341", "train_ppl": "1.27", "train_wps": "1499.1", "train_ups": "2.55", "train_wpb": "586.8", "train_bsz": "16", "train_num_updates": "11025", "train_lr": "4.94735e-05", "train_gnorm": "1.931", "train_train_wall": "252", "train_wall": "4282"}
2021-10-22 23:06:08 | INFO | fairseq_cli.train | begin training epoch 9
2021-10-22 23:06:24 | INFO | train_inner | {"epoch": 10, "update": 9.061, "loss": "2.205", "nll_loss": "0.306", "ppl": "1.24", "wps": "235.9", "ups": "0.41", "wpb": "580.3", "bsz": "15.9", "num_updates": "11100", "lr": "4.94697e-05", "gnorm": "1.805", "train_wall": "21", "wall": "4299"}
2021-10-22 23:06:46 | INFO | train_inner | {"epoch": 10, "update": 9.143, "loss": "2.226", "nll_loss": "0.326", "ppl": "1.25", "wps": "2507.1", "ups": "4.52", "wpb": "554.9", "bsz": "16", "num_updates": "11200", "lr": "4.94647e-05", "gnorm": "1.866", "train_wall": "22", "wall": "4321"}
2021-10-22 23:07:07 | INFO | train_inner | {"epoch": 10, "update": 9.224, "loss": "2.193", "nll_loss": "0.293", "ppl": "1.23", "wps": "2714", "ups": "4.88", "wpb": "555.9", "bsz": "16", "num_updates": "11300", "lr": "4.94597e-05", "gnorm": "1.862", "train_wall": "20", "wall": "4341"}
2021-10-22 23:07:29 | INFO | train_inner | {"epoch": 10, "update": 9.306, "loss": "2.193", "nll_loss": "0.296", "ppl": "1.23", "wps": "3000.5", "ups": "4.64", "wpb": "646.5", "bsz": "16", "num_updates": "11400", "lr": "4.94547e-05", "gnorm": "1.791", "train_wall": "21", "wall": "4363"}
2021-10-22 23:07:49 | INFO | train_inner | {"epoch": 10, "update": 9.388, "loss": "2.21", "nll_loss": "0.31", "ppl": "1.24", "wps": "2662.5", "ups": "4.86", "wpb": "548", "bsz": "16", "num_updates": "11500", "lr": "4.94497e-05", "gnorm": "1.845", "train_wall": "20", "wall": "4384"}
2021-10-22 23:08:11 | INFO | train_inner | {"epoch": 10, "update": 9.469, "loss": "2.208", "nll_loss": "0.312", "ppl": "1.24", "wps": "2909.4", "ups": "4.65", "wpb": "626", "bsz": "16", "num_updates": "11600", "lr": "4.94447e-05", "gnorm": "1.931", "train_wall": "21", "wall": "4405"}
2021-10-22 23:08:32 | INFO | train_inner | {"epoch": 10, "update": 9.551, "loss": "2.193", "nll_loss": "0.296", "ppl": "1.23", "wps": "2990.9", "ups": "4.62", "wpb": "647.6", "bsz": "16", "num_updates": "11700", "lr": "4.94397e-05", "gnorm": "2.115", "train_wall": "21", "wall": "4427"}
2021-10-22 23:08:53 | INFO | train_inner | {"epoch": 10, "update": 9.633, "loss": "2.225", "nll_loss": "0.328", "ppl": "1.26", "wps": "2697.2", "ups": "4.8", "wpb": "562.3", "bsz": "16", "num_updates": "11800", "lr": "4.94347e-05", "gnorm": "1.984", "train_wall": "21", "wall": "4448"}
2021-10-22 23:09:13 | INFO | train_inner | {"epoch": 10, "update": 9.714, "loss": "2.245", "nll_loss": "0.347", "ppl": "1.27", "wps": "2588.4", "ups": "5.09", "wpb": "508.1", "bsz": "16", "num_updates": "11900", "lr": "4.94297e-05", "gnorm": "2.014", "train_wall": "19", "wall": "4467"}
2021-10-22 23:09:34 | INFO | train_inner | {"epoch": 10, "update": 9.796, "loss": "2.237", "nll_loss": "0.341", "ppl": "1.27", "wps": "2576.7", "ups": "4.81", "wpb": "535.1", "bsz": "16", "num_updates": "12000", "lr": "4.94247e-05", "gnorm": "2.008", "train_wall": "21", "wall": "4488"}
2021-10-22 23:09:55 | INFO | train_inner | {"epoch": 10, "update": 9.878, "loss": "2.246", "nll_loss": "0.352", "ppl": "1.28", "wps": "2662.2", "ups": "4.67", "wpb": "569.6", "bsz": "16", "num_updates": "12100", "lr": "4.94197e-05", "gnorm": "1.954", "train_wall": "21", "wall": "4509"}
2021-10-22 23:10:18 | INFO | train_inner | {"epoch": 10, "update": 9.959, "loss": "2.194", "nll_loss": "0.298", "ppl": "1.23", "wps": "2970.3", "ups": "4.25", "wpb": "699.2", "bsz": "16", "num_updates": "12200", "lr": "4.94147e-05", "gnorm": "1.651", "train_wall": "23", "wall": "4533"}
2021-10-22 23:10:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-22 23:13:47 | INFO | valid | {"epoch": 10, "valid_loss": "2.64", "valid_nll_loss": "0.68", "valid_ppl": "1.6", "valid_bleu": "54.11", "valid_wps": "433.2", "valid_wpb": "281.5", "valid_bsz": "8", "valid_num_updates": "12250", "valid_best_bleu": "54.98"}
2021-10-22 23:13:47 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-22 23:13:54 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/large/checkpoint_last.pt (epoch 10 @ 12250 updates, score 54.11) (writing took 6.614228026010096 seconds)
2021-10-22 23:13:54 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2021-10-22 23:13:54 | INFO | train | {"epoch": 10, "train_loss": "2.212", "train_nll_loss": "0.314", "train_ppl": "1.24", "train_wps": "1542", "train_ups": "2.63", "train_wpb": "586.8", "train_bsz": "16", "train_num_updates": "12250", "train_lr": "4.94122e-05", "train_gnorm": "1.895", "train_train_wall": "257", "train_wall": "4749"}
2021-10-22 23:13:54 | INFO | fairseq_cli.train | begin training epoch 10
2021-10-22 23:14:05 | INFO | train_inner | {"epoch": 11, "update": 10.041, "loss": "2.191", "nll_loss": "0.292", "ppl": "1.22", "wps": "242", "ups": "0.44", "wpb": "547.6", "bsz": "15.9", "num_updates": "12300", "lr": "4.94097e-05", "gnorm": "1.643", "train_wall": "19", "wall": "4759"}
2021-10-22 23:14:25 | INFO | train_inner | {"epoch": 11, "update": 10.122, "loss": "2.189", "nll_loss": "0.29", "ppl": "1.22", "wps": "2874.5", "ups": "4.91", "wpb": "585.8", "bsz": "16", "num_updates": "12400", "lr": "4.94047e-05", "gnorm": "1.549", "train_wall": "20", "wall": "4780"}
2021-10-22 23:14:47 | INFO | train_inner | {"epoch": 11, "update": 10.204, "loss": "2.182", "nll_loss": "0.283", "ppl": "1.22", "wps": "2873.1", "ups": "4.61", "wpb": "623.3", "bsz": "16", "num_updates": "12500", "lr": "4.93997e-05", "gnorm": "1.663", "train_wall": "21", "wall": "4801"}
2021-10-22 23:15:09 | INFO | train_inner | {"epoch": 11, "update": 10.286, "loss": "2.181", "nll_loss": "0.28", "ppl": "1.21", "wps": "2821.8", "ups": "4.61", "wpb": "612.8", "bsz": "16", "num_updates": "12600", "lr": "4.93947e-05", "gnorm": "1.736", "train_wall": "21", "wall": "4823"}
2021-10-22 23:15:31 | INFO | train_inner | {"epoch": 11, "update": 10.367, "loss": "2.188", "nll_loss": "0.29", "ppl": "1.22", "wps": "2548.5", "ups": "4.39", "wpb": "580", "bsz": "16", "num_updates": "12700", "lr": "4.93897e-05", "gnorm": "1.837", "train_wall": "23", "wall": "4846"}
2021-10-22 23:15:51 | INFO | train_inner | {"epoch": 11, "update": 10.449, "loss": "2.192", "nll_loss": "0.293", "ppl": "1.22", "wps": "2627.4", "ups": "4.98", "wpb": "528", "bsz": "16", "num_updates": "12800", "lr": "4.93847e-05", "gnorm": "1.914", "train_wall": "20", "wall": "4866"}
2021-10-22 23:16:13 | INFO | train_inner | {"epoch": 11, "update": 10.531, "loss": "2.194", "nll_loss": "0.295", "ppl": "1.23", "wps": "2678.7", "ups": "4.69", "wpb": "571.7", "bsz": "16", "num_updates": "12900", "lr": "4.93797e-05", "gnorm": "1.747", "train_wall": "21", "wall": "4887"}
2021-10-22 23:16:34 | INFO | train_inner | {"epoch": 11, "update": 10.612, "loss": "2.207", "nll_loss": "0.308", "ppl": "1.24", "wps": "2635.3", "ups": "4.77", "wpb": "552.8", "bsz": "16", "num_updates": "13000", "lr": "4.93747e-05", "gnorm": "1.949", "train_wall": "21", "wall": "4908"}
2021-10-22 23:16:55 | INFO | train_inner | {"epoch": 11, "update": 10.694, "loss": "2.211", "nll_loss": "0.312", "ppl": "1.24", "wps": "2852.2", "ups": "4.73", "wpb": "603.4", "bsz": "16", "num_updates": "13100", "lr": "4.93697e-05", "gnorm": "1.764", "train_wall": "21", "wall": "4929"}
2021-10-22 23:17:17 | INFO | train_inner | {"epoch": 11, "update": 10.776, "loss": "2.175", "nll_loss": "0.277", "ppl": "1.21", "wps": "3145.3", "ups": "4.57", "wpb": "688.1", "bsz": "16", "num_updates": "13200", "lr": "4.93647e-05", "gnorm": "1.778", "train_wall": "22", "wall": "4951"}
2021-10-22 23:17:37 | INFO | train_inner | {"epoch": 11, "update": 10.857, "loss": "2.206", "nll_loss": "0.306", "ppl": "1.24", "wps": "2733.5", "ups": "4.91", "wpb": "557.1", "bsz": "16", "num_updates": "13300", "lr": "4.93597e-05", "gnorm": "2.011", "train_wall": "20", "wall": "4972"}
2021-10-22 23:17:58 | INFO | train_inner | {"epoch": 11, "update": 10.939, "loss": "2.193", "nll_loss": "0.295", "ppl": "1.23", "wps": "2911.6", "ups": "4.73", "wpb": "616.1", "bsz": "16", "num_updates": "13400", "lr": "4.93547e-05", "gnorm": "1.776", "train_wall": "21", "wall": "4993"}
2021-10-22 23:18:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-22 23:21:47 | INFO | valid | {"epoch": 11, "valid_loss": "2.656", "valid_nll_loss": "0.695", "valid_ppl": "1.62", "valid_bleu": "55.03", "valid_wps": "403.4", "valid_wpb": "281.5", "valid_bsz": "8", "valid_num_updates": "13475", "valid_best_bleu": "55.03"}
2021-10-22 23:21:47 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-22 23:22:12 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/large/checkpoint_best.pt (epoch 11 @ 13475 updates, score 55.03) (writing took 25.126949480036274 seconds)
2021-10-22 23:22:12 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2021-10-22 23:22:12 | INFO | train | {"epoch": 11, "train_loss": "2.192", "train_nll_loss": "0.293", "train_ppl": "1.23", "train_wps": "1442.3", "train_ups": "2.46", "train_wpb": "586.8", "train_bsz": "16", "train_num_updates": "13475", "train_lr": "4.93509e-05", "train_gnorm": "1.784", "train_train_wall": "256", "train_wall": "5247"}
2021-10-22 23:22:12 | INFO | fairseq_cli.train | begin training epoch 11
2021-10-22 23:22:18 | INFO | train_inner | {"epoch": 12, "update": 11.02, "loss": "2.186", "nll_loss": "0.288", "ppl": "1.22", "wps": "207.1", "ups": "0.39", "wpb": "537.3", "bsz": "15.9", "num_updates": "13500", "lr": "4.93497e-05", "gnorm": "1.717", "train_wall": "19", "wall": "5252"}
2021-10-22 23:22:40 | INFO | train_inner | {"epoch": 12, "update": 11.102, "loss": "2.178", "nll_loss": "0.275", "ppl": "1.21", "wps": "2698.8", "ups": "4.47", "wpb": "603.7", "bsz": "16", "num_updates": "13600", "lr": "4.93447e-05", "gnorm": "1.69", "train_wall": "22", "wall": "5275"}
2021-10-22 23:23:01 | INFO | train_inner | {"epoch": 12, "update": 11.184, "loss": "2.17", "nll_loss": "0.269", "ppl": "1.2", "wps": "2789.9", "ups": "4.79", "wpb": "582.4", "bsz": "16", "num_updates": "13700", "lr": "4.93397e-05", "gnorm": "1.68", "train_wall": "21", "wall": "5295"}
2021-10-22 23:23:22 | INFO | train_inner | {"epoch": 12, "update": 11.265, "loss": "2.166", "nll_loss": "0.265", "ppl": "1.2", "wps": "2746.8", "ups": "4.65", "wpb": "590.4", "bsz": "16", "num_updates": "13800", "lr": "4.93347e-05", "gnorm": "1.645", "train_wall": "21", "wall": "5317"}
2021-10-22 23:23:44 | INFO | train_inner | {"epoch": 12, "update": 11.347, "loss": "2.182", "nll_loss": "0.281", "ppl": "1.21", "wps": "2455", "ups": "4.54", "wpb": "540.4", "bsz": "16", "num_updates": "13900", "lr": "4.93297e-05", "gnorm": "1.986", "train_wall": "22", "wall": "5339"}
2021-10-22 23:24:06 | INFO | train_inner | {"epoch": 12, "update": 11.429, "loss": "2.18", "nll_loss": "0.279", "ppl": "1.21", "wps": "2598.6", "ups": "4.58", "wpb": "567.1", "bsz": "16", "num_updates": "14000", "lr": "4.93247e-05", "gnorm": "1.814", "train_wall": "22", "wall": "5361"}
2021-10-22 23:24:26 | INFO | train_inner | {"epoch": 12, "update": 11.51, "loss": "2.177", "nll_loss": "0.277", "ppl": "1.21", "wps": "2745", "ups": "5.02", "wpb": "547.3", "bsz": "16", "num_updates": "14100", "lr": "4.93197e-05", "gnorm": "1.776", "train_wall": "20", "wall": "5381"}
2021-10-22 23:24:47 | INFO | train_inner | {"epoch": 12, "update": 11.592, "loss": "2.174", "nll_loss": "0.276", "ppl": "1.21", "wps": "2823.6", "ups": "4.72", "wpb": "597.6", "bsz": "16", "num_updates": "14200", "lr": "4.93147e-05", "gnorm": "1.654", "train_wall": "21", "wall": "5402"}
2021-10-22 23:25:10 | INFO | train_inner | {"epoch": 12, "update": 11.673, "loss": "2.175", "nll_loss": "0.277", "ppl": "1.21", "wps": "3251", "ups": "4.45", "wpb": "730.2", "bsz": "16", "num_updates": "14300", "lr": "4.93097e-05", "gnorm": "1.816", "train_wall": "22", "wall": "5424"}
2021-10-22 23:25:31 | INFO | train_inner | {"epoch": 12, "update": 11.755, "loss": "2.175", "nll_loss": "0.277", "ppl": "1.21", "wps": "2647.7", "ups": "4.73", "wpb": "560.1", "bsz": "16", "num_updates": "14400", "lr": "4.93047e-05", "gnorm": "1.715", "train_wall": "21", "wall": "5445"}
2021-10-22 23:25:54 | INFO | train_inner | {"epoch": 12, "update": 11.837, "loss": "2.181", "nll_loss": "0.282", "ppl": "1.22", "wps": "2653.5", "ups": "4.45", "wpb": "596.9", "bsz": "16", "num_updates": "14500", "lr": "4.92996e-05", "gnorm": "1.789", "train_wall": "22", "wall": "5468"}
2021-10-22 23:26:16 | INFO | train_inner | {"epoch": 12, "update": 11.918, "loss": "2.181", "nll_loss": "0.285", "ppl": "1.22", "wps": "2639.7", "ups": "4.49", "wpb": "588.2", "bsz": "16", "num_updates": "14600", "lr": "4.92946e-05", "gnorm": "1.781", "train_wall": "22", "wall": "5490"}
2021-10-22 23:26:36 | INFO | train_inner | {"epoch": 12, "update": 12.0, "loss": "2.189", "nll_loss": "0.29", "ppl": "1.22", "wps": "2671.5", "ups": "4.83", "wpb": "552.6", "bsz": "15.9", "num_updates": "14700", "lr": "4.92896e-05", "gnorm": "1.74", "train_wall": "20", "wall": "5511"}
2021-10-22 23:26:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-22 23:30:15 | INFO | valid | {"epoch": 12, "valid_loss": "2.665", "valid_nll_loss": "0.707", "valid_ppl": "1.63", "valid_bleu": "54.53", "valid_wps": "396", "valid_wpb": "281.5", "valid_bsz": "8", "valid_num_updates": "14700", "valid_best_bleu": "55.03"}
2021-10-22 23:30:15 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-22 23:30:22 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/large/checkpoint_last.pt (epoch 12 @ 14700 updates, score 54.53) (writing took 6.728858213988133 seconds)
2021-10-22 23:30:22 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2021-10-22 23:30:22 | INFO | train | {"epoch": 12, "train_loss": "2.177", "train_nll_loss": "0.277", "train_ppl": "1.21", "train_wps": "1469.1", "train_ups": "2.5", "train_wpb": "586.8", "train_bsz": "16", "train_num_updates": "14700", "train_lr": "4.92896e-05", "train_gnorm": "1.753", "train_train_wall": "261", "train_wall": "5736"}
2021-10-22 23:30:22 | INFO | fairseq_cli.train | begin training epoch 12
2021-10-22 23:30:42 | INFO | train_inner | {"epoch": 13, "update": 12.082, "loss": "2.161", "nll_loss": "0.259", "ppl": "1.2", "wps": "218.9", "ups": "0.41", "wpb": "537", "bsz": "16", "num_updates": "14800", "lr": "4.92846e-05", "gnorm": "1.617", "train_wall": "20", "wall": "5756"}
2021-10-22 23:31:02 | INFO | train_inner | {"epoch": 13, "update": 12.163, "loss": "2.167", "nll_loss": "0.266", "ppl": "1.2", "wps": "2655.7", "ups": "4.95", "wpb": "536.8", "bsz": "16", "num_updates": "14900", "lr": "4.92796e-05", "gnorm": "1.659", "train_wall": "20", "wall": "5777"}
2021-10-22 23:31:23 | INFO | train_inner | {"epoch": 13, "update": 12.245, "loss": "2.174", "nll_loss": "0.271", "ppl": "1.21", "wps": "2654.8", "ups": "4.88", "wpb": "544", "bsz": "16", "num_updates": "15000", "lr": "4.92746e-05", "gnorm": "1.797", "train_wall": "20", "wall": "5797"}
2021-10-22 23:31:45 | INFO | train_inner | {"epoch": 13, "update": 12.327, "loss": "2.149", "nll_loss": "0.248", "ppl": "1.19", "wps": "2799.3", "ups": "4.5", "wpb": "621.9", "bsz": "16", "num_updates": "15100", "lr": "4.92696e-05", "gnorm": "1.544", "train_wall": "22", "wall": "5819"}
2021-10-22 23:32:06 | INFO | train_inner | {"epoch": 13, "update": 12.408, "loss": "2.159", "nll_loss": "0.259", "ppl": "1.2", "wps": "2733", "ups": "4.76", "wpb": "573.6", "bsz": "16", "num_updates": "15200", "lr": "4.92646e-05", "gnorm": "1.724", "train_wall": "21", "wall": "5840"}
2021-10-22 23:32:24 | INFO | train_inner | {"epoch": 13, "update": 12.49, "loss": "2.162", "nll_loss": "0.261", "ppl": "1.2", "wps": "2889.7", "ups": "5.37", "wpb": "538", "bsz": "16", "num_updates": "15300", "lr": "4.92596e-05", "gnorm": "1.692", "train_wall": "18", "wall": "5859"}
2021-10-22 23:32:45 | INFO | train_inner | {"epoch": 13, "update": 12.571, "loss": "2.173", "nll_loss": "0.271", "ppl": "1.21", "wps": "2674.6", "ups": "4.79", "wpb": "558.4", "bsz": "16", "num_updates": "15400", "lr": "4.92546e-05", "gnorm": "1.637", "train_wall": "21", "wall": "5880"}
2021-10-22 23:33:06 | INFO | train_inner | {"epoch": 13, "update": 12.653, "loss": "2.163", "nll_loss": "0.263", "ppl": "1.2", "wps": "2927.1", "ups": "4.8", "wpb": "609.4", "bsz": "16", "num_updates": "15500", "lr": "4.92496e-05", "gnorm": "1.896", "train_wall": "21", "wall": "5901"}
2021-10-22 23:33:27 | INFO | train_inner | {"epoch": 13, "update": 12.735, "loss": "2.158", "nll_loss": "0.258", "ppl": "1.2", "wps": "2715.7", "ups": "4.74", "wpb": "572.6", "bsz": "16", "num_updates": "15600", "lr": "4.92446e-05", "gnorm": "1.74", "train_wall": "21", "wall": "5922"}
2021-10-22 23:33:49 | INFO | train_inner | {"epoch": 13, "update": 12.816, "loss": "2.166", "nll_loss": "0.267", "ppl": "1.2", "wps": "2617.4", "ups": "4.53", "wpb": "577.2", "bsz": "16", "num_updates": "15700", "lr": "4.92396e-05", "gnorm": "1.667", "train_wall": "22", "wall": "5944"}
2021-10-22 23:34:13 | INFO | train_inner | {"epoch": 13, "update": 12.898, "loss": "2.161", "nll_loss": "0.265", "ppl": "1.2", "wps": "3173.3", "ups": "4.21", "wpb": "754", "bsz": "16", "num_updates": "15800", "lr": "4.92346e-05", "gnorm": "1.632", "train_wall": "24", "wall": "5967"}
2021-10-22 23:34:33 | INFO | train_inner | {"epoch": 13, "update": 12.98, "loss": "2.171", "nll_loss": "0.272", "ppl": "1.21", "wps": "3081.7", "ups": "5.11", "wpb": "603", "bsz": "16", "num_updates": "15900", "lr": "4.92296e-05", "gnorm": "1.741", "train_wall": "19", "wall": "5987"}
2021-10-22 23:34:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-22 23:38:05 | INFO | valid | {"epoch": 13, "valid_loss": "2.666", "valid_nll_loss": "0.711", "valid_ppl": "1.64", "valid_bleu": "54.61", "valid_wps": "416.8", "valid_wpb": "281.5", "valid_bsz": "8", "valid_num_updates": "15925", "valid_best_bleu": "55.03"}
2021-10-22 23:38:05 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-22 23:38:17 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/large/checkpoint_last.pt (epoch 13 @ 15925 updates, score 54.61) (writing took 11.638999363058247 seconds)
2021-10-22 23:38:17 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2021-10-22 23:38:17 | INFO | train | {"epoch": 13, "train_loss": "2.163", "train_nll_loss": "0.263", "train_ppl": "1.2", "train_wps": "1512.9", "train_ups": "2.58", "train_wpb": "586.8", "train_bsz": "16", "train_num_updates": "15925", "train_lr": "4.92284e-05", "train_gnorm": "1.698", "train_train_wall": "253", "train_wall": "6211"}
2021-10-22 23:38:17 | INFO | fairseq_cli.train | begin training epoch 13
2021-10-22 23:38:34 | INFO | train_inner | {"epoch": 14, "update": 13.061, "loss": "2.144", "nll_loss": "0.244", "ppl": "1.18", "wps": "282.5", "ups": "0.41", "wpb": "682.2", "bsz": "15.9", "num_updates": "16000", "lr": "4.92246e-05", "gnorm": "1.607", "train_wall": "22", "wall": "6229"}
2021-10-22 23:38:55 | INFO | train_inner | {"epoch": 14, "update": 13.143, "loss": "2.143", "nll_loss": "0.242", "ppl": "1.18", "wps": "2657.8", "ups": "4.77", "wpb": "556.8", "bsz": "16", "num_updates": "16100", "lr": "4.92196e-05", "gnorm": "1.737", "train_wall": "21", "wall": "6249"}
2021-10-22 23:39:17 | INFO | train_inner | {"epoch": 14, "update": 13.224, "loss": "2.154", "nll_loss": "0.252", "ppl": "1.19", "wps": "2889.8", "ups": "4.65", "wpb": "621.6", "bsz": "16", "num_updates": "16200", "lr": "4.92146e-05", "gnorm": "1.592", "train_wall": "21", "wall": "6271"}
2021-10-22 23:39:38 | INFO | train_inner | {"epoch": 14, "update": 13.306, "loss": "2.151", "nll_loss": "0.248", "ppl": "1.19", "wps": "2478", "ups": "4.6", "wpb": "539.2", "bsz": "16", "num_updates": "16300", "lr": "4.92096e-05", "gnorm": "1.544", "train_wall": "22", "wall": "6293"}
2021-10-22 23:40:00 | INFO | train_inner | {"epoch": 14, "update": 13.388, "loss": "2.155", "nll_loss": "0.256", "ppl": "1.19", "wps": "2802.3", "ups": "4.64", "wpb": "603.9", "bsz": "16", "num_updates": "16400", "lr": "4.92046e-05", "gnorm": "2.063", "train_wall": "21", "wall": "6314"}
2021-10-22 23:40:21 | INFO | train_inner | {"epoch": 14, "update": 13.469, "loss": "2.148", "nll_loss": "0.248", "ppl": "1.19", "wps": "2725", "ups": "4.77", "wpb": "571.6", "bsz": "16", "num_updates": "16500", "lr": "4.91996e-05", "gnorm": "1.664", "train_wall": "21", "wall": "6335"}
2021-10-22 23:40:42 | INFO | train_inner | {"epoch": 14, "update": 13.551, "loss": "2.153", "nll_loss": "0.251", "ppl": "1.19", "wps": "2675.6", "ups": "4.77", "wpb": "560.8", "bsz": "16", "num_updates": "16600", "lr": "4.91946e-05", "gnorm": "1.848", "train_wall": "21", "wall": "6356"}
2021-10-22 23:41:02 | INFO | train_inner | {"epoch": 14, "update": 13.633, "loss": "2.148", "nll_loss": "0.248", "ppl": "1.19", "wps": "2941.4", "ups": "4.83", "wpb": "608.8", "bsz": "16", "num_updates": "16700", "lr": "4.91896e-05", "gnorm": "1.59", "train_wall": "20", "wall": "6377"}
2021-10-22 23:41:23 | INFO | train_inner | {"epoch": 14, "update": 13.714, "loss": "2.155", "nll_loss": "0.256", "ppl": "1.19", "wps": "2747.8", "ups": "4.77", "wpb": "576.6", "bsz": "16", "num_updates": "16800", "lr": "4.91846e-05", "gnorm": "1.75", "train_wall": "21", "wall": "6398"}
2021-10-22 23:41:45 | INFO | train_inner | {"epoch": 14, "update": 13.796, "loss": "2.159", "nll_loss": "0.258", "ppl": "1.2", "wps": "2636", "ups": "4.72", "wpb": "558.6", "bsz": "16", "num_updates": "16900", "lr": "4.91796e-05", "gnorm": "1.645", "train_wall": "21", "wall": "6419"}
2021-10-22 23:42:05 | INFO | train_inner | {"epoch": 14, "update": 13.878, "loss": "2.156", "nll_loss": "0.257", "ppl": "1.19", "wps": "2827.7", "ups": "4.8", "wpb": "589.1", "bsz": "16", "num_updates": "17000", "lr": "4.91746e-05", "gnorm": "1.689", "train_wall": "21", "wall": "6440"}
2021-10-22 23:42:27 | INFO | train_inner | {"epoch": 14, "update": 13.959, "loss": "2.147", "nll_loss": "0.249", "ppl": "1.19", "wps": "2934.7", "ups": "4.57", "wpb": "641.5", "bsz": "16", "num_updates": "17100", "lr": "4.91696e-05", "gnorm": "1.493", "train_wall": "22", "wall": "6462"}
2021-10-22 23:42:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-22 23:46:13 | INFO | valid | {"epoch": 14, "valid_loss": "2.68", "valid_nll_loss": "0.729", "valid_ppl": "1.66", "valid_bleu": "55.07", "valid_wps": "401.2", "valid_wpb": "281.5", "valid_bsz": "8", "valid_num_updates": "17150", "valid_best_bleu": "55.07"}
2021-10-22 23:46:13 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-22 23:46:29 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/large/checkpoint_best.pt (epoch 14 @ 17150 updates, score 55.07) (writing took 15.816690906998701 seconds)
2021-10-22 23:46:29 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2021-10-22 23:46:29 | INFO | train | {"epoch": 14, "train_loss": "2.151", "train_nll_loss": "0.251", "train_ppl": "1.19", "train_wps": "1460.5", "train_ups": "2.49", "train_wpb": "586.8", "train_bsz": "16", "train_num_updates": "17150", "train_lr": "4.91671e-05", "train_gnorm": "1.682", "train_train_wall": "258", "train_wall": "6703"}
2021-10-22 23:46:29 | INFO | fairseq_cli.train | begin training epoch 14
2021-10-22 23:46:40 | INFO | train_inner | {"epoch": 15, "update": 14.041, "loss": "2.143", "nll_loss": "0.242", "ppl": "1.18", "wps": "200.1", "ups": "0.4", "wpb": "504.6", "bsz": "15.9", "num_updates": "17200", "lr": "4.91646e-05", "gnorm": "1.629", "train_wall": "20", "wall": "6714"}
2021-10-22 23:47:00 | INFO | train_inner | {"epoch": 15, "update": 14.122, "loss": "2.135", "nll_loss": "0.234", "ppl": "1.18", "wps": "3113.3", "ups": "4.82", "wpb": "645.9", "bsz": "16", "num_updates": "17300", "lr": "4.91596e-05", "gnorm": "1.461", "train_wall": "21", "wall": "6735"}
2021-10-22 23:47:21 | INFO | train_inner | {"epoch": 15, "update": 14.204, "loss": "2.151", "nll_loss": "0.249", "ppl": "1.19", "wps": "2450.3", "ups": "4.89", "wpb": "500.9", "bsz": "16", "num_updates": "17400", "lr": "4.91546e-05", "gnorm": "1.551", "train_wall": "20", "wall": "6755"}
2021-10-22 23:47:40 | INFO | train_inner | {"epoch": 15, "update": 14.286, "loss": "2.135", "nll_loss": "0.234", "ppl": "1.18", "wps": "3105.4", "ups": "5.13", "wpb": "605", "bsz": "16", "num_updates": "17500", "lr": "4.91496e-05", "gnorm": "1.463", "train_wall": "19", "wall": "6775"}
2021-10-22 23:48:00 | INFO | train_inner | {"epoch": 15, "update": 14.367, "loss": "2.145", "nll_loss": "0.246", "ppl": "1.19", "wps": "2823.8", "ups": "5.17", "wpb": "546.7", "bsz": "16", "num_updates": "17600", "lr": "4.91446e-05", "gnorm": "1.45", "train_wall": "19", "wall": "6794"}
2021-10-22 23:48:21 | INFO | train_inner | {"epoch": 15, "update": 14.449, "loss": "2.14", "nll_loss": "0.24", "ppl": "1.18", "wps": "2893.1", "ups": "4.69", "wpb": "616.8", "bsz": "16", "num_updates": "17700", "lr": "4.91396e-05", "gnorm": "1.586", "train_wall": "21", "wall": "6815"}
2021-10-22 23:48:41 | INFO | train_inner | {"epoch": 15, "update": 14.531, "loss": "2.153", "nll_loss": "0.25", "ppl": "1.19", "wps": "2547.9", "ups": "4.88", "wpb": "522", "bsz": "16", "num_updates": "17800", "lr": "4.91346e-05", "gnorm": "1.596", "train_wall": "20", "wall": "6836"}
2021-10-22 23:49:02 | INFO | train_inner | {"epoch": 15, "update": 14.612, "loss": "2.149", "nll_loss": "0.249", "ppl": "1.19", "wps": "2759.7", "ups": "4.8", "wpb": "575.5", "bsz": "16", "num_updates": "17900", "lr": "4.91296e-05", "gnorm": "1.772", "train_wall": "21", "wall": "6857"}
2021-10-22 23:49:24 | INFO | train_inner | {"epoch": 15, "update": 14.694, "loss": "2.137", "nll_loss": "0.238", "ppl": "1.18", "wps": "3009", "ups": "4.53", "wpb": "664.4", "bsz": "16", "num_updates": "18000", "lr": "4.91246e-05", "gnorm": "1.609", "train_wall": "22", "wall": "6879"}
2021-10-22 23:49:45 | INFO | train_inner | {"epoch": 15, "update": 14.776, "loss": "2.144", "nll_loss": "0.245", "ppl": "1.18", "wps": "2815.8", "ups": "4.74", "wpb": "593.5", "bsz": "16", "num_updates": "18100", "lr": "4.91196e-05", "gnorm": "1.548", "train_wall": "21", "wall": "6900"}
2021-10-22 23:50:07 | INFO | train_inner | {"epoch": 15, "update": 14.857, "loss": "2.145", "nll_loss": "0.245", "ppl": "1.19", "wps": "2744.2", "ups": "4.61", "wpb": "595.9", "bsz": "16", "num_updates": "18200", "lr": "4.91146e-05", "gnorm": "1.516", "train_wall": "21", "wall": "6922"}
2021-10-22 23:50:28 | INFO | train_inner | {"epoch": 15, "update": 14.939, "loss": "2.149", "nll_loss": "0.25", "ppl": "1.19", "wps": "2927.2", "ups": "4.72", "wpb": "619.8", "bsz": "16", "num_updates": "18300", "lr": "4.91096e-05", "gnorm": "1.592", "train_wall": "21", "wall": "6943"}
2021-10-22 23:50:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-22 23:54:05 | INFO | valid | {"epoch": 15, "valid_loss": "2.672", "valid_nll_loss": "0.728", "valid_ppl": "1.66", "valid_bleu": "54.35", "valid_wps": "431", "valid_wpb": "281.5", "valid_bsz": "8", "valid_num_updates": "18375", "valid_best_bleu": "55.07"}
2021-10-22 23:54:05 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-22 23:54:17 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/large/checkpoint_last.pt (epoch 15 @ 18375 updates, score 54.35) (writing took 12.03487429895904 seconds)
2021-10-22 23:54:17 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2021-10-22 23:54:17 | INFO | train | {"epoch": 15, "train_loss": "2.144", "train_nll_loss": "0.243", "train_ppl": "1.18", "train_wps": "1536", "train_ups": "2.62", "train_wpb": "586.8", "train_bsz": "16", "train_num_updates": "18375", "train_lr": "4.91058e-05", "train_gnorm": "1.565", "train_train_wall": "252", "train_wall": "7171"}
2021-10-22 23:54:17 | INFO | fairseq_cli.train | begin training epoch 15
2021-10-22 23:54:22 | INFO | train_inner | {"epoch": 16, "update": 15.02, "loss": "2.146", "nll_loss": "0.246", "ppl": "1.19", "wps": "238.3", "ups": "0.43", "wpb": "558", "bsz": "15.9", "num_updates": "18400", "lr": "4.91046e-05", "gnorm": "1.627", "train_wall": "21", "wall": "7177"}
2021-10-22 23:54:43 | INFO | train_inner | {"epoch": 16, "update": 15.102, "loss": "2.13", "nll_loss": "0.227", "ppl": "1.17", "wps": "2487.3", "ups": "4.75", "wpb": "523.3", "bsz": "16", "num_updates": "18500", "lr": "4.90995e-05", "gnorm": "1.484", "train_wall": "21", "wall": "7198"}
2021-10-22 23:55:07 | INFO | train_inner | {"epoch": 16, "update": 15.184, "loss": "2.121", "nll_loss": "0.223", "ppl": "1.17", "wps": "2946", "ups": "4.32", "wpb": "681.9", "bsz": "16", "num_updates": "18600", "lr": "4.90945e-05", "gnorm": "1.513", "train_wall": "23", "wall": "7221"}
2021-10-22 23:55:28 | INFO | train_inner | {"epoch": 16, "update": 15.265, "loss": "2.138", "nll_loss": "0.237", "ppl": "1.18", "wps": "2714.7", "ups": "4.62", "wpb": "587.5", "bsz": "16", "num_updates": "18700", "lr": "4.90895e-05", "gnorm": "1.562", "train_wall": "21", "wall": "7243"}
2021-10-22 23:55:50 | INFO | train_inner | {"epoch": 16, "update": 15.347, "loss": "2.139", "nll_loss": "0.239", "ppl": "1.18", "wps": "2571", "ups": "4.55", "wpb": "565.3", "bsz": "16", "num_updates": "18800", "lr": "4.90845e-05", "gnorm": "1.536", "train_wall": "22", "wall": "7265"}
2021-10-22 23:56:11 | INFO | train_inner | {"epoch": 16, "update": 15.429, "loss": "2.134", "nll_loss": "0.233", "ppl": "1.17", "wps": "2784", "ups": "4.88", "wpb": "570.9", "bsz": "16", "num_updates": "18900", "lr": "4.90795e-05", "gnorm": "1.599", "train_wall": "20", "wall": "7285"}
2021-10-22 23:56:33 | INFO | train_inner | {"epoch": 16, "update": 15.51, "loss": "2.131", "nll_loss": "0.231", "ppl": "1.17", "wps": "2817.4", "ups": "4.55", "wpb": "618.8", "bsz": "16", "num_updates": "19000", "lr": "4.90745e-05", "gnorm": "1.397", "train_wall": "22", "wall": "7307"}
2021-10-22 23:56:55 | INFO | train_inner | {"epoch": 16, "update": 15.592, "loss": "2.134", "nll_loss": "0.234", "ppl": "1.18", "wps": "2712.8", "ups": "4.58", "wpb": "592.8", "bsz": "16", "num_updates": "19100", "lr": "4.90695e-05", "gnorm": "1.511", "train_wall": "22", "wall": "7329"}
2021-10-22 23:57:16 | INFO | train_inner | {"epoch": 16, "update": 15.673, "loss": "2.129", "nll_loss": "0.23", "ppl": "1.17", "wps": "2873.6", "ups": "4.6", "wpb": "625", "bsz": "16", "num_updates": "19200", "lr": "4.90645e-05", "gnorm": "1.523", "train_wall": "21", "wall": "7351"}
2021-10-22 23:57:38 | INFO | train_inner | {"epoch": 16, "update": 15.755, "loss": "2.146", "nll_loss": "0.247", "ppl": "1.19", "wps": "2805.3", "ups": "4.54", "wpb": "617.3", "bsz": "16", "num_updates": "19300", "lr": "4.90595e-05", "gnorm": "1.556", "train_wall": "22", "wall": "7373"}
2021-10-22 23:58:00 | INFO | train_inner | {"epoch": 16, "update": 15.837, "loss": "2.146", "nll_loss": "0.247", "ppl": "1.19", "wps": "2573.5", "ups": "4.52", "wpb": "569.9", "bsz": "16", "num_updates": "19400", "lr": "4.90545e-05", "gnorm": "1.942", "train_wall": "22", "wall": "7395"}
2021-10-22 23:58:20 | INFO | train_inner | {"epoch": 16, "update": 15.918, "loss": "2.152", "nll_loss": "0.251", "ppl": "1.19", "wps": "2561.6", "ups": "5.08", "wpb": "504.4", "bsz": "16", "num_updates": "19500", "lr": "4.90495e-05", "gnorm": "1.637", "train_wall": "19", "wall": "7415"}
2021-10-22 23:58:41 | INFO | train_inner | {"epoch": 16, "update": 16.0, "loss": "2.126", "nll_loss": "0.227", "ppl": "1.17", "wps": "2905.9", "ups": "4.77", "wpb": "608.9", "bsz": "15.9", "num_updates": "19600", "lr": "4.90445e-05", "gnorm": "1.534", "train_wall": "21", "wall": "7436"}
2021-10-22 23:58:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-23 00:02:07 | INFO | valid | {"epoch": 16, "valid_loss": "2.682", "valid_nll_loss": "0.743", "valid_ppl": "1.67", "valid_bleu": "55.28", "valid_wps": "419.9", "valid_wpb": "281.5", "valid_bsz": "8", "valid_num_updates": "19600", "valid_best_bleu": "55.28"}
2021-10-23 00:02:07 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-23 00:02:31 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/large/checkpoint_best.pt (epoch 16 @ 19600 updates, score 55.28) (writing took 23.84173431096133 seconds)
2021-10-23 00:02:31 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2021-10-23 00:02:31 | INFO | train | {"epoch": 16, "train_loss": "2.135", "train_nll_loss": "0.235", "train_ppl": "1.18", "train_wps": "1455", "train_ups": "2.48", "train_wpb": "586.8", "train_bsz": "16", "train_num_updates": "19600", "train_lr": "4.90445e-05", "train_gnorm": "1.565", "train_train_wall": "261", "train_wall": "7665"}
2021-10-23 00:02:31 | INFO | fairseq_cli.train | begin training epoch 16
2021-10-23 00:02:52 | INFO | train_inner | {"epoch": 17, "update": 16.082, "loss": "2.121", "nll_loss": "0.22", "ppl": "1.16", "wps": "263.5", "ups": "0.4", "wpb": "661.7", "bsz": "16", "num_updates": "19700", "lr": "4.90395e-05", "gnorm": "1.396", "train_wall": "21", "wall": "7687"}
2021-10-23 00:03:12 | INFO | train_inner | {"epoch": 17, "update": 16.163, "loss": "2.127", "nll_loss": "0.226", "ppl": "1.17", "wps": "2568.1", "ups": "5.03", "wpb": "510.5", "bsz": "16", "num_updates": "19800", "lr": "4.90345e-05", "gnorm": "1.505", "train_wall": "20", "wall": "7707"}
2021-10-23 00:03:32 | INFO | train_inner | {"epoch": 17, "update": 16.245, "loss": "2.118", "nll_loss": "0.218", "ppl": "1.16", "wps": "3091.1", "ups": "5.14", "wpb": "601.4", "bsz": "16", "num_updates": "19900", "lr": "4.90295e-05", "gnorm": "1.394", "train_wall": "19", "wall": "7726"}
2021-10-23 00:03:53 | INFO | train_inner | {"epoch": 17, "update": 16.327, "loss": "2.122", "nll_loss": "0.222", "ppl": "1.17", "wps": "2666.9", "ups": "4.77", "wpb": "559.3", "bsz": "16", "num_updates": "20000", "lr": "4.90245e-05", "gnorm": "1.37", "train_wall": "21", "wall": "7747"}
2021-10-23 00:04:13 | INFO | train_inner | {"epoch": 17, "update": 16.408, "loss": "2.126", "nll_loss": "0.226", "ppl": "1.17", "wps": "2827.7", "ups": "4.95", "wpb": "570.9", "bsz": "16", "num_updates": "20100", "lr": "4.90195e-05", "gnorm": "1.466", "train_wall": "20", "wall": "7767"}
2021-10-23 00:04:33 | INFO | train_inner | {"epoch": 17, "update": 16.49, "loss": "2.128", "nll_loss": "0.228", "ppl": "1.17", "wps": "2936.3", "ups": "4.81", "wpb": "610", "bsz": "16", "num_updates": "20200", "lr": "4.90145e-05", "gnorm": "1.526", "train_wall": "21", "wall": "7788"}
2021-10-23 00:04:53 | INFO | train_inner | {"epoch": 17, "update": 16.571, "loss": "2.125", "nll_loss": "0.227", "ppl": "1.17", "wps": "2822.3", "ups": "5.04", "wpb": "560", "bsz": "16", "num_updates": "20300", "lr": "4.90095e-05", "gnorm": "1.521", "train_wall": "20", "wall": "7808"}
2021-10-23 00:05:16 | INFO | train_inner | {"epoch": 17, "update": 16.653, "loss": "2.136", "nll_loss": "0.236", "ppl": "1.18", "wps": "3041.8", "ups": "4.46", "wpb": "682.3", "bsz": "16", "num_updates": "20400", "lr": "4.90045e-05", "gnorm": "1.55", "train_wall": "22", "wall": "7830"}
2021-10-23 00:05:37 | INFO | train_inner | {"epoch": 17, "update": 16.735, "loss": "2.137", "nll_loss": "0.237", "ppl": "1.18", "wps": "2635.3", "ups": "4.7", "wpb": "560.6", "bsz": "16", "num_updates": "20500", "lr": "4.89995e-05", "gnorm": "1.549", "train_wall": "21", "wall": "7852"}
2021-10-23 00:05:58 | INFO | train_inner | {"epoch": 17, "update": 16.816, "loss": "2.133", "nll_loss": "0.235", "ppl": "1.18", "wps": "2800.7", "ups": "4.82", "wpb": "580.6", "bsz": "16", "num_updates": "20600", "lr": "4.89945e-05", "gnorm": "1.526", "train_wall": "21", "wall": "7872"}
2021-10-23 00:06:19 | INFO | train_inner | {"epoch": 17, "update": 16.898, "loss": "2.128", "nll_loss": "0.229", "ppl": "1.17", "wps": "2928.3", "ups": "4.74", "wpb": "617.6", "bsz": "16", "num_updates": "20700", "lr": "4.89895e-05", "gnorm": "1.546", "train_wall": "21", "wall": "7893"}
2021-10-23 00:06:40 | INFO | train_inner | {"epoch": 17, "update": 16.98, "loss": "2.14", "nll_loss": "0.239", "ppl": "1.18", "wps": "2704.1", "ups": "4.84", "wpb": "559", "bsz": "16", "num_updates": "20800", "lr": "4.89845e-05", "gnorm": "1.682", "train_wall": "20", "wall": "7914"}
2021-10-23 00:06:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-23 00:10:16 | INFO | valid | {"epoch": 17, "valid_loss": "2.691", "valid_nll_loss": "0.741", "valid_ppl": "1.67", "valid_bleu": "55", "valid_wps": "408.4", "valid_wpb": "281.5", "valid_bsz": "8", "valid_num_updates": "20825", "valid_best_bleu": "55.28"}
2021-10-23 00:10:16 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-23 00:10:30 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/large/checkpoint_last.pt (epoch 17 @ 20825 updates, score 55.0) (writing took 13.572654370917007 seconds)
2021-10-23 00:10:30 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2021-10-23 00:10:30 | INFO | train | {"epoch": 17, "train_loss": "2.129", "train_nll_loss": "0.229", "train_ppl": "1.17", "train_wps": "1501", "train_ups": "2.56", "train_wpb": "586.8", "train_bsz": "16", "train_num_updates": "20825", "train_lr": "4.89832e-05", "train_gnorm": "1.505", "train_train_wall": "251", "train_wall": "8144"}
2021-10-23 00:10:30 | INFO | fairseq_cli.train | begin training epoch 17
2021-10-23 00:10:45 | INFO | train_inner | {"epoch": 18, "update": 17.061, "loss": "2.123", "nll_loss": "0.223", "ppl": "1.17", "wps": "217.7", "ups": "0.41", "wpb": "534.2", "bsz": "15.9", "num_updates": "20900", "lr": "4.89795e-05", "gnorm": "1.441", "train_wall": "20", "wall": "8159"}
2021-10-23 00:11:06 | INFO | train_inner | {"epoch": 18, "update": 17.143, "loss": "2.117", "nll_loss": "0.218", "ppl": "1.16", "wps": "3079", "ups": "4.77", "wpb": "644.9", "bsz": "16", "num_updates": "21000", "lr": "4.89745e-05", "gnorm": "1.397", "train_wall": "21", "wall": "8180"}
2021-10-23 00:11:25 | INFO | train_inner | {"epoch": 18, "update": 17.224, "loss": "2.125", "nll_loss": "0.224", "ppl": "1.17", "wps": "2974", "ups": "5.32", "wpb": "558.9", "bsz": "16", "num_updates": "21100", "lr": "4.89695e-05", "gnorm": "1.384", "train_wall": "19", "wall": "8199"}
2021-10-23 00:11:45 | INFO | train_inner | {"epoch": 18, "update": 17.306, "loss": "2.112", "nll_loss": "0.213", "ppl": "1.16", "wps": "3078", "ups": "4.94", "wpb": "622.6", "bsz": "16", "num_updates": "21200", "lr": "4.89645e-05", "gnorm": "1.338", "train_wall": "20", "wall": "8219"}
2021-10-23 00:12:05 | INFO | train_inner | {"epoch": 18, "update": 17.388, "loss": "2.122", "nll_loss": "0.222", "ppl": "1.17", "wps": "3004.6", "ups": "5", "wpb": "601", "bsz": "16", "num_updates": "21300", "lr": "4.89595e-05", "gnorm": "1.373", "train_wall": "20", "wall": "8239"}
2021-10-23 00:12:26 | INFO | train_inner | {"epoch": 18, "update": 17.469, "loss": "2.125", "nll_loss": "0.225", "ppl": "1.17", "wps": "2780.8", "ups": "4.75", "wpb": "585.9", "bsz": "16", "num_updates": "21400", "lr": "4.89545e-05", "gnorm": "1.427", "train_wall": "21", "wall": "8260"}
2021-10-23 00:12:46 | INFO | train_inner | {"epoch": 18, "update": 17.551, "loss": "2.12", "nll_loss": "0.22", "ppl": "1.16", "wps": "2806.7", "ups": "4.98", "wpb": "563.6", "bsz": "16", "num_updates": "21500", "lr": "4.89495e-05", "gnorm": "1.533", "train_wall": "20", "wall": "8281"}
2021-10-23 00:13:08 | INFO | train_inner | {"epoch": 18, "update": 17.633, "loss": "2.127", "nll_loss": "0.226", "ppl": "1.17", "wps": "2867.1", "ups": "4.54", "wpb": "631.5", "bsz": "16", "num_updates": "21600", "lr": "4.89445e-05", "gnorm": "1.394", "train_wall": "22", "wall": "8303"}
2021-10-23 00:13:29 | INFO | train_inner | {"epoch": 18, "update": 17.714, "loss": "2.115", "nll_loss": "0.218", "ppl": "1.16", "wps": "2938.1", "ups": "4.83", "wpb": "608.5", "bsz": "16", "num_updates": "21700", "lr": "4.89395e-05", "gnorm": "1.246", "train_wall": "20", "wall": "8323"}
2021-10-23 00:13:49 | INFO | train_inner | {"epoch": 18, "update": 17.796, "loss": "2.12", "nll_loss": "0.221", "ppl": "1.17", "wps": "2822.6", "ups": "4.87", "wpb": "580.1", "bsz": "16", "num_updates": "21800", "lr": "4.89345e-05", "gnorm": "1.468", "train_wall": "20", "wall": "8344"}
2021-10-23 00:14:11 | INFO | train_inner | {"epoch": 18, "update": 17.878, "loss": "2.132", "nll_loss": "0.233", "ppl": "1.18", "wps": "2826.2", "ups": "4.74", "wpb": "596.6", "bsz": "16", "num_updates": "21900", "lr": "4.89295e-05", "gnorm": "1.499", "train_wall": "21", "wall": "8365"}
2021-10-23 00:14:31 | INFO | train_inner | {"epoch": 18, "update": 17.959, "loss": "2.135", "nll_loss": "0.235", "ppl": "1.18", "wps": "2439.6", "ups": "4.96", "wpb": "491.4", "bsz": "16", "num_updates": "22000", "lr": "4.89245e-05", "gnorm": "1.599", "train_wall": "20", "wall": "8385"}
2021-10-23 00:14:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-23 00:18:17 | INFO | valid | {"epoch": 18, "valid_loss": "2.69", "valid_nll_loss": "0.749", "valid_ppl": "1.68", "valid_bleu": "54.15", "valid_wps": "400", "valid_wpb": "281.5", "valid_bsz": "8", "valid_num_updates": "22050", "valid_best_bleu": "55.28"}
2021-10-23 00:18:17 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-23 00:18:24 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/large/checkpoint_last.pt (epoch 18 @ 22050 updates, score 54.15) (writing took 6.962623720057309 seconds)
2021-10-23 00:18:24 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2021-10-23 00:18:24 | INFO | train | {"epoch": 18, "train_loss": "2.123", "train_nll_loss": "0.223", "train_ppl": "1.17", "train_wps": "1515.9", "train_ups": "2.58", "train_wpb": "586.8", "train_bsz": "16", "train_num_updates": "22050", "train_lr": "4.8922e-05", "train_gnorm": "1.423", "train_train_wall": "248", "train_wall": "8619"}
2021-10-23 00:18:24 | INFO | fairseq_cli.train | begin training epoch 18
2021-10-23 00:18:35 | INFO | train_inner | {"epoch": 19, "update": 18.041, "loss": "2.129", "nll_loss": "0.229", "ppl": "1.17", "wps": "226.2", "ups": "0.41", "wpb": "553.2", "bsz": "15.9", "num_updates": "22100", "lr": "4.89195e-05", "gnorm": "1.436", "train_wall": "21", "wall": "8630"}
2021-10-23 00:18:56 | INFO | train_inner | {"epoch": 19, "update": 18.122, "loss": "2.116", "nll_loss": "0.216", "ppl": "1.16", "wps": "2952.6", "ups": "4.9", "wpb": "602.5", "bsz": "16", "num_updates": "22200", "lr": "4.89145e-05", "gnorm": "1.323", "train_wall": "20", "wall": "8650"}
2021-10-23 00:19:18 | INFO | train_inner | {"epoch": 19, "update": 18.204, "loss": "2.114", "nll_loss": "0.213", "ppl": "1.16", "wps": "2554.5", "ups": "4.47", "wpb": "571.2", "bsz": "16", "num_updates": "22300", "lr": "4.89095e-05", "gnorm": "1.299", "train_wall": "22", "wall": "8672"}
2021-10-23 00:19:41 | INFO | train_inner | {"epoch": 19, "update": 18.286, "loss": "2.119", "nll_loss": "0.219", "ppl": "1.16", "wps": "2525.9", "ups": "4.42", "wpb": "571", "bsz": "16", "num_updates": "22400", "lr": "4.89045e-05", "gnorm": "1.534", "train_wall": "22", "wall": "8695"}
2021-10-23 00:20:03 | INFO | train_inner | {"epoch": 19, "update": 18.367, "loss": "2.117", "nll_loss": "0.218", "ppl": "1.16", "wps": "2925.5", "ups": "4.44", "wpb": "659.6", "bsz": "16", "num_updates": "22500", "lr": "4.88994e-05", "gnorm": "1.453", "train_wall": "22", "wall": "8718"}
2021-10-23 00:20:23 | INFO | train_inner | {"epoch": 19, "update": 18.449, "loss": "2.123", "nll_loss": "0.222", "ppl": "1.17", "wps": "2630.1", "ups": "4.93", "wpb": "533.5", "bsz": "16", "num_updates": "22600", "lr": "4.88944e-05", "gnorm": "1.786", "train_wall": "20", "wall": "8738"}
2021-10-23 00:20:42 | INFO | train_inner | {"epoch": 19, "update": 18.531, "loss": "2.111", "nll_loss": "0.211", "ppl": "1.16", "wps": "2956", "ups": "5.4", "wpb": "547.8", "bsz": "16", "num_updates": "22700", "lr": "4.88894e-05", "gnorm": "1.355", "train_wall": "18", "wall": "8756"}
2021-10-23 00:21:02 | INFO | train_inner | {"epoch": 19, "update": 18.612, "loss": "2.125", "nll_loss": "0.226", "ppl": "1.17", "wps": "2817.7", "ups": "5.09", "wpb": "553.7", "bsz": "16", "num_updates": "22800", "lr": "4.88844e-05", "gnorm": "1.487", "train_wall": "19", "wall": "8776"}
2021-10-23 00:21:22 | INFO | train_inner | {"epoch": 19, "update": 18.694, "loss": "2.117", "nll_loss": "0.219", "ppl": "1.16", "wps": "3071.9", "ups": "4.82", "wpb": "637.7", "bsz": "16", "num_updates": "22900", "lr": "4.88794e-05", "gnorm": "1.736", "train_wall": "21", "wall": "8797"}
2021-10-23 00:21:44 | INFO | train_inner | {"epoch": 19, "update": 18.776, "loss": "2.117", "nll_loss": "0.219", "ppl": "1.16", "wps": "2732.1", "ups": "4.61", "wpb": "592.1", "bsz": "16", "num_updates": "23000", "lr": "4.88744e-05", "gnorm": "1.585", "train_wall": "21", "wall": "8819"}
2021-10-23 00:22:05 | INFO | train_inner | {"epoch": 19, "update": 18.857, "loss": "2.116", "nll_loss": "0.217", "ppl": "1.16", "wps": "2924.5", "ups": "4.78", "wpb": "612.1", "bsz": "16", "num_updates": "23100", "lr": "4.88694e-05", "gnorm": "1.298", "train_wall": "21", "wall": "8839"}
2021-10-23 00:22:26 | INFO | train_inner | {"epoch": 19, "update": 18.939, "loss": "2.128", "nll_loss": "0.229", "ppl": "1.17", "wps": "2704.2", "ups": "4.73", "wpb": "571.7", "bsz": "16", "num_updates": "23200", "lr": "4.88644e-05", "gnorm": "1.616", "train_wall": "21", "wall": "8861"}
2021-10-23 00:22:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-23 00:26:09 | INFO | valid | {"epoch": 19, "valid_loss": "2.698", "valid_nll_loss": "0.756", "valid_ppl": "1.69", "valid_bleu": "54.73", "valid_wps": "420.5", "valid_wpb": "281.5", "valid_bsz": "8", "valid_num_updates": "23275", "valid_best_bleu": "55.28"}
2021-10-23 00:26:09 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-23 00:26:27 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/large/checkpoint_last.pt (epoch 19 @ 23275 updates, score 54.73) (writing took 18.271483180928044 seconds)
2021-10-23 00:26:27 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2021-10-23 00:26:27 | INFO | train | {"epoch": 19, "train_loss": "2.118", "train_nll_loss": "0.219", "train_ppl": "1.16", "train_wps": "1487.8", "train_ups": "2.54", "train_wpb": "586.8", "train_bsz": "16", "train_num_updates": "23275", "train_lr": "4.88607e-05", "train_gnorm": "1.488", "train_train_wall": "256", "train_wall": "9102"}
2021-10-23 00:26:27 | INFO | fairseq_cli.train | begin training epoch 19
2021-10-23 00:26:33 | INFO | train_inner | {"epoch": 20, "update": 19.02, "loss": "2.114", "nll_loss": "0.216", "ppl": "1.16", "wps": "238.8", "ups": "0.41", "wpb": "589", "bsz": "15.9", "num_updates": "23300", "lr": "4.88594e-05", "gnorm": "1.341", "train_wall": "22", "wall": "9107"}
2021-10-23 00:26:53 | INFO | train_inner | {"epoch": 20, "update": 19.102, "loss": "2.108", "nll_loss": "0.207", "ppl": "1.15", "wps": "2557", "ups": "4.86", "wpb": "525.9", "bsz": "16", "num_updates": "23400", "lr": "4.88544e-05", "gnorm": "1.454", "train_wall": "20", "wall": "9128"}
2021-10-23 00:27:15 | INFO | train_inner | {"epoch": 20, "update": 19.184, "loss": "2.108", "nll_loss": "0.209", "ppl": "1.16", "wps": "2719.9", "ups": "4.63", "wpb": "586.9", "bsz": "16", "num_updates": "23500", "lr": "4.88494e-05", "gnorm": "1.398", "train_wall": "21", "wall": "9149"}
2021-10-23 00:27:36 | INFO | train_inner | {"epoch": 20, "update": 19.265, "loss": "2.117", "nll_loss": "0.218", "ppl": "1.16", "wps": "2770.9", "ups": "4.69", "wpb": "590.8", "bsz": "16", "num_updates": "23600", "lr": "4.88444e-05", "gnorm": "1.312", "train_wall": "21", "wall": "9171"}
2021-10-23 00:27:58 | INFO | train_inner | {"epoch": 20, "update": 19.347, "loss": "2.115", "nll_loss": "0.215", "ppl": "1.16", "wps": "2826.2", "ups": "4.61", "wpb": "612.6", "bsz": "16", "num_updates": "23700", "lr": "4.88394e-05", "gnorm": "1.424", "train_wall": "21", "wall": "9192"}
2021-10-23 00:28:21 | INFO | train_inner | {"epoch": 20, "update": 19.429, "loss": "2.109", "nll_loss": "0.211", "ppl": "1.16", "wps": "2714.9", "ups": "4.4", "wpb": "616.4", "bsz": "16", "num_updates": "23800", "lr": "4.88344e-05", "gnorm": "1.398", "train_wall": "22", "wall": "9215"}
2021-10-23 00:28:41 | INFO | train_inner | {"epoch": 20, "update": 19.51, "loss": "2.111", "nll_loss": "0.213", "ppl": "1.16", "wps": "2597.2", "ups": "4.95", "wpb": "524.6", "bsz": "16", "num_updates": "23900", "lr": "4.88294e-05", "gnorm": "1.311", "train_wall": "20", "wall": "9235"}
2021-10-23 00:29:04 | INFO | train_inner | {"epoch": 20, "update": 19.592, "loss": "2.11", "nll_loss": "0.211", "ppl": "1.16", "wps": "2890.2", "ups": "4.3", "wpb": "671.7", "bsz": "16", "num_updates": "24000", "lr": "4.88244e-05", "gnorm": "1.272", "train_wall": "23", "wall": "9259"}
2021-10-23 00:29:26 | INFO | train_inner | {"epoch": 20, "update": 19.673, "loss": "2.114", "nll_loss": "0.215", "ppl": "1.16", "wps": "2897.9", "ups": "4.61", "wpb": "628.7", "bsz": "16", "num_updates": "24100", "lr": "4.88194e-05", "gnorm": "1.344", "train_wall": "21", "wall": "9280"}
2021-10-23 00:29:49 | INFO | train_inner | {"epoch": 20, "update": 19.755, "loss": "2.117", "nll_loss": "0.219", "ppl": "1.16", "wps": "2647.4", "ups": "4.39", "wpb": "603.6", "bsz": "16", "num_updates": "24200", "lr": "4.88144e-05", "gnorm": "1.538", "train_wall": "23", "wall": "9303"}
2021-10-23 00:30:10 | INFO | train_inner | {"epoch": 20, "update": 19.837, "loss": "2.122", "nll_loss": "0.222", "ppl": "1.17", "wps": "2522", "ups": "4.76", "wpb": "529.4", "bsz": "16", "num_updates": "24300", "lr": "4.88094e-05", "gnorm": "1.687", "train_wall": "21", "wall": "9324"}
2021-10-23 00:30:32 | INFO | train_inner | {"epoch": 20, "update": 19.918, "loss": "2.124", "nll_loss": "0.223", "ppl": "1.17", "wps": "2559.7", "ups": "4.44", "wpb": "577", "bsz": "16", "num_updates": "24400", "lr": "4.88044e-05", "gnorm": "1.526", "train_wall": "22", "wall": "9347"}
2021-10-23 00:30:52 | INFO | train_inner | {"epoch": 20, "update": 20.0, "loss": "2.118", "nll_loss": "0.219", "ppl": "1.16", "wps": "2934.1", "ups": "4.93", "wpb": "595.6", "bsz": "15.9", "num_updates": "24500", "lr": "4.87994e-05", "gnorm": "1.442", "train_wall": "20", "wall": "9367"}
2021-10-23 00:30:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-23 00:34:27 | INFO | valid | {"epoch": 20, "valid_loss": "2.691", "valid_nll_loss": "0.763", "valid_ppl": "1.7", "valid_bleu": "54.71", "valid_wps": "403.3", "valid_wpb": "281.5", "valid_bsz": "8", "valid_num_updates": "24500", "valid_best_bleu": "55.28"}
2021-10-23 00:34:27 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-23 00:34:41 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/large/checkpoint_last.pt (epoch 20 @ 24500 updates, score 54.71) (writing took 14.278974340995774 seconds)
2021-10-23 00:34:41 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2021-10-23 00:34:41 | INFO | train | {"epoch": 20, "train_loss": "2.114", "train_nll_loss": "0.215", "train_ppl": "1.16", "train_wps": "1455", "train_ups": "2.48", "train_wpb": "586.8", "train_bsz": "16", "train_num_updates": "24500", "train_lr": "4.87994e-05", "train_gnorm": "1.42", "train_train_wall": "262", "train_wall": "9596"}
2021-10-23 00:34:41 | INFO | fairseq_cli.train | begin training epoch 20
2021-10-23 00:35:04 | INFO | train_inner | {"epoch": 21, "update": 20.082, "loss": "2.105", "nll_loss": "0.206", "ppl": "1.15", "wps": "265.2", "ups": "0.4", "wpb": "667.2", "bsz": "16", "num_updates": "24600", "lr": "4.87944e-05", "gnorm": "1.28", "train_wall": "22", "wall": "9618"}
2021-10-23 00:35:25 | INFO | train_inner | {"epoch": 21, "update": 20.163, "loss": "2.101", "nll_loss": "0.203", "ppl": "1.15", "wps": "2739.6", "ups": "4.72", "wpb": "580.7", "bsz": "16", "num_updates": "24700", "lr": "4.87894e-05", "gnorm": "1.45", "train_wall": "21", "wall": "9640"}
2021-10-23 00:35:46 | INFO | train_inner | {"epoch": 21, "update": 20.245, "loss": "2.103", "nll_loss": "0.203", "ppl": "1.15", "wps": "2708.2", "ups": "4.74", "wpb": "571.5", "bsz": "16", "num_updates": "24800", "lr": "4.87844e-05", "gnorm": "1.298", "train_wall": "21", "wall": "9661"}
2021-10-23 00:36:08 | INFO | train_inner | {"epoch": 21, "update": 20.327, "loss": "2.111", "nll_loss": "0.212", "ppl": "1.16", "wps": "2719", "ups": "4.55", "wpb": "597", "bsz": "16", "num_updates": "24900", "lr": "4.87794e-05", "gnorm": "1.399", "train_wall": "22", "wall": "9683"}
2021-10-23 00:36:31 | INFO | train_inner | {"epoch": 21, "update": 20.408, "loss": "2.112", "nll_loss": "0.213", "ppl": "1.16", "wps": "2636.2", "ups": "4.47", "wpb": "589.4", "bsz": "16", "num_updates": "25000", "lr": "4.87744e-05", "gnorm": "1.705", "train_wall": "22", "wall": "9705"}
2021-10-23 00:36:51 | INFO | train_inner | {"epoch": 21, "update": 20.49, "loss": "2.113", "nll_loss": "0.214", "ppl": "1.16", "wps": "2989.7", "ups": "4.9", "wpb": "609.9", "bsz": "16", "num_updates": "25100", "lr": "4.87694e-05", "gnorm": "1.442", "train_wall": "20", "wall": "9725"}
2021-10-23 00:37:12 | INFO | train_inner | {"epoch": 21, "update": 20.571, "loss": "2.111", "nll_loss": "0.211", "ppl": "1.16", "wps": "2769", "ups": "4.82", "wpb": "574.9", "bsz": "16", "num_updates": "25200", "lr": "4.87644e-05", "gnorm": "1.448", "train_wall": "21", "wall": "9746"}
2021-10-23 00:37:31 | INFO | train_inner | {"epoch": 21, "update": 20.653, "loss": "2.115", "nll_loss": "0.216", "ppl": "1.16", "wps": "2881.6", "ups": "5.1", "wpb": "565.2", "bsz": "16", "num_updates": "25300", "lr": "4.87594e-05", "gnorm": "1.409", "train_wall": "19", "wall": "9766"}
2021-10-23 00:37:53 | INFO | train_inner | {"epoch": 21, "update": 20.735, "loss": "2.111", "nll_loss": "0.212", "ppl": "1.16", "wps": "2689.9", "ups": "4.53", "wpb": "593.3", "bsz": "16", "num_updates": "25400", "lr": "4.87544e-05", "gnorm": "1.453", "train_wall": "22", "wall": "9788"}
2021-10-23 00:38:16 | INFO | train_inner | {"epoch": 21, "update": 20.816, "loss": "2.112", "nll_loss": "0.214", "ppl": "1.16", "wps": "2607.8", "ups": "4.43", "wpb": "589.2", "bsz": "16", "num_updates": "25500", "lr": "4.87494e-05", "gnorm": "1.281", "train_wall": "22", "wall": "9810"}
2021-10-23 00:38:38 | INFO | train_inner | {"epoch": 21, "update": 20.898, "loss": "2.116", "nll_loss": "0.218", "ppl": "1.16", "wps": "2372.5", "ups": "4.52", "wpb": "524.8", "bsz": "16", "num_updates": "25600", "lr": "4.87444e-05", "gnorm": "1.376", "train_wall": "22", "wall": "9833"}
2021-10-23 00:39:00 | INFO | train_inner | {"epoch": 21, "update": 20.98, "loss": "2.117", "nll_loss": "0.219", "ppl": "1.16", "wps": "2656.7", "ups": "4.67", "wpb": "569.2", "bsz": "16", "num_updates": "25700", "lr": "4.87394e-05", "gnorm": "1.458", "train_wall": "21", "wall": "9854"}
2021-10-23 00:39:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-23 00:42:33 | INFO | valid | {"epoch": 21, "valid_loss": "2.694", "valid_nll_loss": "0.763", "valid_ppl": "1.7", "valid_bleu": "55.25", "valid_wps": "416.4", "valid_wpb": "281.5", "valid_bsz": "8", "valid_num_updates": "25725", "valid_best_bleu": "55.28"}
2021-10-23 00:42:33 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-23 00:42:46 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/large/checkpoint_last.pt (epoch 21 @ 25725 updates, score 55.25) (writing took 13.016958079999313 seconds)
2021-10-23 00:42:46 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2021-10-23 00:42:46 | INFO | train | {"epoch": 21, "train_loss": "2.111", "train_nll_loss": "0.212", "train_ppl": "1.16", "train_wps": "1482.1", "train_ups": "2.53", "train_wpb": "586.8", "train_bsz": "16", "train_num_updates": "25725", "train_lr": "4.87381e-05", "train_gnorm": "1.418", "train_train_wall": "261", "train_wall": "10081"}
2021-10-23 00:42:46 | INFO | fairseq_cli.train | begin training epoch 21
2021-10-23 00:43:03 | INFO | train_inner | {"epoch": 22, "update": 21.061, "loss": "2.113", "nll_loss": "0.212", "ppl": "1.16", "wps": "259.4", "ups": "0.41", "wpb": "630.1", "bsz": "15.9", "num_updates": "25800", "lr": "4.87344e-05", "gnorm": "1.398", "train_wall": "22", "wall": "10097"}
2021-10-23 00:43:23 | INFO | train_inner | {"epoch": 22, "update": 21.143, "loss": "2.102", "nll_loss": "0.204", "ppl": "1.15", "wps": "2602.2", "ups": "4.8", "wpb": "541.8", "bsz": "16", "num_updates": "25900", "lr": "4.87294e-05", "gnorm": "1.561", "train_wall": "21", "wall": "10118"}
2021-10-23 00:43:46 | INFO | train_inner | {"epoch": 22, "update": 21.224, "loss": "2.103", "nll_loss": "0.206", "ppl": "1.15", "wps": "2685.4", "ups": "4.43", "wpb": "606.3", "bsz": "16", "num_updates": "26000", "lr": "4.87244e-05", "gnorm": "1.268", "train_wall": "22", "wall": "10140"}
2021-10-23 00:44:09 | INFO | train_inner | {"epoch": 22, "update": 21.306, "loss": "2.103", "nll_loss": "0.206", "ppl": "1.15", "wps": "2800.9", "ups": "4.41", "wpb": "635.7", "bsz": "16", "num_updates": "26100", "lr": "4.87194e-05", "gnorm": "1.203", "train_wall": "22", "wall": "10163"}
2021-10-23 00:44:29 | INFO | train_inner | {"epoch": 22, "update": 21.388, "loss": "2.104", "nll_loss": "0.205", "ppl": "1.15", "wps": "2903.1", "ups": "4.95", "wpb": "586.1", "bsz": "16", "num_updates": "26200", "lr": "4.87144e-05", "gnorm": "1.244", "train_wall": "20", "wall": "10183"}
2021-10-23 00:44:49 | INFO | train_inner | {"epoch": 22, "update": 21.469, "loss": "2.105", "nll_loss": "0.207", "ppl": "1.15", "wps": "2795.3", "ups": "4.95", "wpb": "564.6", "bsz": "16", "num_updates": "26300", "lr": "4.87094e-05", "gnorm": "1.297", "train_wall": "20", "wall": "10203"}
2021-10-23 00:45:10 | INFO | train_inner | {"epoch": 22, "update": 21.551, "loss": "2.11", "nll_loss": "0.211", "ppl": "1.16", "wps": "2856.6", "ups": "4.67", "wpb": "611.8", "bsz": "16", "num_updates": "26400", "lr": "4.87044e-05", "gnorm": "1.283", "train_wall": "21", "wall": "10225"}
2021-10-23 00:45:32 | INFO | train_inner | {"epoch": 22, "update": 21.633, "loss": "2.109", "nll_loss": "0.21", "ppl": "1.16", "wps": "2892.4", "ups": "4.73", "wpb": "611.1", "bsz": "16", "num_updates": "26500", "lr": "4.86993e-05", "gnorm": "1.393", "train_wall": "21", "wall": "10246"}
2021-10-23 00:45:53 | INFO | train_inner | {"epoch": 22, "update": 21.714, "loss": "2.111", "nll_loss": "0.212", "ppl": "1.16", "wps": "2626.6", "ups": "4.71", "wpb": "558.2", "bsz": "16", "num_updates": "26600", "lr": "4.86943e-05", "gnorm": "1.313", "train_wall": "21", "wall": "10267"}
2021-10-23 00:46:14 | INFO | train_inner | {"epoch": 22, "update": 21.796, "loss": "2.112", "nll_loss": "0.216", "ppl": "1.16", "wps": "2692.3", "ups": "4.67", "wpb": "576", "bsz": "16", "num_updates": "26700", "lr": "4.86893e-05", "gnorm": "1.519", "train_wall": "21", "wall": "10289"}
2021-10-23 00:46:35 | INFO | train_inner | {"epoch": 22, "update": 21.878, "loss": "2.107", "nll_loss": "0.211", "ppl": "1.16", "wps": "2952.6", "ups": "4.81", "wpb": "613.6", "bsz": "16", "num_updates": "26800", "lr": "4.86843e-05", "gnorm": "1.357", "train_wall": "21", "wall": "10309"}
2021-10-23 00:46:56 | INFO | train_inner | {"epoch": 22, "update": 21.959, "loss": "2.109", "nll_loss": "0.21", "ppl": "1.16", "wps": "2624.6", "ups": "4.88", "wpb": "538.1", "bsz": "16", "num_updates": "26900", "lr": "4.86793e-05", "gnorm": "1.404", "train_wall": "20", "wall": "10330"}
2021-10-23 00:47:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-23 00:50:37 | INFO | valid | {"epoch": 22, "valid_loss": "2.696", "valid_nll_loss": "0.77", "valid_ppl": "1.7", "valid_bleu": "55.17", "valid_wps": "406.9", "valid_wpb": "281.5", "valid_bsz": "8", "valid_num_updates": "26950", "valid_best_bleu": "55.28"}
2021-10-23 00:50:37 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-23 00:50:52 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/large/checkpoint_last.pt (epoch 22 @ 26950 updates, score 55.17) (writing took 14.579117367975414 seconds)
2021-10-23 00:50:52 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2021-10-23 00:50:52 | INFO | train | {"epoch": 22, "train_loss": "2.108", "train_nll_loss": "0.209", "train_ppl": "1.16", "train_wps": "1479.7", "train_ups": "2.52", "train_wpb": "586.8", "train_bsz": "16", "train_num_updates": "26950", "train_lr": "4.86768e-05", "train_gnorm": "1.355", "train_train_wall": "255", "train_wall": "10566"}
2021-10-23 00:50:52 | INFO | fairseq_cli.train | begin training epoch 22
2021-10-23 00:51:02 | INFO | train_inner | {"epoch": 23, "update": 22.041, "loss": "2.111", "nll_loss": "0.212", "ppl": "1.16", "wps": "229.3", "ups": "0.41", "wpb": "565.5", "bsz": "15.9", "num_updates": "27000", "lr": "4.86743e-05", "gnorm": "1.392", "train_wall": "19", "wall": "10577"}
2021-10-23 00:51:22 | INFO | train_inner | {"epoch": 23, "update": 22.122, "loss": "2.105", "nll_loss": "0.206", "ppl": "1.15", "wps": "2847.8", "ups": "4.96", "wpb": "574.5", "bsz": "16", "num_updates": "27100", "lr": "4.86693e-05", "gnorm": "1.193", "train_wall": "20", "wall": "10597"}
2021-10-23 00:51:41 | INFO | train_inner | {"epoch": 23, "update": 22.204, "loss": "2.105", "nll_loss": "0.205", "ppl": "1.15", "wps": "2724.6", "ups": "5.27", "wpb": "517.5", "bsz": "16", "num_updates": "27200", "lr": "4.86643e-05", "gnorm": "1.369", "train_wall": "19", "wall": "10616"}
2021-10-23 00:52:02 | INFO | train_inner | {"epoch": 23, "update": 22.286, "loss": "2.103", "nll_loss": "0.206", "ppl": "1.15", "wps": "2908.9", "ups": "4.96", "wpb": "586.1", "bsz": "16", "num_updates": "27300", "lr": "4.86593e-05", "gnorm": "1.335", "train_wall": "20", "wall": "10636"}
2021-10-23 00:52:21 | INFO | train_inner | {"epoch": 23, "update": 22.367, "loss": "2.097", "nll_loss": "0.198", "ppl": "1.15", "wps": "2937.5", "ups": "5.07", "wpb": "579", "bsz": "16", "num_updates": "27400", "lr": "4.86543e-05", "gnorm": "1.158", "train_wall": "19", "wall": "10656"}
2021-10-23 00:52:42 | INFO | train_inner | {"epoch": 23, "update": 22.449, "loss": "2.103", "nll_loss": "0.205", "ppl": "1.15", "wps": "2831.9", "ups": "4.79", "wpb": "591.5", "bsz": "16", "num_updates": "27500", "lr": "4.86493e-05", "gnorm": "1.421", "train_wall": "21", "wall": "10677"}
2021-10-23 00:53:02 | INFO | train_inner | {"epoch": 23, "update": 22.531, "loss": "2.107", "nll_loss": "0.209", "ppl": "1.16", "wps": "2793.9", "ups": "5.04", "wpb": "554.2", "bsz": "16", "num_updates": "27600", "lr": "4.86443e-05", "gnorm": "1.565", "train_wall": "20", "wall": "10696"}
2021-10-23 00:53:23 | INFO | train_inner | {"epoch": 23, "update": 22.612, "loss": "2.107", "nll_loss": "0.21", "ppl": "1.16", "wps": "2887.8", "ups": "4.79", "wpb": "602.6", "bsz": "16", "num_updates": "27700", "lr": "4.86393e-05", "gnorm": "1.448", "train_wall": "21", "wall": "10717"}
2021-10-23 00:53:43 | INFO | train_inner | {"epoch": 23, "update": 22.694, "loss": "2.102", "nll_loss": "0.204", "ppl": "1.15", "wps": "2827.9", "ups": "4.91", "wpb": "575.5", "bsz": "16", "num_updates": "27800", "lr": "4.86343e-05", "gnorm": "1.297", "train_wall": "20", "wall": "10738"}
2021-10-23 00:54:02 | INFO | train_inner | {"epoch": 23, "update": 22.776, "loss": "2.111", "nll_loss": "0.211", "ppl": "1.16", "wps": "2859", "ups": "5.45", "wpb": "525", "bsz": "16", "num_updates": "27900", "lr": "4.86293e-05", "gnorm": "1.357", "train_wall": "18", "wall": "10756"}
2021-10-23 00:54:24 | INFO | train_inner | {"epoch": 23, "update": 22.857, "loss": "2.101", "nll_loss": "0.204", "ppl": "1.15", "wps": "3088.3", "ups": "4.49", "wpb": "687.2", "bsz": "16", "num_updates": "28000", "lr": "4.86243e-05", "gnorm": "1.292", "train_wall": "22", "wall": "10778"}
2021-10-23 00:54:43 | INFO | train_inner | {"epoch": 23, "update": 22.939, "loss": "2.112", "nll_loss": "0.213", "ppl": "1.16", "wps": "3349.4", "ups": "5.14", "wpb": "652", "bsz": "16", "num_updates": "28100", "lr": "4.86193e-05", "gnorm": "1.299", "train_wall": "19", "wall": "10798"}
2021-10-23 00:54:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-23 00:58:32 | INFO | valid | {"epoch": 23, "valid_loss": "2.7", "valid_nll_loss": "0.774", "valid_ppl": "1.71", "valid_bleu": "55.4", "valid_wps": "405.2", "valid_wpb": "281.5", "valid_bsz": "8", "valid_num_updates": "28175", "valid_best_bleu": "55.4"}
2021-10-23 00:58:32 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-23 00:59:01 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/large/checkpoint_best.pt (epoch 23 @ 28175 updates, score 55.4) (writing took 29.19224588898942 seconds)
2021-10-23 00:59:01 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2021-10-23 00:59:01 | INFO | train | {"epoch": 23, "train_loss": "2.105", "train_nll_loss": "0.206", "train_ppl": "1.15", "train_wps": "1468.3", "train_ups": "2.5", "train_wpb": "586.8", "train_bsz": "16", "train_num_updates": "28175", "train_lr": "4.86156e-05", "train_gnorm": "1.343", "train_train_wall": "244", "train_wall": "11056"}
2021-10-23 00:59:01 | INFO | fairseq_cli.train | begin training epoch 23
2021-10-23 00:59:06 | INFO | train_inner | {"epoch": 24, "update": 23.02, "loss": "2.107", "nll_loss": "0.208", "ppl": "1.16", "wps": "223.8", "ups": "0.38", "wpb": "589.1", "bsz": "15.9", "num_updates": "28200", "lr": "4.86143e-05", "gnorm": "1.315", "train_wall": "20", "wall": "11061"}
2021-10-23 00:59:26 | INFO | train_inner | {"epoch": 24, "update": 23.102, "loss": "2.099", "nll_loss": "0.2", "ppl": "1.15", "wps": "2876.2", "ups": "5.2", "wpb": "552.8", "bsz": "16", "num_updates": "28300", "lr": "4.86093e-05", "gnorm": "1.132", "train_wall": "19", "wall": "11080"}
2021-10-23 00:59:44 | INFO | train_inner | {"epoch": 24, "update": 23.184, "loss": "2.099", "nll_loss": "0.201", "ppl": "1.15", "wps": "2532.5", "ups": "5.34", "wpb": "474.6", "bsz": "16", "num_updates": "28400", "lr": "4.86043e-05", "gnorm": "1.246", "train_wall": "19", "wall": "11099"}
2021-10-23 01:00:03 | INFO | train_inner | {"epoch": 24, "update": 23.265, "loss": "2.099", "nll_loss": "0.202", "ppl": "1.15", "wps": "3234.5", "ups": "5.29", "wpb": "611.9", "bsz": "16", "num_updates": "28500", "lr": "4.85993e-05", "gnorm": "1.322", "train_wall": "19", "wall": "11118"}
2021-10-23 01:00:22 | INFO | train_inner | {"epoch": 24, "update": 23.347, "loss": "2.099", "nll_loss": "0.201", "ppl": "1.15", "wps": "3349", "ups": "5.22", "wpb": "641.5", "bsz": "16", "num_updates": "28600", "lr": "4.85943e-05", "gnorm": "1.053", "train_wall": "19", "wall": "11137"}
2021-10-23 01:00:42 | INFO | train_inner | {"epoch": 24, "update": 23.429, "loss": "2.094", "nll_loss": "0.197", "ppl": "1.15", "wps": "3361", "ups": "5.19", "wpb": "647.2", "bsz": "16", "num_updates": "28700", "lr": "4.85893e-05", "gnorm": "1.141", "train_wall": "19", "wall": "11156"}
2021-10-23 01:00:59 | INFO | train_inner | {"epoch": 24, "update": 23.51, "loss": "2.108", "nll_loss": "0.209", "ppl": "1.16", "wps": "2945.2", "ups": "5.76", "wpb": "511.5", "bsz": "16", "num_updates": "28800", "lr": "4.85843e-05", "gnorm": "1.392", "train_wall": "17", "wall": "11174"}
2021-10-23 01:01:19 | INFO | train_inner | {"epoch": 24, "update": 23.592, "loss": "2.101", "nll_loss": "0.204", "ppl": "1.15", "wps": "3413.7", "ups": "4.98", "wpb": "685.7", "bsz": "16", "num_updates": "28900", "lr": "4.85793e-05", "gnorm": "1.302", "train_wall": "20", "wall": "11194"}
2021-10-23 01:01:37 | INFO | train_inner | {"epoch": 24, "update": 23.673, "loss": "2.107", "nll_loss": "0.208", "ppl": "1.16", "wps": "3291.5", "ups": "5.49", "wpb": "599.9", "bsz": "16", "num_updates": "29000", "lr": "4.85743e-05", "gnorm": "1.278", "train_wall": "18", "wall": "11212"}
2021-10-23 01:01:56 | INFO | train_inner | {"epoch": 24, "update": 23.755, "loss": "2.1", "nll_loss": "0.204", "ppl": "1.15", "wps": "3192.5", "ups": "5.25", "wpb": "607.8", "bsz": "16", "num_updates": "29100", "lr": "4.85693e-05", "gnorm": "1.391", "train_wall": "19", "wall": "11231"}
2021-10-23 01:02:16 | INFO | train_inner | {"epoch": 24, "update": 23.837, "loss": "2.104", "nll_loss": "0.207", "ppl": "1.15", "wps": "3008.3", "ups": "5.1", "wpb": "590.1", "bsz": "16", "num_updates": "29200", "lr": "4.85643e-05", "gnorm": "1.404", "train_wall": "19", "wall": "11251"}
2021-10-23 01:02:35 | INFO | train_inner | {"epoch": 24, "update": 23.918, "loss": "2.109", "nll_loss": "0.212", "ppl": "1.16", "wps": "3102.8", "ups": "5.43", "wpb": "571.9", "bsz": "16", "num_updates": "29300", "lr": "4.85593e-05", "gnorm": "1.317", "train_wall": "18", "wall": "11269"}
2021-10-23 01:02:53 | INFO | train_inner | {"epoch": 24, "update": 24.0, "loss": "2.103", "nll_loss": "0.206", "ppl": "1.15", "wps": "3002", "ups": "5.44", "wpb": "551.3", "bsz": "15.9", "num_updates": "29400", "lr": "4.85543e-05", "gnorm": "1.312", "train_wall": "18", "wall": "11287"}
2021-10-23 01:02:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-23 01:06:19 | INFO | valid | {"epoch": 24, "valid_loss": "2.703", "valid_nll_loss": "0.783", "valid_ppl": "1.72", "valid_bleu": "55.37", "valid_wps": "418.7", "valid_wpb": "281.5", "valid_bsz": "8", "valid_num_updates": "29400", "valid_best_bleu": "55.4"}
2021-10-23 01:06:19 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-23 01:06:26 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/large/checkpoint_last.pt (epoch 24 @ 29400 updates, score 55.37) (writing took 6.745305838994682 seconds)
2021-10-23 01:06:26 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2021-10-23 01:06:26 | INFO | train | {"epoch": 24, "train_loss": "2.102", "train_nll_loss": "0.204", "train_ppl": "1.15", "train_wps": "1616.1", "train_ups": "2.75", "train_wpb": "586.8", "train_bsz": "16", "train_num_updates": "29400", "train_lr": "4.85543e-05", "train_gnorm": "1.27", "train_train_wall": "229", "train_wall": "11501"}
2021-10-23 01:06:26 | INFO | fairseq_cli.train | begin training epoch 24
2021-10-23 01:06:48 | INFO | train_inner | {"epoch": 25, "update": 24.082, "loss": "2.091", "nll_loss": "0.195", "ppl": "1.15", "wps": "318", "ups": "0.42", "wpb": "748.4", "bsz": "16", "num_updates": "29500", "lr": "4.85493e-05", "gnorm": "1.169", "train_wall": "22", "wall": "11523"}
2021-10-23 01:07:08 | INFO | train_inner | {"epoch": 25, "update": 24.163, "loss": "2.09", "nll_loss": "0.193", "ppl": "1.14", "wps": "3414.9", "ups": "5.05", "wpb": "676", "bsz": "16", "num_updates": "29600", "lr": "4.85443e-05", "gnorm": "1.135", "train_wall": "20", "wall": "11542"}
2021-10-23 01:07:27 | INFO | train_inner | {"epoch": 25, "update": 24.245, "loss": "2.095", "nll_loss": "0.198", "ppl": "1.15", "wps": "3043.7", "ups": "5.15", "wpb": "590.5", "bsz": "16", "num_updates": "29700", "lr": "4.85393e-05", "gnorm": "1.279", "train_wall": "19", "wall": "11562"}
2021-10-23 01:07:47 | INFO | train_inner | {"epoch": 25, "update": 24.327, "loss": "2.099", "nll_loss": "0.201", "ppl": "1.15", "wps": "3014.4", "ups": "5.16", "wpb": "583.7", "bsz": "16", "num_updates": "29800", "lr": "4.85343e-05", "gnorm": "1.301", "train_wall": "19", "wall": "11581"}
2021-10-23 01:08:06 | INFO | train_inner | {"epoch": 25, "update": 24.408, "loss": "2.099", "nll_loss": "0.202", "ppl": "1.15", "wps": "3125.3", "ups": "5.34", "wpb": "585.5", "bsz": "16", "num_updates": "29900", "lr": "4.85293e-05", "gnorm": "1.235", "train_wall": "19", "wall": "11600"}
2021-10-23 01:08:24 | INFO | train_inner | {"epoch": 25, "update": 24.49, "loss": "2.108", "nll_loss": "0.208", "ppl": "1.16", "wps": "2851.8", "ups": "5.36", "wpb": "531.9", "bsz": "16", "num_updates": "30000", "lr": "4.85243e-05", "gnorm": "1.516", "train_wall": "18", "wall": "11619"}
2021-10-23 01:08:43 | INFO | train_inner | {"epoch": 25, "update": 24.571, "loss": "2.103", "nll_loss": "0.205", "ppl": "1.15", "wps": "2690.8", "ups": "5.19", "wpb": "518.2", "bsz": "16", "num_updates": "30100", "lr": "4.85193e-05", "gnorm": "1.355", "train_wall": "19", "wall": "11638"}
2021-10-23 01:09:02 | INFO | train_inner | {"epoch": 25, "update": 24.653, "loss": "2.099", "nll_loss": "0.202", "ppl": "1.15", "wps": "2988.3", "ups": "5.43", "wpb": "550.5", "bsz": "16", "num_updates": "30200", "lr": "4.85143e-05", "gnorm": "1.294", "train_wall": "18", "wall": "11656"}
2021-10-23 01:09:22 | INFO | train_inner | {"epoch": 25, "update": 24.735, "loss": "2.1", "nll_loss": "0.203", "ppl": "1.15", "wps": "2766.1", "ups": "4.88", "wpb": "566.6", "bsz": "16", "num_updates": "30300", "lr": "4.85093e-05", "gnorm": "1.318", "train_wall": "20", "wall": "11677"}
2021-10-23 01:09:40 | INFO | train_inner | {"epoch": 25, "update": 24.816, "loss": "2.107", "nll_loss": "0.208", "ppl": "1.15", "wps": "2986", "ups": "5.66", "wpb": "527.8", "bsz": "16", "num_updates": "30400", "lr": "4.85043e-05", "gnorm": "1.234", "train_wall": "17", "wall": "11694"}
2021-10-23 01:10:00 | INFO | train_inner | {"epoch": 25, "update": 24.898, "loss": "2.101", "nll_loss": "0.203", "ppl": "1.15", "wps": "3182.8", "ups": "5.08", "wpb": "627.1", "bsz": "16", "num_updates": "30500", "lr": "4.84992e-05", "gnorm": "1.405", "train_wall": "19", "wall": "11714"}
2021-10-23 01:10:18 | INFO | train_inner | {"epoch": 25, "update": 24.98, "loss": "2.096", "nll_loss": "0.2", "ppl": "1.15", "wps": "2990.9", "ups": "5.44", "wpb": "549.9", "bsz": "16", "num_updates": "30600", "lr": "4.84942e-05", "gnorm": "1.187", "train_wall": "18", "wall": "11733"}
2021-10-23 01:10:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-23 01:13:50 | INFO | valid | {"epoch": 25, "valid_loss": "2.707", "valid_nll_loss": "0.789", "valid_ppl": "1.73", "valid_bleu": "55.39", "valid_wps": "417.6", "valid_wpb": "281.5", "valid_bsz": "8", "valid_num_updates": "30625", "valid_best_bleu": "55.4"}
2021-10-23 01:13:50 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-23 01:13:57 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/large/checkpoint_last.pt (epoch 25 @ 30625 updates, score 55.39) (writing took 7.471523422980681 seconds)
2021-10-23 01:13:57 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2021-10-23 01:13:57 | INFO | train | {"epoch": 25, "train_loss": "2.098", "train_nll_loss": "0.201", "train_ppl": "1.15", "train_wps": "1594.6", "train_ups": "2.72", "train_wpb": "586.8", "train_bsz": "16", "train_num_updates": "30625", "train_lr": "4.8493e-05", "train_gnorm": "1.282", "train_train_wall": "233", "train_wall": "11951"}
2021-10-23 01:13:57 | INFO | fairseq_cli.train | begin training epoch 25
2021-10-23 01:14:10 | INFO | train_inner | {"epoch": 26, "update": 25.061, "loss": "2.096", "nll_loss": "0.197", "ppl": "1.15", "wps": "223", "ups": "0.43", "wpb": "517.4", "bsz": "15.9", "num_updates": "30700", "lr": "4.84892e-05", "gnorm": "1.117", "train_wall": "17", "wall": "11965"}
2021-10-23 01:14:29 | INFO | train_inner | {"epoch": 26, "update": 25.143, "loss": "2.091", "nll_loss": "0.195", "ppl": "1.14", "wps": "3131.1", "ups": "5.29", "wpb": "591.5", "bsz": "16", "num_updates": "30800", "lr": "4.84842e-05", "gnorm": "1.161", "train_wall": "19", "wall": "11984"}
2021-10-23 01:14:48 | INFO | train_inner | {"epoch": 26, "update": 25.224, "loss": "2.098", "nll_loss": "0.201", "ppl": "1.15", "wps": "2979.7", "ups": "5.29", "wpb": "562.8", "bsz": "16", "num_updates": "30900", "lr": "4.84792e-05", "gnorm": "1.121", "train_wall": "19", "wall": "12002"}
2021-10-23 01:15:06 | INFO | train_inner | {"epoch": 26, "update": 25.306, "loss": "2.097", "nll_loss": "0.199", "ppl": "1.15", "wps": "2891.4", "ups": "5.44", "wpb": "531.5", "bsz": "16", "num_updates": "31000", "lr": "4.84742e-05", "gnorm": "1.219", "train_wall": "18", "wall": "12021"}
2021-10-23 01:15:25 | INFO | train_inner | {"epoch": 26, "update": 25.388, "loss": "2.096", "nll_loss": "0.199", "ppl": "1.15", "wps": "3076.5", "ups": "5.26", "wpb": "584.5", "bsz": "16", "num_updates": "31100", "lr": "4.84692e-05", "gnorm": "1.139", "train_wall": "19", "wall": "12040"}
2021-10-23 01:15:46 | INFO | train_inner | {"epoch": 26, "update": 25.469, "loss": "2.095", "nll_loss": "0.198", "ppl": "1.15", "wps": "3054.5", "ups": "4.93", "wpb": "619.2", "bsz": "16", "num_updates": "31200", "lr": "4.84642e-05", "gnorm": "1.29", "train_wall": "20", "wall": "12060"}
2021-10-23 01:16:04 | INFO | train_inner | {"epoch": 26, "update": 25.551, "loss": "2.096", "nll_loss": "0.2", "ppl": "1.15", "wps": "3272.9", "ups": "5.54", "wpb": "591", "bsz": "16", "num_updates": "31300", "lr": "4.84592e-05", "gnorm": "1.136", "train_wall": "18", "wall": "12078"}
2021-10-23 01:16:24 | INFO | train_inner | {"epoch": 26, "update": 25.633, "loss": "2.097", "nll_loss": "0.199", "ppl": "1.15", "wps": "2931.2", "ups": "4.98", "wpb": "588.9", "bsz": "16", "num_updates": "31400", "lr": "4.84542e-05", "gnorm": "1.194", "train_wall": "20", "wall": "12098"}
2021-10-23 01:16:45 | INFO | train_inner | {"epoch": 26, "update": 25.714, "loss": "2.088", "nll_loss": "0.192", "ppl": "1.14", "wps": "3482.4", "ups": "4.8", "wpb": "725.8", "bsz": "16", "num_updates": "31500", "lr": "4.84492e-05", "gnorm": "1.041", "train_wall": "21", "wall": "12119"}
2021-10-23 01:17:05 | INFO | train_inner | {"epoch": 26, "update": 25.796, "loss": "2.093", "nll_loss": "0.197", "ppl": "1.15", "wps": "3114.1", "ups": "4.88", "wpb": "638.5", "bsz": "16", "num_updates": "31600", "lr": "4.84442e-05", "gnorm": "1.158", "train_wall": "20", "wall": "12140"}
2021-10-23 01:17:24 | INFO | train_inner | {"epoch": 26, "update": 25.878, "loss": "2.107", "nll_loss": "0.211", "ppl": "1.16", "wps": "2916.9", "ups": "5.33", "wpb": "547.1", "bsz": "16", "num_updates": "31700", "lr": "4.84392e-05", "gnorm": "1.424", "train_wall": "19", "wall": "12158"}
2021-10-23 01:17:42 | INFO | train_inner | {"epoch": 26, "update": 25.959, "loss": "2.105", "nll_loss": "0.206", "ppl": "1.15", "wps": "2877.4", "ups": "5.45", "wpb": "528", "bsz": "16", "num_updates": "31800", "lr": "4.84342e-05", "gnorm": "1.347", "train_wall": "18", "wall": "12177"}
2021-10-23 01:17:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-23 01:21:21 | INFO | valid | {"epoch": 26, "valid_loss": "2.714", "valid_nll_loss": "0.786", "valid_ppl": "1.72", "valid_bleu": "54.86", "valid_wps": "414.4", "valid_wpb": "281.5", "valid_bsz": "8", "valid_num_updates": "31850", "valid_best_bleu": "55.4"}
2021-10-23 01:21:21 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-23 01:21:35 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/large/checkpoint_last.pt (epoch 26 @ 31850 updates, score 54.86) (writing took 14.625524159986526 seconds)
2021-10-23 01:21:35 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2021-10-23 01:21:35 | INFO | train | {"epoch": 26, "train_loss": "2.096", "train_nll_loss": "0.199", "train_ppl": "1.15", "train_wps": "1568.8", "train_ups": "2.67", "train_wpb": "586.8", "train_bsz": "16", "train_num_updates": "31850", "train_lr": "4.84317e-05", "train_gnorm": "1.203", "train_train_wall": "232", "train_wall": "12410"}
2021-10-23 01:21:35 | INFO | fairseq_cli.train | begin training epoch 26
2021-10-23 01:21:46 | INFO | train_inner | {"epoch": 27, "update": 26.041, "loss": "2.094", "nll_loss": "0.197", "ppl": "1.15", "wps": "263.4", "ups": "0.41", "wpb": "641.3", "bsz": "15.9", "num_updates": "31900", "lr": "4.84292e-05", "gnorm": "1.219", "train_wall": "20", "wall": "12420"}
2021-10-23 01:22:04 | INFO | train_inner | {"epoch": 27, "update": 26.122, "loss": "2.098", "nll_loss": "0.199", "ppl": "1.15", "wps": "3148", "ups": "5.6", "wpb": "562.2", "bsz": "16", "num_updates": "32000", "lr": "4.84242e-05", "gnorm": "1.216", "train_wall": "18", "wall": "12438"}
2021-10-23 01:22:23 | INFO | train_inner | {"epoch": 27, "update": 26.204, "loss": "2.094", "nll_loss": "0.198", "ppl": "1.15", "wps": "2890.6", "ups": "5.06", "wpb": "571.1", "bsz": "16", "num_updates": "32100", "lr": "4.84192e-05", "gnorm": "1.177", "train_wall": "20", "wall": "12458"}
2021-10-23 01:22:43 | INFO | train_inner | {"epoch": 27, "update": 26.286, "loss": "2.093", "nll_loss": "0.196", "ppl": "1.15", "wps": "3101.9", "ups": "5", "wpb": "620.5", "bsz": "16", "num_updates": "32200", "lr": "4.84142e-05", "gnorm": "1.329", "train_wall": "20", "wall": "12478"}
2021-10-23 01:23:02 | INFO | train_inner | {"epoch": 27, "update": 26.367, "loss": "2.095", "nll_loss": "0.199", "ppl": "1.15", "wps": "3037.9", "ups": "5.25", "wpb": "579.1", "bsz": "16", "num_updates": "32300", "lr": "4.84092e-05", "gnorm": "1.204", "train_wall": "19", "wall": "12497"}
2021-10-23 01:23:20 | INFO | train_inner | {"epoch": 27, "update": 26.449, "loss": "2.098", "nll_loss": "0.198", "ppl": "1.15", "wps": "2851.9", "ups": "5.67", "wpb": "502.9", "bsz": "16", "num_updates": "32400", "lr": "4.84042e-05", "gnorm": "1.316", "train_wall": "17", "wall": "12514"}
2021-10-23 01:23:40 | INFO | train_inner | {"epoch": 27, "update": 26.531, "loss": "2.093", "nll_loss": "0.197", "ppl": "1.15", "wps": "3193.4", "ups": "5.1", "wpb": "626", "bsz": "16", "num_updates": "32500", "lr": "4.83992e-05", "gnorm": "1.085", "train_wall": "19", "wall": "12534"}
2021-10-23 01:24:00 | INFO | train_inner | {"epoch": 27, "update": 26.612, "loss": "2.09", "nll_loss": "0.196", "ppl": "1.15", "wps": "3326.3", "ups": "4.99", "wpb": "666.9", "bsz": "16", "num_updates": "32600", "lr": "4.83942e-05", "gnorm": "1.185", "train_wall": "20", "wall": "12554"}
2021-10-23 01:24:20 | INFO | train_inner | {"epoch": 27, "update": 26.694, "loss": "2.1", "nll_loss": "0.204", "ppl": "1.15", "wps": "3117.1", "ups": "4.96", "wpb": "628.8", "bsz": "16", "num_updates": "32700", "lr": "4.83892e-05", "gnorm": "1.313", "train_wall": "20", "wall": "12574"}
2021-10-23 01:24:40 | INFO | train_inner | {"epoch": 27, "update": 26.776, "loss": "2.092", "nll_loss": "0.197", "ppl": "1.15", "wps": "3070.5", "ups": "4.91", "wpb": "625.4", "bsz": "16", "num_updates": "32800", "lr": "4.83842e-05", "gnorm": "1.1", "train_wall": "20", "wall": "12595"}
2021-10-23 01:24:59 | INFO | train_inner | {"epoch": 27, "update": 26.857, "loss": "2.097", "nll_loss": "0.201", "ppl": "1.15", "wps": "2780.7", "ups": "5.18", "wpb": "537.2", "bsz": "16", "num_updates": "32900", "lr": "4.83792e-05", "gnorm": "1.229", "train_wall": "19", "wall": "12614"}
2021-10-23 01:25:18 | INFO | train_inner | {"epoch": 27, "update": 26.939, "loss": "2.099", "nll_loss": "0.202", "ppl": "1.15", "wps": "2734.8", "ups": "5.53", "wpb": "495", "bsz": "16", "num_updates": "33000", "lr": "4.83742e-05", "gnorm": "1.254", "train_wall": "18", "wall": "12632"}
2021-10-23 01:25:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-23 01:28:55 | INFO | valid | {"epoch": 27, "valid_loss": "2.7", "valid_nll_loss": "0.782", "valid_ppl": "1.72", "valid_bleu": "55.59", "valid_wps": "427.6", "valid_wpb": "281.5", "valid_bsz": "8", "valid_num_updates": "33075", "valid_best_bleu": "55.59"}
2021-10-23 01:28:55 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-23 01:29:21 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/large/checkpoint_best.pt (epoch 27 @ 33075 updates, score 55.59) (writing took 26.900452729896642 seconds)
2021-10-23 01:29:21 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2021-10-23 01:29:21 | INFO | train | {"epoch": 27, "train_loss": "2.095", "train_nll_loss": "0.198", "train_ppl": "1.15", "train_wps": "1541.6", "train_ups": "2.63", "train_wpb": "586.8", "train_bsz": "16", "train_num_updates": "33075", "train_lr": "4.83704e-05", "train_gnorm": "1.212", "train_train_wall": "234", "train_wall": "12876"}
2021-10-23 01:29:21 | INFO | fairseq_cli.train | begin training epoch 27
2021-10-23 01:29:27 | INFO | train_inner | {"epoch": 28, "update": 27.02, "loss": "2.092", "nll_loss": "0.196", "ppl": "1.15", "wps": "234.4", "ups": "0.4", "wpb": "583.6", "bsz": "15.9", "num_updates": "33100", "lr": "4.83692e-05", "gnorm": "1.183", "train_wall": "19", "wall": "12881"}
2021-10-23 01:29:45 | INFO | train_inner | {"epoch": 28, "update": 27.102, "loss": "2.093", "nll_loss": "0.194", "ppl": "1.14", "wps": "2877.3", "ups": "5.46", "wpb": "526.7", "bsz": "16", "num_updates": "33200", "lr": "4.83642e-05", "gnorm": "1.446", "train_wall": "18", "wall": "12899"}
2021-10-23 01:30:03 | INFO | train_inner | {"epoch": 28, "update": 27.184, "loss": "2.093", "nll_loss": "0.195", "ppl": "1.14", "wps": "2746.8", "ups": "5.47", "wpb": "502", "bsz": "16", "num_updates": "33300", "lr": "4.83592e-05", "gnorm": "1.228", "train_wall": "18", "wall": "12918"}
2021-10-23 01:30:25 | INFO | train_inner | {"epoch": 28, "update": 27.265, "loss": "2.096", "nll_loss": "0.201", "ppl": "1.15", "wps": "2936.7", "ups": "4.67", "wpb": "628.8", "bsz": "16", "num_updates": "33400", "lr": "4.83542e-05", "gnorm": "1.251", "train_wall": "21", "wall": "12939"}
2021-10-23 01:30:44 | INFO | train_inner | {"epoch": 28, "update": 27.347, "loss": "2.092", "nll_loss": "0.196", "ppl": "1.15", "wps": "2970.2", "ups": "5.13", "wpb": "578.6", "bsz": "16", "num_updates": "33500", "lr": "4.83492e-05", "gnorm": "1.065", "train_wall": "19", "wall": "12958"}
2021-10-23 01:31:04 | INFO | train_inner | {"epoch": 28, "update": 27.429, "loss": "2.089", "nll_loss": "0.193", "ppl": "1.14", "wps": "3097.7", "ups": "5.11", "wpb": "606.5", "bsz": "16", "num_updates": "33600", "lr": "4.83442e-05", "gnorm": "1.113", "train_wall": "19", "wall": "12978"}
2021-10-23 01:31:24 | INFO | train_inner | {"epoch": 28, "update": 27.51, "loss": "2.092", "nll_loss": "0.197", "ppl": "1.15", "wps": "2898.4", "ups": "4.85", "wpb": "597.7", "bsz": "16", "num_updates": "33700", "lr": "4.83392e-05", "gnorm": "1.11", "train_wall": "20", "wall": "12999"}
2021-10-23 01:31:44 | INFO | train_inner | {"epoch": 28, "update": 27.592, "loss": "2.099", "nll_loss": "0.201", "ppl": "1.15", "wps": "2935.5", "ups": "5.05", "wpb": "581.8", "bsz": "16", "num_updates": "33800", "lr": "4.83342e-05", "gnorm": "1.292", "train_wall": "20", "wall": "13019"}
2021-10-23 01:32:03 | INFO | train_inner | {"epoch": 28, "update": 27.673, "loss": "2.088", "nll_loss": "0.192", "ppl": "1.14", "wps": "2835.7", "ups": "5.23", "wpb": "542.3", "bsz": "16", "num_updates": "33900", "lr": "4.83292e-05", "gnorm": "1.12", "train_wall": "19", "wall": "13038"}
2021-10-23 01:32:25 | INFO | train_inner | {"epoch": 28, "update": 27.755, "loss": "2.092", "nll_loss": "0.196", "ppl": "1.15", "wps": "3090.6", "ups": "4.59", "wpb": "672.6", "bsz": "16", "num_updates": "34000", "lr": "4.83242e-05", "gnorm": "1.228", "train_wall": "22", "wall": "13059"}
2021-10-23 01:32:44 | INFO | train_inner | {"epoch": 28, "update": 27.837, "loss": "2.091", "nll_loss": "0.194", "ppl": "1.14", "wps": "3110.3", "ups": "5.19", "wpb": "599.6", "bsz": "16", "num_updates": "34100", "lr": "4.83192e-05", "gnorm": "1.28", "train_wall": "19", "wall": "13079"}
2021-10-23 01:33:03 | INFO | train_inner | {"epoch": 28, "update": 27.918, "loss": "2.094", "nll_loss": "0.197", "ppl": "1.15", "wps": "2986", "ups": "5.39", "wpb": "554.5", "bsz": "16", "num_updates": "34200", "lr": "4.83142e-05", "gnorm": "1.106", "train_wall": "18", "wall": "13097"}
2021-10-23 01:33:23 | INFO | train_inner | {"epoch": 28, "update": 28.0, "loss": "2.092", "nll_loss": "0.196", "ppl": "1.15", "wps": "3210", "ups": "5.03", "wpb": "638.4", "bsz": "15.9", "num_updates": "34300", "lr": "4.83092e-05", "gnorm": "1.182", "train_wall": "20", "wall": "13117"}
2021-10-23 01:33:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-23 01:36:50 | INFO | valid | {"epoch": 28, "valid_loss": "2.711", "valid_nll_loss": "0.803", "valid_ppl": "1.74", "valid_bleu": "55.66", "valid_wps": "416.3", "valid_wpb": "281.5", "valid_bsz": "8", "valid_num_updates": "34300", "valid_best_bleu": "55.66"}
2021-10-23 01:36:51 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-23 01:37:11 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/large/checkpoint_best.pt (epoch 28 @ 34300 updates, score 55.66) (writing took 20.82400596200023 seconds)
2021-10-23 01:37:11 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2021-10-23 01:37:11 | INFO | train | {"epoch": 28, "train_loss": "2.092", "train_nll_loss": "0.196", "train_ppl": "1.15", "train_wps": "1529.7", "train_ups": "2.61", "train_wpb": "586.8", "train_bsz": "16", "train_num_updates": "34300", "train_lr": "4.83092e-05", "train_gnorm": "1.202", "train_train_wall": "239", "train_wall": "13346"}
2021-10-23 01:37:11 | INFO | fairseq_cli.train | begin training epoch 28
2021-10-23 01:37:30 | INFO | train_inner | {"epoch": 29, "update": 28.082, "loss": "2.093", "nll_loss": "0.197", "ppl": "1.15", "wps": "235.8", "ups": "0.4", "wpb": "582.5", "bsz": "16", "num_updates": "34400", "lr": "4.83042e-05", "gnorm": "1.117", "train_wall": "18", "wall": "13364"}
2021-10-23 01:37:49 | INFO | train_inner | {"epoch": 29, "update": 28.163, "loss": "2.083", "nll_loss": "0.188", "ppl": "1.14", "wps": "2853", "ups": "5.25", "wpb": "543.4", "bsz": "16", "num_updates": "34500", "lr": "4.82991e-05", "gnorm": "1.072", "train_wall": "19", "wall": "13383"}
2021-10-23 01:38:10 | INFO | train_inner | {"epoch": 29, "update": 28.245, "loss": "2.087", "nll_loss": "0.191", "ppl": "1.14", "wps": "3205.1", "ups": "4.72", "wpb": "679", "bsz": "16", "num_updates": "34600", "lr": "4.82941e-05", "gnorm": "1.03", "train_wall": "21", "wall": "13404"}
2021-10-23 01:38:30 | INFO | train_inner | {"epoch": 29, "update": 28.327, "loss": "2.09", "nll_loss": "0.193", "ppl": "1.14", "wps": "3160.6", "ups": "5.03", "wpb": "627.9", "bsz": "16", "num_updates": "34700", "lr": "4.82891e-05", "gnorm": "1.07", "train_wall": "20", "wall": "13424"}
2021-10-23 01:38:49 | INFO | train_inner | {"epoch": 29, "update": 28.408, "loss": "2.089", "nll_loss": "0.194", "ppl": "1.14", "wps": "3146.4", "ups": "5.23", "wpb": "601.7", "bsz": "16", "num_updates": "34800", "lr": "4.82841e-05", "gnorm": "1.237", "train_wall": "19", "wall": "13443"}
2021-10-23 01:39:10 | INFO | train_inner | {"epoch": 29, "update": 28.49, "loss": "2.092", "nll_loss": "0.198", "ppl": "1.15", "wps": "2904.4", "ups": "4.66", "wpb": "623.8", "bsz": "16", "num_updates": "34900", "lr": "4.82791e-05", "gnorm": "1.552", "train_wall": "21", "wall": "13465"}
2021-10-23 01:39:29 | INFO | train_inner | {"epoch": 29, "update": 28.571, "loss": "2.092", "nll_loss": "0.197", "ppl": "1.15", "wps": "3002.7", "ups": "5.28", "wpb": "568.4", "bsz": "16", "num_updates": "35000", "lr": "4.82741e-05", "gnorm": "1.204", "train_wall": "19", "wall": "13484"}
2021-10-23 01:39:47 | INFO | train_inner | {"epoch": 29, "update": 28.653, "loss": "2.096", "nll_loss": "0.199", "ppl": "1.15", "wps": "2743.1", "ups": "5.64", "wpb": "486", "bsz": "16", "num_updates": "35100", "lr": "4.82691e-05", "gnorm": "1.17", "train_wall": "18", "wall": "13502"}
2021-10-23 01:40:07 | INFO | train_inner | {"epoch": 29, "update": 28.735, "loss": "2.096", "nll_loss": "0.201", "ppl": "1.15", "wps": "3087", "ups": "5.13", "wpb": "601.3", "bsz": "16", "num_updates": "35200", "lr": "4.82641e-05", "gnorm": "1.347", "train_wall": "19", "wall": "13521"}
2021-10-23 01:40:25 | INFO | train_inner | {"epoch": 29, "update": 28.816, "loss": "2.094", "nll_loss": "0.198", "ppl": "1.15", "wps": "2856.8", "ups": "5.4", "wpb": "528.7", "bsz": "16", "num_updates": "35300", "lr": "4.82591e-05", "gnorm": "1.272", "train_wall": "18", "wall": "13540"}
2021-10-23 01:40:44 | INFO | train_inner | {"epoch": 29, "update": 28.898, "loss": "2.091", "nll_loss": "0.196", "ppl": "1.15", "wps": "3003", "ups": "5.2", "wpb": "577.5", "bsz": "16", "num_updates": "35400", "lr": "4.82541e-05", "gnorm": "1.134", "train_wall": "19", "wall": "13559"}
2021-10-23 01:41:05 | INFO | train_inner | {"epoch": 29, "update": 28.98, "loss": "2.093", "nll_loss": "0.199", "ppl": "1.15", "wps": "2970.3", "ups": "4.85", "wpb": "612.8", "bsz": "16", "num_updates": "35500", "lr": "4.82491e-05", "gnorm": "1.206", "train_wall": "20", "wall": "13579"}
2021-10-23 01:41:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-23 01:44:47 | INFO | valid | {"epoch": 29, "valid_loss": "2.698", "valid_nll_loss": "0.793", "valid_ppl": "1.73", "valid_bleu": "55.59", "valid_wps": "398.5", "valid_wpb": "281.5", "valid_bsz": "8", "valid_num_updates": "35525", "valid_best_bleu": "55.66"}
2021-10-23 01:44:47 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-23 01:44:54 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/large/checkpoint_last.pt (epoch 29 @ 35525 updates, score 55.59) (writing took 6.800397790968418 seconds)
2021-10-23 01:44:54 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2021-10-23 01:44:54 | INFO | train | {"epoch": 29, "train_loss": "2.091", "train_nll_loss": "0.196", "train_ppl": "1.15", "train_wps": "1554.6", "train_ups": "2.65", "train_wpb": "586.8", "train_bsz": "16", "train_num_updates": "35525", "train_lr": "4.82479e-05", "train_gnorm": "1.206", "train_train_wall": "236", "train_wall": "13808"}
2021-10-23 01:44:54 | INFO | fairseq_cli.train | begin training epoch 29
2021-10-23 01:45:08 | INFO | train_inner | {"epoch": 30, "update": 29.061, "loss": "2.091", "nll_loss": "0.194", "ppl": "1.14", "wps": "239.6", "ups": "0.41", "wpb": "582", "bsz": "15.9", "num_updates": "35600", "lr": "4.82441e-05", "gnorm": "1.177", "train_wall": "19", "wall": "13822"}
2021-10-23 01:45:28 | INFO | train_inner | {"epoch": 30, "update": 29.143, "loss": "2.089", "nll_loss": "0.192", "ppl": "1.14", "wps": "2867.4", "ups": "4.97", "wpb": "576.7", "bsz": "16", "num_updates": "35700", "lr": "4.82391e-05", "gnorm": "1.234", "train_wall": "20", "wall": "13842"}
2021-10-23 01:45:47 | INFO | train_inner | {"epoch": 30, "update": 29.224, "loss": "2.087", "nll_loss": "0.191", "ppl": "1.14", "wps": "2886.2", "ups": "5.27", "wpb": "547.6", "bsz": "16", "num_updates": "35800", "lr": "4.82341e-05", "gnorm": "1.106", "train_wall": "19", "wall": "13861"}
2021-10-23 01:46:07 | INFO | train_inner | {"epoch": 30, "update": 29.306, "loss": "2.089", "nll_loss": "0.194", "ppl": "1.14", "wps": "3192.2", "ups": "5.07", "wpb": "629.1", "bsz": "16", "num_updates": "35900", "lr": "4.82291e-05", "gnorm": "1.211", "train_wall": "20", "wall": "13881"}
2021-10-23 01:46:25 | INFO | train_inner | {"epoch": 30, "update": 29.388, "loss": "2.094", "nll_loss": "0.197", "ppl": "1.15", "wps": "2936.9", "ups": "5.43", "wpb": "540.6", "bsz": "16", "num_updates": "36000", "lr": "4.82241e-05", "gnorm": "1.236", "train_wall": "18", "wall": "13900"}
2021-10-23 01:46:44 | INFO | train_inner | {"epoch": 30, "update": 29.469, "loss": "2.085", "nll_loss": "0.19", "ppl": "1.14", "wps": "3412.3", "ups": "5.19", "wpb": "657.4", "bsz": "16", "num_updates": "36100", "lr": "4.82191e-05", "gnorm": "1.636", "train_wall": "19", "wall": "13919"}
2021-10-23 01:47:03 | INFO | train_inner | {"epoch": 30, "update": 29.551, "loss": "2.088", "nll_loss": "0.193", "ppl": "1.14", "wps": "3127.8", "ups": "5.47", "wpb": "571.8", "bsz": "16", "num_updates": "36200", "lr": "4.82141e-05", "gnorm": "1.197", "train_wall": "18", "wall": "13937"}
2021-10-23 01:47:21 | INFO | train_inner | {"epoch": 30, "update": 29.633, "loss": "2.092", "nll_loss": "0.195", "ppl": "1.14", "wps": "3067.6", "ups": "5.52", "wpb": "555.9", "bsz": "16", "num_updates": "36300", "lr": "4.82091e-05", "gnorm": "1.184", "train_wall": "18", "wall": "13955"}
2021-10-23 01:47:40 | INFO | train_inner | {"epoch": 30, "update": 29.714, "loss": "2.085", "nll_loss": "0.19", "ppl": "1.14", "wps": "3198", "ups": "5.09", "wpb": "628.6", "bsz": "16", "num_updates": "36400", "lr": "4.82041e-05", "gnorm": "1.132", "train_wall": "19", "wall": "13975"}
2021-10-23 01:48:01 | INFO | train_inner | {"epoch": 30, "update": 29.796, "loss": "2.09", "nll_loss": "0.193", "ppl": "1.14", "wps": "3038", "ups": "4.91", "wpb": "618.2", "bsz": "16", "num_updates": "36500", "lr": "4.81991e-05", "gnorm": "1.043", "train_wall": "20", "wall": "13995"}
2021-10-23 01:48:19 | INFO | train_inner | {"epoch": 30, "update": 29.878, "loss": "2.093", "nll_loss": "0.197", "ppl": "1.15", "wps": "3044.6", "ups": "5.59", "wpb": "544.6", "bsz": "16", "num_updates": "36600", "lr": "4.81941e-05", "gnorm": "1.077", "train_wall": "18", "wall": "14013"}
2021-10-23 01:48:38 | INFO | train_inner | {"epoch": 30, "update": 29.959, "loss": "2.09", "nll_loss": "0.195", "ppl": "1.14", "wps": "3004.7", "ups": "5.18", "wpb": "580.3", "bsz": "16", "num_updates": "36700", "lr": "4.81891e-05", "gnorm": "1.316", "train_wall": "19", "wall": "14032"}
2021-10-23 01:48:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-23 01:52:19 | INFO | valid | {"epoch": 30, "valid_loss": "2.707", "valid_nll_loss": "0.804", "valid_ppl": "1.75", "valid_bleu": "55.51", "valid_wps": "410.1", "valid_wpb": "281.5", "valid_bsz": "8", "valid_num_updates": "36750", "valid_best_bleu": "55.66"}
2021-10-23 01:52:19 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-23 01:52:33 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/large/checkpoint_last.pt (epoch 30 @ 36750 updates, score 55.51) (writing took 13.828795267967507 seconds)
2021-10-23 01:52:33 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2021-10-23 01:52:33 | INFO | train | {"epoch": 30, "train_loss": "2.089", "train_nll_loss": "0.193", "train_ppl": "1.14", "train_wps": "1565.8", "train_ups": "2.67", "train_wpb": "586.8", "train_bsz": "16", "train_num_updates": "36750", "train_lr": "4.81866e-05", "train_gnorm": "1.2", "train_train_wall": "232", "train_wall": "14267"}
2021-10-23 01:52:33 | INFO | fairseq_cli.train | done training in 14262.2 seconds
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
Traceback (most recent call last):
  File "/home/mahim/miniconda3/envs/python36/bin/fairseq-generate", line 8, in <module>
    sys.exit(cli_main())
  File "/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/fairseq_cli/generate.py", line 274, in cli_main
    main(args)
  File "/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/fairseq_cli/generate.py", line 38, in main
    return _main(args, sys.stdout)
  File "/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/fairseq_cli/generate.py", line 108, in _main
    num_workers=args.num_workers,
  File "/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/fairseq/tasks/fairseq_task.py", line 176, in get_batch_iterator
    raise_exception=(not ignore_invalid_inputs),
  File "/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/fairseq/data/data_utils.py", line 199, in filter_by_size
    ).format(ignored[0], dataset.size(ignored[0]), max_positions))
Exception: Size of sample #1911 is invalid (=(1024, 1211)) since max_positions=(1024, 1024), skip this example with --skip-invalid-size-inputs-valid-test

### from scartch started ####

Source: source Target: target
2021-10-23 15:07:44 | INFO | fairseq_cli.train | Namespace(activation_fn='gelu', adam_betas='(0.9, 0.98)', adam_eps=1e-06, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='mbart_base', attention_dropout=0.1, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_suffix='', clip_norm=0.0, cpu=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='../processed_data/large/data-bin', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', decoder_attention_heads=12, decoder_embed_dim=768, decoder_embed_path=None, decoder_ffn_embed_dim=3072, decoder_input_dim=768, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=True, decoder_normalize_before=False, decoder_output_dim=768, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', dropout=0.1, empty_cache_freq=0, encoder_attention_heads=12, encoder_embed_dim=768, encoder_embed_path=None, encoder_ffn_embed_dim=3072, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=False, end_learning_rate=0.0, eval_bleu=True, eval_bleu_args='{"beam": 5}', eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.1, langs='java,python,en_XX', layernorm_embedding=True, left_pad_source='True', left_pad_target='False', load_alignments=False, localsgd_frequency=3, log_format='json', log_interval=100, lr=[5e-05], lr_scheduler='polynomial_decay', max_epoch=30, max_sentences=8, max_sentences_valid=8, max_source_positions=1024, max_target_positions=1024, max_tokens=None, max_tokens_valid=None, max_update=100000, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=-1.0, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_workers=1, optimizer='adam', optimizer_overrides='{}', patience=10, pooler_activation_fn='tanh', pooler_dropout=0.0, power=1.0, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, relu_dropout=0.0, required_batch_size_multiple=8, reset_dataloader=True, reset_lr_scheduler=True, reset_meters=True, reset_optimizer=True, restore_file='../plbart/checkpoint_11_100000.pt', save_dir='../models/large', save_interval=1, save_interval_updates=0, seed=1234, sentence_avg=False, share_all_embeddings=True, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='source', stop_time_hours=0, target_lang='target', task='translation_without_lang_token', tensorboard_logdir='', threshold_loss_scale=None, tokenizer=None, total_num_update=1000000, tpu=False, train_subset='train', truncate_source=True, update_freq=[2], upsample_primary=1, use_bmuf=False, use_old_adam=False, user_dir='../user_dir', valid_subset='valid', validate_interval=1, warmup_updates=500, weight_decay=0.0)
2021-10-23 15:07:44 | INFO | fairseq.tasks.translation | [source] dictionary: 50001 types
2021-10-23 15:07:44 | INFO | fairseq.tasks.translation | [target] dictionary: 50001 types
2021-10-23 15:07:44 | INFO | fairseq.data.data_utils | loaded 2449 examples from: ../processed_data/large/data-bin/valid.source-target.source
2021-10-23 15:07:44 | INFO | fairseq.data.data_utils | loaded 2449 examples from: ../processed_data/large/data-bin/valid.source-target.target
2021-10-23 15:07:44 | INFO | fairseq.tasks.translation | ../processed_data/large/data-bin valid source-target 2449 examples
2021-10-23 15:07:49 | INFO | fairseq_cli.train | BARTModel(
  (encoder): TransformerEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(50005, 768, padding_idx=1)
    (embed_positions): LearnedPositionalEmbedding(1026, 768, padding_idx=1)
    (layernorm_embedding): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(50005, 768, padding_idx=1)
    (embed_positions): LearnedPositionalEmbedding(1026, 768, padding_idx=1)
    (layernorm_embedding): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=768, out_features=50005, bias=False)
  )
  (classification_heads): ModuleDict()
)
2021-10-23 15:07:49 | INFO | fairseq_cli.train | model mbart_base, criterion LabelSmoothedCrossEntropyCriterion
2021-10-23 15:07:49 | INFO | fairseq_cli.train | num. model params: 139220736 (num. trained: 139220736)
2021-10-23 15:07:53 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight
2021-10-23 15:07:53 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight
2021-10-23 15:07:53 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2021-10-23 15:07:53 | INFO | fairseq.utils | rank   0: capabilities =  6.1  ; total memory = 12.000 GB ; name = GRID P40-12Q                            
2021-10-23 15:07:53 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2021-10-23 15:07:53 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2021-10-23 15:07:53 | INFO | fairseq_cli.train | max tokens per GPU = None and max sentences per GPU = 8
2021-10-23 15:07:57 | INFO | fairseq.trainer | loaded checkpoint ../plbart/checkpoint_11_100000.pt (epoch 11 @ 0 updates)
2021-10-23 15:07:57 | INFO | fairseq.optim.adam | using FusedAdam
2021-10-23 15:07:57 | INFO | fairseq.trainer | loading train data for epoch 1
2021-10-23 15:07:57 | INFO | fairseq.data.data_utils | loaded 19590 examples from: ../processed_data/large/data-bin/train.source-target.source
2021-10-23 15:07:57 | INFO | fairseq.data.data_utils | loaded 19590 examples from: ../processed_data/large/data-bin/train.source-target.target
2021-10-23 15:07:57 | INFO | fairseq.tasks.translation | ../processed_data/large/data-bin train source-target 19590 examples
2021-10-23 15:07:58 | INFO | fairseq_cli.train | begin training epoch 1
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
2021-10-23 15:08:17 | INFO | train_inner | {"epoch": 1, "update": 0.082, "loss": "6.95", "nll_loss": "4.977", "ppl": "31.5", "wps": "1514.9", "ups": "5.42", "wpb": "279.4", "bsz": "16", "num_updates": "100", "lr": "1e-05", "gnorm": "52.044", "train_wall": "19", "wall": "24"}
2021-10-23 15:08:37 | INFO | train_inner | {"epoch": 1, "update": 0.163, "loss": "4.085", "nll_loss": "2.057", "ppl": "4.16", "wps": "1367.1", "ups": "5.02", "wpb": "272.4", "bsz": "16", "num_updates": "200", "lr": "2e-05", "gnorm": "12.82", "train_wall": "20", "wall": "44"}
2021-10-23 15:08:56 | INFO | train_inner | {"epoch": 1, "update": 0.245, "loss": "3.431", "nll_loss": "1.431", "ppl": "2.7", "wps": "1509.2", "ups": "5.16", "wpb": "292.6", "bsz": "16", "num_updates": "300", "lr": "3e-05", "gnorm": "6.962", "train_wall": "19", "wall": "63"}
2021-10-23 15:09:14 | INFO | train_inner | {"epoch": 1, "update": 0.327, "loss": "3.284", "nll_loss": "1.348", "ppl": "2.54", "wps": "1495.5", "ups": "5.62", "wpb": "266.2", "bsz": "16", "num_updates": "400", "lr": "4e-05", "gnorm": "5.1", "train_wall": "18", "wall": "81"}
2021-10-23 15:09:32 | INFO | train_inner | {"epoch": 1, "update": 0.408, "loss": "3.049", "nll_loss": "1.107", "ppl": "2.15", "wps": "1765.8", "ups": "5.55", "wpb": "318.1", "bsz": "16", "num_updates": "500", "lr": "5e-05", "gnorm": "3.996", "train_wall": "18", "wall": "99"}
2021-10-23 15:09:51 | INFO | train_inner | {"epoch": 1, "update": 0.49, "loss": "2.966", "nll_loss": "1.036", "ppl": "2.05", "wps": "1576.6", "ups": "5.11", "wpb": "308.8", "bsz": "16", "num_updates": "600", "lr": "4.9995e-05", "gnorm": "4.212", "train_wall": "19", "wall": "119"}
2021-10-23 15:10:10 | INFO | train_inner | {"epoch": 1, "update": 0.571, "loss": "2.943", "nll_loss": "1.02", "ppl": "2.03", "wps": "1706.6", "ups": "5.28", "wpb": "323.3", "bsz": "16", "num_updates": "700", "lr": "4.999e-05", "gnorm": "4.151", "train_wall": "19", "wall": "138"}
2021-10-23 15:10:30 | INFO | train_inner | {"epoch": 1, "update": 0.653, "loss": "3.034", "nll_loss": "1.133", "ppl": "2.19", "wps": "1501.9", "ups": "5.19", "wpb": "289.6", "bsz": "16", "num_updates": "800", "lr": "4.9985e-05", "gnorm": "3.822", "train_wall": "19", "wall": "157"}
2021-10-23 15:10:49 | INFO | train_inner | {"epoch": 1, "update": 0.735, "loss": "2.838", "nll_loss": "0.918", "ppl": "1.89", "wps": "1689", "ups": "5.14", "wpb": "328.9", "bsz": "16", "num_updates": "900", "lr": "4.998e-05", "gnorm": "3.625", "train_wall": "19", "wall": "176"}
2021-10-23 15:11:07 | INFO | train_inner | {"epoch": 1, "update": 0.816, "loss": "3.021", "nll_loss": "1.13", "ppl": "2.19", "wps": "1516.1", "ups": "5.43", "wpb": "279", "bsz": "16", "num_updates": "1000", "lr": "4.9975e-05", "gnorm": "3.548", "train_wall": "18", "wall": "195"}
2021-10-23 15:11:27 | INFO | train_inner | {"epoch": 1, "update": 0.898, "loss": "2.835", "nll_loss": "0.927", "ppl": "1.9", "wps": "1569.8", "ups": "5.23", "wpb": "299.9", "bsz": "16", "num_updates": "1100", "lr": "4.997e-05", "gnorm": "3.407", "train_wall": "19", "wall": "214"}
2021-10-23 15:11:46 | INFO | train_inner | {"epoch": 1, "update": 0.98, "loss": "2.841", "nll_loss": "0.938", "ppl": "1.92", "wps": "1588.4", "ups": "5.17", "wpb": "307", "bsz": "16", "num_updates": "1200", "lr": "4.9965e-05", "gnorm": "3.415", "train_wall": "19", "wall": "233"}
2021-10-23 15:11:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-23 15:13:41 | INFO | valid | {"epoch": 1, "valid_loss": "2.935", "valid_nll_loss": "0.898", "valid_ppl": "1.86", "valid_bleu": "66.42", "valid_wps": "393.1", "valid_wpb": "140.1", "valid_bsz": "8", "valid_num_updates": "1225"}
2021-10-23 15:13:41 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-23 15:14:06 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/large/checkpoint_best.pt (epoch 1 @ 1225 updates, score 66.42) (writing took 25.513220365042798 seconds)
2021-10-23 15:14:06 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2021-10-23 15:14:06 | INFO | train | {"epoch": 1, "train_loss": "3.401", "train_nll_loss": "1.465", "train_ppl": "2.76", "train_wps": "984.3", "train_ups": "3.33", "train_wpb": "295.9", "train_bsz": "16", "train_num_updates": "1225", "train_lr": "4.99637e-05", "train_gnorm": "8.816", "train_train_wall": "229", "train_wall": "374"}
2021-10-23 15:14:06 | INFO | fairseq_cli.train | begin training epoch 1
2021-10-23 15:14:19 | INFO | train_inner | {"epoch": 2, "update": 1.061, "loss": "2.735", "nll_loss": "0.82", "ppl": "1.77", "wps": "216.3", "ups": "0.65", "wpb": "331.8", "bsz": "15.9", "num_updates": "1300", "lr": "4.996e-05", "gnorm": "3.096", "train_wall": "17", "wall": "387"}
2021-10-23 15:14:36 | INFO | train_inner | {"epoch": 2, "update": 1.143, "loss": "2.745", "nll_loss": "0.826", "ppl": "1.77", "wps": "1813.9", "ups": "5.83", "wpb": "311.3", "bsz": "16", "num_updates": "1400", "lr": "4.9955e-05", "gnorm": "3.199", "train_wall": "17", "wall": "404"}
2021-10-23 15:14:56 | INFO | train_inner | {"epoch": 2, "update": 1.224, "loss": "2.774", "nll_loss": "0.863", "ppl": "1.82", "wps": "1401.2", "ups": "5.04", "wpb": "278", "bsz": "16", "num_updates": "1500", "lr": "4.995e-05", "gnorm": "3.315", "train_wall": "20", "wall": "424"}
2021-10-23 15:15:14 | INFO | train_inner | {"epoch": 2, "update": 1.306, "loss": "2.824", "nll_loss": "0.926", "ppl": "1.9", "wps": "1502.6", "ups": "5.62", "wpb": "267.6", "bsz": "16", "num_updates": "1600", "lr": "4.9945e-05", "gnorm": "3.629", "train_wall": "18", "wall": "441"}
2021-10-23 15:15:35 | INFO | train_inner | {"epoch": 2, "update": 1.388, "loss": "2.732", "nll_loss": "0.816", "ppl": "1.76", "wps": "1473.9", "ups": "4.78", "wpb": "308.3", "bsz": "16", "num_updates": "1700", "lr": "4.994e-05", "gnorm": "3.248", "train_wall": "21", "wall": "462"}
2021-10-23 15:15:56 | INFO | train_inner | {"epoch": 2, "update": 1.469, "loss": "2.691", "nll_loss": "0.781", "ppl": "1.72", "wps": "1531", "ups": "4.86", "wpb": "315.3", "bsz": "16", "num_updates": "1800", "lr": "4.9935e-05", "gnorm": "2.856", "train_wall": "20", "wall": "483"}
2021-10-23 15:16:15 | INFO | train_inner | {"epoch": 2, "update": 1.551, "loss": "2.858", "nll_loss": "0.968", "ppl": "1.96", "wps": "1330.8", "ups": "5.2", "wpb": "255.7", "bsz": "16", "num_updates": "1900", "lr": "4.993e-05", "gnorm": "3.414", "train_wall": "19", "wall": "502"}
2021-10-23 15:16:34 | INFO | train_inner | {"epoch": 2, "update": 1.633, "loss": "2.907", "nll_loss": "1.03", "ppl": "2.04", "wps": "1291.2", "ups": "5.12", "wpb": "252", "bsz": "16", "num_updates": "2000", "lr": "4.9925e-05", "gnorm": "3.601", "train_wall": "19", "wall": "522"}
2021-10-23 15:16:54 | INFO | train_inner | {"epoch": 2, "update": 1.714, "loss": "2.716", "nll_loss": "0.809", "ppl": "1.75", "wps": "1503.9", "ups": "5.04", "wpb": "298.5", "bsz": "16", "num_updates": "2100", "lr": "4.992e-05", "gnorm": "3.586", "train_wall": "20", "wall": "542"}
2021-10-23 15:17:13 | INFO | train_inner | {"epoch": 2, "update": 1.796, "loss": "2.665", "nll_loss": "0.756", "ppl": "1.69", "wps": "1893.6", "ups": "5.22", "wpb": "362.7", "bsz": "16", "num_updates": "2200", "lr": "4.9915e-05", "gnorm": "3.236", "train_wall": "19", "wall": "561"}
2021-10-23 15:17:32 | INFO | train_inner | {"epoch": 2, "update": 1.878, "loss": "2.712", "nll_loss": "0.815", "ppl": "1.76", "wps": "1714.7", "ups": "5.39", "wpb": "318.2", "bsz": "16", "num_updates": "2300", "lr": "4.991e-05", "gnorm": "3.399", "train_wall": "18", "wall": "579"}
2021-10-23 15:17:50 | INFO | train_inner | {"epoch": 2, "update": 1.959, "loss": "2.83", "nll_loss": "0.943", "ppl": "1.92", "wps": "1506.6", "ups": "5.5", "wpb": "273.8", "bsz": "16", "num_updates": "2400", "lr": "4.9905e-05", "gnorm": "3.234", "train_wall": "18", "wall": "597"}
2021-10-23 15:18:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-23 15:19:57 | INFO | valid | {"epoch": 2, "valid_loss": "2.886", "valid_nll_loss": "0.853", "valid_ppl": "1.81", "valid_bleu": "68.07", "valid_wps": "369", "valid_wpb": "140.1", "valid_bsz": "8", "valid_num_updates": "2450", "valid_best_bleu": "68.07"}
2021-10-23 15:19:57 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-23 15:20:23 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/large/checkpoint_best.pt (epoch 2 @ 2450 updates, score 68.07) (writing took 26.037231639958918 seconds)
2021-10-23 15:20:23 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2021-10-23 15:20:23 | INFO | train | {"epoch": 2, "train_loss": "2.759", "train_nll_loss": "0.856", "train_ppl": "1.81", "train_wps": "963", "train_ups": "3.25", "train_wpb": "295.9", "train_bsz": "16", "train_num_updates": "2450", "train_lr": "4.99025e-05", "train_gnorm": "3.315", "train_train_wall": "231", "train_wall": "750"}
2021-10-23 15:20:23 | INFO | fairseq_cli.train | begin training epoch 2
2021-10-23 15:20:32 | INFO | train_inner | {"epoch": 3, "update": 2.041, "loss": "2.788", "nll_loss": "0.895", "ppl": "1.86", "wps": "149.4", "ups": "0.62", "wpb": "242.5", "bsz": "15.9", "num_updates": "2500", "lr": "4.98999e-05", "gnorm": "3.287", "train_wall": "19", "wall": "760"}
2021-10-23 15:20:52 | INFO | train_inner | {"epoch": 3, "update": 2.122, "loss": "2.577", "nll_loss": "0.652", "ppl": "1.57", "wps": "1504.6", "ups": "5.11", "wpb": "294.6", "bsz": "16", "num_updates": "2600", "lr": "4.98949e-05", "gnorm": "3.348", "train_wall": "19", "wall": "779"}
2021-10-23 15:21:12 | INFO | train_inner | {"epoch": 3, "update": 2.204, "loss": "2.584", "nll_loss": "0.666", "ppl": "1.59", "wps": "1429.6", "ups": "5", "wpb": "285.8", "bsz": "16", "num_updates": "2700", "lr": "4.98899e-05", "gnorm": "3.121", "train_wall": "20", "wall": "799"}
2021-10-23 15:21:30 | INFO | train_inner | {"epoch": 3, "update": 2.286, "loss": "2.585", "nll_loss": "0.666", "ppl": "1.59", "wps": "1854", "ups": "5.47", "wpb": "339", "bsz": "16", "num_updates": "2800", "lr": "4.98849e-05", "gnorm": "3.16", "train_wall": "18", "wall": "818"}
2021-10-23 15:21:49 | INFO | train_inner | {"epoch": 3, "update": 2.367, "loss": "2.67", "nll_loss": "0.761", "ppl": "1.69", "wps": "1349.8", "ups": "5.24", "wpb": "257.5", "bsz": "16", "num_updates": "2900", "lr": "4.98799e-05", "gnorm": "3.201", "train_wall": "19", "wall": "837"}
2021-10-23 15:22:09 | INFO | train_inner | {"epoch": 3, "update": 2.449, "loss": "2.558", "nll_loss": "0.641", "ppl": "1.56", "wps": "1686.9", "ups": "5.08", "wpb": "332.2", "bsz": "16", "num_updates": "3000", "lr": "4.98749e-05", "gnorm": "3.169", "train_wall": "19", "wall": "856"}
2021-10-23 15:22:27 | INFO | train_inner | {"epoch": 3, "update": 2.531, "loss": "2.655", "nll_loss": "0.752", "ppl": "1.68", "wps": "1392.2", "ups": "5.44", "wpb": "255.8", "bsz": "16", "num_updates": "3100", "lr": "4.98699e-05", "gnorm": "3.072", "train_wall": "18", "wall": "875"}
2021-10-23 15:22:47 | INFO | train_inner | {"epoch": 3, "update": 2.612, "loss": "2.568", "nll_loss": "0.655", "ppl": "1.57", "wps": "1602.3", "ups": "5.23", "wpb": "306.3", "bsz": "16", "num_updates": "3200", "lr": "4.98649e-05", "gnorm": "3.184", "train_wall": "19", "wall": "894"}
2021-10-23 15:23:04 | INFO | train_inner | {"epoch": 3, "update": 2.694, "loss": "2.656", "nll_loss": "0.75", "ppl": "1.68", "wps": "1664", "ups": "5.86", "wpb": "284.1", "bsz": "16", "num_updates": "3300", "lr": "4.98599e-05", "gnorm": "3.205", "train_wall": "17", "wall": "911"}
2021-10-23 15:23:21 | INFO | train_inner | {"epoch": 3, "update": 2.776, "loss": "2.619", "nll_loss": "0.713", "ppl": "1.64", "wps": "1517", "ups": "5.64", "wpb": "268.9", "bsz": "16", "num_updates": "3400", "lr": "4.98549e-05", "gnorm": "3.153", "train_wall": "18", "wall": "929"}
2021-10-23 15:23:41 | INFO | train_inner | {"epoch": 3, "update": 2.857, "loss": "2.574", "nll_loss": "0.664", "ppl": "1.58", "wps": "1686.9", "ups": "5.09", "wpb": "331.4", "bsz": "16", "num_updates": "3500", "lr": "4.98499e-05", "gnorm": "2.92", "train_wall": "19", "wall": "948"}
2021-10-23 15:23:58 | INFO | train_inner | {"epoch": 3, "update": 2.939, "loss": "2.545", "nll_loss": "0.629", "ppl": "1.55", "wps": "1987.3", "ups": "6.04", "wpb": "329", "bsz": "16", "num_updates": "3600", "lr": "4.98449e-05", "gnorm": "3.147", "train_wall": "16", "wall": "965"}
2021-10-23 15:24:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-23 15:26:03 | INFO | valid | {"epoch": 3, "valid_loss": "2.891", "valid_nll_loss": "0.87", "valid_ppl": "1.83", "valid_bleu": "68.66", "valid_wps": "387.6", "valid_wpb": "140.1", "valid_bsz": "8", "valid_num_updates": "3675", "valid_best_bleu": "68.66"}
2021-10-23 15:26:03 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-23 15:26:28 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/large/checkpoint_best.pt (epoch 3 @ 3675 updates, score 68.66) (writing took 25.312837758101523 seconds)
2021-10-23 15:26:28 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2021-10-23 15:26:28 | INFO | train | {"epoch": 3, "train_loss": "2.603", "train_nll_loss": "0.691", "train_ppl": "1.61", "train_wps": "991.2", "train_ups": "3.35", "train_wpb": "295.9", "train_bsz": "16", "train_num_updates": "3675", "train_lr": "4.98412e-05", "train_gnorm": "3.173", "train_train_wall": "226", "train_wall": "1116"}
2021-10-23 15:26:28 | INFO | fairseq_cli.train | begin training epoch 3
2021-10-23 15:26:34 | INFO | train_inner | {"epoch": 4, "update": 3.02, "loss": "2.619", "nll_loss": "0.716", "ppl": "1.64", "wps": "174.6", "ups": "0.64", "wpb": "272.6", "bsz": "15.9", "num_updates": "3700", "lr": "4.98399e-05", "gnorm": "3.305", "train_wall": "19", "wall": "1121"}
2021-10-23 15:26:54 | INFO | train_inner | {"epoch": 4, "update": 3.102, "loss": "2.462", "nll_loss": "0.531", "ppl": "1.44", "wps": "1309.5", "ups": "4.96", "wpb": "263.8", "bsz": "16", "num_updates": "3800", "lr": "4.98349e-05", "gnorm": "3.16", "train_wall": "20", "wall": "1141"}
2021-10-23 15:27:14 | INFO | train_inner | {"epoch": 4, "update": 3.184, "loss": "2.457", "nll_loss": "0.525", "ppl": "1.44", "wps": "1394.4", "ups": "5.04", "wpb": "276.4", "bsz": "16", "num_updates": "3900", "lr": "4.98299e-05", "gnorm": "3.119", "train_wall": "20", "wall": "1161"}
2021-10-23 15:27:33 | INFO | train_inner | {"epoch": 4, "update": 3.265, "loss": "2.452", "nll_loss": "0.523", "ppl": "1.44", "wps": "1624.4", "ups": "5.12", "wpb": "317.6", "bsz": "16", "num_updates": "4000", "lr": "4.98249e-05", "gnorm": "3.181", "train_wall": "19", "wall": "1180"}
2021-10-23 15:27:52 | INFO | train_inner | {"epoch": 4, "update": 3.347, "loss": "2.521", "nll_loss": "0.6", "ppl": "1.52", "wps": "1675.7", "ups": "5.27", "wpb": "318.1", "bsz": "16", "num_updates": "4100", "lr": "4.98199e-05", "gnorm": "3.18", "train_wall": "19", "wall": "1199"}
2021-10-23 15:28:12 | INFO | train_inner | {"epoch": 4, "update": 3.429, "loss": "2.432", "nll_loss": "0.505", "ppl": "1.42", "wps": "1726.3", "ups": "4.91", "wpb": "351.7", "bsz": "16", "num_updates": "4200", "lr": "4.98149e-05", "gnorm": "3.015", "train_wall": "20", "wall": "1220"}
2021-10-23 15:28:31 | INFO | train_inner | {"epoch": 4, "update": 3.51, "loss": "2.479", "nll_loss": "0.554", "ppl": "1.47", "wps": "1675.8", "ups": "5.55", "wpb": "302", "bsz": "16", "num_updates": "4300", "lr": "4.98099e-05", "gnorm": "3.325", "train_wall": "18", "wall": "1238"}
2021-10-23 15:28:49 | INFO | train_inner | {"epoch": 4, "update": 3.592, "loss": "2.508", "nll_loss": "0.586", "ppl": "1.5", "wps": "1532.8", "ups": "5.31", "wpb": "288.6", "bsz": "16", "num_updates": "4400", "lr": "4.98049e-05", "gnorm": "3.329", "train_wall": "19", "wall": "1257"}
2021-10-23 15:29:08 | INFO | train_inner | {"epoch": 4, "update": 3.673, "loss": "2.542", "nll_loss": "0.626", "ppl": "1.54", "wps": "1413.1", "ups": "5.38", "wpb": "262.6", "bsz": "16", "num_updates": "4500", "lr": "4.97999e-05", "gnorm": "3.374", "train_wall": "18", "wall": "1275"}
2021-10-23 15:29:27 | INFO | train_inner | {"epoch": 4, "update": 3.755, "loss": "2.529", "nll_loss": "0.614", "ppl": "1.53", "wps": "1444.1", "ups": "5.28", "wpb": "273.2", "bsz": "16", "num_updates": "4600", "lr": "4.97949e-05", "gnorm": "3.364", "train_wall": "19", "wall": "1294"}
2021-10-23 15:29:44 | INFO | train_inner | {"epoch": 4, "update": 3.837, "loss": "2.538", "nll_loss": "0.627", "ppl": "1.54", "wps": "1635.9", "ups": "5.7", "wpb": "287.1", "bsz": "16", "num_updates": "4700", "lr": "4.97899e-05", "gnorm": "3.091", "train_wall": "17", "wall": "1312"}
2021-10-23 15:30:03 | INFO | train_inner | {"epoch": 4, "update": 3.918, "loss": "2.481", "nll_loss": "0.561", "ppl": "1.48", "wps": "1474.6", "ups": "5.39", "wpb": "273.7", "bsz": "16", "num_updates": "4800", "lr": "4.97849e-05", "gnorm": "3.317", "train_wall": "18", "wall": "1330"}
2021-10-23 15:30:22 | INFO | train_inner | {"epoch": 4, "update": 4.0, "loss": "2.477", "nll_loss": "0.561", "ppl": "1.47", "wps": "1863.3", "ups": "5.39", "wpb": "345.5", "bsz": "15.9", "num_updates": "4900", "lr": "4.97799e-05", "gnorm": "2.914", "train_wall": "18", "wall": "1349"}
2021-10-23 15:30:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-23 15:32:12 | INFO | valid | {"epoch": 4, "valid_loss": "2.903", "valid_nll_loss": "0.864", "valid_ppl": "1.82", "valid_bleu": "69.8", "valid_wps": "389.1", "valid_wpb": "140.1", "valid_bsz": "8", "valid_num_updates": "4900", "valid_best_bleu": "69.8"}
2021-10-23 15:32:12 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-23 15:32:36 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/large/checkpoint_best.pt (epoch 4 @ 4900 updates, score 69.8) (writing took 24.051247289055027 seconds)
2021-10-23 15:32:36 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2021-10-23 15:32:36 | INFO | train | {"epoch": 4, "train_loss": "2.488", "train_nll_loss": "0.566", "train_ppl": "1.48", "train_wps": "984.9", "train_ups": "3.33", "train_wpb": "295.9", "train_bsz": "16", "train_num_updates": "4900", "train_lr": "4.97799e-05", "train_gnorm": "3.19", "train_train_wall": "230", "train_wall": "1484"}
2021-10-23 15:32:36 | INFO | fairseq_cli.train | begin training epoch 4
2021-10-23 15:32:57 | INFO | train_inner | {"epoch": 5, "update": 4.082, "loss": "2.373", "nll_loss": "0.436", "ppl": "1.35", "wps": "201.6", "ups": "0.64", "wpb": "314.3", "bsz": "16", "num_updates": "5000", "lr": "4.97749e-05", "gnorm": "2.908", "train_wall": "21", "wall": "1505"}
2021-10-23 15:33:16 | INFO | train_inner | {"epoch": 5, "update": 4.163, "loss": "2.408", "nll_loss": "0.474", "ppl": "1.39", "wps": "1462.4", "ups": "5.24", "wpb": "279.1", "bsz": "16", "num_updates": "5100", "lr": "4.97699e-05", "gnorm": "2.894", "train_wall": "19", "wall": "1524"}
2021-10-23 15:33:35 | INFO | train_inner | {"epoch": 5, "update": 4.245, "loss": "2.411", "nll_loss": "0.472", "ppl": "1.39", "wps": "1444.4", "ups": "5.39", "wpb": "268.1", "bsz": "16", "num_updates": "5200", "lr": "4.97649e-05", "gnorm": "3.279", "train_wall": "18", "wall": "1542"}
2021-10-23 15:33:53 | INFO | train_inner | {"epoch": 5, "update": 4.327, "loss": "2.379", "nll_loss": "0.445", "ppl": "1.36", "wps": "1807.6", "ups": "5.46", "wpb": "331.2", "bsz": "16", "num_updates": "5300", "lr": "4.97599e-05", "gnorm": "3.018", "train_wall": "18", "wall": "1561"}
2021-10-23 15:34:11 | INFO | train_inner | {"epoch": 5, "update": 4.408, "loss": "2.354", "nll_loss": "0.418", "ppl": "1.34", "wps": "1691.2", "ups": "5.67", "wpb": "298.1", "bsz": "16", "num_updates": "5400", "lr": "4.97549e-05", "gnorm": "2.781", "train_wall": "17", "wall": "1578"}
2021-10-23 15:34:28 | INFO | train_inner | {"epoch": 5, "update": 4.49, "loss": "2.429", "nll_loss": "0.497", "ppl": "1.41", "wps": "1468.4", "ups": "5.78", "wpb": "253.9", "bsz": "16", "num_updates": "5500", "lr": "4.97499e-05", "gnorm": "3.069", "train_wall": "17", "wall": "1596"}
2021-10-23 15:34:48 | INFO | train_inner | {"epoch": 5, "update": 4.571, "loss": "2.41", "nll_loss": "0.481", "ppl": "1.4", "wps": "1567.7", "ups": "5.17", "wpb": "303.1", "bsz": "16", "num_updates": "5600", "lr": "4.97449e-05", "gnorm": "3.255", "train_wall": "19", "wall": "1615"}
2021-10-23 15:35:07 | INFO | train_inner | {"epoch": 5, "update": 4.653, "loss": "2.412", "nll_loss": "0.487", "ppl": "1.4", "wps": "1463.6", "ups": "5.14", "wpb": "284.8", "bsz": "16", "num_updates": "5700", "lr": "4.97399e-05", "gnorm": "3.084", "train_wall": "19", "wall": "1634"}
2021-10-23 15:35:27 | INFO | train_inner | {"epoch": 5, "update": 4.735, "loss": "2.41", "nll_loss": "0.479", "ppl": "1.39", "wps": "1512.5", "ups": "5.13", "wpb": "294.6", "bsz": "16", "num_updates": "5800", "lr": "4.97349e-05", "gnorm": "3.069", "train_wall": "19", "wall": "1654"}
2021-10-23 15:35:47 | INFO | train_inner | {"epoch": 5, "update": 4.816, "loss": "2.366", "nll_loss": "0.436", "ppl": "1.35", "wps": "1626.4", "ups": "4.86", "wpb": "334.7", "bsz": "16", "num_updates": "5900", "lr": "4.97299e-05", "gnorm": "3.189", "train_wall": "20", "wall": "1674"}
2021-10-23 15:36:06 | INFO | train_inner | {"epoch": 5, "update": 4.898, "loss": "2.4", "nll_loss": "0.474", "ppl": "1.39", "wps": "1475.6", "ups": "5.29", "wpb": "279", "bsz": "16", "num_updates": "6000", "lr": "4.97249e-05", "gnorm": "3.274", "train_wall": "19", "wall": "1693"}
2021-10-23 15:36:25 | INFO | train_inner | {"epoch": 5, "update": 4.98, "loss": "2.425", "nll_loss": "0.502", "ppl": "1.42", "wps": "1529.5", "ups": "5.34", "wpb": "286.7", "bsz": "16", "num_updates": "6100", "lr": "4.97199e-05", "gnorm": "3.154", "train_wall": "19", "wall": "1712"}
2021-10-23 15:36:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-23 15:38:29 | INFO | valid | {"epoch": 5, "valid_loss": "2.933", "valid_nll_loss": "0.913", "valid_ppl": "1.88", "valid_bleu": "69.12", "valid_wps": "360.6", "valid_wpb": "140.1", "valid_bsz": "8", "valid_num_updates": "6125", "valid_best_bleu": "69.8"}
2021-10-23 15:38:29 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-23 15:38:45 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/large/checkpoint_last.pt (epoch 5 @ 6125 updates, score 69.12) (writing took 15.208132044994272 seconds)
2021-10-23 15:38:45 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2021-10-23 15:38:45 | INFO | train | {"epoch": 5, "train_loss": "2.397", "train_nll_loss": "0.465", "train_ppl": "1.38", "train_wps": "984.3", "train_ups": "3.33", "train_wpb": "295.9", "train_bsz": "16", "train_num_updates": "6125", "train_lr": "4.97186e-05", "train_gnorm": "3.081", "train_train_wall": "231", "train_wall": "1852"}
2021-10-23 15:38:45 | INFO | fairseq_cli.train | begin training epoch 5
2021-10-23 15:38:59 | INFO | train_inner | {"epoch": 6, "update": 5.061, "loss": "2.37", "nll_loss": "0.431", "ppl": "1.35", "wps": "200.6", "ups": "0.65", "wpb": "309.9", "bsz": "15.9", "num_updates": "6200", "lr": "4.97149e-05", "gnorm": "2.967", "train_wall": "19", "wall": "1867"}
2021-10-23 15:39:20 | INFO | train_inner | {"epoch": 6, "update": 5.143, "loss": "2.305", "nll_loss": "0.364", "ppl": "1.29", "wps": "1567.9", "ups": "4.79", "wpb": "327.6", "bsz": "16", "num_updates": "6300", "lr": "4.97099e-05", "gnorm": "2.856", "train_wall": "21", "wall": "1887"}
2021-10-23 15:39:40 | INFO | train_inner | {"epoch": 6, "update": 5.224, "loss": "2.305", "nll_loss": "0.365", "ppl": "1.29", "wps": "1587.5", "ups": "5.17", "wpb": "307.2", "bsz": "16", "num_updates": "6400", "lr": "4.97049e-05", "gnorm": "3.005", "train_wall": "19", "wall": "1907"}
2021-10-23 15:39:58 | INFO | train_inner | {"epoch": 6, "update": 5.306, "loss": "2.369", "nll_loss": "0.426", "ppl": "1.34", "wps": "1390.7", "ups": "5.44", "wpb": "255.6", "bsz": "16", "num_updates": "6500", "lr": "4.96998e-05", "gnorm": "3.09", "train_wall": "18", "wall": "1925"}
2021-10-23 15:40:16 | INFO | train_inner | {"epoch": 6, "update": 5.388, "loss": "2.309", "nll_loss": "0.373", "ppl": "1.29", "wps": "1901.1", "ups": "5.45", "wpb": "349", "bsz": "16", "num_updates": "6600", "lr": "4.96948e-05", "gnorm": "2.981", "train_wall": "18", "wall": "1944"}
2021-10-23 15:40:35 | INFO | train_inner | {"epoch": 6, "update": 5.469, "loss": "2.316", "nll_loss": "0.379", "ppl": "1.3", "wps": "1569.2", "ups": "5.31", "wpb": "295.6", "bsz": "16", "num_updates": "6700", "lr": "4.96898e-05", "gnorm": "3.036", "train_wall": "19", "wall": "1962"}
2021-10-23 15:40:55 | INFO | train_inner | {"epoch": 6, "update": 5.551, "loss": "2.346", "nll_loss": "0.409", "ppl": "1.33", "wps": "1427.1", "ups": "5.05", "wpb": "282.8", "bsz": "16", "num_updates": "6800", "lr": "4.96848e-05", "gnorm": "3.043", "train_wall": "20", "wall": "1982"}
2021-10-23 15:41:15 | INFO | train_inner | {"epoch": 6, "update": 5.633, "loss": "2.335", "nll_loss": "0.398", "ppl": "1.32", "wps": "1423.6", "ups": "5.02", "wpb": "283.7", "bsz": "16", "num_updates": "6900", "lr": "4.96798e-05", "gnorm": "3.126", "train_wall": "20", "wall": "2002"}
2021-10-23 15:41:35 | INFO | train_inner | {"epoch": 6, "update": 5.714, "loss": "2.334", "nll_loss": "0.403", "ppl": "1.32", "wps": "1661.2", "ups": "4.91", "wpb": "338.6", "bsz": "16", "num_updates": "7000", "lr": "4.96748e-05", "gnorm": "2.842", "train_wall": "20", "wall": "2023"}
2021-10-23 15:41:56 | INFO | train_inner | {"epoch": 6, "update": 5.796, "loss": "2.36", "nll_loss": "0.43", "ppl": "1.35", "wps": "1279.3", "ups": "4.94", "wpb": "259", "bsz": "16", "num_updates": "7100", "lr": "4.96698e-05", "gnorm": "3.617", "train_wall": "20", "wall": "2043"}
2021-10-23 15:42:14 | INFO | train_inner | {"epoch": 6, "update": 5.878, "loss": "2.311", "nll_loss": "0.379", "ppl": "1.3", "wps": "1760.9", "ups": "5.5", "wpb": "320.1", "bsz": "16", "num_updates": "7200", "lr": "4.96648e-05", "gnorm": "2.845", "train_wall": "18", "wall": "2061"}
2021-10-23 15:42:33 | INFO | train_inner | {"epoch": 6, "update": 5.959, "loss": "2.396", "nll_loss": "0.463", "ppl": "1.38", "wps": "1258.4", "ups": "5.18", "wpb": "243", "bsz": "16", "num_updates": "7300", "lr": "4.96598e-05", "gnorm": "3.169", "train_wall": "19", "wall": "2080"}
2021-10-23 15:42:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-23 15:44:37 | INFO | valid | {"epoch": 6, "valid_loss": "2.937", "valid_nll_loss": "0.935", "valid_ppl": "1.91", "valid_bleu": "68.98", "valid_wps": "379.5", "valid_wpb": "140.1", "valid_bsz": "8", "valid_num_updates": "7350", "valid_best_bleu": "69.8"}
2021-10-23 15:44:37 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-23 15:44:50 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/large/checkpoint_last.pt (epoch 6 @ 7350 updates, score 68.98) (writing took 13.40099148300942 seconds)
2021-10-23 15:44:50 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2021-10-23 15:44:50 | INFO | train | {"epoch": 6, "train_loss": "2.336", "train_nll_loss": "0.4", "train_ppl": "1.32", "train_wps": "992.1", "train_ups": "3.35", "train_wpb": "295.9", "train_bsz": "16", "train_num_updates": "7350", "train_lr": "4.96573e-05", "train_gnorm": "3.046", "train_train_wall": "235", "train_wall": "2217"}
2021-10-23 15:44:50 | INFO | fairseq_cli.train | begin training epoch 6
2021-10-23 15:45:00 | INFO | train_inner | {"epoch": 7, "update": 6.041, "loss": "2.311", "nll_loss": "0.373", "ppl": "1.3", "wps": "206", "ups": "0.68", "wpb": "302.3", "bsz": "15.9", "num_updates": "7400", "lr": "4.96548e-05", "gnorm": "2.658", "train_wall": "19", "wall": "2227"}
2021-10-23 15:45:18 | INFO | train_inner | {"epoch": 7, "update": 6.122, "loss": "2.279", "nll_loss": "0.339", "ppl": "1.26", "wps": "1635.3", "ups": "5.62", "wpb": "291.1", "bsz": "16", "num_updates": "7500", "lr": "4.96498e-05", "gnorm": "2.76", "train_wall": "18", "wall": "2245"}
2021-10-23 15:45:36 | INFO | train_inner | {"epoch": 7, "update": 6.204, "loss": "2.302", "nll_loss": "0.36", "ppl": "1.28", "wps": "1332.6", "ups": "5.55", "wpb": "240", "bsz": "16", "num_updates": "7600", "lr": "4.96448e-05", "gnorm": "2.916", "train_wall": "18", "wall": "2263"}
2021-10-23 15:45:53 | INFO | train_inner | {"epoch": 7, "update": 6.286, "loss": "2.284", "nll_loss": "0.342", "ppl": "1.27", "wps": "1508.8", "ups": "5.79", "wpb": "260.7", "bsz": "16", "num_updates": "7700", "lr": "4.96398e-05", "gnorm": "2.948", "train_wall": "17", "wall": "2280"}
2021-10-23 15:46:13 | INFO | train_inner | {"epoch": 7, "update": 6.367, "loss": "2.296", "nll_loss": "0.359", "ppl": "1.28", "wps": "1519.1", "ups": "5.09", "wpb": "298.4", "bsz": "16", "num_updates": "7800", "lr": "4.96348e-05", "gnorm": "2.827", "train_wall": "19", "wall": "2300"}
2021-10-23 15:46:33 | INFO | train_inner | {"epoch": 7, "update": 6.449, "loss": "2.271", "nll_loss": "0.333", "ppl": "1.26", "wps": "1672.2", "ups": "4.92", "wpb": "339.8", "bsz": "16", "num_updates": "7900", "lr": "4.96298e-05", "gnorm": "2.63", "train_wall": "20", "wall": "2320"}
2021-10-23 15:46:53 | INFO | train_inner | {"epoch": 7, "update": 6.531, "loss": "2.29", "nll_loss": "0.352", "ppl": "1.28", "wps": "1481.6", "ups": "4.85", "wpb": "305.2", "bsz": "16", "num_updates": "8000", "lr": "4.96248e-05", "gnorm": "2.946", "train_wall": "20", "wall": "2341"}
2021-10-23 15:47:14 | INFO | train_inner | {"epoch": 7, "update": 6.612, "loss": "2.271", "nll_loss": "0.333", "ppl": "1.26", "wps": "1869", "ups": "4.96", "wpb": "376.4", "bsz": "16", "num_updates": "8100", "lr": "4.96198e-05", "gnorm": "2.987", "train_wall": "20", "wall": "2361"}
2021-10-23 15:47:32 | INFO | train_inner | {"epoch": 7, "update": 6.694, "loss": "2.321", "nll_loss": "0.387", "ppl": "1.31", "wps": "1625.2", "ups": "5.37", "wpb": "302.9", "bsz": "16", "num_updates": "8200", "lr": "4.96148e-05", "gnorm": "2.831", "train_wall": "18", "wall": "2380"}
2021-10-23 15:47:51 | INFO | train_inner | {"epoch": 7, "update": 6.776, "loss": "2.307", "nll_loss": "0.373", "ppl": "1.3", "wps": "1524.7", "ups": "5.34", "wpb": "285.5", "bsz": "16", "num_updates": "8300", "lr": "4.96098e-05", "gnorm": "3.141", "train_wall": "19", "wall": "2398"}
2021-10-23 15:48:10 | INFO | train_inner | {"epoch": 7, "update": 6.857, "loss": "2.322", "nll_loss": "0.391", "ppl": "1.31", "wps": "1536.7", "ups": "5.24", "wpb": "293", "bsz": "16", "num_updates": "8400", "lr": "4.96048e-05", "gnorm": "2.894", "train_wall": "19", "wall": "2417"}
2021-10-23 15:48:29 | INFO | train_inner | {"epoch": 7, "update": 6.939, "loss": "2.309", "nll_loss": "0.378", "ppl": "1.3", "wps": "1328.9", "ups": "5.23", "wpb": "254.2", "bsz": "16", "num_updates": "8500", "lr": "4.95998e-05", "gnorm": "2.821", "train_wall": "19", "wall": "2436"}
2021-10-23 15:48:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-23 15:50:34 | INFO | valid | {"epoch": 7, "valid_loss": "2.983", "valid_nll_loss": "0.984", "valid_ppl": "1.98", "valid_bleu": "68.92", "valid_wps": "392.9", "valid_wpb": "140.1", "valid_bsz": "8", "valid_num_updates": "8575", "valid_best_bleu": "69.8"}
2021-10-23 15:50:34 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-23 15:50:41 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/large/checkpoint_last.pt (epoch 7 @ 8575 updates, score 68.92) (writing took 6.9636059749173 seconds)
2021-10-23 15:50:41 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2021-10-23 15:50:41 | INFO | train | {"epoch": 7, "train_loss": "2.292", "train_nll_loss": "0.355", "train_ppl": "1.28", "train_wps": "1031.8", "train_ups": "3.49", "train_wpb": "295.9", "train_bsz": "16", "train_num_updates": "8575", "train_lr": "4.9596e-05", "train_gnorm": "2.877", "train_train_wall": "232", "train_wall": "2569"}
2021-10-23 15:50:41 | INFO | fairseq_cli.train | begin training epoch 7
2021-10-23 15:50:47 | INFO | train_inner | {"epoch": 8, "update": 7.02, "loss": "2.274", "nll_loss": "0.334", "ppl": "1.26", "wps": "207.8", "ups": "0.73", "wpb": "286", "bsz": "15.9", "num_updates": "8600", "lr": "4.95948e-05", "gnorm": "2.961", "train_wall": "21", "wall": "2574"}
2021-10-23 15:51:07 | INFO | train_inner | {"epoch": 8, "update": 7.102, "loss": "2.24", "nll_loss": "0.3", "ppl": "1.23", "wps": "1618.4", "ups": "4.98", "wpb": "324.8", "bsz": "16", "num_updates": "8700", "lr": "4.95898e-05", "gnorm": "2.451", "train_wall": "20", "wall": "2594"}
2021-10-23 15:51:26 | INFO | train_inner | {"epoch": 8, "update": 7.184, "loss": "2.227", "nll_loss": "0.289", "ppl": "1.22", "wps": "1811.9", "ups": "5.22", "wpb": "346.8", "bsz": "16", "num_updates": "8800", "lr": "4.95848e-05", "gnorm": "2.427", "train_wall": "19", "wall": "2613"}
2021-10-23 15:51:47 | INFO | train_inner | {"epoch": 8, "update": 7.265, "loss": "2.264", "nll_loss": "0.324", "ppl": "1.25", "wps": "1377.8", "ups": "4.87", "wpb": "283", "bsz": "16", "num_updates": "8900", "lr": "4.95798e-05", "gnorm": "2.67", "train_wall": "20", "wall": "2634"}
2021-10-23 15:52:07 | INFO | train_inner | {"epoch": 8, "update": 7.347, "loss": "2.256", "nll_loss": "0.317", "ppl": "1.25", "wps": "1409", "ups": "4.93", "wpb": "285.7", "bsz": "16", "num_updates": "9000", "lr": "4.95748e-05", "gnorm": "2.873", "train_wall": "20", "wall": "2654"}
2021-10-23 15:52:24 | INFO | train_inner | {"epoch": 8, "update": 7.429, "loss": "2.254", "nll_loss": "0.317", "ppl": "1.25", "wps": "1734.2", "ups": "5.71", "wpb": "303.7", "bsz": "16", "num_updates": "9100", "lr": "4.95698e-05", "gnorm": "2.709", "train_wall": "17", "wall": "2672"}
2021-10-23 15:52:43 | INFO | train_inner | {"epoch": 8, "update": 7.51, "loss": "2.29", "nll_loss": "0.357", "ppl": "1.28", "wps": "1474.1", "ups": "5.5", "wpb": "268.1", "bsz": "16", "num_updates": "9200", "lr": "4.95648e-05", "gnorm": "3.394", "train_wall": "18", "wall": "2690"}
2021-10-23 15:53:00 | INFO | train_inner | {"epoch": 8, "update": 7.592, "loss": "2.284", "nll_loss": "0.346", "ppl": "1.27", "wps": "1507.1", "ups": "5.62", "wpb": "268", "bsz": "16", "num_updates": "9300", "lr": "4.95598e-05", "gnorm": "2.942", "train_wall": "18", "wall": "2708"}
2021-10-23 15:53:19 | INFO | train_inner | {"epoch": 8, "update": 7.673, "loss": "2.265", "nll_loss": "0.331", "ppl": "1.26", "wps": "1387.3", "ups": "5.21", "wpb": "266.1", "bsz": "16", "num_updates": "9400", "lr": "4.95548e-05", "gnorm": "2.758", "train_wall": "19", "wall": "2727"}
2021-10-23 15:53:40 | INFO | train_inner | {"epoch": 8, "update": 7.755, "loss": "2.269", "nll_loss": "0.333", "ppl": "1.26", "wps": "1371.1", "ups": "4.91", "wpb": "279.1", "bsz": "16", "num_updates": "9500", "lr": "4.95498e-05", "gnorm": "2.864", "train_wall": "20", "wall": "2747"}
2021-10-23 15:54:01 | INFO | train_inner | {"epoch": 8, "update": 7.837, "loss": "2.28", "nll_loss": "0.347", "ppl": "1.27", "wps": "1531.6", "ups": "4.7", "wpb": "325.5", "bsz": "16", "num_updates": "9600", "lr": "4.95448e-05", "gnorm": "2.767", "train_wall": "21", "wall": "2768"}
2021-10-23 15:54:21 | INFO | train_inner | {"epoch": 8, "update": 7.918, "loss": "2.272", "nll_loss": "0.339", "ppl": "1.26", "wps": "1565.6", "ups": "5.11", "wpb": "306.6", "bsz": "16", "num_updates": "9700", "lr": "4.95398e-05", "gnorm": "3.022", "train_wall": "19", "wall": "2788"}
2021-10-23 15:54:40 | INFO | train_inner | {"epoch": 8, "update": 8.0, "loss": "2.26", "nll_loss": "0.326", "ppl": "1.25", "wps": "1582.1", "ups": "5.18", "wpb": "305.4", "bsz": "15.9", "num_updates": "9800", "lr": "4.95348e-05", "gnorm": "3.11", "train_wall": "19", "wall": "2807"}
2021-10-23 15:54:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-23 15:56:35 | INFO | valid | {"epoch": 8, "valid_loss": "3.003", "valid_nll_loss": "1.008", "valid_ppl": "2.01", "valid_bleu": "67.92", "valid_wps": "375.6", "valid_wpb": "140.1", "valid_bsz": "8", "valid_num_updates": "9800", "valid_best_bleu": "69.8"}
2021-10-23 15:56:35 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-23 15:56:49 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/large/checkpoint_last.pt (epoch 8 @ 9800 updates, score 67.92) (writing took 13.946749674971215 seconds)
2021-10-23 15:56:49 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2021-10-23 15:56:49 | INFO | train | {"epoch": 8, "train_loss": "2.262", "train_nll_loss": "0.326", "train_ppl": "1.25", "train_wps": "986.7", "train_ups": "3.33", "train_wpb": "295.9", "train_bsz": "16", "train_num_updates": "9800", "train_lr": "4.95348e-05", "train_gnorm": "2.822", "train_train_wall": "236", "train_wall": "2936"}
2021-10-23 15:56:49 | INFO | fairseq_cli.train | begin training epoch 8
2021-10-23 15:57:08 | INFO | train_inner | {"epoch": 9, "update": 8.082, "loss": "2.225", "nll_loss": "0.286", "ppl": "1.22", "wps": "204.4", "ups": "0.67", "wpb": "303.1", "bsz": "16", "num_updates": "9900", "lr": "4.95298e-05", "gnorm": "2.567", "train_wall": "19", "wall": "2956"}
2021-10-23 15:57:28 | INFO | train_inner | {"epoch": 9, "update": 8.163, "loss": "2.226", "nll_loss": "0.289", "ppl": "1.22", "wps": "1451.6", "ups": "5.02", "wpb": "289.1", "bsz": "16", "num_updates": "10000", "lr": "4.95248e-05", "gnorm": "2.6", "train_wall": "20", "wall": "2976"}
2021-10-23 15:57:46 | INFO | train_inner | {"epoch": 9, "update": 8.245, "loss": "2.258", "nll_loss": "0.32", "ppl": "1.25", "wps": "1331.6", "ups": "5.74", "wpb": "231.8", "bsz": "16", "num_updates": "10100", "lr": "4.95198e-05", "gnorm": "3.054", "train_wall": "17", "wall": "2993"}
2021-10-23 15:58:02 | INFO | train_inner | {"epoch": 9, "update": 8.327, "loss": "2.209", "nll_loss": "0.274", "ppl": "1.21", "wps": "1915", "ups": "5.97", "wpb": "320.8", "bsz": "16", "num_updates": "10200", "lr": "4.95148e-05", "gnorm": "2.238", "train_wall": "17", "wall": "3010"}
2021-10-23 15:58:21 | INFO | train_inner | {"epoch": 9, "update": 8.408, "loss": "2.235", "nll_loss": "0.295", "ppl": "1.23", "wps": "1379.9", "ups": "5.44", "wpb": "253.8", "bsz": "16", "num_updates": "10300", "lr": "4.95098e-05", "gnorm": "2.492", "train_wall": "18", "wall": "3028"}
2021-10-23 15:58:41 | INFO | train_inner | {"epoch": 9, "update": 8.49, "loss": "2.249", "nll_loss": "0.315", "ppl": "1.24", "wps": "1200", "ups": "4.89", "wpb": "245.3", "bsz": "16", "num_updates": "10400", "lr": "4.95048e-05", "gnorm": "2.806", "train_wall": "20", "wall": "3049"}
2021-10-23 15:59:01 | INFO | train_inner | {"epoch": 9, "update": 8.571, "loss": "2.228", "nll_loss": "0.294", "ppl": "1.23", "wps": "1378.6", "ups": "4.93", "wpb": "279.4", "bsz": "16", "num_updates": "10500", "lr": "4.94997e-05", "gnorm": "2.438", "train_wall": "20", "wall": "3069"}
2021-10-23 15:59:22 | INFO | train_inner | {"epoch": 9, "update": 8.653, "loss": "2.237", "nll_loss": "0.303", "ppl": "1.23", "wps": "1639.6", "ups": "4.79", "wpb": "341.9", "bsz": "16", "num_updates": "10600", "lr": "4.94947e-05", "gnorm": "2.504", "train_wall": "21", "wall": "3090"}
2021-10-23 15:59:44 | INFO | train_inner | {"epoch": 9, "update": 8.735, "loss": "2.251", "nll_loss": "0.319", "ppl": "1.25", "wps": "1536.7", "ups": "4.51", "wpb": "340.6", "bsz": "16", "num_updates": "10700", "lr": "4.94897e-05", "gnorm": "2.589", "train_wall": "22", "wall": "3112"}
2021-10-23 16:00:05 | INFO | train_inner | {"epoch": 9, "update": 8.816, "loss": "2.25", "nll_loss": "0.317", "ppl": "1.25", "wps": "1552.4", "ups": "4.88", "wpb": "318.4", "bsz": "16", "num_updates": "10800", "lr": "4.94847e-05", "gnorm": "2.756", "train_wall": "20", "wall": "3132"}
2021-10-23 16:00:25 | INFO | train_inner | {"epoch": 9, "update": 8.898, "loss": "2.261", "nll_loss": "0.328", "ppl": "1.26", "wps": "1561", "ups": "4.9", "wpb": "318.4", "bsz": "16", "num_updates": "10900", "lr": "4.94797e-05", "gnorm": "2.848", "train_wall": "20", "wall": "3153"}
2021-10-23 16:00:45 | INFO | train_inner | {"epoch": 9, "update": 8.98, "loss": "2.247", "nll_loss": "0.316", "ppl": "1.24", "wps": "1585.9", "ups": "5.11", "wpb": "310.4", "bsz": "16", "num_updates": "11000", "lr": "4.94747e-05", "gnorm": "2.655", "train_wall": "19", "wall": "3172"}
2021-10-23 16:00:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-23 16:02:46 | INFO | valid | {"epoch": 9, "valid_loss": "3.03", "valid_nll_loss": "1.047", "valid_ppl": "2.07", "valid_bleu": "66.1", "valid_wps": "370.2", "valid_wpb": "140.1", "valid_bsz": "8", "valid_num_updates": "11025", "valid_best_bleu": "69.8"}
2021-10-23 16:02:46 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-23 16:03:01 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/large/checkpoint_last.pt (epoch 9 @ 11025 updates, score 66.1) (writing took 14.899468293995596 seconds)
2021-10-23 16:03:01 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2021-10-23 16:03:01 | INFO | train | {"epoch": 9, "train_loss": "2.24", "train_nll_loss": "0.305", "train_ppl": "1.24", "train_wps": "973.1", "train_ups": "3.29", "train_wpb": "295.9", "train_bsz": "16", "train_num_updates": "11025", "train_lr": "4.94735e-05", "train_gnorm": "2.632", "train_train_wall": "238", "train_wall": "3308"}
2021-10-23 16:03:01 | INFO | fairseq_cli.train | begin training epoch 9
2021-10-23 16:03:16 | INFO | train_inner | {"epoch": 10, "update": 9.061, "loss": "2.224", "nll_loss": "0.285", "ppl": "1.22", "wps": "205.5", "ups": "0.66", "wpb": "311.3", "bsz": "15.9", "num_updates": "11100", "lr": "4.94697e-05", "gnorm": "2.607", "train_wall": "20", "wall": "3324"}
2021-10-23 16:03:36 | INFO | train_inner | {"epoch": 10, "update": 9.143, "loss": "2.21", "nll_loss": "0.272", "ppl": "1.21", "wps": "1302.9", "ups": "5.01", "wpb": "260", "bsz": "16", "num_updates": "11200", "lr": "4.94647e-05", "gnorm": "2.525", "train_wall": "20", "wall": "3344"}
2021-10-23 16:03:53 | INFO | train_inner | {"epoch": 10, "update": 9.224, "loss": "2.214", "nll_loss": "0.277", "ppl": "1.21", "wps": "1712.3", "ups": "5.97", "wpb": "286.7", "bsz": "16", "num_updates": "11300", "lr": "4.94597e-05", "gnorm": "2.383", "train_wall": "17", "wall": "3360"}
2021-10-23 16:04:10 | INFO | train_inner | {"epoch": 10, "update": 9.306, "loss": "2.206", "nll_loss": "0.273", "ppl": "1.21", "wps": "1963.4", "ups": "6.06", "wpb": "324.2", "bsz": "16", "num_updates": "11400", "lr": "4.94547e-05", "gnorm": "2.406", "train_wall": "16", "wall": "3377"}
2021-10-23 16:04:24 | INFO | train_inner | {"epoch": 10, "update": 9.388, "loss": "2.227", "nll_loss": "0.292", "ppl": "1.22", "wps": "1870.5", "ups": "6.88", "wpb": "271.8", "bsz": "16", "num_updates": "11500", "lr": "4.94497e-05", "gnorm": "2.687", "train_wall": "14", "wall": "3392"}
2021-10-23 16:04:42 | INFO | train_inner | {"epoch": 10, "update": 9.469, "loss": "2.228", "nll_loss": "0.294", "ppl": "1.23", "wps": "1747.2", "ups": "5.61", "wpb": "311.6", "bsz": "16", "num_updates": "11600", "lr": "4.94447e-05", "gnorm": "2.647", "train_wall": "18", "wall": "3409"}
2021-10-23 16:04:57 | INFO | train_inner | {"epoch": 10, "update": 9.551, "loss": "2.207", "nll_loss": "0.279", "ppl": "1.21", "wps": "2042", "ups": "6.52", "wpb": "313", "bsz": "16", "num_updates": "11700", "lr": "4.94397e-05", "gnorm": "2.389", "train_wall": "15", "wall": "3425"}
2021-10-23 16:05:16 | INFO | train_inner | {"epoch": 10, "update": 9.633, "loss": "2.251", "nll_loss": "0.32", "ppl": "1.25", "wps": "1495.5", "ups": "5.26", "wpb": "284.1", "bsz": "16", "num_updates": "11800", "lr": "4.94347e-05", "gnorm": "2.744", "train_wall": "19", "wall": "3444"}
2021-10-23 16:05:34 | INFO | train_inner | {"epoch": 10, "update": 9.714, "loss": "2.254", "nll_loss": "0.321", "ppl": "1.25", "wps": "1479", "ups": "5.79", "wpb": "255.3", "bsz": "16", "num_updates": "11900", "lr": "4.94297e-05", "gnorm": "2.726", "train_wall": "17", "wall": "3461"}
2021-10-23 16:05:53 | INFO | train_inner | {"epoch": 10, "update": 9.796, "loss": "2.244", "nll_loss": "0.313", "ppl": "1.24", "wps": "1421.1", "ups": "5.24", "wpb": "271.3", "bsz": "16", "num_updates": "12000", "lr": "4.94247e-05", "gnorm": "2.815", "train_wall": "19", "wall": "3480"}
2021-10-23 16:06:13 | INFO | train_inner | {"epoch": 10, "update": 9.878, "loss": "2.249", "nll_loss": "0.316", "ppl": "1.25", "wps": "1326.1", "ups": "4.93", "wpb": "268.8", "bsz": "16", "num_updates": "12100", "lr": "4.94197e-05", "gnorm": "2.643", "train_wall": "20", "wall": "3500"}
2021-10-23 16:06:33 | INFO | train_inner | {"epoch": 10, "update": 9.959, "loss": "2.227", "nll_loss": "0.298", "ppl": "1.23", "wps": "1910.6", "ups": "4.91", "wpb": "389.3", "bsz": "16", "num_updates": "12200", "lr": "4.94147e-05", "gnorm": "2.845", "train_wall": "20", "wall": "3521"}
2021-10-23 16:06:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-23 16:08:39 | INFO | valid | {"epoch": 10, "valid_loss": "3.067", "valid_nll_loss": "1.093", "valid_ppl": "2.13", "valid_bleu": "64.68", "valid_wps": "373", "valid_wpb": "140.1", "valid_bsz": "8", "valid_num_updates": "12250", "valid_best_bleu": "69.8"}
2021-10-23 16:08:39 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-23 16:08:52 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/large/checkpoint_last.pt (epoch 10 @ 12250 updates, score 64.68) (writing took 12.988534911070019 seconds)
2021-10-23 16:08:52 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2021-10-23 16:08:52 | INFO | train | {"epoch": 10, "train_loss": "2.228", "train_nll_loss": "0.295", "train_ppl": "1.23", "train_wps": "1034.1", "train_ups": "3.49", "train_wpb": "295.9", "train_bsz": "16", "train_num_updates": "12250", "train_lr": "4.94122e-05", "train_gnorm": "2.623", "train_train_wall": "219", "train_wall": "3659"}
2021-10-23 16:08:52 | INFO | fairseq_cli.train | begin training epoch 10
2021-10-23 16:09:01 | INFO | train_inner | {"epoch": 11, "update": 10.041, "loss": "2.226", "nll_loss": "0.296", "ppl": "1.23", "wps": "188.6", "ups": "0.68", "wpb": "278.2", "bsz": "15.9", "num_updates": "12300", "lr": "4.94097e-05", "gnorm": "2.575", "train_wall": "19", "wall": "3668"}
2021-10-23 16:09:19 | INFO | train_inner | {"epoch": 11, "update": 10.122, "loss": "2.201", "nll_loss": "0.267", "ppl": "1.2", "wps": "1663.1", "ups": "5.5", "wpb": "302.5", "bsz": "16", "num_updates": "12400", "lr": "4.94047e-05", "gnorm": "2.41", "train_wall": "18", "wall": "3686"}
2021-10-23 16:09:39 | INFO | train_inner | {"epoch": 11, "update": 10.204, "loss": "2.208", "nll_loss": "0.277", "ppl": "1.21", "wps": "1617.5", "ups": "5.04", "wpb": "321.1", "bsz": "16", "num_updates": "12500", "lr": "4.93997e-05", "gnorm": "2.48", "train_wall": "20", "wall": "3706"}
2021-10-23 16:09:59 | INFO | train_inner | {"epoch": 11, "update": 10.286, "loss": "2.196", "nll_loss": "0.266", "ppl": "1.2", "wps": "1485.5", "ups": "4.95", "wpb": "299.8", "bsz": "16", "num_updates": "12600", "lr": "4.93947e-05", "gnorm": "2.29", "train_wall": "20", "wall": "3726"}
2021-10-23 16:10:18 | INFO | train_inner | {"epoch": 11, "update": 10.367, "loss": "2.222", "nll_loss": "0.289", "ppl": "1.22", "wps": "1603", "ups": "5.3", "wpb": "302.6", "bsz": "16", "num_updates": "12700", "lr": "4.93897e-05", "gnorm": "2.691", "train_wall": "19", "wall": "3745"}
2021-10-23 16:10:37 | INFO | train_inner | {"epoch": 11, "update": 10.449, "loss": "2.221", "nll_loss": "0.288", "ppl": "1.22", "wps": "1425.3", "ups": "5.34", "wpb": "267.2", "bsz": "16", "num_updates": "12800", "lr": "4.93847e-05", "gnorm": "2.591", "train_wall": "19", "wall": "3764"}
2021-10-23 16:10:57 | INFO | train_inner | {"epoch": 11, "update": 10.531, "loss": "2.216", "nll_loss": "0.286", "ppl": "1.22", "wps": "1423", "ups": "5.01", "wpb": "284.2", "bsz": "16", "num_updates": "12900", "lr": "4.93797e-05", "gnorm": "2.375", "train_wall": "20", "wall": "3784"}
2021-10-23 16:11:14 | INFO | train_inner | {"epoch": 11, "update": 10.612, "loss": "2.218", "nll_loss": "0.286", "ppl": "1.22", "wps": "1520.4", "ups": "5.73", "wpb": "265.5", "bsz": "16", "num_updates": "13000", "lr": "4.93747e-05", "gnorm": "2.499", "train_wall": "17", "wall": "3801"}
2021-10-23 16:11:33 | INFO | train_inner | {"epoch": 11, "update": 10.694, "loss": "2.224", "nll_loss": "0.295", "ppl": "1.23", "wps": "1517.8", "ups": "5.3", "wpb": "286.4", "bsz": "16", "num_updates": "13100", "lr": "4.93697e-05", "gnorm": "2.695", "train_wall": "19", "wall": "3820"}
2021-10-23 16:11:53 | INFO | train_inner | {"epoch": 11, "update": 10.776, "loss": "2.216", "nll_loss": "0.288", "ppl": "1.22", "wps": "1790.9", "ups": "4.99", "wpb": "358.7", "bsz": "16", "num_updates": "13200", "lr": "4.93647e-05", "gnorm": "2.768", "train_wall": "20", "wall": "3840"}
2021-10-23 16:12:13 | INFO | train_inner | {"epoch": 11, "update": 10.857, "loss": "2.245", "nll_loss": "0.317", "ppl": "1.25", "wps": "1487", "ups": "5.11", "wpb": "290.9", "bsz": "16", "num_updates": "13300", "lr": "4.93597e-05", "gnorm": "2.671", "train_wall": "19", "wall": "3860"}
2021-10-23 16:12:33 | INFO | train_inner | {"epoch": 11, "update": 10.939, "loss": "2.228", "nll_loss": "0.303", "ppl": "1.23", "wps": "1579.3", "ups": "4.94", "wpb": "319.8", "bsz": "16", "num_updates": "13400", "lr": "4.93547e-05", "gnorm": "3.038", "train_wall": "20", "wall": "3880"}
2021-10-23 16:12:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-23 16:14:40 | INFO | valid | {"epoch": 11, "valid_loss": "3.085", "valid_nll_loss": "1.124", "valid_ppl": "2.18", "valid_bleu": "62.26", "valid_wps": "382.3", "valid_wpb": "140.1", "valid_bsz": "8", "valid_num_updates": "13475", "valid_best_bleu": "69.8"}
2021-10-23 16:14:40 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-23 16:14:54 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/large/checkpoint_last.pt (epoch 11 @ 13475 updates, score 62.26) (writing took 14.353047881973907 seconds)
2021-10-23 16:14:54 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2021-10-23 16:14:54 | INFO | train | {"epoch": 11, "train_loss": "2.218", "train_nll_loss": "0.288", "train_ppl": "1.22", "train_wps": "1000.2", "train_ups": "3.38", "train_wpb": "295.9", "train_bsz": "16", "train_num_updates": "13475", "train_lr": "4.93509e-05", "train_gnorm": "2.603", "train_train_wall": "232", "train_wall": "4021"}
2021-10-23 16:14:54 | INFO | fairseq_cli.train | begin training epoch 11
2021-10-23 16:14:59 | INFO | train_inner | {"epoch": 12, "update": 11.02, "loss": "2.219", "nll_loss": "0.291", "ppl": "1.22", "wps": "178", "ups": "0.69", "wpb": "259.6", "bsz": "15.9", "num_updates": "13500", "lr": "4.93497e-05", "gnorm": "2.679", "train_wall": "18", "wall": "4026"}
2021-10-23 16:15:16 | INFO | train_inner | {"epoch": 12, "update": 11.102, "loss": "2.194", "nll_loss": "0.263", "ppl": "1.2", "wps": "1673.4", "ups": "5.7", "wpb": "293.6", "bsz": "16", "num_updates": "13600", "lr": "4.93447e-05", "gnorm": "2.141", "train_wall": "17", "wall": "4044"}
2021-10-23 16:15:33 | INFO | train_inner | {"epoch": 12, "update": 11.184, "loss": "2.195", "nll_loss": "0.26", "ppl": "1.2", "wps": "1796.6", "ups": "5.84", "wpb": "307.5", "bsz": "16", "num_updates": "13700", "lr": "4.93397e-05", "gnorm": "2.284", "train_wall": "17", "wall": "4061"}
2021-10-23 16:15:51 | INFO | train_inner | {"epoch": 12, "update": 11.265, "loss": "2.206", "nll_loss": "0.279", "ppl": "1.21", "wps": "1741.2", "ups": "5.58", "wpb": "311.9", "bsz": "16", "num_updates": "13800", "lr": "4.93347e-05", "gnorm": "2.259", "train_wall": "18", "wall": "4079"}
2021-10-23 16:16:10 | INFO | train_inner | {"epoch": 12, "update": 11.347, "loss": "2.211", "nll_loss": "0.282", "ppl": "1.22", "wps": "1405.8", "ups": "5.24", "wpb": "268.5", "bsz": "16", "num_updates": "13900", "lr": "4.93297e-05", "gnorm": "2.449", "train_wall": "19", "wall": "4098"}
2021-10-23 16:16:30 | INFO | train_inner | {"epoch": 12, "update": 11.429, "loss": "2.196", "nll_loss": "0.267", "ppl": "1.2", "wps": "1477.9", "ups": "5.18", "wpb": "285.4", "bsz": "16", "num_updates": "14000", "lr": "4.93247e-05", "gnorm": "2.309", "train_wall": "19", "wall": "4117"}
2021-10-23 16:16:49 | INFO | train_inner | {"epoch": 12, "update": 11.51, "loss": "2.212", "nll_loss": "0.284", "ppl": "1.22", "wps": "1474.4", "ups": "5.28", "wpb": "279.2", "bsz": "16", "num_updates": "14100", "lr": "4.93197e-05", "gnorm": "2.592", "train_wall": "19", "wall": "4136"}
2021-10-23 16:17:09 | INFO | train_inner | {"epoch": 12, "update": 11.592, "loss": "2.206", "nll_loss": "0.279", "ppl": "1.21", "wps": "1444.1", "ups": "4.84", "wpb": "298.2", "bsz": "16", "num_updates": "14200", "lr": "4.93147e-05", "gnorm": "2.25", "train_wall": "20", "wall": "4157"}
2021-10-23 16:17:29 | INFO | train_inner | {"epoch": 12, "update": 11.673, "loss": "2.204", "nll_loss": "0.279", "ppl": "1.21", "wps": "1780.5", "ups": "5.04", "wpb": "353", "bsz": "16", "num_updates": "14300", "lr": "4.93097e-05", "gnorm": "2.572", "train_wall": "20", "wall": "4176"}
2021-10-23 16:17:48 | INFO | train_inner | {"epoch": 12, "update": 11.755, "loss": "2.222", "nll_loss": "0.299", "ppl": "1.23", "wps": "1390.7", "ups": "5.18", "wpb": "268.7", "bsz": "16", "num_updates": "14400", "lr": "4.93047e-05", "gnorm": "2.671", "train_wall": "19", "wall": "4196"}
2021-10-23 16:18:09 | INFO | train_inner | {"epoch": 12, "update": 11.837, "loss": "2.219", "nll_loss": "0.292", "ppl": "1.22", "wps": "1498", "ups": "4.86", "wpb": "308.3", "bsz": "16", "num_updates": "14500", "lr": "4.92996e-05", "gnorm": "2.736", "train_wall": "20", "wall": "4216"}
2021-10-23 16:18:29 | INFO | train_inner | {"epoch": 12, "update": 11.918, "loss": "2.231", "nll_loss": "0.308", "ppl": "1.24", "wps": "1631.5", "ups": "5.09", "wpb": "320.5", "bsz": "16", "num_updates": "14600", "lr": "4.92946e-05", "gnorm": "2.675", "train_wall": "19", "wall": "4236"}
2021-10-23 16:18:49 | INFO | train_inner | {"epoch": 12, "update": 12.0, "loss": "2.22", "nll_loss": "0.295", "ppl": "1.23", "wps": "1315.5", "ups": "4.93", "wpb": "266.8", "bsz": "15.9", "num_updates": "14700", "lr": "4.92896e-05", "gnorm": "2.503", "train_wall": "20", "wall": "4256"}
2021-10-23 16:18:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-23 16:20:44 | INFO | valid | {"epoch": 12, "valid_loss": "3.123", "valid_nll_loss": "1.153", "valid_ppl": "2.22", "valid_bleu": "61.39", "valid_wps": "374", "valid_wpb": "140.1", "valid_bsz": "8", "valid_num_updates": "14700", "valid_best_bleu": "69.8"}
2021-10-23 16:20:44 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-23 16:20:51 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/large/checkpoint_last.pt (epoch 12 @ 14700 updates, score 61.39) (writing took 6.932894234079868 seconds)
2021-10-23 16:20:51 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2021-10-23 16:20:51 | INFO | train | {"epoch": 12, "train_loss": "2.209", "train_nll_loss": "0.281", "train_ppl": "1.22", "train_wps": "1014.8", "train_ups": "3.43", "train_wpb": "295.9", "train_bsz": "16", "train_num_updates": "14700", "train_lr": "4.92896e-05", "train_gnorm": "2.441", "train_train_wall": "232", "train_wall": "4378"}
2021-10-23 16:20:51 | INFO | fairseq_cli.train | begin training epoch 12
2021-10-23 16:21:11 | INFO | train_inner | {"epoch": 13, "update": 12.082, "loss": "2.19", "nll_loss": "0.258", "ppl": "1.2", "wps": "186.9", "ups": "0.71", "wpb": "264.9", "bsz": "16", "num_updates": "14800", "lr": "4.92846e-05", "gnorm": "2.246", "train_wall": "19", "wall": "4398"}
2021-10-23 16:21:30 | INFO | train_inner | {"epoch": 13, "update": 12.163, "loss": "2.184", "nll_loss": "0.256", "ppl": "1.19", "wps": "1318.5", "ups": "5.22", "wpb": "252.6", "bsz": "16", "num_updates": "14900", "lr": "4.92796e-05", "gnorm": "2.285", "train_wall": "19", "wall": "4417"}
2021-10-23 16:21:48 | INFO | train_inner | {"epoch": 13, "update": 12.245, "loss": "2.197", "nll_loss": "0.267", "ppl": "1.2", "wps": "1483.9", "ups": "5.38", "wpb": "276", "bsz": "16", "num_updates": "15000", "lr": "4.92746e-05", "gnorm": "2.32", "train_wall": "18", "wall": "4436"}
2021-10-23 16:22:08 | INFO | train_inner | {"epoch": 13, "update": 12.327, "loss": "2.191", "nll_loss": "0.266", "ppl": "1.2", "wps": "1593.3", "ups": "5.02", "wpb": "317.6", "bsz": "16", "num_updates": "15100", "lr": "4.92696e-05", "gnorm": "2.215", "train_wall": "20", "wall": "4456"}
2021-10-23 16:22:28 | INFO | train_inner | {"epoch": 13, "update": 12.408, "loss": "2.202", "nll_loss": "0.273", "ppl": "1.21", "wps": "1522.4", "ups": "5.01", "wpb": "303.8", "bsz": "16", "num_updates": "15200", "lr": "4.92646e-05", "gnorm": "2.619", "train_wall": "20", "wall": "4476"}
2021-10-23 16:22:48 | INFO | train_inner | {"epoch": 13, "update": 12.49, "loss": "2.207", "nll_loss": "0.28", "ppl": "1.21", "wps": "1371.1", "ups": "5.15", "wpb": "266.3", "bsz": "16", "num_updates": "15300", "lr": "4.92596e-05", "gnorm": "2.594", "train_wall": "19", "wall": "4495"}
2021-10-23 16:23:07 | INFO | train_inner | {"epoch": 13, "update": 12.571, "loss": "2.211", "nll_loss": "0.287", "ppl": "1.22", "wps": "1379.7", "ups": "5.15", "wpb": "267.9", "bsz": "16", "num_updates": "15400", "lr": "4.92546e-05", "gnorm": "2.425", "train_wall": "19", "wall": "4514"}
2021-10-23 16:23:27 | INFO | train_inner | {"epoch": 13, "update": 12.653, "loss": "2.216", "nll_loss": "0.292", "ppl": "1.22", "wps": "1476.1", "ups": "4.96", "wpb": "297.7", "bsz": "16", "num_updates": "15500", "lr": "4.92496e-05", "gnorm": "2.461", "train_wall": "20", "wall": "4535"}
2021-10-23 16:23:48 | INFO | train_inner | {"epoch": 13, "update": 12.735, "loss": "2.211", "nll_loss": "0.286", "ppl": "1.22", "wps": "1375.2", "ups": "4.77", "wpb": "288.2", "bsz": "16", "num_updates": "15600", "lr": "4.92446e-05", "gnorm": "2.531", "train_wall": "21", "wall": "4556"}
2021-10-23 16:24:08 | INFO | train_inner | {"epoch": 13, "update": 12.816, "loss": "2.207", "nll_loss": "0.282", "ppl": "1.22", "wps": "1425.7", "ups": "5.06", "wpb": "281.5", "bsz": "16", "num_updates": "15700", "lr": "4.92396e-05", "gnorm": "2.795", "train_wall": "19", "wall": "4575"}
2021-10-23 16:24:30 | INFO | train_inner | {"epoch": 13, "update": 12.898, "loss": "2.217", "nll_loss": "0.3", "ppl": "1.23", "wps": "2033.4", "ups": "4.66", "wpb": "436.4", "bsz": "16", "num_updates": "15800", "lr": "4.92346e-05", "gnorm": "2.248", "train_wall": "21", "wall": "4597"}
2021-10-23 16:24:47 | INFO | train_inner | {"epoch": 13, "update": 12.98, "loss": "2.217", "nll_loss": "0.3", "ppl": "1.23", "wps": "1668.7", "ups": "5.75", "wpb": "290.1", "bsz": "16", "num_updates": "15900", "lr": "4.92296e-05", "gnorm": "2.455", "train_wall": "17", "wall": "4614"}
2021-10-23 16:24:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-23 16:26:44 | INFO | valid | {"epoch": 13, "valid_loss": "3.125", "valid_nll_loss": "1.165", "valid_ppl": "2.24", "valid_bleu": "60.33", "valid_wps": "383.5", "valid_wpb": "140.1", "valid_bsz": "8", "valid_num_updates": "15925", "valid_best_bleu": "69.8"}
2021-10-23 16:26:44 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-23 16:26:51 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/large/checkpoint_last.pt (epoch 13 @ 15925 updates, score 60.33) (writing took 7.161231757025234 seconds)
2021-10-23 16:26:51 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2021-10-23 16:26:51 | INFO | train | {"epoch": 13, "train_loss": "2.205", "train_nll_loss": "0.28", "train_ppl": "1.21", "train_wps": "1008.3", "train_ups": "3.41", "train_wpb": "295.9", "train_bsz": "16", "train_num_updates": "15925", "train_lr": "4.92284e-05", "train_gnorm": "2.429", "train_train_wall": "237", "train_wall": "4738"}
2021-10-23 16:26:51 | INFO | fairseq_cli.train | begin training epoch 13
2021-10-23 16:27:05 | INFO | train_inner | {"epoch": 14, "update": 13.061, "loss": "2.188", "nll_loss": "0.263", "ppl": "1.2", "wps": "246.5", "ups": "0.72", "wpb": "341.3", "bsz": "15.9", "num_updates": "16000", "lr": "4.92246e-05", "gnorm": "2.382", "train_wall": "19", "wall": "4753"}
2021-10-23 16:27:25 | INFO | train_inner | {"epoch": 14, "update": 13.143, "loss": "2.19", "nll_loss": "0.263", "ppl": "1.2", "wps": "1401.9", "ups": "5.05", "wpb": "277.5", "bsz": "16", "num_updates": "16100", "lr": "4.92196e-05", "gnorm": "2.427", "train_wall": "20", "wall": "4772"}
2021-10-23 16:27:44 | INFO | train_inner | {"epoch": 14, "update": 13.224, "loss": "2.192", "nll_loss": "0.269", "ppl": "1.2", "wps": "1593.8", "ups": "5.27", "wpb": "302.6", "bsz": "16", "num_updates": "16200", "lr": "4.92146e-05", "gnorm": "2.575", "train_wall": "19", "wall": "4791"}
2021-10-23 16:28:04 | INFO | train_inner | {"epoch": 14, "update": 13.306, "loss": "2.194", "nll_loss": "0.27", "ppl": "1.21", "wps": "1412.4", "ups": "5.13", "wpb": "275.3", "bsz": "16", "num_updates": "16300", "lr": "4.92096e-05", "gnorm": "2.451", "train_wall": "19", "wall": "4811"}
2021-10-23 16:28:24 | INFO | train_inner | {"epoch": 14, "update": 13.388, "loss": "2.203", "nll_loss": "0.28", "ppl": "1.21", "wps": "1474.1", "ups": "4.82", "wpb": "306", "bsz": "16", "num_updates": "16400", "lr": "4.92046e-05", "gnorm": "2.341", "train_wall": "20", "wall": "4832"}
2021-10-23 16:28:46 | INFO | train_inner | {"epoch": 14, "update": 13.469, "loss": "2.19", "nll_loss": "0.265", "ppl": "1.2", "wps": "1381.9", "ups": "4.69", "wpb": "294.4", "bsz": "16", "num_updates": "16500", "lr": "4.91996e-05", "gnorm": "2.281", "train_wall": "21", "wall": "4853"}
2021-10-23 16:29:05 | INFO | train_inner | {"epoch": 14, "update": 13.551, "loss": "2.198", "nll_loss": "0.275", "ppl": "1.21", "wps": "1439.5", "ups": "5.19", "wpb": "277.4", "bsz": "16", "num_updates": "16600", "lr": "4.91946e-05", "gnorm": "2.573", "train_wall": "19", "wall": "4872"}
2021-10-23 16:29:26 | INFO | train_inner | {"epoch": 14, "update": 13.633, "loss": "2.206", "nll_loss": "0.286", "ppl": "1.22", "wps": "1495.5", "ups": "4.69", "wpb": "318.9", "bsz": "16", "num_updates": "16700", "lr": "4.91896e-05", "gnorm": "2.824", "train_wall": "21", "wall": "4894"}
2021-10-23 16:29:46 | INFO | train_inner | {"epoch": 14, "update": 13.714, "loss": "2.203", "nll_loss": "0.282", "ppl": "1.22", "wps": "1459", "ups": "5.06", "wpb": "288.6", "bsz": "16", "num_updates": "16800", "lr": "4.91846e-05", "gnorm": "2.574", "train_wall": "20", "wall": "4913"}
2021-10-23 16:30:04 | INFO | train_inner | {"epoch": 14, "update": 13.796, "loss": "2.21", "nll_loss": "0.288", "ppl": "1.22", "wps": "1626.9", "ups": "5.74", "wpb": "283.3", "bsz": "16", "num_updates": "16900", "lr": "4.91796e-05", "gnorm": "2.611", "train_wall": "17", "wall": "4931"}
2021-10-23 16:30:24 | INFO | train_inner | {"epoch": 14, "update": 13.878, "loss": "2.215", "nll_loss": "0.296", "ppl": "1.23", "wps": "1426.9", "ups": "4.97", "wpb": "287.1", "bsz": "16", "num_updates": "17000", "lr": "4.91746e-05", "gnorm": "2.66", "train_wall": "20", "wall": "4951"}
2021-10-23 16:30:44 | INFO | train_inner | {"epoch": 14, "update": 13.959, "loss": "2.222", "nll_loss": "0.308", "ppl": "1.24", "wps": "1610.2", "ups": "4.8", "wpb": "335.5", "bsz": "16", "num_updates": "17100", "lr": "4.91696e-05", "gnorm": "2.483", "train_wall": "21", "wall": "4972"}
2021-10-23 16:30:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-23 16:32:48 | INFO | valid | {"epoch": 14, "valid_loss": "3.166", "valid_nll_loss": "1.207", "valid_ppl": "2.31", "valid_bleu": "59.88", "valid_wps": "376.6", "valid_wpb": "140.1", "valid_bsz": "8", "valid_num_updates": "17150", "valid_best_bleu": "69.8"}
2021-10-23 16:32:48 | INFO | fairseq_cli.train | early stop since valid performance hasn't improved for last 10 runs
2021-10-23 16:32:48 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-23 16:33:02 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/large/checkpoint_last.pt (epoch 14 @ 17150 updates, score 59.88) (writing took 14.376842148019932 seconds)
2021-10-23 16:33:02 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2021-10-23 16:33:02 | INFO | train | {"epoch": 14, "train_loss": "2.202", "train_nll_loss": "0.28", "train_ppl": "1.21", "train_wps": "976.2", "train_ups": "3.3", "train_wpb": "295.9", "train_bsz": "16", "train_num_updates": "17150", "train_lr": "4.91671e-05", "train_gnorm": "2.539", "train_train_wall": "239", "train_wall": "5109"}
2021-10-23 16:33:02 | INFO | fairseq_cli.train | done training in 5104.4 seconds
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
Source: source Target: target


2021-10-23 17:38:02 | INFO | fairseq_cli.train | Namespace(activation_fn='gelu', adam_betas='(0.9, 0.98)', adam_eps=1e-06, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='mbart_base', attention_dropout=0.1, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_suffix='', clip_norm=0.0, cpu=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='../processed_data/large/data-bin', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', decoder_attention_heads=12, decoder_embed_dim=768, decoder_embed_path=None, decoder_ffn_embed_dim=3072, decoder_input_dim=768, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=True, decoder_normalize_before=False, decoder_output_dim=768, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', dropout=0.1, empty_cache_freq=0, encoder_attention_heads=12, encoder_embed_dim=768, encoder_embed_path=None, encoder_ffn_embed_dim=3072, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=False, end_learning_rate=0.0, eval_bleu=True, eval_bleu_args='{"beam": 5}', eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=True, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.1, langs='java,python,en_XX', layernorm_embedding=True, left_pad_source='True', left_pad_target='False', load_alignments=False, localsgd_frequency=3, log_format='json', log_interval=100, lr=[5e-05], lr_scheduler='polynomial_decay', max_epoch=30, max_sentences=8, max_sentences_valid=8, max_source_positions=1024, max_target_positions=1024, max_tokens=None, max_tokens_valid=None, max_update=100000, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=-1.0, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_workers=1, optimizer='adam', optimizer_overrides='{}', patience=10, pooler_activation_fn='tanh', pooler_dropout=0.0, power=1.0, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, relu_dropout=0.0, required_batch_size_multiple=8, reset_dataloader=True, reset_lr_scheduler=True, reset_meters=True, reset_optimizer=True, restore_file='checkpoint_last.pt', save_dir='../models/scratch/unique/large', save_interval=1, save_interval_updates=0, seed=1234, sentence_avg=False, share_all_embeddings=True, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='source', stop_time_hours=0, target_lang='target', task='translation_without_lang_token', tensorboard_logdir='', threshold_loss_scale=None, tokenizer=None, total_num_update=1000000, tpu=False, train_subset='train', truncate_source=True, update_freq=[2], upsample_primary=1, use_bmuf=False, use_old_adam=False, user_dir='../user_dir', valid_subset='valid', validate_interval=1, warmup_updates=500, weight_decay=0.0)
2021-10-23 17:38:02 | INFO | fairseq.tasks.translation | [source] dictionary: 50001 types
2021-10-23 17:38:02 | INFO | fairseq.tasks.translation | [target] dictionary: 50001 types
2021-10-23 17:38:02 | INFO | fairseq.data.data_utils | loaded 2449 examples from: ../processed_data/large/data-bin/valid.source-target.source
2021-10-23 17:38:02 | INFO | fairseq.data.data_utils | loaded 2449 examples from: ../processed_data/large/data-bin/valid.source-target.target
2021-10-23 17:38:02 | INFO | fairseq.tasks.translation | ../processed_data/large/data-bin valid source-target 2449 examples
2021-10-23 17:38:07 | INFO | fairseq_cli.train | BARTModel(
  (encoder): TransformerEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(50005, 768, padding_idx=1)
    (embed_positions): LearnedPositionalEmbedding(1026, 768, padding_idx=1)
    (layernorm_embedding): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(50005, 768, padding_idx=1)
    (embed_positions): LearnedPositionalEmbedding(1026, 768, padding_idx=1)
    (layernorm_embedding): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=768, out_features=50005, bias=False)
  )
  (classification_heads): ModuleDict()
)
2021-10-23 17:38:07 | INFO | fairseq_cli.train | model mbart_base, criterion LabelSmoothedCrossEntropyCriterion
2021-10-23 17:38:07 | INFO | fairseq_cli.train | num. model params: 139220736 (num. trained: 139220736)
2021-10-23 17:38:11 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight
2021-10-23 17:38:11 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight
2021-10-23 17:38:11 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2021-10-23 17:38:11 | INFO | fairseq.utils | rank   0: capabilities =  6.1  ; total memory = 12.000 GB ; name = GRID P40-12Q                            
2021-10-23 17:38:11 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2021-10-23 17:38:11 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2021-10-23 17:38:11 | INFO | fairseq_cli.train | max tokens per GPU = None and max sentences per GPU = 8
2021-10-23 17:38:11 | INFO | fairseq.trainer | no existing checkpoint found ../models/scratch/unique/large/checkpoint_last.pt
2021-10-23 17:38:11 | INFO | fairseq.trainer | loading train data for epoch 1
2021-10-23 17:38:11 | INFO | fairseq.data.data_utils | loaded 19590 examples from: ../processed_data/large/data-bin/train.source-target.source
2021-10-23 17:38:11 | INFO | fairseq.data.data_utils | loaded 19590 examples from: ../processed_data/large/data-bin/train.source-target.target
2021-10-23 17:38:11 | INFO | fairseq.tasks.translation | ../processed_data/large/data-bin train source-target 19590 examples
2021-10-23 17:38:11 | INFO | fairseq.trainer | NOTE: your device does NOT support faster training with --fp16, please switch to FP32 which is likely to be faster
2021-10-23 17:38:11 | INFO | fairseq.optim.adam | using FusedAdam
2021-10-23 17:38:11 | INFO | fairseq_cli.train | begin training epoch 1
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
2021-10-23 17:38:31 | INFO | train_inner | {"epoch": 1, "update": 0.082, "loss": "14.934", "nll_loss": "14.827", "ppl": "29073.4", "wps": "2236.9", "ups": "5.01", "wpb": "446.2", "bsz": "16", "num_updates": "100", "lr": "1e-05", "gnorm": "3.497", "loss_scale": "128", "train_wall": "20", "wall": "21"}
2021-10-23 17:38:52 | INFO | train_inner | {"epoch": 1, "update": 0.163, "loss": "12.982", "nll_loss": "12.658", "ppl": "6464.58", "wps": "2123.2", "ups": "4.84", "wpb": "439", "bsz": "16", "num_updates": "200", "lr": "2e-05", "gnorm": "2.891", "loss_scale": "128", "train_wall": "20", "wall": "41"}
2021-10-23 17:39:13 | INFO | train_inner | {"epoch": 1, "update": 0.245, "loss": "10.841", "nll_loss": "10.239", "ppl": "1208.44", "wps": "2372.4", "ups": "4.83", "wpb": "491.1", "bsz": "16", "num_updates": "300", "lr": "3e-05", "gnorm": "2.393", "loss_scale": "128", "train_wall": "20", "wall": "62"}
2021-10-23 17:39:32 | INFO | train_inner | {"epoch": 1, "update": 0.327, "loss": "9.161", "nll_loss": "8.266", "ppl": "307.88", "wps": "2167.5", "ups": "5.12", "wpb": "423.5", "bsz": "16", "num_updates": "400", "lr": "4e-05", "gnorm": "2.295", "loss_scale": "128", "train_wall": "19", "wall": "82"}
2021-10-23 17:39:53 | INFO | train_inner | {"epoch": 1, "update": 0.408, "loss": "8.543", "nll_loss": "7.505", "ppl": "181.64", "wps": "2513", "ups": "4.83", "wpb": "520.4", "bsz": "16", "num_updates": "500", "lr": "5e-05", "gnorm": "2.398", "loss_scale": "128", "train_wall": "20", "wall": "102"}
2021-10-23 17:40:14 | INFO | train_inner | {"epoch": 1, "update": 0.49, "loss": "7.993", "nll_loss": "6.855", "ppl": "115.73", "wps": "2315.4", "ups": "4.73", "wpb": "489.3", "bsz": "16", "num_updates": "600", "lr": "4.9995e-05", "gnorm": "2.623", "loss_scale": "128", "train_wall": "21", "wall": "124"}
2021-10-23 17:40:33 | INFO | train_inner | {"epoch": 1, "update": 0.571, "loss": "7.419", "nll_loss": "6.196", "ppl": "73.32", "wps": "2503.3", "ups": "5.17", "wpb": "484.1", "bsz": "16", "num_updates": "700", "lr": "4.999e-05", "gnorm": "2.731", "loss_scale": "128", "train_wall": "19", "wall": "143"}
2021-10-23 17:40:54 | INFO | train_inner | {"epoch": 1, "update": 0.653, "loss": "7.058", "nll_loss": "5.781", "ppl": "54.97", "wps": "2272.3", "ups": "4.91", "wpb": "462.9", "bsz": "16", "num_updates": "800", "lr": "4.9985e-05", "gnorm": "2.757", "loss_scale": "128", "train_wall": "20", "wall": "163"}
2021-10-23 17:41:15 | INFO | train_inner | {"epoch": 1, "update": 0.735, "loss": "6.86", "nll_loss": "5.551", "ppl": "46.87", "wps": "2376.1", "ups": "4.8", "wpb": "494.7", "bsz": "16", "num_updates": "900", "lr": "4.998e-05", "gnorm": "2.795", "loss_scale": "128", "train_wall": "21", "wall": "184"}
2021-10-23 17:41:34 | INFO | train_inner | {"epoch": 1, "update": 0.816, "loss": "6.54", "nll_loss": "5.188", "ppl": "36.45", "wps": "2375.5", "ups": "5.14", "wpb": "461.9", "bsz": "16", "num_updates": "1000", "lr": "4.9975e-05", "gnorm": "2.826", "loss_scale": "128", "train_wall": "19", "wall": "204"}
2021-10-23 17:41:55 | INFO | train_inner | {"epoch": 1, "update": 0.898, "loss": "6.467", "nll_loss": "5.1", "ppl": "34.29", "wps": "2298.7", "ups": "4.68", "wpb": "490.7", "bsz": "16", "num_updates": "1100", "lr": "4.997e-05", "gnorm": "2.959", "loss_scale": "128", "train_wall": "21", "wall": "225"}
2021-10-23 17:42:17 | INFO | train_inner | {"epoch": 1, "update": 0.98, "loss": "6.271", "nll_loss": "4.879", "ppl": "29.43", "wps": "2315", "ups": "4.67", "wpb": "495.2", "bsz": "16", "num_updates": "1200", "lr": "4.9965e-05", "gnorm": "2.938", "loss_scale": "128", "train_wall": "21", "wall": "246"}
2021-10-23 17:42:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-23 17:48:42 | INFO | fairseq.data.iterators | Data loading buffer is empty or nearly empty. This may indicate a data loading bottleneck, and increasing the number of workers (--num-workers) may help.
2021-10-23 17:48:42 | INFO | valid | {"epoch": 1, "valid_loss": "5.938", "valid_nll_loss": "4.461", "valid_ppl": "22.03", "valid_bleu": "2.52", "valid_wps": "183", "valid_wpb": "226.2", "valid_bsz": "8", "valid_num_updates": "1225"}
2021-10-23 17:48:42 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-23 17:48:51 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/scratch/unique/large/checkpoint_best.pt (epoch 1 @ 1225 updates, score 2.52) (writing took 8.42525496694725 seconds)
2021-10-23 17:48:51 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2021-10-23 17:48:51 | INFO | train | {"epoch": 1, "train_loss": "8.635", "train_nll_loss": "7.615", "train_ppl": "195.99", "train_wps": "906.7", "train_ups": "1.92", "train_wpb": "473.3", "train_bsz": "16", "train_num_updates": "1225", "train_lr": "4.99637e-05", "train_gnorm": "2.767", "train_loss_scale": "128", "train_train_wall": "248", "train_wall": "640"}
2021-10-23 17:48:51 | INFO | fairseq_cli.train | begin training epoch 1
2021-10-23 17:49:07 | INFO | train_inner | {"epoch": 2, "update": 1.061, "loss": "6.19", "nll_loss": "4.786", "ppl": "27.59", "wps": "123.5", "ups": "0.24", "wpb": "506.2", "bsz": "15.9", "num_updates": "1300", "lr": "4.996e-05", "gnorm": "3.047", "loss_scale": "128", "train_wall": "21", "wall": "656"}
2021-10-23 17:49:29 | INFO | train_inner | {"epoch": 2, "update": 1.143, "loss": "5.939", "nll_loss": "4.502", "ppl": "22.65", "wps": "2298.3", "ups": "4.61", "wpb": "498.7", "bsz": "16", "num_updates": "1400", "lr": "4.9955e-05", "gnorm": "2.987", "loss_scale": "128", "train_wall": "21", "wall": "678"}
2021-10-23 17:49:49 | INFO | train_inner | {"epoch": 2, "update": 1.224, "loss": "5.76", "nll_loss": "4.301", "ppl": "19.71", "wps": "2133.5", "ups": "4.92", "wpb": "434", "bsz": "16", "num_updates": "1500", "lr": "4.995e-05", "gnorm": "3.129", "loss_scale": "128", "train_wall": "20", "wall": "698"}
2021-10-23 17:50:08 | INFO | train_inner | {"epoch": 2, "update": 1.306, "loss": "5.575", "nll_loss": "4.093", "ppl": "17.07", "wps": "2249", "ups": "5.13", "wpb": "438.8", "bsz": "16", "num_updates": "1600", "lr": "4.9945e-05", "gnorm": "3.119", "loss_scale": "128", "train_wall": "19", "wall": "718"}
2021-10-23 17:50:28 | INFO | train_inner | {"epoch": 2, "update": 1.388, "loss": "5.771", "nll_loss": "4.308", "ppl": "19.81", "wps": "2468.6", "ups": "5.1", "wpb": "483.7", "bsz": "16", "num_updates": "1700", "lr": "4.994e-05", "gnorm": "3.097", "loss_scale": "128", "train_wall": "19", "wall": "737"}
2021-10-23 17:50:50 | INFO | train_inner | {"epoch": 2, "update": 1.469, "loss": "5.648", "nll_loss": "4.17", "ppl": "18", "wps": "2360.3", "ups": "4.56", "wpb": "518", "bsz": "16", "num_updates": "1800", "lr": "4.9935e-05", "gnorm": "3.047", "loss_scale": "128", "train_wall": "22", "wall": "759"}
2021-10-23 17:51:10 | INFO | train_inner | {"epoch": 2, "update": 1.551, "loss": "5.299", "nll_loss": "3.779", "ppl": "13.73", "wps": "2065.9", "ups": "5.03", "wpb": "411", "bsz": "16", "num_updates": "1900", "lr": "4.993e-05", "gnorm": "3.333", "loss_scale": "128", "train_wall": "20", "wall": "779"}
2021-10-23 17:51:31 | INFO | train_inner | {"epoch": 2, "update": 1.633, "loss": "5.336", "nll_loss": "3.819", "ppl": "14.12", "wps": "1937.7", "ups": "4.77", "wpb": "405.8", "bsz": "16", "num_updates": "2000", "lr": "4.9925e-05", "gnorm": "3.411", "loss_scale": "128", "train_wall": "21", "wall": "800"}
2021-10-23 17:51:53 | INFO | train_inner | {"epoch": 2, "update": 1.714, "loss": "5.504", "nll_loss": "4.007", "ppl": "16.08", "wps": "2321.5", "ups": "4.55", "wpb": "510.4", "bsz": "16", "num_updates": "2100", "lr": "4.992e-05", "gnorm": "3.255", "loss_scale": "128", "train_wall": "22", "wall": "822"}
2021-10-23 17:52:16 | INFO | train_inner | {"epoch": 2, "update": 1.796, "loss": "5.621", "nll_loss": "4.135", "ppl": "17.57", "wps": "2417.9", "ups": "4.36", "wpb": "554.9", "bsz": "16", "num_updates": "2200", "lr": "4.9915e-05", "gnorm": "3.324", "loss_scale": "128", "train_wall": "23", "wall": "845"}
2021-10-23 17:52:36 | INFO | train_inner | {"epoch": 2, "update": 1.878, "loss": "5.377", "nll_loss": "3.862", "ppl": "14.54", "wps": "2552.5", "ups": "5.04", "wpb": "506.1", "bsz": "16", "num_updates": "2300", "lr": "4.991e-05", "gnorm": "3.355", "loss_scale": "128", "train_wall": "20", "wall": "865"}
2021-10-23 17:52:52 | INFO | train_inner | {"epoch": 2, "update": 1.959, "loss": "5.123", "nll_loss": "3.576", "ppl": "11.93", "wps": "2635.8", "ups": "5.91", "wpb": "445.7", "bsz": "16", "num_updates": "2400", "lr": "4.9905e-05", "gnorm": "3.396", "loss_scale": "128", "train_wall": "17", "wall": "882"}
2021-10-23 17:53:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-23 17:57:05 | INFO | valid | {"epoch": 2, "valid_loss": "4.997", "valid_nll_loss": "3.385", "valid_ppl": "10.44", "valid_bleu": "6.25", "valid_wps": "285", "valid_wpb": "226.2", "valid_bsz": "8", "valid_num_updates": "2450", "valid_best_bleu": "6.25"}
2021-10-23 17:57:05 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-23 17:57:22 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/scratch/unique/large/checkpoint_best.pt (epoch 2 @ 2450 updates, score 6.25) (writing took 16.89073762507178 seconds)
2021-10-23 17:57:22 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2021-10-23 17:57:22 | INFO | train | {"epoch": 2, "train_loss": "5.578", "train_nll_loss": "4.092", "train_ppl": "17.05", "train_wps": "1133.5", "train_ups": "2.4", "train_wpb": "473.3", "train_bsz": "16", "train_num_updates": "2450", "train_lr": "4.99025e-05", "train_gnorm": "3.224", "train_loss_scale": "128", "train_train_wall": "248", "train_wall": "1151"}
2021-10-23 17:57:22 | INFO | fairseq_cli.train | begin training epoch 2
2021-10-23 17:57:32 | INFO | train_inner | {"epoch": 3, "update": 2.041, "loss": "4.867", "nll_loss": "3.291", "ppl": "9.79", "wps": "141.3", "ups": "0.36", "wpb": "395.4", "bsz": "15.9", "num_updates": "2500", "lr": "4.98999e-05", "gnorm": "3.447", "loss_scale": "128", "train_wall": "19", "wall": "1162"}
2021-10-23 17:57:52 | INFO | train_inner | {"epoch": 3, "update": 2.122, "loss": "5.043", "nll_loss": "3.487", "ppl": "11.21", "wps": "2350.1", "ups": "5.13", "wpb": "457.9", "bsz": "16", "num_updates": "2600", "lr": "4.98949e-05", "gnorm": "3.572", "loss_scale": "128", "train_wall": "19", "wall": "1181"}
2021-10-23 17:58:11 | INFO | train_inner | {"epoch": 3, "update": 2.204, "loss": "5.093", "nll_loss": "3.54", "ppl": "11.63", "wps": "2448.1", "ups": "5.12", "wpb": "478.6", "bsz": "16", "num_updates": "2700", "lr": "4.98899e-05", "gnorm": "3.26", "loss_scale": "128", "train_wall": "19", "wall": "1201"}
2021-10-23 17:58:30 | INFO | train_inner | {"epoch": 3, "update": 2.286, "loss": "5.086", "nll_loss": "3.534", "ppl": "11.58", "wps": "2779.7", "ups": "5.5", "wpb": "504.9", "bsz": "16", "num_updates": "2800", "lr": "4.98849e-05", "gnorm": "3.368", "loss_scale": "128", "train_wall": "18", "wall": "1219"}
2021-10-23 17:58:49 | INFO | train_inner | {"epoch": 3, "update": 2.367, "loss": "4.738", "nll_loss": "3.142", "ppl": "8.82", "wps": "2193.3", "ups": "5.14", "wpb": "426.5", "bsz": "16", "num_updates": "2900", "lr": "4.98799e-05", "gnorm": "3.416", "loss_scale": "128", "train_wall": "19", "wall": "1238"}
2021-10-23 17:59:11 | INFO | train_inner | {"epoch": 3, "update": 2.449, "loss": "5.027", "nll_loss": "3.463", "ppl": "11.02", "wps": "2391.8", "ups": "4.5", "wpb": "532", "bsz": "16", "num_updates": "3000", "lr": "4.98749e-05", "gnorm": "3.244", "loss_scale": "128", "train_wall": "22", "wall": "1261"}
2021-10-23 17:59:30 | INFO | train_inner | {"epoch": 3, "update": 2.531, "loss": "4.7", "nll_loss": "3.099", "ppl": "8.57", "wps": "2351.2", "ups": "5.44", "wpb": "432.2", "bsz": "16", "num_updates": "3100", "lr": "4.98699e-05", "gnorm": "3.398", "loss_scale": "128", "train_wall": "18", "wall": "1279"}
2021-10-23 17:59:50 | INFO | train_inner | {"epoch": 3, "update": 2.612, "loss": "4.871", "nll_loss": "3.291", "ppl": "9.79", "wps": "2328.3", "ups": "4.84", "wpb": "481.1", "bsz": "16", "num_updates": "3200", "lr": "4.98649e-05", "gnorm": "3.419", "loss_scale": "128", "train_wall": "20", "wall": "1300"}
2021-10-23 18:00:10 | INFO | train_inner | {"epoch": 3, "update": 2.694, "loss": "4.75", "nll_loss": "3.154", "ppl": "8.9", "wps": "2235", "ups": "4.96", "wpb": "450.3", "bsz": "16", "num_updates": "3300", "lr": "4.98599e-05", "gnorm": "3.443", "loss_scale": "128", "train_wall": "20", "wall": "1320"}
2021-10-23 18:00:31 | INFO | train_inner | {"epoch": 3, "update": 2.776, "loss": "4.723", "nll_loss": "3.123", "ppl": "8.71", "wps": "2088", "ups": "4.78", "wpb": "436.8", "bsz": "16", "num_updates": "3400", "lr": "4.98549e-05", "gnorm": "3.523", "loss_scale": "128", "train_wall": "21", "wall": "1341"}
2021-10-23 18:00:51 | INFO | train_inner | {"epoch": 3, "update": 2.857, "loss": "4.869", "nll_loss": "3.287", "ppl": "9.76", "wps": "2689.9", "ups": "5.08", "wpb": "530", "bsz": "16", "num_updates": "3500", "lr": "4.98499e-05", "gnorm": "3.286", "loss_scale": "128", "train_wall": "19", "wall": "1361"}
2021-10-23 18:01:13 | INFO | train_inner | {"epoch": 3, "update": 2.939, "loss": "4.934", "nll_loss": "3.359", "ppl": "10.26", "wps": "2289.9", "ups": "4.54", "wpb": "504.1", "bsz": "16", "num_updates": "3600", "lr": "4.98449e-05", "gnorm": "3.427", "loss_scale": "128", "train_wall": "22", "wall": "1383"}
2021-10-23 18:01:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-23 18:05:05 | INFO | valid | {"epoch": 3, "valid_loss": "4.569", "valid_nll_loss": "2.878", "valid_ppl": "7.35", "valid_bleu": "8.84", "valid_wps": "319.6", "valid_wpb": "226.2", "valid_bsz": "8", "valid_num_updates": "3675", "valid_best_bleu": "8.84"}
2021-10-23 18:05:05 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-23 18:05:31 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/scratch/unique/large/checkpoint_best.pt (epoch 3 @ 3675 updates, score 8.84) (writing took 26.07390201999806 seconds)
2021-10-23 18:05:31 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2021-10-23 18:05:32 | INFO | train | {"epoch": 3, "train_loss": "4.889", "train_nll_loss": "3.311", "train_ppl": "9.92", "train_wps": "1184.3", "train_ups": "2.5", "train_wpb": "473.3", "train_bsz": "16", "train_num_updates": "3675", "train_lr": "4.98412e-05", "train_gnorm": "3.392", "train_loss_scale": "128", "train_train_wall": "243", "train_wall": "1641"}
2021-10-23 18:05:32 | INFO | fairseq_cli.train | begin training epoch 3
2021-10-23 18:05:37 | INFO | train_inner | {"epoch": 4, "update": 3.02, "loss": "4.676", "nll_loss": "3.071", "ppl": "8.4", "wps": "173.6", "ups": "0.38", "wpb": "457.7", "bsz": "15.9", "num_updates": "3700", "lr": "4.98399e-05", "gnorm": "3.377", "loss_scale": "128", "train_wall": "20", "wall": "1646"}
2021-10-23 18:05:58 | INFO | train_inner | {"epoch": 4, "update": 3.102, "loss": "4.451", "nll_loss": "2.817", "ppl": "7.05", "wps": "2063.2", "ups": "4.78", "wpb": "431.2", "bsz": "16", "num_updates": "3800", "lr": "4.98349e-05", "gnorm": "3.289", "loss_scale": "128", "train_wall": "21", "wall": "1667"}
2021-10-23 18:06:18 | INFO | train_inner | {"epoch": 4, "update": 3.184, "loss": "4.585", "nll_loss": "2.967", "ppl": "7.82", "wps": "2242.3", "ups": "4.91", "wpb": "456.9", "bsz": "16", "num_updates": "3900", "lr": "4.98299e-05", "gnorm": "3.389", "loss_scale": "128", "train_wall": "20", "wall": "1688"}
2021-10-23 18:06:37 | INFO | train_inner | {"epoch": 4, "update": 3.265, "loss": "4.627", "nll_loss": "3.015", "ppl": "8.08", "wps": "2513.9", "ups": "5.18", "wpb": "485.1", "bsz": "16", "num_updates": "4000", "lr": "4.98249e-05", "gnorm": "3.363", "loss_scale": "128", "train_wall": "19", "wall": "1707"}
2021-10-23 18:06:59 | INFO | train_inner | {"epoch": 4, "update": 3.347, "loss": "4.561", "nll_loss": "2.941", "ppl": "7.68", "wps": "2343.8", "ups": "4.6", "wpb": "509.5", "bsz": "16", "num_updates": "4100", "lr": "4.98199e-05", "gnorm": "3.291", "loss_scale": "128", "train_wall": "21", "wall": "1729"}
2021-10-23 18:07:21 | INFO | train_inner | {"epoch": 4, "update": 3.429, "loss": "4.71", "nll_loss": "3.107", "ppl": "8.61", "wps": "2407.5", "ups": "4.51", "wpb": "534.2", "bsz": "16", "num_updates": "4200", "lr": "4.98149e-05", "gnorm": "3.24", "loss_scale": "128", "train_wall": "22", "wall": "1751"}
2021-10-23 18:07:42 | INFO | train_inner | {"epoch": 4, "update": 3.51, "loss": "4.585", "nll_loss": "2.965", "ppl": "7.81", "wps": "2241.4", "ups": "4.76", "wpb": "471.1", "bsz": "16", "num_updates": "4300", "lr": "4.98099e-05", "gnorm": "3.43", "loss_scale": "128", "train_wall": "21", "wall": "1772"}
2021-10-23 18:08:02 | INFO | train_inner | {"epoch": 4, "update": 3.592, "loss": "4.409", "nll_loss": "2.769", "ppl": "6.81", "wps": "2183.1", "ups": "4.98", "wpb": "438.1", "bsz": "16", "num_updates": "4400", "lr": "4.98049e-05", "gnorm": "3.43", "loss_scale": "128", "train_wall": "20", "wall": "1792"}
2021-10-23 18:08:22 | INFO | train_inner | {"epoch": 4, "update": 3.673, "loss": "4.318", "nll_loss": "2.668", "ppl": "6.35", "wps": "2249.5", "ups": "5.11", "wpb": "439.8", "bsz": "16", "num_updates": "4500", "lr": "4.97999e-05", "gnorm": "3.391", "loss_scale": "128", "train_wall": "19", "wall": "1811"}
2021-10-23 18:08:40 | INFO | train_inner | {"epoch": 4, "update": 3.755, "loss": "4.4", "nll_loss": "2.757", "ppl": "6.76", "wps": "2375.9", "ups": "5.4", "wpb": "440", "bsz": "16", "num_updates": "4600", "lr": "4.97949e-05", "gnorm": "3.425", "loss_scale": "128", "train_wall": "18", "wall": "1830"}
2021-10-23 18:09:00 | INFO | train_inner | {"epoch": 4, "update": 3.837, "loss": "4.447", "nll_loss": "2.812", "ppl": "7.02", "wps": "2458.5", "ups": "5.04", "wpb": "487.6", "bsz": "16", "num_updates": "4700", "lr": "4.97899e-05", "gnorm": "3.334", "loss_scale": "128", "train_wall": "20", "wall": "1850"}
2021-10-23 18:09:21 | INFO | train_inner | {"epoch": 4, "update": 3.918, "loss": "4.42", "nll_loss": "2.779", "ppl": "6.87", "wps": "2139.3", "ups": "4.78", "wpb": "447.5", "bsz": "16", "num_updates": "4800", "lr": "4.97849e-05", "gnorm": "3.365", "loss_scale": "128", "train_wall": "21", "wall": "1871"}
2021-10-23 18:09:44 | INFO | train_inner | {"epoch": 4, "update": 4.0, "loss": "4.534", "nll_loss": "2.908", "ppl": "7.5", "wps": "2456.8", "ups": "4.47", "wpb": "549.4", "bsz": "15.9", "num_updates": "4900", "lr": "4.97799e-05", "gnorm": "3.197", "loss_scale": "128", "train_wall": "22", "wall": "1893"}
2021-10-23 18:09:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-23 18:13:07 | INFO | valid | {"epoch": 4, "valid_loss": "4.319", "valid_nll_loss": "2.607", "valid_ppl": "6.09", "valid_bleu": "10.54", "valid_wps": "341.6", "valid_wpb": "226.2", "valid_bsz": "8", "valid_num_updates": "4900", "valid_best_bleu": "10.54"}
2021-10-23 18:13:07 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-23 18:13:31 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/scratch/unique/large/checkpoint_best.pt (epoch 4 @ 4900 updates, score 10.54) (writing took 24.323994345963 seconds)
2021-10-23 18:13:31 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2021-10-23 18:13:31 | INFO | train | {"epoch": 4, "train_loss": "4.509", "train_nll_loss": "2.881", "train_ppl": "7.37", "train_wps": "1207.9", "train_ups": "2.55", "train_wpb": "473.3", "train_bsz": "16", "train_num_updates": "4900", "train_lr": "4.97799e-05", "train_gnorm": "3.345", "train_loss_scale": "128", "train_train_wall": "249", "train_wall": "2121"}
2021-10-23 18:13:31 | INFO | fairseq_cli.train | begin training epoch 4
2021-10-23 18:13:53 | INFO | train_inner | {"epoch": 5, "update": 4.082, "loss": "4.401", "nll_loss": "2.758", "ppl": "6.77", "wps": "204.7", "ups": "0.4", "wpb": "510.1", "bsz": "16", "num_updates": "5000", "lr": "4.97749e-05", "gnorm": "3.199", "loss_scale": "128", "train_wall": "21", "wall": "2142"}
2021-10-23 18:14:14 | INFO | train_inner | {"epoch": 5, "update": 4.163, "loss": "4.172", "nll_loss": "2.502", "ppl": "5.66", "wps": "2087.6", "ups": "4.78", "wpb": "436.6", "bsz": "16", "num_updates": "5100", "lr": "4.97699e-05", "gnorm": "3.287", "loss_scale": "128", "train_wall": "21", "wall": "2163"}
2021-10-23 18:14:34 | INFO | train_inner | {"epoch": 5, "update": 4.245, "loss": "4.192", "nll_loss": "2.527", "ppl": "5.77", "wps": "2101.1", "ups": "4.84", "wpb": "434.1", "bsz": "16", "num_updates": "5200", "lr": "4.97649e-05", "gnorm": "3.299", "loss_scale": "128", "train_wall": "20", "wall": "2184"}
2021-10-23 18:14:56 | INFO | train_inner | {"epoch": 5, "update": 4.327, "loss": "4.438", "nll_loss": "2.799", "ppl": "6.96", "wps": "2414", "ups": "4.64", "wpb": "520.3", "bsz": "16", "num_updates": "5300", "lr": "4.97599e-05", "gnorm": "3.28", "loss_scale": "128", "train_wall": "21", "wall": "2205"}
2021-10-23 18:15:17 | INFO | train_inner | {"epoch": 5, "update": 4.408, "loss": "4.238", "nll_loss": "2.577", "ppl": "5.97", "wps": "2337.9", "ups": "4.8", "wpb": "487.1", "bsz": "16", "num_updates": "5400", "lr": "4.97549e-05", "gnorm": "3.223", "loss_scale": "128", "train_wall": "21", "wall": "2226"}
2021-10-23 18:15:36 | INFO | train_inner | {"epoch": 5, "update": 4.49, "loss": "4.013", "nll_loss": "2.322", "ppl": "5", "wps": "2100.9", "ups": "5.22", "wpb": "402.3", "bsz": "16", "num_updates": "5500", "lr": "4.97499e-05", "gnorm": "3.378", "loss_scale": "128", "train_wall": "19", "wall": "2245"}
2021-10-23 18:15:54 | INFO | train_inner | {"epoch": 5, "update": 4.571, "loss": "4.155", "nll_loss": "2.481", "ppl": "5.58", "wps": "2606.4", "ups": "5.48", "wpb": "476", "bsz": "16", "num_updates": "5600", "lr": "4.97449e-05", "gnorm": "3.278", "loss_scale": "128", "train_wall": "18", "wall": "2264"}
2021-10-23 18:16:13 | INFO | train_inner | {"epoch": 5, "update": 4.653, "loss": "4.188", "nll_loss": "2.518", "ppl": "5.73", "wps": "2490.8", "ups": "5.35", "wpb": "466", "bsz": "16", "num_updates": "5700", "lr": "4.97399e-05", "gnorm": "3.261", "loss_scale": "128", "train_wall": "19", "wall": "2282"}
2021-10-23 18:16:34 | INFO | train_inner | {"epoch": 5, "update": 4.735, "loss": "4.23", "nll_loss": "2.568", "ppl": "5.93", "wps": "2293.3", "ups": "4.85", "wpb": "473.2", "bsz": "16", "num_updates": "5800", "lr": "4.97349e-05", "gnorm": "3.351", "loss_scale": "128", "train_wall": "20", "wall": "2303"}
2021-10-23 18:16:55 | INFO | train_inner | {"epoch": 5, "update": 4.816, "loss": "4.308", "nll_loss": "2.653", "ppl": "6.29", "wps": "2366.2", "ups": "4.58", "wpb": "516.1", "bsz": "16", "num_updates": "5900", "lr": "4.97299e-05", "gnorm": "3.253", "loss_scale": "128", "train_wall": "22", "wall": "2325"}
2021-10-23 18:17:17 | INFO | train_inner | {"epoch": 5, "update": 4.898, "loss": "4.254", "nll_loss": "2.592", "ppl": "6.03", "wps": "2151.5", "ups": "4.64", "wpb": "464.1", "bsz": "16", "num_updates": "6000", "lr": "4.97249e-05", "gnorm": "3.413", "loss_scale": "128", "train_wall": "21", "wall": "2346"}
2021-10-23 18:17:37 | INFO | train_inner | {"epoch": 5, "update": 4.98, "loss": "4.101", "nll_loss": "2.421", "ppl": "5.35", "wps": "2293.7", "ups": "5.01", "wpb": "458.2", "bsz": "16", "num_updates": "6100", "lr": "4.97199e-05", "gnorm": "3.247", "loss_scale": "128", "train_wall": "20", "wall": "2366"}
2021-10-23 18:17:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-23 18:21:08 | INFO | valid | {"epoch": 5, "valid_loss": "4.16", "valid_nll_loss": "2.405", "valid_ppl": "5.3", "valid_bleu": "11.31", "valid_wps": "338.9", "valid_wpb": "226.2", "valid_bsz": "8", "valid_num_updates": "6125", "valid_best_bleu": "11.31"}
2021-10-23 18:21:08 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-23 18:21:18 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/scratch/unique/large/checkpoint_best.pt (epoch 5 @ 6125 updates, score 11.31) (writing took 10.044375372002833 seconds)
2021-10-23 18:21:18 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2021-10-23 18:21:18 | INFO | train | {"epoch": 5, "train_loss": "4.236", "train_nll_loss": "2.573", "train_ppl": "5.95", "train_wps": "1243.6", "train_ups": "2.63", "train_wpb": "473.3", "train_bsz": "16", "train_num_updates": "6125", "train_lr": "4.97186e-05", "train_gnorm": "3.287", "train_loss_scale": "128", "train_train_wall": "248", "train_wall": "2587"}
2021-10-23 18:21:18 | INFO | fairseq_cli.train | begin training epoch 5
2021-10-23 18:21:34 | INFO | train_inner | {"epoch": 6, "update": 5.061, "loss": "4.065", "nll_loss": "2.38", "ppl": "5.21", "wps": "204.7", "ups": "0.42", "wpb": "485.2", "bsz": "15.9", "num_updates": "6200", "lr": "4.97149e-05", "gnorm": "3.151", "loss_scale": "128", "train_wall": "21", "wall": "2603"}
2021-10-23 18:21:55 | INFO | train_inner | {"epoch": 6, "update": 5.143, "loss": "4.178", "nll_loss": "2.505", "ppl": "5.68", "wps": "2329.2", "ups": "4.66", "wpb": "499.5", "bsz": "16", "num_updates": "6300", "lr": "4.97099e-05", "gnorm": "3.22", "loss_scale": "128", "train_wall": "21", "wall": "2625"}
2021-10-23 18:22:16 | INFO | train_inner | {"epoch": 6, "update": 5.224, "loss": "4.1", "nll_loss": "2.421", "ppl": "5.36", "wps": "2401.5", "ups": "4.82", "wpb": "498.6", "bsz": "16", "num_updates": "6400", "lr": "4.97049e-05", "gnorm": "3.148", "loss_scale": "128", "train_wall": "21", "wall": "2646"}
2021-10-23 18:22:34 | INFO | train_inner | {"epoch": 6, "update": 5.306, "loss": "3.807", "nll_loss": "2.093", "ppl": "4.27", "wps": "2197.9", "ups": "5.57", "wpb": "394.4", "bsz": "16", "num_updates": "6500", "lr": "4.96998e-05", "gnorm": "3.248", "loss_scale": "128", "train_wall": "18", "wall": "2664"}
2021-10-23 18:22:55 | INFO | train_inner | {"epoch": 6, "update": 5.388, "loss": "4.18", "nll_loss": "2.509", "ppl": "5.69", "wps": "2616.2", "ups": "4.82", "wpb": "542.3", "bsz": "16", "num_updates": "6600", "lr": "4.96948e-05", "gnorm": "3.107", "loss_scale": "128", "train_wall": "21", "wall": "2684"}
2021-10-23 18:23:16 | INFO | train_inner | {"epoch": 6, "update": 5.469, "loss": "3.989", "nll_loss": "2.296", "ppl": "4.91", "wps": "2264.7", "ups": "4.76", "wpb": "476.1", "bsz": "16", "num_updates": "6700", "lr": "4.96898e-05", "gnorm": "3.224", "loss_scale": "128", "train_wall": "21", "wall": "2705"}
2021-10-23 18:23:36 | INFO | train_inner | {"epoch": 6, "update": 5.551, "loss": "3.876", "nll_loss": "2.167", "ppl": "4.49", "wps": "2243.4", "ups": "4.94", "wpb": "454", "bsz": "16", "num_updates": "6800", "lr": "4.96848e-05", "gnorm": "3.205", "loss_scale": "128", "train_wall": "20", "wall": "2726"}
2021-10-23 18:23:56 | INFO | train_inner | {"epoch": 6, "update": 5.633, "loss": "3.932", "nll_loss": "2.229", "ppl": "4.69", "wps": "2334.7", "ups": "5.12", "wpb": "456.2", "bsz": "16", "num_updates": "6900", "lr": "4.96798e-05", "gnorm": "3.233", "loss_scale": "128", "train_wall": "19", "wall": "2745"}
2021-10-23 18:24:17 | INFO | train_inner | {"epoch": 6, "update": 5.714, "loss": "4.2", "nll_loss": "2.532", "ppl": "5.78", "wps": "2499.9", "ups": "4.68", "wpb": "534.2", "bsz": "16", "num_updates": "7000", "lr": "4.96748e-05", "gnorm": "3.182", "loss_scale": "128", "train_wall": "21", "wall": "2766"}
2021-10-23 18:24:37 | INFO | train_inner | {"epoch": 6, "update": 5.796, "loss": "3.93", "nll_loss": "2.226", "ppl": "4.68", "wps": "2117.9", "ups": "4.99", "wpb": "424.4", "bsz": "16", "num_updates": "7100", "lr": "4.96698e-05", "gnorm": "3.351", "loss_scale": "128", "train_wall": "20", "wall": "2786"}
2021-10-23 18:24:58 | INFO | train_inner | {"epoch": 6, "update": 5.878, "loss": "4.157", "nll_loss": "2.482", "ppl": "5.59", "wps": "2639", "ups": "4.82", "wpb": "548", "bsz": "16", "num_updates": "7200", "lr": "4.96648e-05", "gnorm": "3.12", "loss_scale": "128", "train_wall": "21", "wall": "2807"}
2021-10-23 18:25:19 | INFO | train_inner | {"epoch": 6, "update": 5.959, "loss": "3.81", "nll_loss": "2.093", "ppl": "4.27", "wps": "1905", "ups": "4.78", "wpb": "398.3", "bsz": "16", "num_updates": "7300", "lr": "4.96598e-05", "gnorm": "3.281", "loss_scale": "128", "train_wall": "21", "wall": "2828"}
2021-10-23 18:25:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-23 18:28:38 | INFO | valid | {"epoch": 6, "valid_loss": "4.049", "valid_nll_loss": "2.3", "valid_ppl": "4.92", "valid_bleu": "13.71", "valid_wps": "366.4", "valid_wpb": "226.2", "valid_bsz": "8", "valid_num_updates": "7350", "valid_best_bleu": "13.71"}
2021-10-23 18:28:38 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-23 18:28:59 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/scratch/unique/large/checkpoint_best.pt (epoch 6 @ 7350 updates, score 13.71) (writing took 21.092386311967857 seconds)
2021-10-23 18:28:59 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2021-10-23 18:28:59 | INFO | train | {"epoch": 6, "train_loss": "4.02", "train_nll_loss": "2.33", "train_ppl": "5.03", "train_wps": "1255.4", "train_ups": "2.65", "train_wpb": "473.3", "train_bsz": "16", "train_num_updates": "7350", "train_lr": "4.96573e-05", "train_gnorm": "3.208", "train_loss_scale": "128", "train_train_wall": "248", "train_wall": "3049"}
2021-10-23 18:28:59 | INFO | fairseq_cli.train | begin training epoch 6
2021-10-23 18:29:10 | INFO | train_inner | {"epoch": 7, "update": 6.041, "loss": "3.958", "nll_loss": "2.261", "ppl": "4.79", "wps": "209.4", "ups": "0.43", "wpb": "484.2", "bsz": "15.9", "num_updates": "7400", "lr": "4.96548e-05", "gnorm": "3.108", "loss_scale": "128", "train_wall": "20", "wall": "3059"}
2021-10-23 18:29:28 | INFO | train_inner | {"epoch": 7, "update": 6.122, "loss": "3.775", "nll_loss": "2.057", "ppl": "4.16", "wps": "2581.3", "ups": "5.6", "wpb": "461.1", "bsz": "16", "num_updates": "7500", "lr": "4.96498e-05", "gnorm": "3", "loss_scale": "128", "train_wall": "18", "wall": "3077"}
2021-10-23 18:29:45 | INFO | train_inner | {"epoch": 7, "update": 6.204, "loss": "3.518", "nll_loss": "1.767", "ppl": "3.4", "wps": "2199.4", "ups": "5.69", "wpb": "386.9", "bsz": "16", "num_updates": "7600", "lr": "4.96448e-05", "gnorm": "3.084", "loss_scale": "128", "train_wall": "17", "wall": "3095"}
2021-10-23 18:30:06 | INFO | train_inner | {"epoch": 7, "update": 6.286, "loss": "3.697", "nll_loss": "1.969", "ppl": "3.91", "wps": "2167.1", "ups": "4.89", "wpb": "442.8", "bsz": "16", "num_updates": "7700", "lr": "4.96398e-05", "gnorm": "3.125", "loss_scale": "128", "train_wall": "20", "wall": "3115"}
2021-10-23 18:30:26 | INFO | train_inner | {"epoch": 7, "update": 6.367, "loss": "3.755", "nll_loss": "2.03", "ppl": "4.08", "wps": "2440.8", "ups": "4.89", "wpb": "499.2", "bsz": "16", "num_updates": "7800", "lr": "4.96348e-05", "gnorm": "3.078", "loss_scale": "128", "train_wall": "20", "wall": "3136"}
2021-10-23 18:30:48 | INFO | train_inner | {"epoch": 7, "update": 6.449, "loss": "4.02", "nll_loss": "2.33", "ppl": "5.03", "wps": "2493.6", "ups": "4.69", "wpb": "531.1", "bsz": "16", "num_updates": "7900", "lr": "4.96298e-05", "gnorm": "3.104", "loss_scale": "128", "train_wall": "21", "wall": "3157"}
2021-10-23 18:31:08 | INFO | train_inner | {"epoch": 7, "update": 6.531, "loss": "3.856", "nll_loss": "2.145", "ppl": "4.42", "wps": "2338.7", "ups": "4.94", "wpb": "473.3", "bsz": "16", "num_updates": "8000", "lr": "4.96248e-05", "gnorm": "3.151", "loss_scale": "128", "train_wall": "20", "wall": "3177"}
2021-10-23 18:31:30 | INFO | train_inner | {"epoch": 7, "update": 6.612, "loss": "4.181", "nll_loss": "2.509", "ppl": "5.69", "wps": "2571.9", "ups": "4.47", "wpb": "575.3", "bsz": "16", "num_updates": "8100", "lr": "4.96198e-05", "gnorm": "3.122", "loss_scale": "128", "train_wall": "22", "wall": "3200"}
2021-10-23 18:31:50 | INFO | train_inner | {"epoch": 7, "update": 6.694, "loss": "3.815", "nll_loss": "2.097", "ppl": "4.28", "wps": "2399.7", "ups": "4.95", "wpb": "484.7", "bsz": "16", "num_updates": "8200", "lr": "4.96148e-05", "gnorm": "3.093", "loss_scale": "140", "train_wall": "20", "wall": "3220"}
2021-10-23 18:31:55 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 128.0
2021-10-23 18:32:12 | INFO | train_inner | {"epoch": 7, "update": 6.776, "loss": "3.86", "nll_loss": "2.148", "ppl": "4.43", "wps": "1959.3", "ups": "4.65", "wpb": "421.1", "bsz": "16", "num_updates": "8300", "lr": "4.96098e-05", "gnorm": "3.299", "loss_scale": "153", "train_wall": "21", "wall": "3241"}
2021-10-23 18:32:32 | INFO | train_inner | {"epoch": 7, "update": 6.858, "loss": "3.757", "nll_loss": "2.032", "ppl": "4.09", "wps": "2427.3", "ups": "5.05", "wpb": "480.9", "bsz": "16", "num_updates": "8400", "lr": "4.96048e-05", "gnorm": "3.128", "loss_scale": "128", "train_wall": "20", "wall": "3261"}
2021-10-23 18:32:52 | INFO | train_inner | {"epoch": 7, "update": 6.94, "loss": "3.618", "nll_loss": "1.877", "ppl": "3.67", "wps": "2117.9", "ups": "4.96", "wpb": "427.1", "bsz": "16", "num_updates": "8500", "lr": "4.95998e-05", "gnorm": "3.175", "loss_scale": "128", "train_wall": "20", "wall": "3281"}
2021-10-23 18:33:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-23 18:36:07 | INFO | valid | {"epoch": 7, "valid_loss": "3.976", "valid_nll_loss": "2.214", "valid_ppl": "4.64", "valid_bleu": "14.64", "valid_wps": "388.9", "valid_wpb": "226.2", "valid_bsz": "8", "valid_num_updates": "8574", "valid_best_bleu": "14.64"}
2021-10-23 18:36:07 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-23 18:36:31 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/scratch/unique/large/checkpoint_best.pt (epoch 7 @ 8574 updates, score 14.64) (writing took 23.88713132101111 seconds)
2021-10-23 18:36:31 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2021-10-23 18:36:31 | INFO | train | {"epoch": 7, "train_loss": "3.827", "train_nll_loss": "2.113", "train_ppl": "4.32", "train_wps": "1280.7", "train_ups": "2.71", "train_wpb": "471.9", "train_bsz": "16", "train_num_updates": "8574", "train_lr": "4.95961e-05", "train_gnorm": "3.117", "train_loss_scale": "131", "train_train_wall": "245", "train_wall": "3500"}
2021-10-23 18:36:31 | INFO | fairseq_cli.train | begin training epoch 7
2021-10-23 18:36:36 | INFO | train_inner | {"epoch": 8, "update": 7.021, "loss": "3.764", "nll_loss": "2.042", "ppl": "4.12", "wps": "207.1", "ups": "0.45", "wpb": "464.8", "bsz": "15.9", "num_updates": "8600", "lr": "4.95948e-05", "gnorm": "3.102", "loss_scale": "128", "train_wall": "21", "wall": "3506"}
2021-10-23 18:36:58 | INFO | train_inner | {"epoch": 8, "update": 7.103, "loss": "3.742", "nll_loss": "2.017", "ppl": "4.05", "wps": "2393.9", "ups": "4.69", "wpb": "510.6", "bsz": "16", "num_updates": "8700", "lr": "4.95898e-05", "gnorm": "2.966", "loss_scale": "128", "train_wall": "21", "wall": "3527"}
2021-10-23 18:37:18 | INFO | train_inner | {"epoch": 8, "update": 7.184, "loss": "3.835", "nll_loss": "2.124", "ppl": "4.36", "wps": "2622.4", "ups": "4.97", "wpb": "527.7", "bsz": "16", "num_updates": "8800", "lr": "4.95848e-05", "gnorm": "2.977", "loss_scale": "128", "train_wall": "20", "wall": "3547"}
2021-10-23 18:37:37 | INFO | train_inner | {"epoch": 8, "update": 7.266, "loss": "3.618", "nll_loss": "1.878", "ppl": "3.68", "wps": "2353.2", "ups": "5.3", "wpb": "443.8", "bsz": "16", "num_updates": "8900", "lr": "4.95798e-05", "gnorm": "3.095", "loss_scale": "128", "train_wall": "19", "wall": "3566"}
2021-10-23 18:37:57 | INFO | train_inner | {"epoch": 8, "update": 7.348, "loss": "3.582", "nll_loss": "1.835", "ppl": "3.57", "wps": "2156.2", "ups": "4.89", "wpb": "440.6", "bsz": "16", "num_updates": "9000", "lr": "4.95748e-05", "gnorm": "3.027", "loss_scale": "128", "train_wall": "20", "wall": "3586"}
2021-10-23 18:38:17 | INFO | train_inner | {"epoch": 8, "update": 7.429, "loss": "3.7", "nll_loss": "1.967", "ppl": "3.91", "wps": "2440.3", "ups": "4.98", "wpb": "489.8", "bsz": "16", "num_updates": "9100", "lr": "4.95698e-05", "gnorm": "3.057", "loss_scale": "128", "train_wall": "20", "wall": "3607"}
2021-10-23 18:38:36 | INFO | train_inner | {"epoch": 8, "update": 7.511, "loss": "3.548", "nll_loss": "1.8", "ppl": "3.48", "wps": "2324.1", "ups": "5.16", "wpb": "450", "bsz": "16", "num_updates": "9200", "lr": "4.95648e-05", "gnorm": "3.068", "loss_scale": "128", "train_wall": "19", "wall": "3626"}
2021-10-23 18:38:57 | INFO | train_inner | {"epoch": 8, "update": 7.593, "loss": "3.689", "nll_loss": "1.953", "ppl": "3.87", "wps": "2125.1", "ups": "4.78", "wpb": "444.6", "bsz": "16", "num_updates": "9300", "lr": "4.95598e-05", "gnorm": "3.173", "loss_scale": "128", "train_wall": "21", "wall": "3647"}
2021-10-23 18:39:18 | INFO | train_inner | {"epoch": 8, "update": 7.674, "loss": "3.418", "nll_loss": "1.653", "ppl": "3.15", "wps": "2109.9", "ups": "4.77", "wpb": "442.1", "bsz": "16", "num_updates": "9400", "lr": "4.95548e-05", "gnorm": "3.106", "loss_scale": "128", "train_wall": "21", "wall": "3668"}
2021-10-23 18:39:34 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 64.0
2021-10-23 18:39:41 | INFO | train_inner | {"epoch": 8, "update": 7.757, "loss": "3.684", "nll_loss": "1.949", "ppl": "3.86", "wps": "2062", "ups": "4.49", "wpb": "459.1", "bsz": "16", "num_updates": "9500", "lr": "4.95498e-05", "gnorm": "3.172", "loss_scale": "110", "train_wall": "22", "wall": "3690"}
2021-10-23 18:40:02 | INFO | train_inner | {"epoch": 8, "update": 7.838, "loss": "3.751", "nll_loss": "2.024", "ppl": "4.07", "wps": "2378.3", "ups": "4.59", "wpb": "517.8", "bsz": "16", "num_updates": "9600", "lr": "4.95448e-05", "gnorm": "3.034", "loss_scale": "64", "train_wall": "22", "wall": "3712"}
2021-10-23 18:40:24 | INFO | train_inner | {"epoch": 8, "update": 7.92, "loss": "3.811", "nll_loss": "2.095", "ppl": "4.27", "wps": "2192.9", "ups": "4.67", "wpb": "469.8", "bsz": "16", "num_updates": "9700", "lr": "4.95398e-05", "gnorm": "3.199", "loss_scale": "64", "train_wall": "21", "wall": "3733"}
2021-10-23 18:40:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-23 18:43:46 | INFO | valid | {"epoch": 8, "valid_loss": "3.912", "valid_nll_loss": "2.124", "valid_ppl": "4.36", "valid_bleu": "15.37", "valid_wps": "382.9", "valid_wpb": "226.2", "valid_bsz": "8", "valid_num_updates": "9798", "valid_best_bleu": "15.37"}
2021-10-23 18:43:46 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-23 18:43:56 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/scratch/unique/large/checkpoint_best.pt (epoch 8 @ 9798 updates, score 15.37) (writing took 9.996540470980108 seconds)
2021-10-23 18:43:56 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2021-10-23 18:43:56 | INFO | train | {"epoch": 8, "train_loss": "3.672", "train_nll_loss": "1.937", "train_ppl": "3.83", "train_wps": "1296.5", "train_ups": "2.75", "train_wpb": "472", "train_bsz": "16", "train_num_updates": "9798", "train_lr": "4.95349e-05", "train_gnorm": "3.081", "train_loss_scale": "111", "train_train_wall": "251", "train_wall": "3946"}
2021-10-23 18:43:56 | INFO | fairseq_cli.train | begin training epoch 8
2021-10-23 18:43:57 | INFO | train_inner | {"epoch": 9, "update": 8.002, "loss": "3.654", "nll_loss": "1.918", "ppl": "3.78", "wps": "225.3", "ups": "0.47", "wpb": "479.8", "bsz": "15.9", "num_updates": "9800", "lr": "4.95348e-05", "gnorm": "3.089", "loss_scale": "64", "train_wall": "21", "wall": "3946"}
2021-10-23 18:44:17 | INFO | train_inner | {"epoch": 9, "update": 8.083, "loss": "3.483", "nll_loss": "1.725", "ppl": "3.31", "wps": "2258", "ups": "4.87", "wpb": "463.8", "bsz": "16", "num_updates": "9900", "lr": "4.95298e-05", "gnorm": "2.829", "loss_scale": "64", "train_wall": "20", "wall": "3967"}
2021-10-23 18:44:38 | INFO | train_inner | {"epoch": 9, "update": 8.165, "loss": "3.495", "nll_loss": "1.738", "ppl": "3.34", "wps": "2275.5", "ups": "4.82", "wpb": "471.7", "bsz": "16", "num_updates": "10000", "lr": "4.95248e-05", "gnorm": "2.972", "loss_scale": "64", "train_wall": "20", "wall": "3987"}
2021-10-23 18:44:57 | INFO | train_inner | {"epoch": 9, "update": 8.247, "loss": "3.269", "nll_loss": "1.486", "ppl": "2.8", "wps": "2015.5", "ups": "5.17", "wpb": "390.2", "bsz": "16", "num_updates": "10100", "lr": "4.95198e-05", "gnorm": "3.033", "loss_scale": "64", "train_wall": "19", "wall": "4007"}
2021-10-23 18:45:19 | INFO | train_inner | {"epoch": 9, "update": 8.328, "loss": "3.522", "nll_loss": "1.769", "ppl": "3.41", "wps": "2383.9", "ups": "4.65", "wpb": "512.2", "bsz": "16", "num_updates": "10200", "lr": "4.95148e-05", "gnorm": "2.955", "loss_scale": "64", "train_wall": "21", "wall": "4028"}
2021-10-23 18:45:39 | INFO | train_inner | {"epoch": 9, "update": 8.41, "loss": "3.448", "nll_loss": "1.684", "ppl": "3.21", "wps": "2134.9", "ups": "5.03", "wpb": "424.3", "bsz": "16", "num_updates": "10300", "lr": "4.95098e-05", "gnorm": "3.055", "loss_scale": "64", "train_wall": "20", "wall": "4048"}
2021-10-23 18:45:58 | INFO | train_inner | {"epoch": 9, "update": 8.491, "loss": "3.263", "nll_loss": "1.477", "ppl": "2.78", "wps": "2102.4", "ups": "5.09", "wpb": "413.2", "bsz": "16", "num_updates": "10400", "lr": "4.95048e-05", "gnorm": "3.005", "loss_scale": "64", "train_wall": "19", "wall": "4068"}
2021-10-23 18:46:19 | INFO | train_inner | {"epoch": 9, "update": 8.573, "loss": "3.627", "nll_loss": "1.887", "ppl": "3.7", "wps": "2248", "ups": "4.79", "wpb": "469.4", "bsz": "16", "num_updates": "10500", "lr": "4.94997e-05", "gnorm": "3.03", "loss_scale": "64", "train_wall": "21", "wall": "4089"}
2021-10-23 18:46:40 | INFO | train_inner | {"epoch": 9, "update": 8.655, "loss": "3.626", "nll_loss": "1.886", "ppl": "3.7", "wps": "2483.7", "ups": "4.8", "wpb": "517.7", "bsz": "16", "num_updates": "10600", "lr": "4.94947e-05", "gnorm": "3", "loss_scale": "64", "train_wall": "21", "wall": "4110"}
2021-10-23 18:47:01 | INFO | train_inner | {"epoch": 9, "update": 8.736, "loss": "3.589", "nll_loss": "1.842", "ppl": "3.59", "wps": "2510.5", "ups": "4.68", "wpb": "537", "bsz": "16", "num_updates": "10700", "lr": "4.94897e-05", "gnorm": "3.011", "loss_scale": "64", "train_wall": "21", "wall": "4131"}
2021-10-23 18:47:24 | INFO | train_inner | {"epoch": 9, "update": 8.818, "loss": "3.702", "nll_loss": "1.971", "ppl": "3.92", "wps": "2246.7", "ups": "4.42", "wpb": "507.9", "bsz": "16", "num_updates": "10800", "lr": "4.94847e-05", "gnorm": "3.09", "loss_scale": "64", "train_wall": "22", "wall": "4154"}
2021-10-23 18:47:45 | INFO | train_inner | {"epoch": 9, "update": 8.9, "loss": "3.63", "nll_loss": "1.886", "ppl": "3.7", "wps": "2246.3", "ups": "4.74", "wpb": "473.8", "bsz": "16", "num_updates": "10900", "lr": "4.94797e-05", "gnorm": "3.107", "loss_scale": "64", "train_wall": "21", "wall": "4175"}
2021-10-23 18:48:06 | INFO | train_inner | {"epoch": 9, "update": 8.981, "loss": "3.593", "nll_loss": "1.848", "ppl": "3.6", "wps": "2394", "ups": "4.74", "wpb": "505.4", "bsz": "16", "num_updates": "11000", "lr": "4.94747e-05", "gnorm": "3.065", "loss_scale": "64", "train_wall": "21", "wall": "4196"}
2021-10-23 18:48:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-23 18:51:16 | INFO | valid | {"epoch": 9, "valid_loss": "3.852", "valid_nll_loss": "2.064", "valid_ppl": "4.18", "valid_bleu": "16.35", "valid_wps": "375.9", "valid_wpb": "226.2", "valid_bsz": "8", "valid_num_updates": "11023", "valid_best_bleu": "16.35"}
2021-10-23 18:51:16 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-23 18:51:34 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/scratch/unique/large/checkpoint_best.pt (epoch 9 @ 11023 updates, score 16.35) (writing took 17.88666524598375 seconds)
2021-10-23 18:51:34 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2021-10-23 18:51:34 | INFO | train | {"epoch": 9, "train_loss": "3.532", "train_nll_loss": "1.779", "train_ppl": "3.43", "train_wps": "1266.4", "train_ups": "2.68", "train_wpb": "473.3", "train_bsz": "16", "train_num_updates": "11023", "train_lr": "4.94736e-05", "train_gnorm": "3.015", "train_loss_scale": "64", "train_train_wall": "252", "train_wall": "4403"}
2021-10-23 18:51:34 | INFO | fairseq_cli.train | begin training epoch 9
2021-10-23 18:51:49 | INFO | train_inner | {"epoch": 10, "update": 9.063, "loss": "3.585", "nll_loss": "1.84", "ppl": "3.58", "wps": "227.1", "ups": "0.45", "wpb": "505.5", "bsz": "15.9", "num_updates": "11100", "lr": "4.94697e-05", "gnorm": "2.92", "loss_scale": "64", "train_wall": "19", "wall": "4418"}
2021-10-23 18:52:09 | INFO | train_inner | {"epoch": 10, "update": 9.144, "loss": "3.215", "nll_loss": "1.424", "ppl": "2.68", "wps": "2082.2", "ups": "4.96", "wpb": "420", "bsz": "16", "num_updates": "11200", "lr": "4.94647e-05", "gnorm": "2.932", "loss_scale": "64", "train_wall": "20", "wall": "4439"}
2021-10-23 18:52:29 | INFO | train_inner | {"epoch": 10, "update": 9.226, "loss": "3.391", "nll_loss": "1.622", "ppl": "3.08", "wps": "2222.2", "ups": "4.93", "wpb": "450.8", "bsz": "16", "num_updates": "11300", "lr": "4.94597e-05", "gnorm": "2.982", "loss_scale": "64", "train_wall": "20", "wall": "4459"}
2021-10-23 18:52:50 | INFO | train_inner | {"epoch": 10, "update": 9.308, "loss": "3.464", "nll_loss": "1.703", "ppl": "3.26", "wps": "2619.8", "ups": "4.94", "wpb": "530.2", "bsz": "16", "num_updates": "11400", "lr": "4.94547e-05", "gnorm": "2.846", "loss_scale": "64", "train_wall": "20", "wall": "4479"}
2021-10-23 18:53:10 | INFO | train_inner | {"epoch": 10, "update": 9.389, "loss": "3.298", "nll_loss": "1.516", "ppl": "2.86", "wps": "2126.8", "ups": "4.93", "wpb": "431.1", "bsz": "16", "num_updates": "11500", "lr": "4.94497e-05", "gnorm": "3.02", "loss_scale": "64", "train_wall": "20", "wall": "4499"}
2021-10-23 18:53:30 | INFO | train_inner | {"epoch": 10, "update": 9.471, "loss": "3.399", "nll_loss": "1.629", "ppl": "3.09", "wps": "2478.4", "ups": "4.89", "wpb": "507.2", "bsz": "16", "num_updates": "11600", "lr": "4.94447e-05", "gnorm": "2.902", "loss_scale": "64", "train_wall": "20", "wall": "4520"}
2021-10-23 18:53:52 | INFO | train_inner | {"epoch": 10, "update": 9.553, "loss": "3.542", "nll_loss": "1.789", "ppl": "3.45", "wps": "2523.3", "ups": "4.66", "wpb": "542", "bsz": "16", "num_updates": "11700", "lr": "4.94397e-05", "gnorm": "2.934", "loss_scale": "64", "train_wall": "21", "wall": "4541"}
2021-10-23 18:54:14 | INFO | train_inner | {"epoch": 10, "update": 9.634, "loss": "3.327", "nll_loss": "1.548", "ppl": "2.92", "wps": "1971.9", "ups": "4.56", "wpb": "432.1", "bsz": "16", "num_updates": "11800", "lr": "4.94347e-05", "gnorm": "3.105", "loss_scale": "64", "train_wall": "22", "wall": "4563"}
2021-10-23 18:54:34 | INFO | train_inner | {"epoch": 10, "update": 9.716, "loss": "3.215", "nll_loss": "1.421", "ppl": "2.68", "wps": "1933.8", "ups": "4.98", "wpb": "387.9", "bsz": "16", "num_updates": "11900", "lr": "4.94297e-05", "gnorm": "3.092", "loss_scale": "64", "train_wall": "20", "wall": "4583"}
2021-10-23 18:54:55 | INFO | train_inner | {"epoch": 10, "update": 9.798, "loss": "3.239", "nll_loss": "1.448", "ppl": "2.73", "wps": "1991.1", "ups": "4.65", "wpb": "427.9", "bsz": "16", "num_updates": "12000", "lr": "4.94247e-05", "gnorm": "3.064", "loss_scale": "64", "train_wall": "21", "wall": "4605"}
2021-10-23 18:55:17 | INFO | train_inner | {"epoch": 10, "update": 9.879, "loss": "3.204", "nll_loss": "1.41", "ppl": "2.66", "wps": "2075.8", "ups": "4.66", "wpb": "445.8", "bsz": "16", "num_updates": "12100", "lr": "4.94197e-05", "gnorm": "2.906", "loss_scale": "64", "train_wall": "21", "wall": "4626"}
2021-10-23 18:55:38 | INFO | train_inner | {"epoch": 10, "update": 9.961, "loss": "3.73", "nll_loss": "2.002", "ppl": "4.01", "wps": "2782.6", "ups": "4.71", "wpb": "591.1", "bsz": "16", "num_updates": "12200", "lr": "4.94147e-05", "gnorm": "2.961", "loss_scale": "64", "train_wall": "21", "wall": "4647"}
2021-10-23 18:55:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-23 18:58:51 | INFO | valid | {"epoch": 10, "valid_loss": "3.805", "valid_nll_loss": "2.01", "valid_ppl": "4.03", "valid_bleu": "17.35", "valid_wps": "377.7", "valid_wpb": "226.2", "valid_bsz": "8", "valid_num_updates": "12248", "valid_best_bleu": "17.35"}
2021-10-23 18:58:51 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-23 18:59:14 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/scratch/unique/large/checkpoint_best.pt (epoch 10 @ 12248 updates, score 17.35) (writing took 22.539263157057576 seconds)
2021-10-23 18:59:14 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2021-10-23 18:59:14 | INFO | train | {"epoch": 10, "train_loss": "3.397", "train_nll_loss": "1.628", "train_ppl": "3.09", "train_wps": "1260.7", "train_ups": "2.66", "train_wpb": "473.3", "train_bsz": "16", "train_num_updates": "12248", "train_lr": "4.94123e-05", "train_gnorm": "2.97", "train_loss_scale": "64", "train_train_wall": "250", "train_wall": "4863"}
2021-10-23 18:59:14 | INFO | fairseq_cli.train | begin training epoch 10
2021-10-23 18:59:25 | INFO | train_inner | {"epoch": 11, "update": 10.042, "loss": "3.175", "nll_loss": "1.379", "ppl": "2.6", "wps": "190.5", "ups": "0.44", "wpb": "432", "bsz": "15.9", "num_updates": "12300", "lr": "4.94097e-05", "gnorm": "2.912", "loss_scale": "64", "train_wall": "20", "wall": "4874"}
2021-10-23 18:59:43 | INFO | train_inner | {"epoch": 11, "update": 10.124, "loss": "3.124", "nll_loss": "1.32", "ppl": "2.5", "wps": "2551.1", "ups": "5.5", "wpb": "463.5", "bsz": "16", "num_updates": "12400", "lr": "4.94047e-05", "gnorm": "2.764", "loss_scale": "64", "train_wall": "18", "wall": "4892"}
2021-10-23 19:00:03 | INFO | train_inner | {"epoch": 11, "update": 10.206, "loss": "3.386", "nll_loss": "1.613", "ppl": "3.06", "wps": "2539", "ups": "5.08", "wpb": "500.1", "bsz": "16", "num_updates": "12500", "lr": "4.93997e-05", "gnorm": "2.87", "loss_scale": "64", "train_wall": "19", "wall": "4912"}
2021-10-23 19:00:23 | INFO | train_inner | {"epoch": 11, "update": 10.287, "loss": "3.247", "nll_loss": "1.46", "ppl": "2.75", "wps": "2447.6", "ups": "4.92", "wpb": "497.3", "bsz": "16", "num_updates": "12600", "lr": "4.93947e-05", "gnorm": "2.817", "loss_scale": "64", "train_wall": "20", "wall": "4932"}
2021-10-23 19:00:43 | INFO | train_inner | {"epoch": 11, "update": 10.369, "loss": "3.346", "nll_loss": "1.57", "ppl": "2.97", "wps": "2391.6", "ups": "4.94", "wpb": "484.2", "bsz": "16", "num_updates": "12700", "lr": "4.93897e-05", "gnorm": "2.895", "loss_scale": "64", "train_wall": "20", "wall": "4953"}
2021-10-23 19:01:03 | INFO | train_inner | {"epoch": 11, "update": 10.451, "loss": "3.195", "nll_loss": "1.399", "ppl": "2.64", "wps": "2218.9", "ups": "5.11", "wpb": "434", "bsz": "16", "num_updates": "12800", "lr": "4.93847e-05", "gnorm": "2.898", "loss_scale": "64", "train_wall": "19", "wall": "4972"}
2021-10-23 19:01:23 | INFO | train_inner | {"epoch": 11, "update": 10.532, "loss": "3.266", "nll_loss": "1.48", "ppl": "2.79", "wps": "2338.4", "ups": "5.03", "wpb": "464.7", "bsz": "16", "num_updates": "12900", "lr": "4.93797e-05", "gnorm": "2.956", "loss_scale": "64", "train_wall": "20", "wall": "4992"}
2021-10-23 19:01:42 | INFO | train_inner | {"epoch": 11, "update": 10.614, "loss": "3.165", "nll_loss": "1.366", "ppl": "2.58", "wps": "2139.2", "ups": "5.04", "wpb": "424.2", "bsz": "16", "num_updates": "13000", "lr": "4.93747e-05", "gnorm": "2.959", "loss_scale": "64", "train_wall": "20", "wall": "5012"}
2021-10-23 19:02:04 | INFO | train_inner | {"epoch": 11, "update": 10.696, "loss": "3.241", "nll_loss": "1.449", "ppl": "2.73", "wps": "2161.7", "ups": "4.65", "wpb": "465.1", "bsz": "16", "num_updates": "13100", "lr": "4.93697e-05", "gnorm": "2.953", "loss_scale": "64", "train_wall": "21", "wall": "5033"}
2021-10-23 19:02:25 | INFO | train_inner | {"epoch": 11, "update": 10.777, "loss": "3.447", "nll_loss": "1.683", "ppl": "3.21", "wps": "2707.6", "ups": "4.7", "wpb": "576", "bsz": "16", "num_updates": "13200", "lr": "4.93647e-05", "gnorm": "2.868", "loss_scale": "64", "train_wall": "21", "wall": "5055"}
2021-10-23 19:02:46 | INFO | train_inner | {"epoch": 11, "update": 10.859, "loss": "3.384", "nll_loss": "1.611", "ppl": "3.06", "wps": "2222.4", "ups": "4.91", "wpb": "452.6", "bsz": "16", "num_updates": "13300", "lr": "4.93597e-05", "gnorm": "3.006", "loss_scale": "64", "train_wall": "20", "wall": "5075"}
2021-10-23 19:03:07 | INFO | train_inner | {"epoch": 11, "update": 10.94, "loss": "3.353", "nll_loss": "1.576", "ppl": "2.98", "wps": "2382.2", "ups": "4.79", "wpb": "497", "bsz": "16", "num_updates": "13400", "lr": "4.93547e-05", "gnorm": "3.009", "loss_scale": "64", "train_wall": "21", "wall": "5096"}
2021-10-23 19:03:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-23 19:06:25 | INFO | valid | {"epoch": 11, "valid_loss": "3.747", "valid_nll_loss": "1.948", "valid_ppl": "3.86", "valid_bleu": "18.48", "valid_wps": "378.2", "valid_wpb": "226.2", "valid_bsz": "8", "valid_num_updates": "13473", "valid_best_bleu": "18.48"}
2021-10-23 19:06:25 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-23 19:06:49 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/scratch/unique/large/checkpoint_best.pt (epoch 11 @ 13473 updates, score 18.48) (writing took 24.136025086045265 seconds)
2021-10-23 19:06:49 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2021-10-23 19:06:49 | INFO | train | {"epoch": 11, "train_loss": "3.277", "train_nll_loss": "1.492", "train_ppl": "2.81", "train_wps": "1273.8", "train_ups": "2.69", "train_wpb": "473.3", "train_bsz": "16", "train_num_updates": "13473", "train_lr": "4.9351e-05", "train_gnorm": "2.909", "train_loss_scale": "64", "train_train_wall": "244", "train_wall": "5318"}
2021-10-23 19:06:49 | INFO | fairseq_cli.train | begin training epoch 11
2021-10-23 19:06:55 | INFO | train_inner | {"epoch": 12, "update": 11.022, "loss": "3.208", "nll_loss": "1.416", "ppl": "2.67", "wps": "202.8", "ups": "0.44", "wpb": "462.6", "bsz": "15.9", "num_updates": "13500", "lr": "4.93497e-05", "gnorm": "2.895", "loss_scale": "64", "train_wall": "20", "wall": "5324"}
2021-10-23 19:07:16 | INFO | train_inner | {"epoch": 12, "update": 11.104, "loss": "3.053", "nll_loss": "1.24", "ppl": "2.36", "wps": "2105.5", "ups": "4.69", "wpb": "448.6", "bsz": "16", "num_updates": "13600", "lr": "4.93447e-05", "gnorm": "2.724", "loss_scale": "64", "train_wall": "21", "wall": "5345"}
2021-10-23 19:07:36 | INFO | train_inner | {"epoch": 12, "update": 11.185, "loss": "3.239", "nll_loss": "1.45", "ppl": "2.73", "wps": "2458.9", "ups": "5.04", "wpb": "487.9", "bsz": "16", "num_updates": "13700", "lr": "4.93397e-05", "gnorm": "2.758", "loss_scale": "64", "train_wall": "20", "wall": "5365"}
2021-10-23 19:07:55 | INFO | train_inner | {"epoch": 12, "update": 11.267, "loss": "3.294", "nll_loss": "1.51", "ppl": "2.85", "wps": "2468.6", "ups": "5.09", "wpb": "484.7", "bsz": "16", "num_updates": "13800", "lr": "4.93347e-05", "gnorm": "2.875", "loss_scale": "64", "train_wall": "19", "wall": "5385"}
2021-10-23 19:08:17 | INFO | train_inner | {"epoch": 12, "update": 11.349, "loss": "3.064", "nll_loss": "1.253", "ppl": "2.38", "wps": "2014.1", "ups": "4.67", "wpb": "431.7", "bsz": "16", "num_updates": "13900", "lr": "4.93297e-05", "gnorm": "2.885", "loss_scale": "64", "train_wall": "21", "wall": "5406"}
2021-10-23 19:08:37 | INFO | train_inner | {"epoch": 12, "update": 11.43, "loss": "3.055", "nll_loss": "1.242", "ppl": "2.37", "wps": "2155", "ups": "4.87", "wpb": "442.7", "bsz": "16", "num_updates": "14000", "lr": "4.93247e-05", "gnorm": "2.81", "loss_scale": "64", "train_wall": "20", "wall": "5427"}
2021-10-23 19:08:57 | INFO | train_inner | {"epoch": 12, "update": 11.512, "loss": "3.152", "nll_loss": "1.353", "ppl": "2.55", "wps": "2324.2", "ups": "5.13", "wpb": "453.1", "bsz": "16", "num_updates": "14100", "lr": "4.93197e-05", "gnorm": "2.855", "loss_scale": "64", "train_wall": "19", "wall": "5446"}
2021-10-23 19:09:17 | INFO | train_inner | {"epoch": 12, "update": 11.593, "loss": "3.067", "nll_loss": "1.255", "ppl": "2.39", "wps": "2290.6", "ups": "4.88", "wpb": "468.9", "bsz": "16", "num_updates": "14200", "lr": "4.93147e-05", "gnorm": "2.803", "loss_scale": "64", "train_wall": "20", "wall": "5467"}
2021-10-23 19:09:38 | INFO | train_inner | {"epoch": 12, "update": 11.675, "loss": "3.361", "nll_loss": "1.585", "ppl": "3", "wps": "2778.8", "ups": "4.79", "wpb": "580", "bsz": "16", "num_updates": "14300", "lr": "4.93097e-05", "gnorm": "2.897", "loss_scale": "64", "train_wall": "21", "wall": "5488"}
2021-10-23 19:09:57 | INFO | train_inner | {"epoch": 12, "update": 11.757, "loss": "3.057", "nll_loss": "1.242", "ppl": "2.37", "wps": "2345.4", "ups": "5.22", "wpb": "449", "bsz": "16", "num_updates": "14400", "lr": "4.93047e-05", "gnorm": "2.916", "loss_scale": "64", "train_wall": "19", "wall": "5507"}
2021-10-23 19:10:17 | INFO | train_inner | {"epoch": 12, "update": 11.838, "loss": "3.233", "nll_loss": "1.442", "ppl": "2.72", "wps": "2443.2", "ups": "5.13", "wpb": "476.3", "bsz": "16", "num_updates": "14500", "lr": "4.92996e-05", "gnorm": "2.891", "loss_scale": "64", "train_wall": "19", "wall": "5526"}
2021-10-23 19:10:39 | INFO | train_inner | {"epoch": 12, "update": 11.92, "loss": "3.324", "nll_loss": "1.545", "ppl": "2.92", "wps": "2276", "ups": "4.57", "wpb": "498.2", "bsz": "16", "num_updates": "14600", "lr": "4.92946e-05", "gnorm": "2.859", "loss_scale": "64", "train_wall": "22", "wall": "5548"}
2021-10-23 19:10:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-23 19:14:07 | INFO | valid | {"epoch": 12, "valid_loss": "3.724", "valid_nll_loss": "1.918", "valid_ppl": "3.78", "valid_bleu": "19.95", "valid_wps": "366.7", "valid_wpb": "226.2", "valid_bsz": "8", "valid_num_updates": "14698", "valid_best_bleu": "19.95"}
2021-10-23 19:14:07 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-23 19:14:16 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/scratch/unique/large/checkpoint_best.pt (epoch 12 @ 14698 updates, score 19.95) (writing took 9.903822121908888 seconds)
2021-10-23 19:14:16 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2021-10-23 19:14:16 | INFO | train | {"epoch": 12, "train_loss": "3.166", "train_nll_loss": "1.366", "train_ppl": "2.58", "train_wps": "1295.8", "train_ups": "2.74", "train_wpb": "473.3", "train_bsz": "16", "train_num_updates": "14698", "train_lr": "4.92897e-05", "train_gnorm": "2.838", "train_loss_scale": "64", "train_train_wall": "245", "train_wall": "5766"}
2021-10-23 19:14:16 | INFO | fairseq_cli.train | begin training epoch 12
2021-10-23 19:14:17 | INFO | train_inner | {"epoch": 13, "update": 12.002, "loss": "2.991", "nll_loss": "1.169", "ppl": "2.25", "wps": "208.2", "ups": "0.46", "wpb": "454.3", "bsz": "15.9", "num_updates": "14700", "lr": "4.92896e-05", "gnorm": "2.826", "loss_scale": "64", "train_wall": "18", "wall": "5766"}
2021-10-23 19:14:35 | INFO | train_inner | {"epoch": 13, "update": 12.083, "loss": "2.916", "nll_loss": "1.088", "ppl": "2.13", "wps": "2391.5", "ups": "5.52", "wpb": "433.6", "bsz": "16", "num_updates": "14800", "lr": "4.92846e-05", "gnorm": "2.631", "loss_scale": "64", "train_wall": "18", "wall": "5785"}
2021-10-23 19:14:54 | INFO | train_inner | {"epoch": 13, "update": 12.165, "loss": "2.851", "nll_loss": "1.014", "ppl": "2.02", "wps": "2241.2", "ups": "5.25", "wpb": "427", "bsz": "16", "num_updates": "14900", "lr": "4.92796e-05", "gnorm": "2.628", "loss_scale": "64", "train_wall": "19", "wall": "5804"}
2021-10-23 19:15:12 | INFO | train_inner | {"epoch": 13, "update": 12.247, "loss": "3.018", "nll_loss": "1.202", "ppl": "2.3", "wps": "2480", "ups": "5.6", "wpb": "442.8", "bsz": "16", "num_updates": "15000", "lr": "4.92746e-05", "gnorm": "2.744", "loss_scale": "64", "train_wall": "18", "wall": "5821"}
2021-10-23 19:15:32 | INFO | train_inner | {"epoch": 13, "update": 12.328, "loss": "3.156", "nll_loss": "1.355", "ppl": "2.56", "wps": "2501.5", "ups": "4.93", "wpb": "507.5", "bsz": "16", "num_updates": "15100", "lr": "4.92696e-05", "gnorm": "2.744", "loss_scale": "64", "train_wall": "20", "wall": "5842"}
2021-10-23 19:15:53 | INFO | train_inner | {"epoch": 13, "update": 12.41, "loss": "3.095", "nll_loss": "1.284", "ppl": "2.44", "wps": "2228.8", "ups": "4.78", "wpb": "466", "bsz": "16", "num_updates": "15200", "lr": "4.92646e-05", "gnorm": "2.762", "loss_scale": "64", "train_wall": "21", "wall": "5863"}
2021-10-23 19:16:12 | INFO | train_inner | {"epoch": 13, "update": 12.491, "loss": "2.935", "nll_loss": "1.107", "ppl": "2.15", "wps": "2352.9", "ups": "5.38", "wpb": "437.7", "bsz": "16", "num_updates": "15300", "lr": "4.92596e-05", "gnorm": "2.767", "loss_scale": "64", "train_wall": "18", "wall": "5881"}
2021-10-23 19:16:32 | INFO | train_inner | {"epoch": 13, "update": 12.573, "loss": "2.969", "nll_loss": "1.143", "ppl": "2.21", "wps": "2129.8", "ups": "4.92", "wpb": "432.5", "bsz": "16", "num_updates": "15400", "lr": "4.92546e-05", "gnorm": "2.859", "loss_scale": "64", "train_wall": "20", "wall": "5902"}
2021-10-23 19:16:53 | INFO | train_inner | {"epoch": 13, "update": 12.655, "loss": "3.015", "nll_loss": "1.198", "ppl": "2.29", "wps": "2251.4", "ups": "4.74", "wpb": "474.8", "bsz": "16", "num_updates": "15500", "lr": "4.92496e-05", "gnorm": "2.784", "loss_scale": "64", "train_wall": "21", "wall": "5923"}
2021-10-23 19:17:13 | INFO | train_inner | {"epoch": 13, "update": 12.736, "loss": "3.153", "nll_loss": "1.35", "ppl": "2.55", "wps": "2334.8", "ups": "4.99", "wpb": "468.2", "bsz": "16", "num_updates": "15600", "lr": "4.92446e-05", "gnorm": "2.878", "loss_scale": "64", "train_wall": "20", "wall": "5943"}
2021-10-23 19:17:35 | INFO | train_inner | {"epoch": 13, "update": 12.818, "loss": "3.071", "nll_loss": "1.259", "ppl": "2.39", "wps": "2190.2", "ups": "4.71", "wpb": "465.2", "bsz": "16", "num_updates": "15700", "lr": "4.92396e-05", "gnorm": "2.818", "loss_scale": "64", "train_wall": "21", "wall": "5964"}
2021-10-23 19:17:56 | INFO | train_inner | {"epoch": 13, "update": 12.9, "loss": "3.397", "nll_loss": "1.626", "ppl": "3.09", "wps": "3086.6", "ups": "4.71", "wpb": "655.2", "bsz": "16", "num_updates": "15800", "lr": "4.92346e-05", "gnorm": "2.764", "loss_scale": "64", "train_wall": "21", "wall": "5985"}
2021-10-23 19:18:16 | INFO | train_inner | {"epoch": 13, "update": 12.981, "loss": "3.026", "nll_loss": "1.208", "ppl": "2.31", "wps": "2290.5", "ups": "4.99", "wpb": "459.3", "bsz": "16", "num_updates": "15900", "lr": "4.92296e-05", "gnorm": "2.869", "loss_scale": "64", "train_wall": "20", "wall": "6005"}
2021-10-23 19:18:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-23 19:21:25 | INFO | valid | {"epoch": 13, "valid_loss": "3.689", "valid_nll_loss": "1.875", "valid_ppl": "3.67", "valid_bleu": "22.11", "valid_wps": "376.3", "valid_wpb": "226.2", "valid_bsz": "8", "valid_num_updates": "15923", "valid_best_bleu": "22.11"}
2021-10-23 19:21:25 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-23 19:21:49 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/scratch/unique/large/checkpoint_best.pt (epoch 13 @ 15923 updates, score 22.11) (writing took 23.719517641002312 seconds)
2021-10-23 19:21:49 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2021-10-23 19:21:49 | INFO | train | {"epoch": 13, "train_loss": "3.07", "train_nll_loss": "1.258", "train_ppl": "2.39", "train_wps": "1282.2", "train_ups": "2.71", "train_wpb": "473.3", "train_bsz": "16", "train_num_updates": "15923", "train_lr": "4.92285e-05", "train_gnorm": "2.772", "train_loss_scale": "64", "train_train_wall": "241", "train_wall": "6218"}
2021-10-23 19:21:49 | INFO | fairseq_cli.train | begin training epoch 13
2021-10-23 19:22:05 | INFO | train_inner | {"epoch": 14, "update": 13.063, "loss": "3.116", "nll_loss": "1.31", "ppl": "2.48", "wps": "234.5", "ups": "0.44", "wpb": "536.4", "bsz": "15.9", "num_updates": "16000", "lr": "4.92246e-05", "gnorm": "2.626", "loss_scale": "64", "train_wall": "20", "wall": "6234"}
2021-10-23 19:22:23 | INFO | train_inner | {"epoch": 14, "update": 13.144, "loss": "2.851", "nll_loss": "1.012", "ppl": "2.02", "wps": "2336", "ups": "5.29", "wpb": "441.7", "bsz": "16", "num_updates": "16100", "lr": "4.92196e-05", "gnorm": "2.661", "loss_scale": "64", "train_wall": "19", "wall": "6253"}
2021-10-23 19:22:43 | INFO | train_inner | {"epoch": 14, "update": 13.226, "loss": "2.966", "nll_loss": "1.141", "ppl": "2.21", "wps": "2545.6", "ups": "5.25", "wpb": "485.1", "bsz": "16", "num_updates": "16200", "lr": "4.92146e-05", "gnorm": "2.657", "loss_scale": "64", "train_wall": "19", "wall": "6272"}
2021-10-23 19:23:03 | INFO | train_inner | {"epoch": 14, "update": 13.308, "loss": "2.933", "nll_loss": "1.106", "ppl": "2.15", "wps": "2113.6", "ups": "5", "wpb": "422.7", "bsz": "16", "num_updates": "16300", "lr": "4.92096e-05", "gnorm": "2.687", "loss_scale": "64", "train_wall": "20", "wall": "6292"}
2021-10-23 19:23:22 | INFO | train_inner | {"epoch": 14, "update": 13.389, "loss": "3.105", "nll_loss": "1.298", "ppl": "2.46", "wps": "2537", "ups": "5.12", "wpb": "495.1", "bsz": "16", "num_updates": "16400", "lr": "4.92046e-05", "gnorm": "2.71", "loss_scale": "64", "train_wall": "19", "wall": "6312"}
2021-10-23 19:23:44 | INFO | train_inner | {"epoch": 14, "update": 13.471, "loss": "2.984", "nll_loss": "1.161", "ppl": "2.24", "wps": "2143.4", "ups": "4.58", "wpb": "468.4", "bsz": "16", "num_updates": "16500", "lr": "4.91996e-05", "gnorm": "2.679", "loss_scale": "64", "train_wall": "22", "wall": "6333"}
2021-10-23 19:24:06 | INFO | train_inner | {"epoch": 14, "update": 13.553, "loss": "2.947", "nll_loss": "1.119", "ppl": "2.17", "wps": "2205.1", "ups": "4.62", "wpb": "477.4", "bsz": "16", "num_updates": "16600", "lr": "4.91946e-05", "gnorm": "2.744", "loss_scale": "64", "train_wall": "21", "wall": "6355"}
2021-10-23 19:24:27 | INFO | train_inner | {"epoch": 14, "update": 13.634, "loss": "2.991", "nll_loss": "1.167", "ppl": "2.25", "wps": "2200.4", "ups": "4.57", "wpb": "481.2", "bsz": "16", "num_updates": "16700", "lr": "4.91896e-05", "gnorm": "2.7", "loss_scale": "64", "train_wall": "22", "wall": "6377"}
2021-10-23 19:24:47 | INFO | train_inner | {"epoch": 14, "update": 13.716, "loss": "3.023", "nll_loss": "1.205", "ppl": "2.31", "wps": "2476.4", "ups": "5.22", "wpb": "474.9", "bsz": "16", "num_updates": "16800", "lr": "4.91846e-05", "gnorm": "2.768", "loss_scale": "64", "train_wall": "19", "wall": "6396"}
2021-10-23 19:25:06 | INFO | train_inner | {"epoch": 14, "update": 13.798, "loss": "2.913", "nll_loss": "1.081", "ppl": "2.11", "wps": "2302.1", "ups": "5.21", "wpb": "442.1", "bsz": "16", "num_updates": "16900", "lr": "4.91796e-05", "gnorm": "2.743", "loss_scale": "64", "train_wall": "19", "wall": "6415"}
2021-10-23 19:25:26 | INFO | train_inner | {"epoch": 14, "update": 13.879, "loss": "3.03", "nll_loss": "1.21", "ppl": "2.31", "wps": "2323.1", "ups": "4.84", "wpb": "479.9", "bsz": "16", "num_updates": "17000", "lr": "4.91746e-05", "gnorm": "2.795", "loss_scale": "64", "train_wall": "20", "wall": "6436"}
2021-10-23 19:25:48 | INFO | train_inner | {"epoch": 14, "update": 13.961, "loss": "3.078", "nll_loss": "1.267", "ppl": "2.41", "wps": "2353.4", "ups": "4.56", "wpb": "515.6", "bsz": "16", "num_updates": "17100", "lr": "4.91696e-05", "gnorm": "2.773", "loss_scale": "64", "train_wall": "22", "wall": "6458"}
2021-10-23 19:25:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-23 19:28:57 | INFO | valid | {"epoch": 14, "valid_loss": "3.679", "valid_nll_loss": "1.857", "valid_ppl": "3.62", "valid_bleu": "23.87", "valid_wps": "385.9", "valid_wpb": "226.2", "valid_bsz": "8", "valid_num_updates": "17148", "valid_best_bleu": "23.87"}
2021-10-23 19:28:57 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-23 19:29:07 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/scratch/unique/large/checkpoint_best.pt (epoch 14 @ 17148 updates, score 23.87) (writing took 9.923867295030504 seconds)
2021-10-23 19:29:07 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2021-10-23 19:29:07 | INFO | train | {"epoch": 14, "train_loss": "2.984", "train_nll_loss": "1.161", "train_ppl": "2.24", "train_wps": "1323.6", "train_ups": "2.8", "train_wpb": "473.3", "train_bsz": "16", "train_num_updates": "17148", "train_lr": "4.91672e-05", "train_gnorm": "2.709", "train_loss_scale": "64", "train_train_wall": "245", "train_wall": "6656"}
2021-10-23 19:29:07 | INFO | fairseq_cli.train | begin training epoch 14
2021-10-23 19:29:18 | INFO | train_inner | {"epoch": 15, "update": 14.042, "loss": "2.72", "nll_loss": "0.865", "ppl": "1.82", "wps": "200.6", "ups": "0.48", "wpb": "420.7", "bsz": "15.9", "num_updates": "17200", "lr": "4.91646e-05", "gnorm": "2.631", "loss_scale": "64", "train_wall": "19", "wall": "6668"}
2021-10-23 19:29:39 | INFO | train_inner | {"epoch": 15, "update": 14.124, "loss": "2.964", "nll_loss": "1.14", "ppl": "2.2", "wps": "2429.7", "ups": "4.72", "wpb": "514.2", "bsz": "16", "num_updates": "17300", "lr": "4.91596e-05", "gnorm": "2.526", "loss_scale": "64", "train_wall": "21", "wall": "6689"}
2021-10-23 19:30:00 | INFO | train_inner | {"epoch": 15, "update": 14.206, "loss": "2.677", "nll_loss": "0.815", "ppl": "1.76", "wps": "1988.4", "ups": "4.84", "wpb": "411.2", "bsz": "16", "num_updates": "17400", "lr": "4.91546e-05", "gnorm": "2.654", "loss_scale": "64", "train_wall": "20", "wall": "6709"}
2021-10-23 19:30:23 | INFO | train_inner | {"epoch": 15, "update": 14.287, "loss": "2.889", "nll_loss": "1.055", "ppl": "2.08", "wps": "2124", "ups": "4.4", "wpb": "483", "bsz": "16", "num_updates": "17500", "lr": "4.91496e-05", "gnorm": "2.585", "loss_scale": "64", "train_wall": "22", "wall": "6732"}
2021-10-23 19:30:42 | INFO | train_inner | {"epoch": 15, "update": 14.369, "loss": "2.685", "nll_loss": "0.826", "ppl": "1.77", "wps": "2269.4", "ups": "5.13", "wpb": "442.8", "bsz": "16", "num_updates": "17600", "lr": "4.91446e-05", "gnorm": "2.577", "loss_scale": "64", "train_wall": "19", "wall": "6752"}
2021-10-23 19:31:02 | INFO | train_inner | {"epoch": 15, "update": 14.451, "loss": "2.871", "nll_loss": "1.033", "ppl": "2.05", "wps": "2446.8", "ups": "5.01", "wpb": "488.1", "bsz": "16", "num_updates": "17700", "lr": "4.91396e-05", "gnorm": "2.65", "loss_scale": "88", "train_wall": "20", "wall": "6772"}
2021-10-23 19:31:22 | INFO | train_inner | {"epoch": 15, "update": 14.532, "loss": "2.808", "nll_loss": "0.964", "ppl": "1.95", "wps": "2036.2", "ups": "5.14", "wpb": "395.9", "bsz": "16", "num_updates": "17800", "lr": "4.91346e-05", "gnorm": "2.684", "loss_scale": "128", "train_wall": "19", "wall": "6791"}
2021-10-23 19:31:42 | INFO | train_inner | {"epoch": 15, "update": 14.614, "loss": "2.876", "nll_loss": "1.038", "ppl": "2.05", "wps": "2316.8", "ups": "5", "wpb": "463.8", "bsz": "16", "num_updates": "17900", "lr": "4.91296e-05", "gnorm": "2.632", "loss_scale": "128", "train_wall": "20", "wall": "6811"}
2021-10-23 19:32:02 | INFO | train_inner | {"epoch": 15, "update": 14.696, "loss": "3.192", "nll_loss": "1.395", "ppl": "2.63", "wps": "2723", "ups": "4.88", "wpb": "558", "bsz": "16", "num_updates": "18000", "lr": "4.91246e-05", "gnorm": "2.675", "loss_scale": "128", "train_wall": "20", "wall": "6832"}
2021-10-23 19:32:23 | INFO | train_inner | {"epoch": 15, "update": 14.777, "loss": "3.044", "nll_loss": "1.227", "ppl": "2.34", "wps": "2436.6", "ups": "4.85", "wpb": "502.6", "bsz": "16", "num_updates": "18100", "lr": "4.91196e-05", "gnorm": "2.604", "loss_scale": "128", "train_wall": "20", "wall": "6852"}
2021-10-23 19:32:45 | INFO | train_inner | {"epoch": 15, "update": 14.859, "loss": "2.972", "nll_loss": "1.147", "ppl": "2.21", "wps": "2136.8", "ups": "4.44", "wpb": "481.2", "bsz": "16", "num_updates": "18200", "lr": "4.91146e-05", "gnorm": "2.695", "loss_scale": "128", "train_wall": "22", "wall": "6875"}
2021-10-23 19:33:06 | INFO | train_inner | {"epoch": 15, "update": 14.94, "loss": "2.955", "nll_loss": "1.126", "ppl": "2.18", "wps": "2284.7", "ups": "4.72", "wpb": "483.8", "bsz": "16", "num_updates": "18300", "lr": "4.91096e-05", "gnorm": "2.689", "loss_scale": "128", "train_wall": "21", "wall": "6896"}
2021-10-23 19:33:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-23 19:36:35 | INFO | valid | {"epoch": 15, "valid_loss": "3.691", "valid_nll_loss": "1.87", "valid_ppl": "3.65", "valid_bleu": "22.92", "valid_wps": "361.1", "valid_wpb": "226.2", "valid_bsz": "8", "valid_num_updates": "18373", "valid_best_bleu": "23.87"}
2021-10-23 19:36:35 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-23 19:36:49 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/scratch/unique/large/checkpoint_last.pt (epoch 15 @ 18373 updates, score 22.92) (writing took 14.290290734032169 seconds)
2021-10-23 19:36:49 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2021-10-23 19:36:49 | INFO | train | {"epoch": 15, "train_loss": "2.908", "train_nll_loss": "1.075", "train_ppl": "2.11", "train_wps": "1254.2", "train_ups": "2.65", "train_wpb": "473.3", "train_bsz": "16", "train_num_updates": "18373", "train_lr": "4.91059e-05", "train_gnorm": "2.638", "train_loss_scale": "101", "train_train_wall": "252", "train_wall": "7118"}
2021-10-23 19:36:49 | INFO | fairseq_cli.train | begin training epoch 15
2021-10-23 19:36:54 | INFO | train_inner | {"epoch": 16, "update": 15.022, "loss": "2.85", "nll_loss": "1.008", "ppl": "2.01", "wps": "197.5", "ups": "0.44", "wpb": "449.9", "bsz": "15.9", "num_updates": "18400", "lr": "4.91046e-05", "gnorm": "2.66", "loss_scale": "128", "train_wall": "21", "wall": "7124"}
2021-10-23 19:37:14 | INFO | train_inner | {"epoch": 16, "update": 15.104, "loss": "2.681", "nll_loss": "0.822", "ppl": "1.77", "wps": "2139", "ups": "4.98", "wpb": "429.4", "bsz": "16", "num_updates": "18500", "lr": "4.90995e-05", "gnorm": "2.464", "loss_scale": "128", "train_wall": "20", "wall": "7144"}
2021-10-23 19:37:36 | INFO | train_inner | {"epoch": 16, "update": 15.185, "loss": "3.049", "nll_loss": "1.234", "ppl": "2.35", "wps": "2555.3", "ups": "4.56", "wpb": "560", "bsz": "16", "num_updates": "18600", "lr": "4.90945e-05", "gnorm": "2.48", "loss_scale": "128", "train_wall": "22", "wall": "7166"}
2021-10-23 19:37:57 | INFO | train_inner | {"epoch": 16, "update": 15.267, "loss": "2.808", "nll_loss": "0.964", "ppl": "1.95", "wps": "2187", "ups": "4.87", "wpb": "449.3", "bsz": "16", "num_updates": "18700", "lr": "4.90895e-05", "gnorm": "2.489", "loss_scale": "128", "train_wall": "20", "wall": "7186"}
2021-10-23 19:38:16 | INFO | train_inner | {"epoch": 16, "update": 15.349, "loss": "2.844", "nll_loss": "1.002", "ppl": "2", "wps": "2408.8", "ups": "5.28", "wpb": "456.4", "bsz": "16", "num_updates": "18800", "lr": "4.90845e-05", "gnorm": "2.599", "loss_scale": "128", "train_wall": "19", "wall": "7205"}
2021-10-23 19:38:35 | INFO | train_inner | {"epoch": 16, "update": 15.43, "loss": "2.781", "nll_loss": "0.932", "ppl": "1.91", "wps": "2338.5", "ups": "5.07", "wpb": "461.3", "bsz": "16", "num_updates": "18900", "lr": "4.90795e-05", "gnorm": "2.555", "loss_scale": "128", "train_wall": "20", "wall": "7225"}
2021-10-23 19:38:54 | INFO | train_inner | {"epoch": 16, "update": 15.512, "loss": "2.761", "nll_loss": "0.908", "ppl": "1.88", "wps": "2535.7", "ups": "5.28", "wpb": "480.3", "bsz": "16", "num_updates": "19000", "lr": "4.90745e-05", "gnorm": "2.577", "loss_scale": "128", "train_wall": "19", "wall": "7244"}
2021-10-23 19:39:15 | INFO | train_inner | {"epoch": 16, "update": 15.593, "loss": "2.797", "nll_loss": "0.951", "ppl": "1.93", "wps": "2359.4", "ups": "4.85", "wpb": "486.4", "bsz": "16", "num_updates": "19100", "lr": "4.90695e-05", "gnorm": "2.566", "loss_scale": "128", "train_wall": "20", "wall": "7264"}
2021-10-23 19:39:36 | INFO | train_inner | {"epoch": 16, "update": 15.675, "loss": "2.959", "nll_loss": "1.132", "ppl": "2.19", "wps": "2548.1", "ups": "4.82", "wpb": "529.1", "bsz": "16", "num_updates": "19200", "lr": "4.90645e-05", "gnorm": "2.658", "loss_scale": "128", "train_wall": "21", "wall": "7285"}
2021-10-23 19:39:56 | INFO | train_inner | {"epoch": 16, "update": 15.757, "loss": "2.815", "nll_loss": "0.97", "ppl": "1.96", "wps": "2413.4", "ups": "5.07", "wpb": "475.9", "bsz": "16", "num_updates": "19300", "lr": "4.90595e-05", "gnorm": "2.567", "loss_scale": "128", "train_wall": "20", "wall": "7305"}
2021-10-23 19:40:17 | INFO | train_inner | {"epoch": 16, "update": 15.838, "loss": "3.039", "nll_loss": "1.223", "ppl": "2.33", "wps": "2262.5", "ups": "4.74", "wpb": "476.8", "bsz": "16", "num_updates": "19400", "lr": "4.90545e-05", "gnorm": "2.723", "loss_scale": "128", "train_wall": "21", "wall": "7326"}
2021-10-23 19:40:37 | INFO | train_inner | {"epoch": 16, "update": 15.92, "loss": "2.628", "nll_loss": "0.76", "ppl": "1.69", "wps": "1980.2", "ups": "4.95", "wpb": "399.7", "bsz": "16", "num_updates": "19500", "lr": "4.90495e-05", "gnorm": "2.667", "loss_scale": "128", "train_wall": "20", "wall": "7346"}
2021-10-23 19:40:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-23 19:44:10 | INFO | valid | {"epoch": 16, "valid_loss": "3.688", "valid_nll_loss": "1.875", "valid_ppl": "3.67", "valid_bleu": "23.4", "valid_wps": "362.7", "valid_wpb": "226.2", "valid_bsz": "8", "valid_num_updates": "19598", "valid_best_bleu": "23.87"}
2021-10-23 19:44:10 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-23 19:44:24 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/scratch/unique/large/checkpoint_last.pt (epoch 16 @ 19598 updates, score 23.4) (writing took 14.445435376022942 seconds)
2021-10-23 19:44:24 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2021-10-23 19:44:24 | INFO | train | {"epoch": 16, "train_loss": "2.838", "train_nll_loss": "0.997", "train_ppl": "2", "train_wps": "1273.8", "train_ups": "2.69", "train_wpb": "473.3", "train_bsz": "16", "train_num_updates": "19598", "train_lr": "4.90446e-05", "train_gnorm": "2.583", "train_loss_scale": "128", "train_train_wall": "246", "train_wall": "7573"}
2021-10-23 19:44:24 | INFO | fairseq_cli.train | begin training epoch 16
2021-10-23 19:44:25 | INFO | train_inner | {"epoch": 17, "update": 16.002, "loss": "2.858", "nll_loss": "1.017", "ppl": "2.02", "wps": "223.7", "ups": "0.44", "wpb": "509.9", "bsz": "15.9", "num_updates": "19600", "lr": "4.90445e-05", "gnorm": "2.694", "loss_scale": "128", "train_wall": "21", "wall": "7574"}
2021-10-23 19:44:45 | INFO | train_inner | {"epoch": 17, "update": 16.083, "loss": "2.847", "nll_loss": "1.009", "ppl": "2.01", "wps": "2513.2", "ups": "4.87", "wpb": "515.9", "bsz": "16", "num_updates": "19700", "lr": "4.90395e-05", "gnorm": "2.319", "loss_scale": "128", "train_wall": "20", "wall": "7595"}
2021-10-23 19:45:06 | INFO | train_inner | {"epoch": 17, "update": 16.165, "loss": "2.651", "nll_loss": "0.788", "ppl": "1.73", "wps": "2029.7", "ups": "4.76", "wpb": "426.1", "bsz": "16", "num_updates": "19800", "lr": "4.90345e-05", "gnorm": "2.557", "loss_scale": "128", "train_wall": "21", "wall": "7616"}
2021-10-23 19:45:26 | INFO | train_inner | {"epoch": 17, "update": 16.247, "loss": "2.729", "nll_loss": "0.874", "ppl": "1.83", "wps": "2516.9", "ups": "5.07", "wpb": "496.5", "bsz": "16", "num_updates": "19900", "lr": "4.90295e-05", "gnorm": "2.378", "loss_scale": "128", "train_wall": "20", "wall": "7635"}
2021-10-23 19:45:45 | INFO | train_inner | {"epoch": 17, "update": 16.328, "loss": "2.69", "nll_loss": "0.831", "ppl": "1.78", "wps": "2387.1", "ups": "5.17", "wpb": "461.7", "bsz": "16", "num_updates": "20000", "lr": "4.90245e-05", "gnorm": "2.448", "loss_scale": "128", "train_wall": "19", "wall": "7655"}
2021-10-23 19:46:05 | INFO | train_inner | {"epoch": 17, "update": 16.41, "loss": "2.732", "nll_loss": "0.877", "ppl": "1.84", "wps": "2271.7", "ups": "4.98", "wpb": "455.7", "bsz": "16", "num_updates": "20100", "lr": "4.90195e-05", "gnorm": "2.52", "loss_scale": "128", "train_wall": "20", "wall": "7675"}
2021-10-23 19:46:27 | INFO | train_inner | {"epoch": 17, "update": 16.491, "loss": "2.819", "nll_loss": "0.975", "ppl": "1.97", "wps": "2183.5", "ups": "4.59", "wpb": "475.2", "bsz": "16", "num_updates": "20200", "lr": "4.90145e-05", "gnorm": "2.485", "loss_scale": "128", "train_wall": "21", "wall": "7697"}
2021-10-23 19:46:49 | INFO | train_inner | {"epoch": 17, "update": 16.573, "loss": "2.784", "nll_loss": "0.935", "ppl": "1.91", "wps": "2100.3", "ups": "4.57", "wpb": "459.8", "bsz": "16", "num_updates": "20300", "lr": "4.90095e-05", "gnorm": "2.486", "loss_scale": "128", "train_wall": "22", "wall": "7718"}
2021-10-23 19:47:11 | INFO | train_inner | {"epoch": 17, "update": 16.655, "loss": "2.901", "nll_loss": "1.066", "ppl": "2.09", "wps": "2435.7", "ups": "4.53", "wpb": "537.7", "bsz": "16", "num_updates": "20400", "lr": "4.90045e-05", "gnorm": "2.458", "loss_scale": "128", "train_wall": "22", "wall": "7741"}
2021-10-23 19:47:33 | INFO | train_inner | {"epoch": 17, "update": 16.736, "loss": "2.667", "nll_loss": "0.804", "ppl": "1.75", "wps": "2096.4", "ups": "4.67", "wpb": "449.3", "bsz": "16", "num_updates": "20500", "lr": "4.89995e-05", "gnorm": "2.611", "loss_scale": "128", "train_wall": "21", "wall": "7762"}
2021-10-23 19:47:55 | INFO | train_inner | {"epoch": 17, "update": 16.818, "loss": "2.844", "nll_loss": "1.002", "ppl": "2", "wps": "2192.4", "ups": "4.51", "wpb": "486.1", "bsz": "16", "num_updates": "20600", "lr": "4.89945e-05", "gnorm": "2.507", "loss_scale": "128", "train_wall": "22", "wall": "7784"}
2021-10-23 19:48:14 | INFO | train_inner | {"epoch": 17, "update": 16.9, "loss": "2.797", "nll_loss": "0.949", "ppl": "1.93", "wps": "2462.3", "ups": "5.09", "wpb": "483.9", "bsz": "16", "num_updates": "20700", "lr": "4.89895e-05", "gnorm": "2.548", "loss_scale": "128", "train_wall": "19", "wall": "7804"}
2021-10-23 19:48:33 | INFO | train_inner | {"epoch": 17, "update": 16.981, "loss": "2.802", "nll_loss": "0.956", "ppl": "1.94", "wps": "2327", "ups": "5.27", "wpb": "441.4", "bsz": "16", "num_updates": "20800", "lr": "4.89845e-05", "gnorm": "2.663", "loss_scale": "128", "train_wall": "19", "wall": "7823"}
2021-10-23 19:48:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-23 19:51:35 | INFO | valid | {"epoch": 17, "valid_loss": "3.711", "valid_nll_loss": "1.925", "valid_ppl": "3.8", "valid_bleu": "23.31", "valid_wps": "393.9", "valid_wpb": "226.2", "valid_bsz": "8", "valid_num_updates": "20823", "valid_best_bleu": "23.87"}
2021-10-23 19:51:35 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-23 19:51:49 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/scratch/unique/large/checkpoint_last.pt (epoch 17 @ 20823 updates, score 23.31) (writing took 14.646854302030988 seconds)
2021-10-23 19:51:49 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2021-10-23 19:51:49 | INFO | train | {"epoch": 17, "train_loss": "2.774", "train_nll_loss": "0.925", "train_ppl": "1.9", "train_wps": "1302", "train_ups": "2.75", "train_wpb": "473.3", "train_bsz": "16", "train_num_updates": "20823", "train_lr": "4.89833e-05", "train_gnorm": "2.503", "train_loss_scale": "128", "train_train_wall": "251", "train_wall": "8019"}
2021-10-23 19:51:49 | INFO | fairseq_cli.train | begin training epoch 17
2021-10-23 19:52:06 | INFO | train_inner | {"epoch": 18, "update": 17.063, "loss": "2.765", "nll_loss": "0.918", "ppl": "1.89", "wps": "210.7", "ups": "0.47", "wpb": "449.1", "bsz": "15.9", "num_updates": "20900", "lr": "4.89795e-05", "gnorm": "2.47", "loss_scale": "128", "train_wall": "22", "wall": "8036"}
2021-10-23 19:52:28 | INFO | train_inner | {"epoch": 18, "update": 17.144, "loss": "2.791", "nll_loss": "0.943", "ppl": "1.92", "wps": "2456.1", "ups": "4.67", "wpb": "525.7", "bsz": "16", "num_updates": "21000", "lr": "4.89745e-05", "gnorm": "2.433", "loss_scale": "128", "train_wall": "21", "wall": "8057"}
2021-10-23 19:52:49 | INFO | train_inner | {"epoch": 18, "update": 17.226, "loss": "2.672", "nll_loss": "0.81", "ppl": "1.75", "wps": "2095", "ups": "4.72", "wpb": "443.6", "bsz": "16", "num_updates": "21100", "lr": "4.89695e-05", "gnorm": "2.395", "loss_scale": "128", "train_wall": "21", "wall": "8079"}
2021-10-23 19:53:08 | INFO | train_inner | {"epoch": 18, "update": 17.308, "loss": "2.7", "nll_loss": "0.841", "ppl": "1.79", "wps": "2579.4", "ups": "5.27", "wpb": "489.2", "bsz": "16", "num_updates": "21200", "lr": "4.89645e-05", "gnorm": "2.415", "loss_scale": "128", "train_wall": "19", "wall": "8097"}
2021-10-23 19:53:25 | INFO | train_inner | {"epoch": 18, "update": 17.389, "loss": "2.602", "nll_loss": "0.732", "ppl": "1.66", "wps": "2787.2", "ups": "5.92", "wpb": "471", "bsz": "16", "num_updates": "21300", "lr": "4.89595e-05", "gnorm": "2.363", "loss_scale": "128", "train_wall": "17", "wall": "8114"}
2021-10-23 19:53:45 | INFO | train_inner | {"epoch": 18, "update": 17.471, "loss": "2.718", "nll_loss": "0.861", "ppl": "1.82", "wps": "2285.7", "ups": "4.88", "wpb": "468.3", "bsz": "16", "num_updates": "21400", "lr": "4.89545e-05", "gnorm": "2.384", "loss_scale": "128", "train_wall": "20", "wall": "8135"}
2021-10-23 19:54:04 | INFO | train_inner | {"epoch": 18, "update": 17.553, "loss": "2.651", "nll_loss": "0.788", "ppl": "1.73", "wps": "2427.7", "ups": "5.28", "wpb": "459.6", "bsz": "16", "num_updates": "21500", "lr": "4.89495e-05", "gnorm": "2.34", "loss_scale": "128", "train_wall": "19", "wall": "8154"}
2021-10-23 19:54:23 | INFO | train_inner | {"epoch": 18, "update": 17.634, "loss": "2.79", "nll_loss": "0.944", "ppl": "1.92", "wps": "2593.6", "ups": "5.23", "wpb": "495.9", "bsz": "16", "num_updates": "21600", "lr": "4.89445e-05", "gnorm": "2.465", "loss_scale": "128", "train_wall": "19", "wall": "8173"}
2021-10-23 19:54:44 | INFO | train_inner | {"epoch": 18, "update": 17.716, "loss": "2.665", "nll_loss": "0.801", "ppl": "1.74", "wps": "2359.9", "ups": "4.82", "wpb": "489.2", "bsz": "16", "num_updates": "21700", "lr": "4.89395e-05", "gnorm": "2.406", "loss_scale": "128", "train_wall": "20", "wall": "8194"}
2021-10-23 19:55:04 | INFO | train_inner | {"epoch": 18, "update": 17.798, "loss": "2.748", "nll_loss": "0.895", "ppl": "1.86", "wps": "2382.7", "ups": "4.97", "wpb": "479.8", "bsz": "16", "num_updates": "21800", "lr": "4.89345e-05", "gnorm": "2.374", "loss_scale": "128", "train_wall": "20", "wall": "8214"}
2021-10-23 19:55:26 | INFO | train_inner | {"epoch": 18, "update": 17.879, "loss": "2.827", "nll_loss": "0.983", "ppl": "1.98", "wps": "2273.4", "ups": "4.66", "wpb": "487.5", "bsz": "16", "num_updates": "21900", "lr": "4.89295e-05", "gnorm": "2.443", "loss_scale": "128", "train_wall": "21", "wall": "8235"}
2021-10-23 19:55:47 | INFO | train_inner | {"epoch": 18, "update": 17.961, "loss": "2.723", "nll_loss": "0.869", "ppl": "1.83", "wps": "1958.3", "ups": "4.8", "wpb": "408.2", "bsz": "16", "num_updates": "22000", "lr": "4.89245e-05", "gnorm": "2.52", "loss_scale": "128", "train_wall": "21", "wall": "8256"}
2021-10-23 19:55:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-23 19:59:02 | INFO | valid | {"epoch": 18, "valid_loss": "3.676", "valid_nll_loss": "1.873", "valid_ppl": "3.66", "valid_bleu": "25.07", "valid_wps": "373.8", "valid_wpb": "226.2", "valid_bsz": "8", "valid_num_updates": "22048", "valid_best_bleu": "25.07"}
2021-10-23 19:59:02 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-23 19:59:27 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/scratch/unique/large/checkpoint_best.pt (epoch 18 @ 22048 updates, score 25.07) (writing took 25.520958491018973 seconds)
2021-10-23 19:59:27 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2021-10-23 19:59:27 | INFO | train | {"epoch": 18, "train_loss": "2.719", "train_nll_loss": "0.863", "train_ppl": "1.82", "train_wps": "1265.7", "train_ups": "2.67", "train_wpb": "473.3", "train_bsz": "16", "train_num_updates": "22048", "train_lr": "4.89221e-05", "train_gnorm": "2.413", "train_loss_scale": "128", "train_train_wall": "243", "train_wall": "8477"}
2021-10-23 19:59:27 | INFO | fairseq_cli.train | begin training epoch 18
2021-10-23 19:59:38 | INFO | train_inner | {"epoch": 19, "update": 18.042, "loss": "2.628", "nll_loss": "0.761", "ppl": "1.69", "wps": "197.7", "ups": "0.43", "wpb": "458.5", "bsz": "15.9", "num_updates": "22100", "lr": "4.89195e-05", "gnorm": "2.327", "loss_scale": "128", "train_wall": "20", "wall": "8488"}
2021-10-23 19:59:59 | INFO | train_inner | {"epoch": 19, "update": 18.124, "loss": "2.706", "nll_loss": "0.852", "ppl": "1.81", "wps": "2390.3", "ups": "4.91", "wpb": "486.8", "bsz": "16", "num_updates": "22200", "lr": "4.89145e-05", "gnorm": "2.306", "loss_scale": "128", "train_wall": "20", "wall": "8508"}
2021-10-23 20:00:20 | INFO | train_inner | {"epoch": 19, "update": 18.206, "loss": "2.645", "nll_loss": "0.782", "ppl": "1.72", "wps": "2181.2", "ups": "4.75", "wpb": "459.5", "bsz": "16", "num_updates": "22300", "lr": "4.89095e-05", "gnorm": "2.309", "loss_scale": "128", "train_wall": "21", "wall": "8529"}
2021-10-23 20:00:41 | INFO | train_inner | {"epoch": 19, "update": 18.287, "loss": "2.566", "nll_loss": "0.688", "ppl": "1.61", "wps": "2208.3", "ups": "4.82", "wpb": "457.7", "bsz": "16", "num_updates": "22400", "lr": "4.89045e-05", "gnorm": "2.426", "loss_scale": "128", "train_wall": "20", "wall": "8550"}
2021-10-23 20:01:03 | INFO | train_inner | {"epoch": 19, "update": 18.369, "loss": "2.737", "nll_loss": "0.881", "ppl": "1.84", "wps": "2360.4", "ups": "4.51", "wpb": "523.8", "bsz": "16", "num_updates": "22500", "lr": "4.88994e-05", "gnorm": "2.334", "loss_scale": "128", "train_wall": "22", "wall": "8572"}
2021-10-23 20:01:25 | INFO | train_inner | {"epoch": 19, "update": 18.451, "loss": "2.587", "nll_loss": "0.716", "ppl": "1.64", "wps": "2041.6", "ups": "4.61", "wpb": "442.5", "bsz": "16", "num_updates": "22600", "lr": "4.88944e-05", "gnorm": "2.316", "loss_scale": "128", "train_wall": "21", "wall": "8594"}
2021-10-23 20:01:46 | INFO | train_inner | {"epoch": 19, "update": 18.532, "loss": "2.698", "nll_loss": "0.841", "ppl": "1.79", "wps": "2069.1", "ups": "4.68", "wpb": "441.7", "bsz": "16", "num_updates": "22700", "lr": "4.88894e-05", "gnorm": "2.446", "loss_scale": "128", "train_wall": "21", "wall": "8615"}
2021-10-23 20:02:07 | INFO | train_inner | {"epoch": 19, "update": 18.614, "loss": "2.615", "nll_loss": "0.745", "ppl": "1.68", "wps": "2049", "ups": "4.74", "wpb": "432.3", "bsz": "16", "num_updates": "22800", "lr": "4.88844e-05", "gnorm": "2.493", "loss_scale": "128", "train_wall": "21", "wall": "8636"}
2021-10-23 20:02:29 | INFO | train_inner | {"epoch": 19, "update": 18.696, "loss": "2.874", "nll_loss": "1.038", "ppl": "2.05", "wps": "2362.4", "ups": "4.53", "wpb": "521", "bsz": "16", "num_updates": "22900", "lr": "4.88794e-05", "gnorm": "2.426", "loss_scale": "128", "train_wall": "22", "wall": "8658"}
2021-10-23 20:02:51 | INFO | train_inner | {"epoch": 19, "update": 18.777, "loss": "2.678", "nll_loss": "0.816", "ppl": "1.76", "wps": "2261.8", "ups": "4.63", "wpb": "488.4", "bsz": "16", "num_updates": "23000", "lr": "4.88744e-05", "gnorm": "2.433", "loss_scale": "128", "train_wall": "21", "wall": "8680"}
2021-10-23 20:03:11 | INFO | train_inner | {"epoch": 19, "update": 18.859, "loss": "2.594", "nll_loss": "0.722", "ppl": "1.65", "wps": "2377.5", "ups": "4.81", "wpb": "494.6", "bsz": "16", "num_updates": "23100", "lr": "4.88694e-05", "gnorm": "2.409", "loss_scale": "128", "train_wall": "21", "wall": "8701"}
2021-10-23 20:03:33 | INFO | train_inner | {"epoch": 19, "update": 18.94, "loss": "2.605", "nll_loss": "0.736", "ppl": "1.67", "wps": "2049.2", "ups": "4.67", "wpb": "438.5", "bsz": "16", "num_updates": "23200", "lr": "4.88644e-05", "gnorm": "2.463", "loss_scale": "128", "train_wall": "21", "wall": "8722"}
2021-10-23 20:03:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-23 20:06:46 | INFO | valid | {"epoch": 19, "valid_loss": "3.664", "valid_nll_loss": "1.844", "valid_ppl": "3.59", "valid_bleu": "25.69", "valid_wps": "393.8", "valid_wpb": "226.2", "valid_bsz": "8", "valid_num_updates": "23273", "valid_best_bleu": "25.69"}
2021-10-23 20:06:46 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-23 20:07:09 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/scratch/unique/large/checkpoint_best.pt (epoch 19 @ 23273 updates, score 25.69) (writing took 23.91543564503081 seconds)
2021-10-23 20:07:09 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2021-10-23 20:07:09 | INFO | train | {"epoch": 19, "train_loss": "2.677", "train_nll_loss": "0.816", "train_ppl": "1.76", "train_wps": "1254.5", "train_ups": "2.65", "train_wpb": "473.3", "train_bsz": "16", "train_num_updates": "23273", "train_lr": "4.88608e-05", "train_gnorm": "2.4", "train_loss_scale": "128", "train_train_wall": "258", "train_wall": "8939"}
2021-10-23 20:07:09 | INFO | fairseq_cli.train | begin training epoch 19
2021-10-23 20:07:15 | INFO | train_inner | {"epoch": 20, "update": 19.022, "loss": "2.792", "nll_loss": "0.946", "ppl": "1.93", "wps": "217.4", "ups": "0.45", "wpb": "483", "bsz": "15.9", "num_updates": "23300", "lr": "4.88594e-05", "gnorm": "2.49", "loss_scale": "128", "train_wall": "21", "wall": "8944"}
2021-10-23 20:07:34 | INFO | train_inner | {"epoch": 20, "update": 19.104, "loss": "2.556", "nll_loss": "0.682", "ppl": "1.6", "wps": "2209.5", "ups": "5.15", "wpb": "428.6", "bsz": "16", "num_updates": "23400", "lr": "4.88544e-05", "gnorm": "2.15", "loss_scale": "128", "train_wall": "19", "wall": "8964"}
2021-10-23 20:07:55 | INFO | train_inner | {"epoch": 20, "update": 19.185, "loss": "2.641", "nll_loss": "0.777", "ppl": "1.71", "wps": "2293.3", "ups": "4.81", "wpb": "476.7", "bsz": "16", "num_updates": "23500", "lr": "4.88494e-05", "gnorm": "2.261", "loss_scale": "128", "train_wall": "21", "wall": "8985"}
2021-10-23 20:08:15 | INFO | train_inner | {"epoch": 20, "update": 19.267, "loss": "2.644", "nll_loss": "0.78", "ppl": "1.72", "wps": "2358.9", "ups": "4.93", "wpb": "478.4", "bsz": "16", "num_updates": "23600", "lr": "4.88444e-05", "gnorm": "2.323", "loss_scale": "128", "train_wall": "20", "wall": "9005"}
2021-10-23 20:08:35 | INFO | train_inner | {"epoch": 20, "update": 19.349, "loss": "2.575", "nll_loss": "0.703", "ppl": "1.63", "wps": "2448.4", "ups": "5.1", "wpb": "480.5", "bsz": "16", "num_updates": "23700", "lr": "4.88394e-05", "gnorm": "2.239", "loss_scale": "128", "train_wall": "19", "wall": "9024"}
2021-10-23 20:08:55 | INFO | train_inner | {"epoch": 20, "update": 19.43, "loss": "2.708", "nll_loss": "0.853", "ppl": "1.81", "wps": "2451.5", "ups": "4.91", "wpb": "499.2", "bsz": "16", "num_updates": "23800", "lr": "4.88344e-05", "gnorm": "2.25", "loss_scale": "128", "train_wall": "20", "wall": "9045"}
2021-10-23 20:09:14 | INFO | train_inner | {"epoch": 20, "update": 19.512, "loss": "2.539", "nll_loss": "0.662", "ppl": "1.58", "wps": "2338.6", "ups": "5.37", "wpb": "435.2", "bsz": "16", "num_updates": "23900", "lr": "4.88294e-05", "gnorm": "2.305", "loss_scale": "128", "train_wall": "18", "wall": "9063"}
2021-10-23 20:09:33 | INFO | train_inner | {"epoch": 20, "update": 19.593, "loss": "2.639", "nll_loss": "0.771", "ppl": "1.71", "wps": "2802.4", "ups": "5.28", "wpb": "531", "bsz": "16", "num_updates": "24000", "lr": "4.88244e-05", "gnorm": "2.259", "loss_scale": "128", "train_wall": "19", "wall": "9082"}
2021-10-23 20:09:53 | INFO | train_inner | {"epoch": 20, "update": 19.675, "loss": "2.595", "nll_loss": "0.723", "ppl": "1.65", "wps": "2494.6", "ups": "5.02", "wpb": "496.4", "bsz": "16", "num_updates": "24100", "lr": "4.88194e-05", "gnorm": "2.335", "loss_scale": "128", "train_wall": "20", "wall": "9102"}
2021-10-23 20:10:13 | INFO | train_inner | {"epoch": 20, "update": 19.757, "loss": "2.762", "nll_loss": "0.913", "ppl": "1.88", "wps": "2424.9", "ups": "4.86", "wpb": "499.1", "bsz": "16", "num_updates": "24200", "lr": "4.88144e-05", "gnorm": "2.355", "loss_scale": "128", "train_wall": "20", "wall": "9123"}
2021-10-23 20:10:33 | INFO | train_inner | {"epoch": 20, "update": 19.838, "loss": "2.596", "nll_loss": "0.726", "ppl": "1.65", "wps": "2230.7", "ups": "5.24", "wpb": "425.9", "bsz": "16", "num_updates": "24300", "lr": "4.88094e-05", "gnorm": "2.434", "loss_scale": "128", "train_wall": "19", "wall": "9142"}
2021-10-23 20:10:54 | INFO | train_inner | {"epoch": 20, "update": 19.92, "loss": "2.592", "nll_loss": "0.719", "ppl": "1.65", "wps": "2141.8", "ups": "4.73", "wpb": "453.1", "bsz": "16", "num_updates": "24400", "lr": "4.88044e-05", "gnorm": "2.412", "loss_scale": "128", "train_wall": "21", "wall": "9163"}
2021-10-23 20:11:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-23 20:14:25 | INFO | valid | {"epoch": 20, "valid_loss": "3.683", "valid_nll_loss": "1.888", "valid_ppl": "3.7", "valid_bleu": "26.35", "valid_wps": "364.5", "valid_wpb": "226.2", "valid_bsz": "8", "valid_num_updates": "24498", "valid_best_bleu": "26.35"}
2021-10-23 20:14:25 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-23 20:14:35 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/scratch/unique/large/checkpoint_best.pt (epoch 20 @ 24498 updates, score 26.35) (writing took 10.423823044984601 seconds)
2021-10-23 20:14:35 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2021-10-23 20:14:35 | INFO | train | {"epoch": 20, "train_loss": "2.63", "train_nll_loss": "0.764", "train_ppl": "1.7", "train_wps": "1300.5", "train_ups": "2.75", "train_wpb": "473.3", "train_bsz": "16", "train_num_updates": "24498", "train_lr": "4.87995e-05", "train_gnorm": "2.305", "train_loss_scale": "128", "train_train_wall": "242", "train_wall": "9385"}
2021-10-23 20:14:35 | INFO | fairseq_cli.train | begin training epoch 20
2021-10-23 20:14:36 | INFO | train_inner | {"epoch": 21, "update": 20.002, "loss": "2.67", "nll_loss": "0.809", "ppl": "1.75", "wps": "218.7", "ups": "0.45", "wpb": "485.8", "bsz": "15.9", "num_updates": "24500", "lr": "4.87994e-05", "gnorm": "2.34", "loss_scale": "128", "train_wall": "21", "wall": "9385"}
2021-10-23 20:14:56 | INFO | train_inner | {"epoch": 21, "update": 20.083, "loss": "2.643", "nll_loss": "0.779", "ppl": "1.72", "wps": "2718.3", "ups": "5.06", "wpb": "536.7", "bsz": "16", "num_updates": "24600", "lr": "4.87944e-05", "gnorm": "2.111", "loss_scale": "128", "train_wall": "20", "wall": "9405"}
2021-10-23 20:15:15 | INFO | train_inner | {"epoch": 21, "update": 20.165, "loss": "2.571", "nll_loss": "0.699", "ppl": "1.62", "wps": "2425.3", "ups": "5.03", "wpb": "481.9", "bsz": "16", "num_updates": "24700", "lr": "4.87894e-05", "gnorm": "2.128", "loss_scale": "128", "train_wall": "20", "wall": "9425"}
2021-10-23 20:15:36 | INFO | train_inner | {"epoch": 21, "update": 20.247, "loss": "2.566", "nll_loss": "0.691", "ppl": "1.61", "wps": "2188.5", "ups": "4.76", "wpb": "459.4", "bsz": "16", "num_updates": "24800", "lr": "4.87844e-05", "gnorm": "2.258", "loss_scale": "128", "train_wall": "21", "wall": "9446"}
2021-10-23 20:15:57 | INFO | train_inner | {"epoch": 21, "update": 20.328, "loss": "2.575", "nll_loss": "0.704", "ppl": "1.63", "wps": "2365.5", "ups": "4.85", "wpb": "487.5", "bsz": "16", "num_updates": "24900", "lr": "4.87794e-05", "gnorm": "2.134", "loss_scale": "128", "train_wall": "20", "wall": "9467"}
2021-10-23 20:16:18 | INFO | train_inner | {"epoch": 21, "update": 20.41, "loss": "2.635", "nll_loss": "0.77", "ppl": "1.7", "wps": "2305.7", "ups": "4.83", "wpb": "477.8", "bsz": "16", "num_updates": "25000", "lr": "4.87744e-05", "gnorm": "2.229", "loss_scale": "128", "train_wall": "20", "wall": "9487"}
2021-10-23 20:16:41 | INFO | train_inner | {"epoch": 21, "update": 20.491, "loss": "2.736", "nll_loss": "0.883", "ppl": "1.84", "wps": "2255.9", "ups": "4.29", "wpb": "526.2", "bsz": "16", "num_updates": "25100", "lr": "4.87694e-05", "gnorm": "2.173", "loss_scale": "128", "train_wall": "23", "wall": "9511"}
2021-10-23 20:17:02 | INFO | train_inner | {"epoch": 21, "update": 20.573, "loss": "2.499", "nll_loss": "0.617", "ppl": "1.53", "wps": "2069.7", "ups": "4.82", "wpb": "429.7", "bsz": "16", "num_updates": "25200", "lr": "4.87644e-05", "gnorm": "2.179", "loss_scale": "128", "train_wall": "21", "wall": "9531"}
2021-10-23 20:17:21 | INFO | train_inner | {"epoch": 21, "update": 20.655, "loss": "2.493", "nll_loss": "0.611", "ppl": "1.53", "wps": "2323", "ups": "5.1", "wpb": "455.3", "bsz": "16", "num_updates": "25300", "lr": "4.87594e-05", "gnorm": "2.283", "loss_scale": "128", "train_wall": "19", "wall": "9551"}
2021-10-23 20:17:42 | INFO | train_inner | {"epoch": 21, "update": 20.736, "loss": "2.647", "nll_loss": "0.783", "ppl": "1.72", "wps": "2333.2", "ups": "4.81", "wpb": "485.4", "bsz": "16", "num_updates": "25400", "lr": "4.87544e-05", "gnorm": "2.336", "loss_scale": "128", "train_wall": "21", "wall": "9572"}
2021-10-23 20:18:01 | INFO | train_inner | {"epoch": 21, "update": 20.818, "loss": "2.63", "nll_loss": "0.763", "ppl": "1.7", "wps": "2408", "ups": "5.21", "wpb": "462.5", "bsz": "16", "num_updates": "25500", "lr": "4.87494e-05", "gnorm": "2.272", "loss_scale": "128", "train_wall": "19", "wall": "9591"}
2021-10-23 20:18:21 | INFO | train_inner | {"epoch": 21, "update": 20.9, "loss": "2.508", "nll_loss": "0.628", "ppl": "1.55", "wps": "2220.3", "ups": "5.2", "wpb": "426.7", "bsz": "16", "num_updates": "25600", "lr": "4.87444e-05", "gnorm": "2.267", "loss_scale": "128", "train_wall": "19", "wall": "9610"}
2021-10-23 20:18:41 | INFO | train_inner | {"epoch": 21, "update": 20.981, "loss": "2.509", "nll_loss": "0.629", "ppl": "1.55", "wps": "2217.2", "ups": "4.96", "wpb": "446.9", "bsz": "16", "num_updates": "25700", "lr": "4.87394e-05", "gnorm": "2.253", "loss_scale": "128", "train_wall": "20", "wall": "9630"}
2021-10-23 20:18:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-23 20:21:39 | INFO | valid | {"epoch": 21, "valid_loss": "3.681", "valid_nll_loss": "1.882", "valid_ppl": "3.69", "valid_bleu": "26.69", "valid_wps": "400.7", "valid_wpb": "226.2", "valid_bsz": "8", "valid_num_updates": "25723", "valid_best_bleu": "26.69"}
2021-10-23 20:21:39 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-23 20:22:04 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/scratch/unique/large/checkpoint_best.pt (epoch 21 @ 25723 updates, score 26.69) (writing took 25.04432225401979 seconds)
2021-10-23 20:22:04 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2021-10-23 20:22:05 | INFO | train | {"epoch": 21, "train_loss": "2.59", "train_nll_loss": "0.719", "train_ppl": "1.65", "train_wps": "1290.5", "train_ups": "2.73", "train_wpb": "473.3", "train_bsz": "16", "train_num_updates": "25723", "train_lr": "4.87382e-05", "train_gnorm": "2.221", "train_loss_scale": "128", "train_train_wall": "248", "train_wall": "9834"}
2021-10-23 20:22:05 | INFO | fairseq_cli.train | begin training epoch 21
2021-10-23 20:22:22 | INFO | train_inner | {"epoch": 22, "update": 21.063, "loss": "2.546", "nll_loss": "0.672", "ppl": "1.59", "wps": "218.7", "ups": "0.45", "wpb": "483.6", "bsz": "15.9", "num_updates": "25800", "lr": "4.87344e-05", "gnorm": "2.159", "loss_scale": "128", "train_wall": "22", "wall": "9851"}
2021-10-23 20:22:42 | INFO | train_inner | {"epoch": 22, "update": 21.144, "loss": "2.477", "nll_loss": "0.595", "ppl": "1.51", "wps": "2252.9", "ups": "5.09", "wpb": "442.4", "bsz": "16", "num_updates": "25900", "lr": "4.87294e-05", "gnorm": "2.057", "loss_scale": "186", "train_wall": "19", "wall": "9871"}
2021-10-23 20:23:01 | INFO | train_inner | {"epoch": 22, "update": 21.226, "loss": "2.54", "nll_loss": "0.664", "ppl": "1.58", "wps": "2478.4", "ups": "5.19", "wpb": "477.7", "bsz": "16", "num_updates": "26000", "lr": "4.87244e-05", "gnorm": "2.241", "loss_scale": "256", "train_wall": "19", "wall": "9890"}
2021-10-23 20:23:23 | INFO | train_inner | {"epoch": 22, "update": 21.308, "loss": "2.636", "nll_loss": "0.772", "ppl": "1.71", "wps": "2252.7", "ups": "4.44", "wpb": "506.9", "bsz": "16", "num_updates": "26100", "lr": "4.87194e-05", "gnorm": "2.195", "loss_scale": "256", "train_wall": "22", "wall": "9913"}
2021-10-23 20:23:44 | INFO | train_inner | {"epoch": 22, "update": 21.389, "loss": "2.579", "nll_loss": "0.708", "ppl": "1.63", "wps": "2418.2", "ups": "4.91", "wpb": "492.5", "bsz": "16", "num_updates": "26200", "lr": "4.87144e-05", "gnorm": "2.186", "loss_scale": "256", "train_wall": "20", "wall": "9933"}
2021-10-23 20:24:04 | INFO | train_inner | {"epoch": 22, "update": 21.471, "loss": "2.479", "nll_loss": "0.595", "ppl": "1.51", "wps": "2314.1", "ups": "4.95", "wpb": "467.7", "bsz": "16", "num_updates": "26300", "lr": "4.87094e-05", "gnorm": "2.1", "loss_scale": "256", "train_wall": "20", "wall": "9953"}
2021-10-23 20:24:24 | INFO | train_inner | {"epoch": 22, "update": 21.553, "loss": "2.491", "nll_loss": "0.609", "ppl": "1.52", "wps": "2356.5", "ups": "5.08", "wpb": "463.6", "bsz": "16", "num_updates": "26400", "lr": "4.87044e-05", "gnorm": "2.186", "loss_scale": "256", "train_wall": "19", "wall": "9973"}
2021-10-23 20:24:44 | INFO | train_inner | {"epoch": 22, "update": 21.634, "loss": "2.579", "nll_loss": "0.709", "ppl": "1.63", "wps": "2452.4", "ups": "4.95", "wpb": "495", "bsz": "16", "num_updates": "26500", "lr": "4.86993e-05", "gnorm": "2.22", "loss_scale": "256", "train_wall": "20", "wall": "9993"}
2021-10-23 20:25:04 | INFO | train_inner | {"epoch": 22, "update": 21.716, "loss": "2.516", "nll_loss": "0.638", "ppl": "1.56", "wps": "2138.2", "ups": "4.86", "wpb": "439.9", "bsz": "16", "num_updates": "26600", "lr": "4.86943e-05", "gnorm": "2.153", "loss_scale": "256", "train_wall": "20", "wall": "10014"}
2021-10-23 20:25:24 | INFO | train_inner | {"epoch": 22, "update": 21.798, "loss": "2.555", "nll_loss": "0.681", "ppl": "1.6", "wps": "2310.3", "ups": "5.08", "wpb": "454.8", "bsz": "16", "num_updates": "26700", "lr": "4.86893e-05", "gnorm": "2.173", "loss_scale": "256", "train_wall": "19", "wall": "10034"}
2021-10-23 20:25:45 | INFO | train_inner | {"epoch": 22, "update": 21.879, "loss": "2.722", "nll_loss": "0.868", "ppl": "1.82", "wps": "2444", "ups": "4.73", "wpb": "516.2", "bsz": "16", "num_updates": "26800", "lr": "4.86843e-05", "gnorm": "2.313", "loss_scale": "256", "train_wall": "21", "wall": "10055"}
2021-10-23 20:26:07 | INFO | train_inner | {"epoch": 22, "update": 21.961, "loss": "2.649", "nll_loss": "0.789", "ppl": "1.73", "wps": "2167.1", "ups": "4.58", "wpb": "473", "bsz": "16", "num_updates": "26900", "lr": "4.86793e-05", "gnorm": "2.246", "loss_scale": "256", "train_wall": "22", "wall": "10076"}
2021-10-23 20:26:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-23 20:29:23 | INFO | valid | {"epoch": 22, "valid_loss": "3.676", "valid_nll_loss": "1.88", "valid_ppl": "3.68", "valid_bleu": "26.84", "valid_wps": "374.4", "valid_wpb": "226.2", "valid_bsz": "8", "valid_num_updates": "26948", "valid_best_bleu": "26.84"}
2021-10-23 20:29:23 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-23 20:29:46 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/scratch/unique/large/checkpoint_best.pt (epoch 22 @ 26948 updates, score 26.84) (writing took 23.513007764937356 seconds)
2021-10-23 20:29:46 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2021-10-23 20:29:46 | INFO | train | {"epoch": 22, "train_loss": "2.56", "train_nll_loss": "0.687", "train_ppl": "1.61", "train_wps": "1255.5", "train_ups": "2.65", "train_wpb": "473.3", "train_bsz": "16", "train_num_updates": "26948", "train_lr": "4.86769e-05", "train_gnorm": "2.182", "train_loss_scale": "242", "train_train_wall": "249", "train_wall": "10296"}
2021-10-23 20:29:46 | INFO | fairseq_cli.train | begin training epoch 22
2021-10-23 20:29:59 | INFO | train_inner | {"epoch": 23, "update": 22.042, "loss": "2.564", "nll_loss": "0.692", "ppl": "1.62", "wps": "195.9", "ups": "0.43", "wpb": "453.7", "bsz": "15.9", "num_updates": "27000", "lr": "4.86743e-05", "gnorm": "2.149", "loss_scale": "256", "train_wall": "22", "wall": "10308"}
2021-10-23 20:30:19 | INFO | train_inner | {"epoch": 23, "update": 22.124, "loss": "2.437", "nll_loss": "0.55", "ppl": "1.46", "wps": "2207.4", "ups": "4.94", "wpb": "447.1", "bsz": "16", "num_updates": "27100", "lr": "4.86693e-05", "gnorm": "2.018", "loss_scale": "256", "train_wall": "20", "wall": "10328"}
2021-10-23 20:30:41 | INFO | train_inner | {"epoch": 23, "update": 22.206, "loss": "2.486", "nll_loss": "0.605", "ppl": "1.52", "wps": "1912.1", "ups": "4.52", "wpb": "423", "bsz": "16", "num_updates": "27200", "lr": "4.86643e-05", "gnorm": "2.12", "loss_scale": "256", "train_wall": "22", "wall": "10350"}
2021-10-23 20:31:01 | INFO | train_inner | {"epoch": 23, "update": 22.287, "loss": "2.518", "nll_loss": "0.64", "ppl": "1.56", "wps": "2354.4", "ups": "4.87", "wpb": "483.8", "bsz": "16", "num_updates": "27300", "lr": "4.86593e-05", "gnorm": "2.026", "loss_scale": "256", "train_wall": "20", "wall": "10371"}
2021-10-23 20:31:23 | INFO | train_inner | {"epoch": 23, "update": 22.369, "loss": "2.502", "nll_loss": "0.623", "ppl": "1.54", "wps": "2194.1", "ups": "4.64", "wpb": "472.4", "bsz": "16", "num_updates": "27400", "lr": "4.86543e-05", "gnorm": "2.073", "loss_scale": "256", "train_wall": "21", "wall": "10392"}
2021-10-23 20:31:45 | INFO | train_inner | {"epoch": 23, "update": 22.451, "loss": "2.515", "nll_loss": "0.638", "ppl": "1.56", "wps": "2297", "ups": "4.64", "wpb": "495", "bsz": "16", "num_updates": "27500", "lr": "4.86493e-05", "gnorm": "2.079", "loss_scale": "256", "train_wall": "21", "wall": "10414"}
2021-10-23 20:32:06 | INFO | train_inner | {"epoch": 23, "update": 22.532, "loss": "2.59", "nll_loss": "0.722", "ppl": "1.65", "wps": "2155.9", "ups": "4.63", "wpb": "465.4", "bsz": "16", "num_updates": "27600", "lr": "4.86443e-05", "gnorm": "2.155", "loss_scale": "256", "train_wall": "21", "wall": "10436"}
2021-10-23 20:32:28 | INFO | train_inner | {"epoch": 23, "update": 22.614, "loss": "2.634", "nll_loss": "0.769", "ppl": "1.7", "wps": "2362.4", "ups": "4.67", "wpb": "505.4", "bsz": "16", "num_updates": "27700", "lr": "4.86393e-05", "gnorm": "2.123", "loss_scale": "256", "train_wall": "21", "wall": "10457"}
2021-10-23 20:32:45 | INFO | train_inner | {"epoch": 23, "update": 22.696, "loss": "2.385", "nll_loss": "0.492", "ppl": "1.41", "wps": "2507.4", "ups": "5.58", "wpb": "449.4", "bsz": "16", "num_updates": "27800", "lr": "4.86343e-05", "gnorm": "2.113", "loss_scale": "256", "train_wall": "18", "wall": "10475"}
2021-10-23 20:33:05 | INFO | train_inner | {"epoch": 23, "update": 22.777, "loss": "2.438", "nll_loss": "0.55", "ppl": "1.46", "wps": "2059.3", "ups": "5.09", "wpb": "404.8", "bsz": "16", "num_updates": "27900", "lr": "4.86293e-05", "gnorm": "2.099", "loss_scale": "256", "train_wall": "19", "wall": "10495"}
2021-10-23 20:33:27 | INFO | train_inner | {"epoch": 23, "update": 22.859, "loss": "2.607", "nll_loss": "0.738", "ppl": "1.67", "wps": "2551.3", "ups": "4.51", "wpb": "565.8", "bsz": "16", "num_updates": "28000", "lr": "4.86243e-05", "gnorm": "2.223", "loss_scale": "256", "train_wall": "22", "wall": "10517"}
2021-10-23 20:33:48 | INFO | train_inner | {"epoch": 23, "update": 22.94, "loss": "2.537", "nll_loss": "0.662", "ppl": "1.58", "wps": "2262.6", "ups": "4.74", "wpb": "477.2", "bsz": "16", "num_updates": "28100", "lr": "4.86193e-05", "gnorm": "2.266", "loss_scale": "256", "train_wall": "21", "wall": "10538"}
2021-10-23 20:34:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-23 20:36:58 | INFO | valid | {"epoch": 23, "valid_loss": "3.725", "valid_nll_loss": "1.947", "valid_ppl": "3.86", "valid_bleu": "26.96", "valid_wps": "399.7", "valid_wpb": "226.2", "valid_bsz": "8", "valid_num_updates": "28173", "valid_best_bleu": "26.96"}
2021-10-23 20:36:58 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-23 20:37:18 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/scratch/unique/large/checkpoint_best.pt (epoch 23 @ 28173 updates, score 26.96) (writing took 19.34085403708741 seconds)
2021-10-23 20:37:18 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2021-10-23 20:37:18 | INFO | train | {"epoch": 23, "train_loss": "2.528", "train_nll_loss": "0.652", "train_ppl": "1.57", "train_wps": "1284.6", "train_ups": "2.71", "train_wpb": "473.3", "train_bsz": "16", "train_num_updates": "28173", "train_lr": "4.86157e-05", "train_gnorm": "2.119", "train_loss_scale": "256", "train_train_wall": "255", "train_wall": "10747"}
2021-10-23 20:37:18 | INFO | fairseq_cli.train | begin training epoch 23
2021-10-23 20:37:23 | INFO | train_inner | {"epoch": 24, "update": 23.022, "loss": "2.51", "nll_loss": "0.63", "ppl": "1.55", "wps": "219.7", "ups": "0.47", "wpb": "472.1", "bsz": "15.9", "num_updates": "28200", "lr": "4.86143e-05", "gnorm": "2.125", "loss_scale": "256", "train_wall": "21", "wall": "10753"}
2021-10-23 20:37:43 | INFO | train_inner | {"epoch": 24, "update": 23.104, "loss": "2.406", "nll_loss": "0.517", "ppl": "1.43", "wps": "2149.7", "ups": "5", "wpb": "430.1", "bsz": "16", "num_updates": "28300", "lr": "4.86093e-05", "gnorm": "2.006", "loss_scale": "256", "train_wall": "20", "wall": "10773"}
2021-10-23 20:38:03 | INFO | train_inner | {"epoch": 24, "update": 23.185, "loss": "2.45", "nll_loss": "0.566", "ppl": "1.48", "wps": "2131.3", "ups": "5.16", "wpb": "413.1", "bsz": "16", "num_updates": "28400", "lr": "4.86043e-05", "gnorm": "2.14", "loss_scale": "256", "train_wall": "19", "wall": "10792"}
2021-10-23 20:38:23 | INFO | train_inner | {"epoch": 24, "update": 23.267, "loss": "2.458", "nll_loss": "0.574", "ppl": "1.49", "wps": "2335", "ups": "4.93", "wpb": "473.6", "bsz": "16", "num_updates": "28500", "lr": "4.85993e-05", "gnorm": "2.093", "loss_scale": "256", "train_wall": "20", "wall": "10812"}
2021-10-23 20:38:44 | INFO | train_inner | {"epoch": 24, "update": 23.349, "loss": "2.504", "nll_loss": "0.625", "ppl": "1.54", "wps": "2452.9", "ups": "4.73", "wpb": "518.2", "bsz": "16", "num_updates": "28600", "lr": "4.85943e-05", "gnorm": "2.03", "loss_scale": "256", "train_wall": "21", "wall": "10834"}
2021-10-23 20:39:05 | INFO | train_inner | {"epoch": 24, "update": 23.43, "loss": "2.556", "nll_loss": "0.683", "ppl": "1.61", "wps": "2468", "ups": "4.7", "wpb": "525.1", "bsz": "16", "num_updates": "28700", "lr": "4.85893e-05", "gnorm": "2.044", "loss_scale": "256", "train_wall": "21", "wall": "10855"}
2021-10-23 20:39:26 | INFO | train_inner | {"epoch": 24, "update": 23.512, "loss": "2.383", "nll_loss": "0.49", "ppl": "1.4", "wps": "2058.3", "ups": "4.94", "wpb": "416.9", "bsz": "16", "num_updates": "28800", "lr": "4.85843e-05", "gnorm": "2.09", "loss_scale": "256", "train_wall": "20", "wall": "10875"}
2021-10-23 20:39:47 | INFO | train_inner | {"epoch": 24, "update": 23.593, "loss": "2.586", "nll_loss": "0.717", "ppl": "1.64", "wps": "2519.7", "ups": "4.58", "wpb": "549.6", "bsz": "16", "num_updates": "28900", "lr": "4.85793e-05", "gnorm": "2.236", "loss_scale": "256", "train_wall": "22", "wall": "10897"}
2021-10-23 20:40:09 | INFO | train_inner | {"epoch": 24, "update": 23.675, "loss": "2.572", "nll_loss": "0.701", "ppl": "1.63", "wps": "2213", "ups": "4.67", "wpb": "474", "bsz": "16", "num_updates": "29000", "lr": "4.85743e-05", "gnorm": "2.204", "loss_scale": "256", "train_wall": "21", "wall": "10918"}
2021-10-23 20:40:31 | INFO | train_inner | {"epoch": 24, "update": 23.757, "loss": "2.539", "nll_loss": "0.666", "ppl": "1.59", "wps": "2184.5", "ups": "4.53", "wpb": "482.2", "bsz": "16", "num_updates": "29100", "lr": "4.85693e-05", "gnorm": "2.174", "loss_scale": "256", "train_wall": "22", "wall": "10940"}
2021-10-23 20:40:51 | INFO | train_inner | {"epoch": 24, "update": 23.838, "loss": "2.557", "nll_loss": "0.686", "ppl": "1.61", "wps": "2380.9", "ups": "4.96", "wpb": "479.6", "bsz": "16", "num_updates": "29200", "lr": "4.85643e-05", "gnorm": "2.111", "loss_scale": "256", "train_wall": "20", "wall": "10961"}
2021-10-23 20:41:12 | INFO | train_inner | {"epoch": 24, "update": 23.92, "loss": "2.478", "nll_loss": "0.597", "ppl": "1.51", "wps": "2231.5", "ups": "4.8", "wpb": "465", "bsz": "16", "num_updates": "29300", "lr": "4.85593e-05", "gnorm": "2.129", "loss_scale": "256", "train_wall": "21", "wall": "10981"}
2021-10-23 20:41:30 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 128.0
2021-10-23 20:41:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-23 20:44:28 | INFO | valid | {"epoch": 24, "valid_loss": "3.693", "valid_nll_loss": "1.911", "valid_ppl": "3.76", "valid_bleu": "28.02", "valid_wps": "394.2", "valid_wpb": "226.2", "valid_bsz": "8", "valid_num_updates": "29397", "valid_best_bleu": "28.02"}
2021-10-23 20:44:28 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-23 20:44:55 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/scratch/unique/large/checkpoint_best.pt (epoch 24 @ 29397 updates, score 28.02) (writing took 27.264018111978658 seconds)
2021-10-23 20:44:55 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2021-10-23 20:44:55 | INFO | train | {"epoch": 24, "train_loss": "2.495", "train_nll_loss": "0.616", "train_ppl": "1.53", "train_wps": "1261.9", "train_ups": "2.67", "train_wpb": "471.9", "train_bsz": "16", "train_num_updates": "29397", "train_lr": "4.85544e-05", "train_gnorm": "2.109", "train_loss_scale": "255", "train_train_wall": "251", "train_wall": "11205"}
2021-10-23 20:44:55 | INFO | fairseq_cli.train | begin training epoch 24
2021-10-23 20:44:56 | INFO | train_inner | {"epoch": 25, "update": 24.002, "loss": "2.44", "nll_loss": "0.554", "ppl": "1.47", "wps": "198.2", "ups": "0.45", "wpb": "444", "bsz": "15.9", "num_updates": "29400", "lr": "4.85543e-05", "gnorm": "2.052", "loss_scale": "241", "train_wall": "20", "wall": "11205"}
2021-10-23 20:45:18 | INFO | train_inner | {"epoch": 25, "update": 24.084, "loss": "2.669", "nll_loss": "0.809", "ppl": "1.75", "wps": "2815.7", "ups": "4.62", "wpb": "610", "bsz": "16", "num_updates": "29500", "lr": "4.85493e-05", "gnorm": "1.965", "loss_scale": "128", "train_wall": "21", "wall": "11227"}
2021-10-23 20:45:39 | INFO | train_inner | {"epoch": 25, "update": 24.166, "loss": "2.589", "nll_loss": "0.723", "ppl": "1.65", "wps": "2552.7", "ups": "4.76", "wpb": "536.7", "bsz": "16", "num_updates": "29600", "lr": "4.85443e-05", "gnorm": "1.98", "loss_scale": "128", "train_wall": "21", "wall": "11248"}
2021-10-23 20:45:57 | INFO | train_inner | {"epoch": 25, "update": 24.247, "loss": "2.468", "nll_loss": "0.585", "ppl": "1.5", "wps": "2521", "ups": "5.31", "wpb": "474.6", "bsz": "16", "num_updates": "29700", "lr": "4.85393e-05", "gnorm": "1.976", "loss_scale": "128", "train_wall": "19", "wall": "11267"}
2021-10-23 20:46:18 | INFO | train_inner | {"epoch": 25, "update": 24.329, "loss": "2.523", "nll_loss": "0.65", "ppl": "1.57", "wps": "2339", "ups": "4.86", "wpb": "481.6", "bsz": "16", "num_updates": "29800", "lr": "4.85343e-05", "gnorm": "1.998", "loss_scale": "128", "train_wall": "20", "wall": "11288"}
2021-10-23 20:46:40 | INFO | train_inner | {"epoch": 25, "update": 24.411, "loss": "2.412", "nll_loss": "0.524", "ppl": "1.44", "wps": "2145.9", "ups": "4.63", "wpb": "463.5", "bsz": "16", "num_updates": "29900", "lr": "4.85293e-05", "gnorm": "2.048", "loss_scale": "128", "train_wall": "21", "wall": "11309"}
2021-10-23 20:46:58 | INFO | train_inner | {"epoch": 25, "update": 24.492, "loss": "2.459", "nll_loss": "0.577", "ppl": "1.49", "wps": "2329.1", "ups": "5.46", "wpb": "426.2", "bsz": "16", "num_updates": "30000", "lr": "4.85243e-05", "gnorm": "2.096", "loss_scale": "128", "train_wall": "18", "wall": "11327"}
2021-10-23 20:47:18 | INFO | train_inner | {"epoch": 25, "update": 24.574, "loss": "2.359", "nll_loss": "0.465", "ppl": "1.38", "wps": "2097.5", "ups": "5.04", "wpb": "416.6", "bsz": "16", "num_updates": "30100", "lr": "4.85193e-05", "gnorm": "2.143", "loss_scale": "128", "train_wall": "20", "wall": "11347"}
2021-10-23 20:47:40 | INFO | train_inner | {"epoch": 25, "update": 24.656, "loss": "2.38", "nll_loss": "0.489", "ppl": "1.4", "wps": "1989.5", "ups": "4.56", "wpb": "436.2", "bsz": "16", "num_updates": "30200", "lr": "4.85143e-05", "gnorm": "2.069", "loss_scale": "128", "train_wall": "22", "wall": "11369"}
2021-10-23 20:48:02 | INFO | train_inner | {"epoch": 25, "update": 24.737, "loss": "2.377", "nll_loss": "0.485", "ppl": "1.4", "wps": "2098.9", "ups": "4.58", "wpb": "458.4", "bsz": "16", "num_updates": "30300", "lr": "4.85093e-05", "gnorm": "2.021", "loss_scale": "128", "train_wall": "22", "wall": "11391"}
2021-10-23 20:48:21 | INFO | train_inner | {"epoch": 25, "update": 24.819, "loss": "2.387", "nll_loss": "0.496", "ppl": "1.41", "wps": "2199.5", "ups": "5.09", "wpb": "431.9", "bsz": "16", "num_updates": "30400", "lr": "4.85043e-05", "gnorm": "2.056", "loss_scale": "128", "train_wall": "19", "wall": "11411"}
2021-10-23 20:48:41 | INFO | train_inner | {"epoch": 25, "update": 24.9, "loss": "2.534", "nll_loss": "0.662", "ppl": "1.58", "wps": "2545.5", "ups": "5.12", "wpb": "497.3", "bsz": "16", "num_updates": "30500", "lr": "4.84992e-05", "gnorm": "2.033", "loss_scale": "128", "train_wall": "19", "wall": "11430"}
2021-10-23 20:49:00 | INFO | train_inner | {"epoch": 25, "update": 24.982, "loss": "2.45", "nll_loss": "0.566", "ppl": "1.48", "wps": "2397.4", "ups": "5.22", "wpb": "459", "bsz": "16", "num_updates": "30600", "lr": "4.84942e-05", "gnorm": "2.141", "loss_scale": "128", "train_wall": "19", "wall": "11449"}
2021-10-23 20:49:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-23 20:52:05 | INFO | valid | {"epoch": 25, "valid_loss": "3.685", "valid_nll_loss": "1.898", "valid_ppl": "3.73", "valid_bleu": "27.49", "valid_wps": "384.7", "valid_wpb": "226.2", "valid_bsz": "8", "valid_num_updates": "30622", "valid_best_bleu": "28.02"}
2021-10-23 20:52:05 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-23 20:52:11 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/scratch/unique/large/checkpoint_last.pt (epoch 25 @ 30622 updates, score 27.49) (writing took 6.729049018933438 seconds)
2021-10-23 20:52:11 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2021-10-23 20:52:11 | INFO | train | {"epoch": 25, "train_loss": "2.474", "train_nll_loss": "0.593", "train_ppl": "1.51", "train_wps": "1329.9", "train_ups": "2.81", "train_wpb": "473.3", "train_bsz": "16", "train_num_updates": "30622", "train_lr": "4.84931e-05", "train_gnorm": "2.045", "train_loss_scale": "128", "train_train_wall": "246", "train_wall": "11641"}
2021-10-23 20:52:11 | INFO | fairseq_cli.train | begin training epoch 25
2021-10-23 20:52:26 | INFO | train_inner | {"epoch": 26, "update": 25.064, "loss": "2.299", "nll_loss": "0.397", "ppl": "1.32", "wps": "197.6", "ups": "0.49", "wpb": "406.6", "bsz": "15.9", "num_updates": "30700", "lr": "4.84892e-05", "gnorm": "1.948", "loss_scale": "128", "train_wall": "18", "wall": "11655"}
2021-10-23 20:52:46 | INFO | train_inner | {"epoch": 26, "update": 25.145, "loss": "2.416", "nll_loss": "0.53", "ppl": "1.44", "wps": "2368.6", "ups": "4.86", "wpb": "487", "bsz": "16", "num_updates": "30800", "lr": "4.84842e-05", "gnorm": "1.969", "loss_scale": "128", "train_wall": "20", "wall": "11676"}
2021-10-23 20:53:07 | INFO | train_inner | {"epoch": 26, "update": 25.227, "loss": "2.432", "nll_loss": "0.548", "ppl": "1.46", "wps": "2200.8", "ups": "4.87", "wpb": "452", "bsz": "16", "num_updates": "30900", "lr": "4.84792e-05", "gnorm": "1.985", "loss_scale": "128", "train_wall": "20", "wall": "11696"}
2021-10-23 20:53:25 | INFO | train_inner | {"epoch": 26, "update": 25.309, "loss": "2.396", "nll_loss": "0.507", "ppl": "1.42", "wps": "2366", "ups": "5.48", "wpb": "431.5", "bsz": "16", "num_updates": "31000", "lr": "4.84742e-05", "gnorm": "1.997", "loss_scale": "128", "train_wall": "18", "wall": "11714"}
2021-10-23 20:53:43 | INFO | train_inner | {"epoch": 26, "update": 25.39, "loss": "2.397", "nll_loss": "0.509", "ppl": "1.42", "wps": "2674.2", "ups": "5.65", "wpb": "473.6", "bsz": "16", "num_updates": "31100", "lr": "4.84692e-05", "gnorm": "1.937", "loss_scale": "128", "train_wall": "18", "wall": "11732"}
2021-10-23 20:54:01 | INFO | train_inner | {"epoch": 26, "update": 25.472, "loss": "2.699", "nll_loss": "0.845", "ppl": "1.8", "wps": "2800.2", "ups": "5.36", "wpb": "522.5", "bsz": "16", "num_updates": "31200", "lr": "4.84642e-05", "gnorm": "2.014", "loss_scale": "128", "train_wall": "18", "wall": "11751"}
2021-10-23 20:54:21 | INFO | train_inner | {"epoch": 26, "update": 25.553, "loss": "2.364", "nll_loss": "0.471", "ppl": "1.39", "wps": "2375.7", "ups": "5.1", "wpb": "466", "bsz": "16", "num_updates": "31300", "lr": "4.84592e-05", "gnorm": "1.969", "loss_scale": "128", "train_wall": "19", "wall": "11770"}
2021-10-23 20:54:41 | INFO | train_inner | {"epoch": 26, "update": 25.635, "loss": "2.529", "nll_loss": "0.656", "ppl": "1.58", "wps": "2315.3", "ups": "4.89", "wpb": "473.9", "bsz": "16", "num_updates": "31400", "lr": "4.84542e-05", "gnorm": "2.103", "loss_scale": "128", "train_wall": "20", "wall": "11791"}
2021-10-23 20:55:04 | INFO | train_inner | {"epoch": 26, "update": 25.717, "loss": "2.54", "nll_loss": "0.666", "ppl": "1.59", "wps": "2641.4", "ups": "4.5", "wpb": "586.9", "bsz": "16", "num_updates": "31500", "lr": "4.84492e-05", "gnorm": "1.95", "loss_scale": "128", "train_wall": "22", "wall": "11813"}
2021-10-23 20:55:23 | INFO | train_inner | {"epoch": 26, "update": 25.798, "loss": "2.48", "nll_loss": "0.6", "ppl": "1.52", "wps": "2645.8", "ups": "5.19", "wpb": "510", "bsz": "16", "num_updates": "31600", "lr": "4.84442e-05", "gnorm": "1.944", "loss_scale": "128", "train_wall": "19", "wall": "11832"}
2021-10-23 20:55:41 | INFO | train_inner | {"epoch": 26, "update": 25.88, "loss": "2.403", "nll_loss": "0.515", "ppl": "1.43", "wps": "2479.3", "ups": "5.52", "wpb": "449.2", "bsz": "16", "num_updates": "31700", "lr": "4.84392e-05", "gnorm": "2.015", "loss_scale": "128", "train_wall": "18", "wall": "11851"}
2021-10-23 20:56:01 | INFO | train_inner | {"epoch": 26, "update": 25.962, "loss": "2.338", "nll_loss": "0.444", "ppl": "1.36", "wps": "2081.6", "ups": "5.09", "wpb": "408.7", "bsz": "16", "num_updates": "31800", "lr": "4.84342e-05", "gnorm": "2.029", "loss_scale": "128", "train_wall": "19", "wall": "11870"}
2021-10-23 20:56:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-23 20:59:11 | INFO | valid | {"epoch": 26, "valid_loss": "3.68", "valid_nll_loss": "1.898", "valid_ppl": "3.73", "valid_bleu": "27.76", "valid_wps": "383.4", "valid_wpb": "226.2", "valid_bsz": "8", "valid_num_updates": "31847", "valid_best_bleu": "28.02"}
2021-10-23 20:59:11 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-23 20:59:26 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/scratch/unique/large/checkpoint_last.pt (epoch 26 @ 31847 updates, score 27.76) (writing took 15.252040933002718 seconds)
2021-10-23 20:59:26 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2021-10-23 20:59:26 | INFO | train | {"epoch": 26, "train_loss": "2.455", "train_nll_loss": "0.573", "train_ppl": "1.49", "train_wps": "1332.7", "train_ups": "2.82", "train_wpb": "473.3", "train_bsz": "16", "train_num_updates": "31847", "train_lr": "4.84319e-05", "train_gnorm": "1.987", "train_loss_scale": "128", "train_train_wall": "236", "train_wall": "12076"}
2021-10-23 20:59:26 | INFO | fairseq_cli.train | begin training epoch 26
2021-10-23 20:59:37 | INFO | train_inner | {"epoch": 27, "update": 26.043, "loss": "2.563", "nll_loss": "0.693", "ppl": "1.62", "wps": "249.2", "ups": "0.46", "wpb": "539.2", "bsz": "15.9", "num_updates": "31900", "lr": "4.84292e-05", "gnorm": "2.001", "loss_scale": "128", "train_wall": "19", "wall": "12087"}
2021-10-23 20:59:55 | INFO | train_inner | {"epoch": 27, "update": 26.125, "loss": "2.422", "nll_loss": "0.54", "ppl": "1.45", "wps": "2372.5", "ups": "5.49", "wpb": "432", "bsz": "16", "num_updates": "32000", "lr": "4.84242e-05", "gnorm": "1.888", "loss_scale": "128", "train_wall": "18", "wall": "12105"}
2021-10-23 21:00:14 | INFO | train_inner | {"epoch": 27, "update": 26.207, "loss": "2.452", "nll_loss": "0.573", "ppl": "1.49", "wps": "2472.9", "ups": "5.45", "wpb": "453.6", "bsz": "16", "num_updates": "32100", "lr": "4.84192e-05", "gnorm": "1.911", "loss_scale": "128", "train_wall": "18", "wall": "12123"}
2021-10-23 21:00:32 | INFO | train_inner | {"epoch": 27, "update": 26.288, "loss": "2.509", "nll_loss": "0.631", "ppl": "1.55", "wps": "2729.5", "ups": "5.39", "wpb": "506.5", "bsz": "16", "num_updates": "32200", "lr": "4.84142e-05", "gnorm": "1.887", "loss_scale": "128", "train_wall": "18", "wall": "12142"}
2021-10-23 21:00:51 | INFO | train_inner | {"epoch": 27, "update": 26.37, "loss": "2.387", "nll_loss": "0.497", "ppl": "1.41", "wps": "2463.6", "ups": "5.36", "wpb": "459.6", "bsz": "16", "num_updates": "32300", "lr": "4.84092e-05", "gnorm": "1.962", "loss_scale": "128", "train_wall": "18", "wall": "12160"}
2021-10-23 21:01:09 | INFO | train_inner | {"epoch": 27, "update": 26.451, "loss": "2.294", "nll_loss": "0.395", "ppl": "1.31", "wps": "2175.4", "ups": "5.42", "wpb": "401.5", "bsz": "16", "num_updates": "32400", "lr": "4.84042e-05", "gnorm": "1.883", "loss_scale": "128", "train_wall": "18", "wall": "12179"}
2021-10-23 21:01:30 | INFO | train_inner | {"epoch": 27, "update": 26.533, "loss": "2.418", "nll_loss": "0.533", "ppl": "1.45", "wps": "2552.9", "ups": "4.84", "wpb": "527.8", "bsz": "16", "num_updates": "32500", "lr": "4.83992e-05", "gnorm": "1.839", "loss_scale": "128", "train_wall": "20", "wall": "12199"}
2021-10-23 21:01:50 | INFO | train_inner | {"epoch": 27, "update": 26.615, "loss": "2.445", "nll_loss": "0.562", "ppl": "1.48", "wps": "2636.7", "ups": "5.02", "wpb": "525.1", "bsz": "16", "num_updates": "32600", "lr": "4.83942e-05", "gnorm": "1.889", "loss_scale": "128", "train_wall": "20", "wall": "12219"}
2021-10-23 21:02:13 | INFO | train_inner | {"epoch": 27, "update": 26.696, "loss": "2.529", "nll_loss": "0.656", "ppl": "1.58", "wps": "2344.3", "ups": "4.4", "wpb": "533.3", "bsz": "16", "num_updates": "32700", "lr": "4.83892e-05", "gnorm": "1.983", "loss_scale": "128", "train_wall": "22", "wall": "12242"}
2021-10-23 21:02:31 | INFO | train_inner | {"epoch": 27, "update": 26.778, "loss": "2.45", "nll_loss": "0.568", "ppl": "1.48", "wps": "2593.1", "ups": "5.39", "wpb": "481.4", "bsz": "16", "num_updates": "32800", "lr": "4.83842e-05", "gnorm": "2.037", "loss_scale": "128", "train_wall": "18", "wall": "12261"}
2021-10-23 21:02:52 | INFO | train_inner | {"epoch": 27, "update": 26.86, "loss": "2.379", "nll_loss": "0.488", "ppl": "1.4", "wps": "2117.3", "ups": "4.85", "wpb": "436.9", "bsz": "16", "num_updates": "32900", "lr": "4.83792e-05", "gnorm": "1.975", "loss_scale": "128", "train_wall": "20", "wall": "12281"}
2021-10-23 21:03:12 | INFO | train_inner | {"epoch": 27, "update": 26.941, "loss": "2.388", "nll_loss": "0.5", "ppl": "1.41", "wps": "2030.4", "ups": "4.97", "wpb": "408.4", "bsz": "16", "num_updates": "33000", "lr": "4.83742e-05", "gnorm": "1.955", "loss_scale": "128", "train_wall": "20", "wall": "12301"}
2021-10-23 21:03:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-23 21:06:24 | INFO | valid | {"epoch": 27, "valid_loss": "3.693", "valid_nll_loss": "1.921", "valid_ppl": "3.79", "valid_bleu": "27.84", "valid_wps": "389.9", "valid_wpb": "226.2", "valid_bsz": "8", "valid_num_updates": "33072", "valid_best_bleu": "28.02"}
2021-10-23 21:06:24 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-23 21:06:38 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/scratch/unique/large/checkpoint_last.pt (epoch 27 @ 33072 updates, score 27.84) (writing took 13.5942068049917 seconds)
2021-10-23 21:06:38 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2021-10-23 21:06:38 | INFO | train | {"epoch": 27, "train_loss": "2.431", "train_nll_loss": "0.547", "train_ppl": "1.46", "train_wps": "1344", "train_ups": "2.84", "train_wpb": "473.3", "train_bsz": "16", "train_num_updates": "33072", "train_lr": "4.83706e-05", "train_gnorm": "1.929", "train_loss_scale": "128", "train_train_wall": "237", "train_wall": "12507"}
2021-10-23 21:06:38 | INFO | fairseq_cli.train | begin training epoch 27
2021-10-23 21:06:43 | INFO | train_inner | {"epoch": 28, "update": 27.023, "loss": "2.372", "nll_loss": "0.481", "ppl": "1.4", "wps": "214.6", "ups": "0.47", "wpb": "453.4", "bsz": "15.9", "num_updates": "33100", "lr": "4.83692e-05", "gnorm": "1.96", "loss_scale": "128", "train_wall": "19", "wall": "12513"}
2021-10-23 21:07:04 | INFO | train_inner | {"epoch": 28, "update": 27.104, "loss": "2.461", "nll_loss": "0.584", "ppl": "1.5", "wps": "2150.3", "ups": "4.91", "wpb": "437.6", "bsz": "16", "num_updates": "33200", "lr": "4.83642e-05", "gnorm": "1.866", "loss_scale": "128", "train_wall": "20", "wall": "12533"}
2021-10-23 21:07:22 | INFO | train_inner | {"epoch": 28, "update": 27.186, "loss": "2.264", "nll_loss": "0.361", "ppl": "1.28", "wps": "2188.4", "ups": "5.52", "wpb": "396.3", "bsz": "16", "num_updates": "33300", "lr": "4.83592e-05", "gnorm": "1.894", "loss_scale": "128", "train_wall": "18", "wall": "12551"}
2021-10-23 21:07:44 | INFO | train_inner | {"epoch": 28, "update": 27.268, "loss": "2.476", "nll_loss": "0.597", "ppl": "1.51", "wps": "2351", "ups": "4.57", "wpb": "514.6", "bsz": "16", "num_updates": "33400", "lr": "4.83542e-05", "gnorm": "1.891", "loss_scale": "128", "train_wall": "22", "wall": "12573"}
2021-10-23 21:08:04 | INFO | train_inner | {"epoch": 28, "update": 27.349, "loss": "2.384", "nll_loss": "0.496", "ppl": "1.41", "wps": "2419.9", "ups": "5.01", "wpb": "482.6", "bsz": "16", "num_updates": "33500", "lr": "4.83492e-05", "gnorm": "1.844", "loss_scale": "128", "train_wall": "20", "wall": "12593"}
2021-10-23 21:08:24 | INFO | train_inner | {"epoch": 28, "update": 27.431, "loss": "2.336", "nll_loss": "0.443", "ppl": "1.36", "wps": "2387.7", "ups": "5.02", "wpb": "475.5", "bsz": "16", "num_updates": "33600", "lr": "4.83442e-05", "gnorm": "1.833", "loss_scale": "128", "train_wall": "20", "wall": "12613"}
2021-10-23 21:08:44 | INFO | train_inner | {"epoch": 28, "update": 27.513, "loss": "2.422", "nll_loss": "0.538", "ppl": "1.45", "wps": "2345.3", "ups": "4.82", "wpb": "486.2", "bsz": "16", "num_updates": "33700", "lr": "4.83392e-05", "gnorm": "1.89", "loss_scale": "128", "train_wall": "20", "wall": "12634"}
2021-10-23 21:09:03 | INFO | train_inner | {"epoch": 28, "update": 27.594, "loss": "2.478", "nll_loss": "0.602", "ppl": "1.52", "wps": "2514", "ups": "5.31", "wpb": "473.4", "bsz": "16", "num_updates": "33800", "lr": "4.83342e-05", "gnorm": "1.901", "loss_scale": "128", "train_wall": "19", "wall": "12653"}
2021-10-23 21:09:23 | INFO | train_inner | {"epoch": 28, "update": 27.676, "loss": "2.301", "nll_loss": "0.403", "ppl": "1.32", "wps": "2147.4", "ups": "4.93", "wpb": "435.3", "bsz": "16", "num_updates": "33900", "lr": "4.83292e-05", "gnorm": "1.818", "loss_scale": "128", "train_wall": "20", "wall": "12673"}
2021-10-23 21:09:42 | INFO | train_inner | {"epoch": 28, "update": 27.758, "loss": "2.421", "nll_loss": "0.535", "ppl": "1.45", "wps": "2772.2", "ups": "5.37", "wpb": "516.3", "bsz": "16", "num_updates": "34000", "lr": "4.83242e-05", "gnorm": "1.873", "loss_scale": "128", "train_wall": "18", "wall": "12691"}
2021-10-23 21:10:03 | INFO | train_inner | {"epoch": 28, "update": 27.839, "loss": "2.591", "nll_loss": "0.728", "ppl": "1.66", "wps": "2340", "ups": "4.66", "wpb": "502", "bsz": "16", "num_updates": "34100", "lr": "4.83192e-05", "gnorm": "2.054", "loss_scale": "128", "train_wall": "21", "wall": "12713"}
2021-10-23 21:10:23 | INFO | train_inner | {"epoch": 28, "update": 27.921, "loss": "2.331", "nll_loss": "0.437", "ppl": "1.35", "wps": "2240", "ups": "5.19", "wpb": "431.7", "bsz": "16", "num_updates": "34200", "lr": "4.83142e-05", "gnorm": "1.93", "loss_scale": "128", "train_wall": "19", "wall": "12732"}
2021-10-23 21:10:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-23 21:13:40 | INFO | valid | {"epoch": 28, "valid_loss": "3.671", "valid_nll_loss": "1.897", "valid_ppl": "3.72", "valid_bleu": "28.72", "valid_wps": "392.4", "valid_wpb": "226.2", "valid_bsz": "8", "valid_num_updates": "34297", "valid_best_bleu": "28.72"}
2021-10-23 21:13:40 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-23 21:14:09 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/scratch/unique/large/checkpoint_best.pt (epoch 28 @ 34297 updates, score 28.72) (writing took 28.45060875499621 seconds)
2021-10-23 21:14:09 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2021-10-23 21:14:09 | INFO | train | {"epoch": 28, "train_loss": "2.417", "train_nll_loss": "0.532", "train_ppl": "1.45", "train_wps": "1285.1", "train_ups": "2.72", "train_wpb": "473.3", "train_bsz": "16", "train_num_updates": "34297", "train_lr": "4.83093e-05", "train_gnorm": "1.896", "train_loss_scale": "128", "train_train_wall": "243", "train_wall": "12958"}
2021-10-23 21:14:09 | INFO | fairseq_cli.train | begin training epoch 28
2021-10-23 21:14:10 | INFO | train_inner | {"epoch": 29, "update": 28.002, "loss": "2.456", "nll_loss": "0.575", "ppl": "1.49", "wps": "230.4", "ups": "0.44", "wpb": "522.6", "bsz": "15.9", "num_updates": "34300", "lr": "4.83092e-05", "gnorm": "1.893", "loss_scale": "128", "train_wall": "21", "wall": "12959"}
2021-10-23 21:14:29 | INFO | train_inner | {"epoch": 29, "update": 28.084, "loss": "2.376", "nll_loss": "0.488", "ppl": "1.4", "wps": "2414.5", "ups": "5.14", "wpb": "469.6", "bsz": "16", "num_updates": "34400", "lr": "4.83042e-05", "gnorm": "1.773", "loss_scale": "128", "train_wall": "19", "wall": "12978"}
2021-10-23 21:14:49 | INFO | train_inner | {"epoch": 29, "update": 28.166, "loss": "2.368", "nll_loss": "0.479", "ppl": "1.39", "wps": "2327.1", "ups": "5.09", "wpb": "457.6", "bsz": "16", "num_updates": "34500", "lr": "4.82991e-05", "gnorm": "1.842", "loss_scale": "128", "train_wall": "19", "wall": "12998"}
2021-10-23 21:15:10 | INFO | train_inner | {"epoch": 29, "update": 28.247, "loss": "2.477", "nll_loss": "0.6", "ppl": "1.52", "wps": "2575.3", "ups": "4.6", "wpb": "560.1", "bsz": "16", "num_updates": "34600", "lr": "4.82941e-05", "gnorm": "1.851", "loss_scale": "128", "train_wall": "22", "wall": "13020"}
2021-10-23 21:15:31 | INFO | train_inner | {"epoch": 29, "update": 28.329, "loss": "2.422", "nll_loss": "0.538", "ppl": "1.45", "wps": "2334.6", "ups": "4.92", "wpb": "474.1", "bsz": "16", "num_updates": "34700", "lr": "4.82891e-05", "gnorm": "1.765", "loss_scale": "128", "train_wall": "20", "wall": "13040"}
2021-10-23 21:15:51 | INFO | train_inner | {"epoch": 29, "update": 28.411, "loss": "2.455", "nll_loss": "0.577", "ppl": "1.49", "wps": "2560.4", "ups": "4.86", "wpb": "526.6", "bsz": "16", "num_updates": "34800", "lr": "4.82841e-05", "gnorm": "1.774", "loss_scale": "128", "train_wall": "20", "wall": "13061"}
2021-10-23 21:16:11 | INFO | train_inner | {"epoch": 29, "update": 28.492, "loss": "2.402", "nll_loss": "0.517", "ppl": "1.43", "wps": "2604.7", "ups": "5.19", "wpb": "501.5", "bsz": "16", "num_updates": "34900", "lr": "4.82791e-05", "gnorm": "1.74", "loss_scale": "128", "train_wall": "19", "wall": "13080"}
2021-10-23 21:16:31 | INFO | train_inner | {"epoch": 29, "update": 28.574, "loss": "2.392", "nll_loss": "0.506", "ppl": "1.42", "wps": "2264.3", "ups": "4.98", "wpb": "454.4", "bsz": "16", "num_updates": "35000", "lr": "4.82741e-05", "gnorm": "1.836", "loss_scale": "128", "train_wall": "20", "wall": "13100"}
2021-10-23 21:16:50 | INFO | train_inner | {"epoch": 29, "update": 28.656, "loss": "2.248", "nll_loss": "0.346", "ppl": "1.27", "wps": "2003.9", "ups": "5.22", "wpb": "383.6", "bsz": "16", "num_updates": "35100", "lr": "4.82691e-05", "gnorm": "1.862", "loss_scale": "128", "train_wall": "19", "wall": "13119"}
2021-10-23 21:17:11 | INFO | train_inner | {"epoch": 29, "update": 28.737, "loss": "2.388", "nll_loss": "0.502", "ppl": "1.42", "wps": "2235.6", "ups": "4.71", "wpb": "474.2", "bsz": "16", "num_updates": "35200", "lr": "4.82641e-05", "gnorm": "1.923", "loss_scale": "128", "train_wall": "21", "wall": "13140"}
2021-10-23 21:17:31 | INFO | train_inner | {"epoch": 29, "update": 28.819, "loss": "2.333", "nll_loss": "0.439", "ppl": "1.36", "wps": "2118.5", "ups": "5.08", "wpb": "417", "bsz": "16", "num_updates": "35300", "lr": "4.82591e-05", "gnorm": "1.908", "loss_scale": "128", "train_wall": "19", "wall": "13160"}
2021-10-23 21:17:49 | INFO | train_inner | {"epoch": 29, "update": 28.9, "loss": "2.35", "nll_loss": "0.458", "ppl": "1.37", "wps": "2483.3", "ups": "5.35", "wpb": "464.1", "bsz": "16", "num_updates": "35400", "lr": "4.82541e-05", "gnorm": "1.87", "loss_scale": "128", "train_wall": "18", "wall": "13179"}
2021-10-23 21:18:08 | INFO | train_inner | {"epoch": 29, "update": 28.982, "loss": "2.494", "nll_loss": "0.62", "ppl": "1.54", "wps": "2569", "ups": "5.27", "wpb": "487.9", "bsz": "16", "num_updates": "35500", "lr": "4.82491e-05", "gnorm": "1.922", "loss_scale": "128", "train_wall": "19", "wall": "13198"}
2021-10-23 21:18:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-23 21:21:03 | INFO | valid | {"epoch": 29, "valid_loss": "3.696", "valid_nll_loss": "1.933", "valid_ppl": "3.82", "valid_bleu": "28.36", "valid_wps": "407.8", "valid_wpb": "226.2", "valid_bsz": "8", "valid_num_updates": "35522", "valid_best_bleu": "28.72"}
2021-10-23 21:21:03 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-23 21:21:09 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/scratch/unique/large/checkpoint_last.pt (epoch 29 @ 35522 updates, score 28.36) (writing took 6.3083945428952575 seconds)
2021-10-23 21:21:09 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2021-10-23 21:21:09 | INFO | train | {"epoch": 29, "train_loss": "2.395", "train_nll_loss": "0.509", "train_ppl": "1.42", "train_wps": "1379.6", "train_ups": "2.92", "train_wpb": "473.3", "train_bsz": "16", "train_num_updates": "35522", "train_lr": "4.8248e-05", "train_gnorm": "1.837", "train_loss_scale": "128", "train_train_wall": "240", "train_wall": "13378"}
2021-10-23 21:21:09 | INFO | fairseq_cli.train | begin training epoch 29
2021-10-23 21:21:25 | INFO | train_inner | {"epoch": 30, "update": 29.064, "loss": "2.344", "nll_loss": "0.453", "ppl": "1.37", "wps": "232.2", "ups": "0.51", "wpb": "456.8", "bsz": "15.9", "num_updates": "35600", "lr": "4.82441e-05", "gnorm": "1.705", "loss_scale": "128", "train_wall": "20", "wall": "13395"}
2021-10-23 21:21:45 | INFO | train_inner | {"epoch": 30, "update": 29.145, "loss": "2.326", "nll_loss": "0.433", "ppl": "1.35", "wps": "2249.1", "ups": "4.97", "wpb": "452.5", "bsz": "16", "num_updates": "35700", "lr": "4.82391e-05", "gnorm": "1.727", "loss_scale": "128", "train_wall": "20", "wall": "13415"}
2021-10-23 21:22:05 | INFO | train_inner | {"epoch": 30, "update": 29.227, "loss": "2.275", "nll_loss": "0.377", "ppl": "1.3", "wps": "2209.8", "ups": "5.1", "wpb": "433.6", "bsz": "16", "num_updates": "35800", "lr": "4.82341e-05", "gnorm": "1.79", "loss_scale": "128", "train_wall": "19", "wall": "13434"}
2021-10-23 21:22:26 | INFO | train_inner | {"epoch": 30, "update": 29.309, "loss": "2.452", "nll_loss": "0.574", "ppl": "1.49", "wps": "2479.4", "ups": "4.84", "wpb": "512.7", "bsz": "16", "num_updates": "35900", "lr": "4.82291e-05", "gnorm": "1.891", "loss_scale": "128", "train_wall": "20", "wall": "13455"}
2021-10-23 21:22:44 | INFO | train_inner | {"epoch": 30, "update": 29.39, "loss": "2.342", "nll_loss": "0.452", "ppl": "1.37", "wps": "2351.4", "ups": "5.3", "wpb": "443.8", "bsz": "16", "num_updates": "36000", "lr": "4.82241e-05", "gnorm": "1.777", "loss_scale": "128", "train_wall": "19", "wall": "13474"}
2021-10-23 21:23:04 | INFO | train_inner | {"epoch": 30, "update": 29.472, "loss": "2.436", "nll_loss": "0.557", "ppl": "1.47", "wps": "2734.2", "ups": "5.08", "wpb": "537.9", "bsz": "16", "num_updates": "36100", "lr": "4.82191e-05", "gnorm": "1.821", "loss_scale": "128", "train_wall": "19", "wall": "13494"}
2021-10-23 21:23:23 | INFO | train_inner | {"epoch": 30, "update": 29.553, "loss": "2.374", "nll_loss": "0.486", "ppl": "1.4", "wps": "2489.8", "ups": "5.38", "wpb": "462.7", "bsz": "16", "num_updates": "36200", "lr": "4.82141e-05", "gnorm": "1.89", "loss_scale": "128", "train_wall": "18", "wall": "13512"}
2021-10-23 21:23:42 | INFO | train_inner | {"epoch": 30, "update": 29.635, "loss": "2.412", "nll_loss": "0.53", "ppl": "1.44", "wps": "2410.6", "ups": "5.26", "wpb": "458.1", "bsz": "16", "num_updates": "36300", "lr": "4.82091e-05", "gnorm": "1.855", "loss_scale": "128", "train_wall": "19", "wall": "13531"}
2021-10-23 21:24:02 | INFO | train_inner | {"epoch": 30, "update": 29.717, "loss": "2.474", "nll_loss": "0.598", "ppl": "1.51", "wps": "2547.9", "ups": "4.91", "wpb": "519.4", "bsz": "16", "num_updates": "36400", "lr": "4.82041e-05", "gnorm": "1.801", "loss_scale": "128", "train_wall": "20", "wall": "13551"}
2021-10-23 21:24:23 | INFO | train_inner | {"epoch": 30, "update": 29.798, "loss": "2.421", "nll_loss": "0.539", "ppl": "1.45", "wps": "2310.7", "ups": "4.74", "wpb": "487.3", "bsz": "16", "num_updates": "36500", "lr": "4.81991e-05", "gnorm": "1.789", "loss_scale": "128", "train_wall": "21", "wall": "13573"}
2021-10-23 21:24:40 | INFO | train_inner | {"epoch": 30, "update": 29.88, "loss": "2.294", "nll_loss": "0.398", "ppl": "1.32", "wps": "2568.8", "ups": "5.91", "wpb": "434.8", "bsz": "16", "num_updates": "36600", "lr": "4.81941e-05", "gnorm": "1.807", "loss_scale": "128", "train_wall": "17", "wall": "13589"}
2021-10-23 21:25:01 | INFO | train_inner | {"epoch": 30, "update": 29.962, "loss": "2.308", "nll_loss": "0.413", "ppl": "1.33", "wps": "2252.5", "ups": "4.82", "wpb": "467.1", "bsz": "16", "num_updates": "36700", "lr": "4.81891e-05", "gnorm": "1.812", "loss_scale": "128", "train_wall": "20", "wall": "13610"}
2021-10-23 21:25:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-23 21:28:08 | INFO | valid | {"epoch": 30, "valid_loss": "3.684", "valid_nll_loss": "1.917", "valid_ppl": "3.78", "valid_bleu": "29.22", "valid_wps": "389.1", "valid_wpb": "226.2", "valid_bsz": "8", "valid_num_updates": "36747", "valid_best_bleu": "29.22"}
2021-10-23 21:28:08 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-23 21:28:31 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/scratch/unique/large/checkpoint_best.pt (epoch 30 @ 36747 updates, score 29.22) (writing took 23.57964006299153 seconds)
2021-10-23 21:28:31 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2021-10-23 21:28:31 | INFO | train | {"epoch": 30, "train_loss": "2.378", "train_nll_loss": "0.491", "train_ppl": "1.41", "train_wps": "1310.4", "train_ups": "2.77", "train_wpb": "473.3", "train_bsz": "16", "train_num_updates": "36747", "train_lr": "4.81867e-05", "train_gnorm": "1.81", "train_loss_scale": "128", "train_train_wall": "237", "train_wall": "13821"}
2021-10-23 21:28:31 | INFO | fairseq_cli.train | done training in 13820.7 seconds
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
Source: source Target: target


2021-10-23 22:30:10 | INFO | fairseq_cli.train | Namespace(activation_fn='gelu', adam_betas='(0.9, 0.98)', adam_eps=1e-06, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='mbart_base', attention_dropout=0.1, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_suffix='', clip_norm=0.0, cpu=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='../processed_data/large/data-bin', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', decoder_attention_heads=12, decoder_embed_dim=768, decoder_embed_path=None, decoder_ffn_embed_dim=3072, decoder_input_dim=768, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=True, decoder_normalize_before=False, decoder_output_dim=768, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', dropout=0.1, empty_cache_freq=0, encoder_attention_heads=12, encoder_embed_dim=768, encoder_embed_path=None, encoder_ffn_embed_dim=3072, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=False, end_learning_rate=0.0, eval_bleu=True, eval_bleu_args='{"beam": 5}', eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.1, langs='java,python,en_XX', layernorm_embedding=True, left_pad_source='True', left_pad_target='False', load_alignments=False, localsgd_frequency=3, log_format='json', log_interval=100, lr=[5e-05], lr_scheduler='polynomial_decay', max_epoch=3000, max_sentences=8, max_sentences_valid=8, max_source_positions=1024, max_target_positions=1024, max_tokens=None, max_tokens_valid=None, max_update=100000, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=-1.0, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_workers=1, optimizer='adam', optimizer_overrides='{}', patience=10, pooler_activation_fn='tanh', pooler_dropout=0.0, power=1.0, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, relu_dropout=0.0, required_batch_size_multiple=8, reset_dataloader=True, reset_lr_scheduler=True, reset_meters=True, reset_optimizer=True, restore_file='../models/scratch/unique/large/checkpoint_last.pt', save_dir='../models/scratch/unique/large', save_interval=1, save_interval_updates=0, seed=1234, sentence_avg=False, share_all_embeddings=True, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='source', stop_time_hours=0, target_lang='target', task='translation_without_lang_token', tensorboard_logdir='', threshold_loss_scale=None, tokenizer=None, total_num_update=1000000, tpu=False, train_subset='train', truncate_source=True, update_freq=[2], upsample_primary=1, use_bmuf=False, use_old_adam=False, user_dir='../user_dir', valid_subset='valid', validate_interval=1, warmup_updates=500, weight_decay=0.0)
2021-10-23 22:30:10 | INFO | fairseq.tasks.translation | [source] dictionary: 50001 types
2021-10-23 22:30:10 | INFO | fairseq.tasks.translation | [target] dictionary: 50001 types
2021-10-23 22:30:10 | INFO | fairseq.data.data_utils | loaded 2449 examples from: ../processed_data/large/data-bin/valid.source-target.source
2021-10-23 22:30:10 | INFO | fairseq.data.data_utils | loaded 2449 examples from: ../processed_data/large/data-bin/valid.source-target.target
2021-10-23 22:30:10 | INFO | fairseq.tasks.translation | ../processed_data/large/data-bin valid source-target 2449 examples
2021-10-23 22:30:16 | INFO | fairseq_cli.train | BARTModel(
  (encoder): TransformerEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(50005, 768, padding_idx=1)
    (embed_positions): LearnedPositionalEmbedding(1026, 768, padding_idx=1)
    (layernorm_embedding): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(50005, 768, padding_idx=1)
    (embed_positions): LearnedPositionalEmbedding(1026, 768, padding_idx=1)
    (layernorm_embedding): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=768, out_features=50005, bias=False)
  )
  (classification_heads): ModuleDict()
)
2021-10-23 22:30:16 | INFO | fairseq_cli.train | model mbart_base, criterion LabelSmoothedCrossEntropyCriterion
2021-10-23 22:30:16 | INFO | fairseq_cli.train | num. model params: 139220736 (num. trained: 139220736)
2021-10-23 22:30:20 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight
2021-10-23 22:30:20 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight
2021-10-23 22:30:20 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2021-10-23 22:30:20 | INFO | fairseq.utils | rank   0: capabilities =  6.1  ; total memory = 12.000 GB ; name = GRID P40-12Q                            
2021-10-23 22:30:20 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2021-10-23 22:30:20 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2021-10-23 22:30:20 | INFO | fairseq_cli.train | max tokens per GPU = None and max sentences per GPU = 8
2021-10-23 22:30:24 | INFO | fairseq.trainer | loaded checkpoint ../models/scratch/unique/large/checkpoint_last.pt (epoch 30 @ 0 updates)
2021-10-23 22:30:24 | INFO | fairseq.optim.adam | using FusedAdam
2021-10-23 22:30:24 | INFO | fairseq.trainer | loading train data for epoch 1
2021-10-23 22:30:24 | INFO | fairseq.data.data_utils | loaded 19590 examples from: ../processed_data/large/data-bin/train.source-target.source
2021-10-23 22:30:24 | INFO | fairseq.data.data_utils | loaded 19590 examples from: ../processed_data/large/data-bin/train.source-target.target
2021-10-23 22:30:24 | INFO | fairseq.tasks.translation | ../processed_data/large/data-bin train source-target 19590 examples
2021-10-23 22:30:25 | INFO | fairseq_cli.train | begin training epoch 1
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
2021-10-23 22:30:42 | INFO | train_inner | {"epoch": 1, "update": 0.082, "loss": "2.322", "nll_loss": "0.425", "ppl": "1.34", "wps": "2592.9", "ups": "5.81", "wpb": "446.2", "bsz": "16", "num_updates": "100", "lr": "1e-05", "gnorm": "1.654", "train_wall": "18", "wall": "23"}
2021-10-23 22:30:59 | INFO | train_inner | {"epoch": 1, "update": 0.163, "loss": "2.34", "nll_loss": "0.451", "ppl": "1.37", "wps": "2575.9", "ups": "5.87", "wpb": "439", "bsz": "16", "num_updates": "200", "lr": "2e-05", "gnorm": "1.578", "train_wall": "17", "wall": "40"}
2021-10-23 22:31:17 | INFO | train_inner | {"epoch": 1, "update": 0.245, "loss": "2.314", "nll_loss": "0.425", "ppl": "1.34", "wps": "2833.2", "ups": "5.77", "wpb": "491.1", "bsz": "16", "num_updates": "300", "lr": "3e-05", "gnorm": "1.485", "train_wall": "17", "wall": "57"}
2021-10-23 22:31:34 | INFO | train_inner | {"epoch": 1, "update": 0.327, "loss": "2.264", "nll_loss": "0.367", "ppl": "1.29", "wps": "2475.2", "ups": "5.84", "wpb": "423.5", "bsz": "16", "num_updates": "400", "lr": "4e-05", "gnorm": "1.54", "train_wall": "17", "wall": "74"}
2021-10-23 22:31:52 | INFO | train_inner | {"epoch": 1, "update": 0.408, "loss": "2.355", "nll_loss": "0.467", "ppl": "1.38", "wps": "2901.3", "ups": "5.58", "wpb": "520.4", "bsz": "16", "num_updates": "500", "lr": "5e-05", "gnorm": "1.577", "train_wall": "18", "wall": "92"}
2021-10-23 22:32:08 | INFO | train_inner | {"epoch": 1, "update": 0.49, "loss": "2.427", "nll_loss": "0.547", "ppl": "1.46", "wps": "2955.1", "ups": "6.04", "wpb": "489.3", "bsz": "16", "num_updates": "600", "lr": "4.9995e-05", "gnorm": "1.741", "train_wall": "16", "wall": "109"}
2021-10-23 22:32:26 | INFO | train_inner | {"epoch": 1, "update": 0.571, "loss": "2.454", "nll_loss": "0.577", "ppl": "1.49", "wps": "2741.4", "ups": "5.66", "wpb": "484.1", "bsz": "16", "num_updates": "700", "lr": "4.999e-05", "gnorm": "1.78", "train_wall": "17", "wall": "126"}
2021-10-23 22:32:43 | INFO | train_inner | {"epoch": 1, "update": 0.653, "loss": "2.28", "nll_loss": "0.383", "ppl": "1.3", "wps": "2659.6", "ups": "5.75", "wpb": "462.9", "bsz": "16", "num_updates": "800", "lr": "4.9985e-05", "gnorm": "1.797", "train_wall": "17", "wall": "144"}
2021-10-23 22:33:02 | INFO | train_inner | {"epoch": 1, "update": 0.735, "loss": "2.427", "nll_loss": "0.547", "ppl": "1.46", "wps": "2683.8", "ups": "5.42", "wpb": "494.7", "bsz": "16", "num_updates": "900", "lr": "4.998e-05", "gnorm": "1.785", "train_wall": "18", "wall": "162"}
2021-10-23 22:33:19 | INFO | train_inner | {"epoch": 1, "update": 0.816, "loss": "2.324", "nll_loss": "0.433", "ppl": "1.35", "wps": "2666.8", "ups": "5.77", "wpb": "461.9", "bsz": "16", "num_updates": "1000", "lr": "4.9975e-05", "gnorm": "1.795", "train_wall": "17", "wall": "180"}
Source: source Target: target


2021-10-23 22:34:07 | INFO | fairseq_cli.train | Namespace(activation_fn='gelu', adam_betas='(0.9, 0.98)', adam_eps=1e-06, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='mbart_base', attention_dropout=0.1, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_suffix='', clip_norm=0.0, cpu=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='../processed_data/large/data-bin', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', decoder_attention_heads=12, decoder_embed_dim=768, decoder_embed_path=None, decoder_ffn_embed_dim=3072, decoder_input_dim=768, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=True, decoder_normalize_before=False, decoder_output_dim=768, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', dropout=0.1, empty_cache_freq=0, encoder_attention_heads=12, encoder_embed_dim=768, encoder_embed_path=None, encoder_ffn_embed_dim=3072, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=False, end_learning_rate=0.0, eval_bleu=True, eval_bleu_args='{"beam": 5}', eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=True, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.1, langs='java,python,en_XX', layernorm_embedding=True, left_pad_source='True', left_pad_target='False', load_alignments=False, localsgd_frequency=3, log_format='json', log_interval=100, lr=[5e-05], lr_scheduler='polynomial_decay', max_epoch=3000, max_sentences=8, max_sentences_valid=8, max_source_positions=1024, max_target_positions=1024, max_tokens=None, max_tokens_valid=None, max_update=100000, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=-1.0, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_workers=1, optimizer='adam', optimizer_overrides='{}', patience=10, pooler_activation_fn='tanh', pooler_dropout=0.0, power=1.0, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, relu_dropout=0.0, required_batch_size_multiple=8, reset_dataloader=True, reset_lr_scheduler=True, reset_meters=True, reset_optimizer=True, restore_file='../models/scratch/unique/large/checkpoint_last.pt', save_dir='../models/scratch/unique/large', save_interval=1, save_interval_updates=0, seed=1234, sentence_avg=False, share_all_embeddings=True, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='source', stop_time_hours=0, target_lang='target', task='translation_without_lang_token', tensorboard_logdir='', threshold_loss_scale=None, tokenizer=None, total_num_update=1000000, tpu=False, train_subset='train', truncate_source=True, update_freq=[2], upsample_primary=1, use_bmuf=False, use_old_adam=False, user_dir='../user_dir', valid_subset='valid', validate_interval=1, warmup_updates=500, weight_decay=0.0)
2021-10-23 22:34:07 | INFO | fairseq.tasks.translation | [source] dictionary: 50001 types
2021-10-23 22:34:07 | INFO | fairseq.tasks.translation | [target] dictionary: 50001 types
2021-10-23 22:34:07 | INFO | fairseq.data.data_utils | loaded 2449 examples from: ../processed_data/large/data-bin/valid.source-target.source
2021-10-23 22:34:07 | INFO | fairseq.data.data_utils | loaded 2449 examples from: ../processed_data/large/data-bin/valid.source-target.target
2021-10-23 22:34:07 | INFO | fairseq.tasks.translation | ../processed_data/large/data-bin valid source-target 2449 examples
2021-10-23 22:34:13 | INFO | fairseq_cli.train | BARTModel(
  (encoder): TransformerEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(50005, 768, padding_idx=1)
    (embed_positions): LearnedPositionalEmbedding(1026, 768, padding_idx=1)
    (layernorm_embedding): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(50005, 768, padding_idx=1)
    (embed_positions): LearnedPositionalEmbedding(1026, 768, padding_idx=1)
    (layernorm_embedding): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=768, out_features=50005, bias=False)
  )
  (classification_heads): ModuleDict()
)
2021-10-23 22:34:13 | INFO | fairseq_cli.train | model mbart_base, criterion LabelSmoothedCrossEntropyCriterion
2021-10-23 22:34:13 | INFO | fairseq_cli.train | num. model params: 139220736 (num. trained: 139220736)
2021-10-23 22:34:16 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight
2021-10-23 22:34:16 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight
2021-10-23 22:34:16 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2021-10-23 22:34:16 | INFO | fairseq.utils | rank   0: capabilities =  6.1  ; total memory = 12.000 GB ; name = GRID P40-12Q                            
2021-10-23 22:34:16 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2021-10-23 22:34:16 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2021-10-23 22:34:16 | INFO | fairseq_cli.train | max tokens per GPU = None and max sentences per GPU = 8
2021-10-23 22:34:21 | INFO | fairseq.trainer | loaded checkpoint ../models/scratch/unique/large/checkpoint_last.pt (epoch 30 @ 0 updates)
2021-10-23 22:34:21 | INFO | fairseq.trainer | NOTE: your device does NOT support faster training with --fp16, please switch to FP32 which is likely to be faster
2021-10-23 22:34:21 | INFO | fairseq.optim.adam | using FusedAdam
2021-10-23 22:34:21 | INFO | fairseq.trainer | loading train data for epoch 1
2021-10-23 22:34:21 | INFO | fairseq.data.data_utils | loaded 19590 examples from: ../processed_data/large/data-bin/train.source-target.source
2021-10-23 22:34:21 | INFO | fairseq.data.data_utils | loaded 19590 examples from: ../processed_data/large/data-bin/train.source-target.target
2021-10-23 22:34:21 | INFO | fairseq.tasks.translation | ../processed_data/large/data-bin train source-target 19590 examples
2021-10-23 22:34:21 | INFO | fairseq_cli.train | begin training epoch 1
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
2021-10-23 22:34:39 | INFO | train_inner | {"epoch": 1, "update": 0.082, "loss": "2.323", "nll_loss": "0.425", "ppl": "1.34", "wps": "2537.7", "ups": "5.68", "wpb": "446.2", "bsz": "16", "num_updates": "100", "lr": "1e-05", "gnorm": "1.655", "loss_scale": "128", "train_wall": "18", "wall": "23"}
2021-10-23 22:34:57 | INFO | train_inner | {"epoch": 1, "update": 0.163, "loss": "2.34", "nll_loss": "0.451", "ppl": "1.37", "wps": "2518.7", "ups": "5.74", "wpb": "439", "bsz": "16", "num_updates": "200", "lr": "2e-05", "gnorm": "1.578", "loss_scale": "128", "train_wall": "17", "wall": "41"}
2021-10-23 22:35:14 | INFO | train_inner | {"epoch": 1, "update": 0.245, "loss": "2.314", "nll_loss": "0.425", "ppl": "1.34", "wps": "2858.4", "ups": "5.82", "wpb": "491.1", "bsz": "16", "num_updates": "300", "lr": "3e-05", "gnorm": "1.485", "loss_scale": "128", "train_wall": "17", "wall": "58"}
2021-10-23 22:35:31 | INFO | train_inner | {"epoch": 1, "update": 0.327, "loss": "2.264", "nll_loss": "0.367", "ppl": "1.29", "wps": "2446.5", "ups": "5.78", "wpb": "423.5", "bsz": "16", "num_updates": "400", "lr": "4e-05", "gnorm": "1.54", "loss_scale": "128", "train_wall": "17", "wall": "75"}
2021-10-23 22:35:49 | INFO | train_inner | {"epoch": 1, "update": 0.408, "loss": "2.355", "nll_loss": "0.467", "ppl": "1.38", "wps": "2890", "ups": "5.55", "wpb": "520.4", "bsz": "16", "num_updates": "500", "lr": "5e-05", "gnorm": "1.578", "loss_scale": "128", "train_wall": "18", "wall": "93"}
2021-10-23 22:36:07 | INFO | train_inner | {"epoch": 1, "update": 0.49, "loss": "2.427", "nll_loss": "0.547", "ppl": "1.46", "wps": "2786.2", "ups": "5.69", "wpb": "489.3", "bsz": "16", "num_updates": "600", "lr": "4.9995e-05", "gnorm": "1.742", "loss_scale": "128", "train_wall": "17", "wall": "111"}
2021-10-23 22:36:24 | INFO | train_inner | {"epoch": 1, "update": 0.571, "loss": "2.454", "nll_loss": "0.577", "ppl": "1.49", "wps": "2768.4", "ups": "5.72", "wpb": "484.1", "bsz": "16", "num_updates": "700", "lr": "4.999e-05", "gnorm": "1.78", "loss_scale": "128", "train_wall": "17", "wall": "128"}
2021-10-23 22:36:42 | INFO | train_inner | {"epoch": 1, "update": 0.653, "loss": "2.28", "nll_loss": "0.383", "ppl": "1.3", "wps": "2584.4", "ups": "5.58", "wpb": "462.9", "bsz": "16", "num_updates": "800", "lr": "4.9985e-05", "gnorm": "1.797", "loss_scale": "128", "train_wall": "18", "wall": "146"}
2021-10-23 22:37:01 | INFO | train_inner | {"epoch": 1, "update": 0.735, "loss": "2.427", "nll_loss": "0.547", "ppl": "1.46", "wps": "2660.3", "ups": "5.38", "wpb": "494.7", "bsz": "16", "num_updates": "900", "lr": "4.998e-05", "gnorm": "1.784", "loss_scale": "128", "train_wall": "18", "wall": "165"}
2021-10-23 22:37:18 | INFO | train_inner | {"epoch": 1, "update": 0.816, "loss": "2.324", "nll_loss": "0.433", "ppl": "1.35", "wps": "2693.2", "ups": "5.83", "wpb": "461.9", "bsz": "16", "num_updates": "1000", "lr": "4.9975e-05", "gnorm": "1.796", "loss_scale": "128", "train_wall": "17", "wall": "182"}
2021-10-23 22:37:35 | INFO | train_inner | {"epoch": 1, "update": 0.898, "loss": "2.368", "nll_loss": "0.479", "ppl": "1.39", "wps": "2841.8", "ups": "5.79", "wpb": "490.7", "bsz": "16", "num_updates": "1100", "lr": "4.997e-05", "gnorm": "1.84", "loss_scale": "128", "train_wall": "17", "wall": "199"}
2021-10-23 22:37:53 | INFO | train_inner | {"epoch": 1, "update": 0.98, "loss": "2.331", "nll_loss": "0.439", "ppl": "1.36", "wps": "2847.2", "ups": "5.75", "wpb": "495.2", "bsz": "16", "num_updates": "1200", "lr": "4.9965e-05", "gnorm": "1.738", "loss_scale": "128", "train_wall": "17", "wall": "217"}
2021-10-23 22:37:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-23 22:40:46 | INFO | valid | {"epoch": 1, "valid_loss": "3.732", "valid_nll_loss": "1.984", "valid_ppl": "3.96", "valid_bleu": "28.16", "valid_wps": "411.2", "valid_wpb": "226.2", "valid_bsz": "8", "valid_num_updates": "1225"}
2021-10-23 22:40:46 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-23 22:41:15 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/scratch/unique/large/checkpoint_best.pt (epoch 1 @ 1225 updates, score 28.16) (writing took 28.400540755945258 seconds)
2021-10-23 22:41:15 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2021-10-23 22:41:15 | INFO | train | {"epoch": 1, "train_loss": "2.35", "train_nll_loss": "0.461", "train_ppl": "1.38", "train_wps": "1402.7", "train_ups": "2.96", "train_wpb": "473.3", "train_bsz": "16", "train_num_updates": "1225", "train_lr": "4.99637e-05", "train_gnorm": "1.693", "train_loss_scale": "128", "train_train_wall": "213", "train_wall": "419"}
2021-10-23 22:41:15 | INFO | fairseq_cli.train | begin training epoch 1
2021-10-23 22:41:29 | INFO | train_inner | {"epoch": 2, "update": 1.061, "loss": "2.423", "nll_loss": "0.543", "ppl": "1.46", "wps": "233.6", "ups": "0.46", "wpb": "506.2", "bsz": "15.9", "num_updates": "1300", "lr": "4.996e-05", "gnorm": "1.659", "loss_scale": "128", "train_wall": "18", "wall": "433"}
2021-10-23 22:41:46 | INFO | train_inner | {"epoch": 2, "update": 1.143, "loss": "2.342", "nll_loss": "0.453", "ppl": "1.37", "wps": "2965.4", "ups": "5.95", "wpb": "498.7", "bsz": "16", "num_updates": "1400", "lr": "4.9955e-05", "gnorm": "1.631", "loss_scale": "128", "train_wall": "17", "wall": "450"}
2021-10-23 22:42:02 | INFO | train_inner | {"epoch": 2, "update": 1.224, "loss": "2.328", "nll_loss": "0.438", "ppl": "1.35", "wps": "2728.6", "ups": "6.29", "wpb": "434", "bsz": "16", "num_updates": "1500", "lr": "4.995e-05", "gnorm": "1.664", "loss_scale": "128", "train_wall": "16", "wall": "466"}
2021-10-23 22:42:20 | INFO | train_inner | {"epoch": 2, "update": 1.306, "loss": "2.253", "nll_loss": "0.354", "ppl": "1.28", "wps": "2468.3", "ups": "5.63", "wpb": "438.8", "bsz": "16", "num_updates": "1600", "lr": "4.9945e-05", "gnorm": "1.634", "loss_scale": "128", "train_wall": "18", "wall": "484"}
2021-10-23 22:42:37 | INFO | train_inner | {"epoch": 2, "update": 1.388, "loss": "2.378", "nll_loss": "0.493", "ppl": "1.41", "wps": "2746", "ups": "5.68", "wpb": "483.7", "bsz": "16", "num_updates": "1700", "lr": "4.994e-05", "gnorm": "1.782", "loss_scale": "128", "train_wall": "17", "wall": "501"}
2021-10-23 22:42:56 | INFO | train_inner | {"epoch": 2, "update": 1.469, "loss": "2.353", "nll_loss": "0.464", "ppl": "1.38", "wps": "2831.9", "ups": "5.47", "wpb": "518", "bsz": "16", "num_updates": "1800", "lr": "4.9935e-05", "gnorm": "1.626", "loss_scale": "128", "train_wall": "18", "wall": "520"}
2021-10-23 22:43:13 | INFO | train_inner | {"epoch": 2, "update": 1.551, "loss": "2.287", "nll_loss": "0.394", "ppl": "1.31", "wps": "2371.1", "ups": "5.77", "wpb": "411", "bsz": "16", "num_updates": "1900", "lr": "4.993e-05", "gnorm": "1.684", "loss_scale": "128", "train_wall": "17", "wall": "537"}
2021-10-23 22:43:29 | INFO | train_inner | {"epoch": 2, "update": 1.633, "loss": "2.303", "nll_loss": "0.41", "ppl": "1.33", "wps": "2464", "ups": "6.07", "wpb": "405.8", "bsz": "16", "num_updates": "2000", "lr": "4.9925e-05", "gnorm": "1.812", "loss_scale": "128", "train_wall": "16", "wall": "553"}
2021-10-23 22:43:47 | INFO | train_inner | {"epoch": 2, "update": 1.714, "loss": "2.375", "nll_loss": "0.489", "ppl": "1.4", "wps": "2946", "ups": "5.77", "wpb": "510.4", "bsz": "16", "num_updates": "2100", "lr": "4.992e-05", "gnorm": "1.843", "loss_scale": "128", "train_wall": "17", "wall": "571"}
2021-10-23 22:44:05 | INFO | train_inner | {"epoch": 2, "update": 1.796, "loss": "2.48", "nll_loss": "0.607", "ppl": "1.52", "wps": "3053.1", "ups": "5.5", "wpb": "554.9", "bsz": "16", "num_updates": "2200", "lr": "4.9915e-05", "gnorm": "1.796", "loss_scale": "128", "train_wall": "18", "wall": "589"}
2021-10-23 22:44:23 | INFO | train_inner | {"epoch": 2, "update": 1.878, "loss": "2.378", "nll_loss": "0.492", "ppl": "1.41", "wps": "2781", "ups": "5.49", "wpb": "506.1", "bsz": "16", "num_updates": "2300", "lr": "4.991e-05", "gnorm": "1.796", "loss_scale": "128", "train_wall": "18", "wall": "607"}
2021-10-23 22:44:41 | INFO | train_inner | {"epoch": 2, "update": 1.959, "loss": "2.3", "nll_loss": "0.407", "ppl": "1.33", "wps": "2529.3", "ups": "5.68", "wpb": "445.7", "bsz": "16", "num_updates": "2400", "lr": "4.9905e-05", "gnorm": "1.779", "loss_scale": "128", "train_wall": "17", "wall": "625"}
2021-10-23 22:44:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-23 22:47:50 | INFO | valid | {"epoch": 2, "valid_loss": "3.696", "valid_nll_loss": "1.93", "valid_ppl": "3.81", "valid_bleu": "28.19", "valid_wps": "382.8", "valid_wpb": "226.2", "valid_bsz": "8", "valid_num_updates": "2450", "valid_best_bleu": "28.19"}
2021-10-23 22:47:50 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-23 22:48:13 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/scratch/unique/large/checkpoint_best.pt (epoch 2 @ 2450 updates, score 28.19) (writing took 23.248296344070695 seconds)
2021-10-23 22:48:13 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2021-10-23 22:48:13 | INFO | train | {"epoch": 2, "train_loss": "2.354", "train_nll_loss": "0.466", "train_ppl": "1.38", "train_wps": "1384.8", "train_ups": "2.93", "train_wpb": "473.3", "train_bsz": "16", "train_num_updates": "2450", "train_lr": "4.99025e-05", "train_gnorm": "1.733", "train_loss_scale": "128", "train_train_wall": "211", "train_wall": "837"}
2021-10-23 22:48:13 | INFO | fairseq_cli.train | begin training epoch 2
2021-10-23 22:48:22 | INFO | train_inner | {"epoch": 3, "update": 2.041, "loss": "2.24", "nll_loss": "0.341", "ppl": "1.27", "wps": "178.9", "ups": "0.45", "wpb": "395.4", "bsz": "15.9", "num_updates": "2500", "lr": "4.98999e-05", "gnorm": "1.817", "loss_scale": "128", "train_wall": "16", "wall": "846"}
2021-10-23 22:48:40 | INFO | train_inner | {"epoch": 3, "update": 2.122, "loss": "2.355", "nll_loss": "0.467", "ppl": "1.38", "wps": "2522.8", "ups": "5.51", "wpb": "457.9", "bsz": "16", "num_updates": "2600", "lr": "4.98949e-05", "gnorm": "1.712", "loss_scale": "128", "train_wall": "18", "wall": "864"}
2021-10-23 22:48:57 | INFO | train_inner | {"epoch": 3, "update": 2.204, "loss": "2.377", "nll_loss": "0.493", "ppl": "1.41", "wps": "2730", "ups": "5.7", "wpb": "478.6", "bsz": "16", "num_updates": "2700", "lr": "4.98899e-05", "gnorm": "1.679", "loss_scale": "128", "train_wall": "17", "wall": "882"}
2021-10-23 22:49:16 | INFO | train_inner | {"epoch": 3, "update": 2.286, "loss": "2.438", "nll_loss": "0.562", "ppl": "1.48", "wps": "2670.8", "ups": "5.29", "wpb": "504.9", "bsz": "16", "num_updates": "2800", "lr": "4.98849e-05", "gnorm": "1.685", "loss_scale": "128", "train_wall": "19", "wall": "900"}
2021-10-23 22:49:35 | INFO | train_inner | {"epoch": 3, "update": 2.367, "loss": "2.258", "nll_loss": "0.362", "ppl": "1.28", "wps": "2330.1", "ups": "5.46", "wpb": "426.5", "bsz": "16", "num_updates": "2900", "lr": "4.98799e-05", "gnorm": "1.644", "loss_scale": "128", "train_wall": "18", "wall": "919"}
2021-10-23 22:49:54 | INFO | train_inner | {"epoch": 3, "update": 2.449, "loss": "2.421", "nll_loss": "0.543", "ppl": "1.46", "wps": "2791.3", "ups": "5.25", "wpb": "532", "bsz": "16", "num_updates": "3000", "lr": "4.98749e-05", "gnorm": "1.679", "loss_scale": "128", "train_wall": "19", "wall": "938"}
2021-10-23 22:50:11 | INFO | train_inner | {"epoch": 3, "update": 2.531, "loss": "2.242", "nll_loss": "0.342", "ppl": "1.27", "wps": "2444.1", "ups": "5.65", "wpb": "432.2", "bsz": "16", "num_updates": "3100", "lr": "4.98699e-05", "gnorm": "1.734", "loss_scale": "128", "train_wall": "17", "wall": "955"}
2021-10-23 22:50:30 | INFO | train_inner | {"epoch": 3, "update": 2.612, "loss": "2.318", "nll_loss": "0.424", "ppl": "1.34", "wps": "2648", "ups": "5.5", "wpb": "481.1", "bsz": "16", "num_updates": "3200", "lr": "4.98649e-05", "gnorm": "1.758", "loss_scale": "128", "train_wall": "18", "wall": "974"}
2021-10-23 22:50:47 | INFO | train_inner | {"epoch": 3, "update": 2.694, "loss": "2.307", "nll_loss": "0.417", "ppl": "1.33", "wps": "2575.4", "ups": "5.72", "wpb": "450.3", "bsz": "16", "num_updates": "3300", "lr": "4.98599e-05", "gnorm": "1.65", "loss_scale": "128", "train_wall": "17", "wall": "991"}
2021-10-23 22:51:06 | INFO | train_inner | {"epoch": 3, "update": 2.776, "loss": "2.311", "nll_loss": "0.418", "ppl": "1.34", "wps": "2372.5", "ups": "5.43", "wpb": "436.8", "bsz": "16", "num_updates": "3400", "lr": "4.98549e-05", "gnorm": "1.624", "loss_scale": "128", "train_wall": "18", "wall": "1010"}
2021-10-23 22:51:24 | INFO | train_inner | {"epoch": 3, "update": 2.857, "loss": "2.37", "nll_loss": "0.485", "ppl": "1.4", "wps": "2803.5", "ups": "5.29", "wpb": "530", "bsz": "16", "num_updates": "3500", "lr": "4.98499e-05", "gnorm": "1.662", "loss_scale": "128", "train_wall": "19", "wall": "1028"}
2021-10-23 22:51:41 | INFO | train_inner | {"epoch": 3, "update": 2.939, "loss": "2.443", "nll_loss": "0.568", "ppl": "1.48", "wps": "3020.4", "ups": "5.99", "wpb": "504.1", "bsz": "16", "num_updates": "3600", "lr": "4.98449e-05", "gnorm": "1.769", "loss_scale": "128", "train_wall": "17", "wall": "1045"}
2021-10-23 22:51:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-23 22:54:48 | INFO | valid | {"epoch": 3, "valid_loss": "3.694", "valid_nll_loss": "1.947", "valid_ppl": "3.86", "valid_bleu": "28.65", "valid_wps": "400.3", "valid_wpb": "226.2", "valid_bsz": "8", "valid_num_updates": "3675", "valid_best_bleu": "28.65"}
2021-10-23 22:54:48 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-23 22:54:57 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/scratch/unique/large/checkpoint_best.pt (epoch 3 @ 3675 updates, score 28.65) (writing took 9.884434291045181 seconds)
2021-10-23 22:54:57 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2021-10-23 22:54:57 | INFO | train | {"epoch": 3, "train_loss": "2.347", "train_nll_loss": "0.46", "train_ppl": "1.38", "train_wps": "1435.3", "train_ups": "3.03", "train_wpb": "473.3", "train_bsz": "16", "train_num_updates": "3675", "train_lr": "4.98412e-05", "train_gnorm": "1.693", "train_loss_scale": "128", "train_train_wall": "218", "train_wall": "1241"}
2021-10-23 22:54:57 | INFO | fairseq_cli.train | begin training epoch 3
2021-10-23 22:55:02 | INFO | train_inner | {"epoch": 4, "update": 3.02, "loss": "2.326", "nll_loss": "0.434", "ppl": "1.35", "wps": "228.1", "ups": "0.5", "wpb": "457.7", "bsz": "15.9", "num_updates": "3700", "lr": "4.98399e-05", "gnorm": "1.687", "loss_scale": "128", "train_wall": "17", "wall": "1246"}
2021-10-23 22:55:20 | INFO | train_inner | {"epoch": 4, "update": 3.102, "loss": "2.265", "nll_loss": "0.37", "ppl": "1.29", "wps": "2337.8", "ups": "5.42", "wpb": "431.2", "bsz": "16", "num_updates": "3800", "lr": "4.98349e-05", "gnorm": "1.599", "loss_scale": "128", "train_wall": "18", "wall": "1264"}
2021-10-23 22:55:40 | INFO | train_inner | {"epoch": 4, "update": 3.184, "loss": "2.325", "nll_loss": "0.435", "ppl": "1.35", "wps": "2366.5", "ups": "5.18", "wpb": "456.9", "bsz": "16", "num_updates": "3900", "lr": "4.98299e-05", "gnorm": "1.564", "loss_scale": "128", "train_wall": "19", "wall": "1284"}
2021-10-23 22:55:59 | INFO | train_inner | {"epoch": 4, "update": 3.265, "loss": "2.375", "nll_loss": "0.492", "ppl": "1.41", "wps": "2434.3", "ups": "5.02", "wpb": "485.1", "bsz": "16", "num_updates": "4000", "lr": "4.98249e-05", "gnorm": "1.66", "loss_scale": "128", "train_wall": "20", "wall": "1304"}
2021-10-23 22:56:18 | INFO | train_inner | {"epoch": 4, "update": 3.347, "loss": "2.294", "nll_loss": "0.4", "ppl": "1.32", "wps": "2734.6", "ups": "5.37", "wpb": "509.5", "bsz": "16", "num_updates": "4100", "lr": "4.98199e-05", "gnorm": "1.566", "loss_scale": "128", "train_wall": "18", "wall": "1322"}
2021-10-23 22:56:37 | INFO | train_inner | {"epoch": 4, "update": 3.429, "loss": "2.382", "nll_loss": "0.498", "ppl": "1.41", "wps": "2770.8", "ups": "5.19", "wpb": "534.2", "bsz": "16", "num_updates": "4200", "lr": "4.98149e-05", "gnorm": "1.633", "loss_scale": "128", "train_wall": "19", "wall": "1341"}
2021-10-23 22:56:55 | INFO | train_inner | {"epoch": 4, "update": 3.51, "loss": "2.425", "nll_loss": "0.548", "ppl": "1.46", "wps": "2668.4", "ups": "5.66", "wpb": "471.1", "bsz": "16", "num_updates": "4300", "lr": "4.98099e-05", "gnorm": "1.663", "loss_scale": "128", "train_wall": "17", "wall": "1359"}
2021-10-23 22:57:13 | INFO | train_inner | {"epoch": 4, "update": 3.592, "loss": "2.326", "nll_loss": "0.44", "ppl": "1.36", "wps": "2394.8", "ups": "5.47", "wpb": "438.1", "bsz": "16", "num_updates": "4400", "lr": "4.98049e-05", "gnorm": "1.651", "loss_scale": "128", "train_wall": "18", "wall": "1377"}
2021-10-23 22:57:31 | INFO | train_inner | {"epoch": 4, "update": 3.673, "loss": "2.239", "nll_loss": "0.339", "ppl": "1.27", "wps": "2462.6", "ups": "5.6", "wpb": "439.8", "bsz": "16", "num_updates": "4500", "lr": "4.97999e-05", "gnorm": "1.652", "loss_scale": "128", "train_wall": "18", "wall": "1395"}
2021-10-23 22:57:49 | INFO | train_inner | {"epoch": 4, "update": 3.755, "loss": "2.321", "nll_loss": "0.431", "ppl": "1.35", "wps": "2481.8", "ups": "5.64", "wpb": "440", "bsz": "16", "num_updates": "4600", "lr": "4.97949e-05", "gnorm": "1.675", "loss_scale": "128", "train_wall": "18", "wall": "1413"}
2021-10-23 22:58:08 | INFO | train_inner | {"epoch": 4, "update": 3.837, "loss": "2.31", "nll_loss": "0.42", "ppl": "1.34", "wps": "2622.6", "ups": "5.38", "wpb": "487.6", "bsz": "16", "num_updates": "4700", "lr": "4.97899e-05", "gnorm": "1.699", "loss_scale": "128", "train_wall": "18", "wall": "1432"}
2021-10-23 22:58:26 | INFO | train_inner | {"epoch": 4, "update": 3.918, "loss": "2.32", "nll_loss": "0.429", "ppl": "1.35", "wps": "2469.2", "ups": "5.52", "wpb": "447.5", "bsz": "16", "num_updates": "4800", "lr": "4.97849e-05", "gnorm": "1.681", "loss_scale": "128", "train_wall": "18", "wall": "1450"}
2021-10-23 22:58:44 | INFO | train_inner | {"epoch": 4, "update": 4.0, "loss": "2.351", "nll_loss": "0.465", "ppl": "1.38", "wps": "2928.3", "ups": "5.33", "wpb": "549.4", "bsz": "15.9", "num_updates": "4900", "lr": "4.97799e-05", "gnorm": "1.614", "loss_scale": "128", "train_wall": "19", "wall": "1468"}
2021-10-23 22:58:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-23 23:01:39 | INFO | valid | {"epoch": 4, "valid_loss": "3.695", "valid_nll_loss": "1.943", "valid_ppl": "3.85", "valid_bleu": "30.17", "valid_wps": "399.1", "valid_wpb": "226.2", "valid_bsz": "8", "valid_num_updates": "4900", "valid_best_bleu": "30.17"}
2021-10-23 23:01:39 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-23 23:01:59 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/scratch/unique/large/checkpoint_best.pt (epoch 4 @ 4900 updates, score 30.17) (writing took 20.674468579003587 seconds)
2021-10-23 23:01:59 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2021-10-23 23:01:59 | INFO | train | {"epoch": 4, "train_loss": "2.329", "train_nll_loss": "0.441", "train_ppl": "1.36", "train_wps": "1373.9", "train_ups": "2.9", "train_wpb": "473.3", "train_bsz": "16", "train_num_updates": "4900", "train_lr": "4.97799e-05", "train_gnorm": "1.639", "train_loss_scale": "128", "train_train_wall": "224", "train_wall": "1663"}
2021-10-23 23:01:59 | INFO | fairseq_cli.train | begin training epoch 4
2021-10-23 23:02:19 | INFO | train_inner | {"epoch": 5, "update": 4.082, "loss": "2.376", "nll_loss": "0.493", "ppl": "1.41", "wps": "238.2", "ups": "0.47", "wpb": "510.1", "bsz": "16", "num_updates": "5000", "lr": "4.97749e-05", "gnorm": "1.572", "loss_scale": "128", "train_wall": "19", "wall": "1683"}
2021-10-23 23:02:36 | INFO | train_inner | {"epoch": 5, "update": 4.163, "loss": "2.284", "nll_loss": "0.391", "ppl": "1.31", "wps": "2476.5", "ups": "5.67", "wpb": "436.6", "bsz": "16", "num_updates": "5100", "lr": "4.97699e-05", "gnorm": "1.525", "loss_scale": "128", "train_wall": "17", "wall": "1700"}
2021-10-23 23:02:54 | INFO | train_inner | {"epoch": 5, "update": 4.245, "loss": "2.281", "nll_loss": "0.388", "ppl": "1.31", "wps": "2425", "ups": "5.59", "wpb": "434.1", "bsz": "16", "num_updates": "5200", "lr": "4.97649e-05", "gnorm": "1.567", "loss_scale": "128", "train_wall": "18", "wall": "1718"}
2021-10-23 23:03:14 | INFO | train_inner | {"epoch": 5, "update": 4.327, "loss": "2.381", "nll_loss": "0.499", "ppl": "1.41", "wps": "2627.9", "ups": "5.05", "wpb": "520.3", "bsz": "16", "num_updates": "5300", "lr": "4.97599e-05", "gnorm": "1.609", "loss_scale": "128", "train_wall": "20", "wall": "1738"}
2021-10-23 23:03:32 | INFO | train_inner | {"epoch": 5, "update": 4.408, "loss": "2.301", "nll_loss": "0.409", "ppl": "1.33", "wps": "2637.3", "ups": "5.41", "wpb": "487.1", "bsz": "16", "num_updates": "5400", "lr": "4.97549e-05", "gnorm": "1.626", "loss_scale": "128", "train_wall": "18", "wall": "1756"}
2021-10-23 23:03:50 | INFO | train_inner | {"epoch": 5, "update": 4.49, "loss": "2.264", "nll_loss": "0.37", "ppl": "1.29", "wps": "2286.5", "ups": "5.68", "wpb": "402.3", "bsz": "16", "num_updates": "5500", "lr": "4.97499e-05", "gnorm": "1.595", "loss_scale": "128", "train_wall": "17", "wall": "1774"}
2021-10-23 23:04:09 | INFO | train_inner | {"epoch": 5, "update": 4.571, "loss": "2.289", "nll_loss": "0.398", "ppl": "1.32", "wps": "2539.9", "ups": "5.34", "wpb": "476", "bsz": "16", "num_updates": "5600", "lr": "4.97449e-05", "gnorm": "1.586", "loss_scale": "128", "train_wall": "19", "wall": "1793"}
2021-10-23 23:04:27 | INFO | train_inner | {"epoch": 5, "update": 4.653, "loss": "2.306", "nll_loss": "0.416", "ppl": "1.33", "wps": "2577.1", "ups": "5.53", "wpb": "466", "bsz": "16", "num_updates": "5700", "lr": "4.97399e-05", "gnorm": "1.638", "loss_scale": "128", "train_wall": "18", "wall": "1811"}
2021-10-23 23:04:45 | INFO | train_inner | {"epoch": 5, "update": 4.735, "loss": "2.306", "nll_loss": "0.417", "ppl": "1.33", "wps": "2638.6", "ups": "5.58", "wpb": "473.2", "bsz": "16", "num_updates": "5800", "lr": "4.97349e-05", "gnorm": "1.685", "loss_scale": "128", "train_wall": "18", "wall": "1829"}
2021-10-23 23:05:03 | INFO | train_inner | {"epoch": 5, "update": 4.816, "loss": "2.379", "nll_loss": "0.498", "ppl": "1.41", "wps": "2781.6", "ups": "5.39", "wpb": "516.1", "bsz": "16", "num_updates": "5900", "lr": "4.97299e-05", "gnorm": "1.612", "loss_scale": "128", "train_wall": "18", "wall": "1847"}
2021-10-23 23:05:20 | INFO | train_inner | {"epoch": 5, "update": 4.898, "loss": "2.315", "nll_loss": "0.425", "ppl": "1.34", "wps": "2701.5", "ups": "5.82", "wpb": "464.1", "bsz": "16", "num_updates": "6000", "lr": "4.97249e-05", "gnorm": "1.663", "loss_scale": "128", "train_wall": "17", "wall": "1864"}
2021-10-23 23:05:38 | INFO | train_inner | {"epoch": 5, "update": 4.98, "loss": "2.271", "nll_loss": "0.378", "ppl": "1.3", "wps": "2667.5", "ups": "5.82", "wpb": "458.2", "bsz": "16", "num_updates": "6100", "lr": "4.97199e-05", "gnorm": "1.564", "loss_scale": "128", "train_wall": "17", "wall": "1882"}
2021-10-23 23:05:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-23 23:08:38 | INFO | valid | {"epoch": 5, "valid_loss": "3.7", "valid_nll_loss": "1.958", "valid_ppl": "3.89", "valid_bleu": "29.78", "valid_wps": "395.3", "valid_wpb": "226.2", "valid_bsz": "8", "valid_num_updates": "6125", "valid_best_bleu": "30.17"}
2021-10-23 23:08:38 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-23 23:08:45 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/scratch/unique/large/checkpoint_last.pt (epoch 5 @ 6125 updates, score 29.78) (writing took 6.1770812519825995 seconds)
2021-10-23 23:08:45 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2021-10-23 23:08:45 | INFO | train | {"epoch": 5, "train_loss": "2.318", "train_nll_loss": "0.429", "train_ppl": "1.35", "train_wps": "1431", "train_ups": "3.02", "train_wpb": "473.3", "train_bsz": "16", "train_num_updates": "6125", "train_lr": "4.97186e-05", "train_gnorm": "1.603", "train_loss_scale": "128", "train_train_wall": "221", "train_wall": "2069"}
2021-10-23 23:08:45 | INFO | fairseq_cli.train | begin training epoch 5
2021-10-23 23:08:58 | INFO | train_inner | {"epoch": 6, "update": 5.061, "loss": "2.298", "nll_loss": "0.407", "ppl": "1.33", "wps": "242.5", "ups": "0.5", "wpb": "485.2", "bsz": "15.9", "num_updates": "6200", "lr": "4.97149e-05", "gnorm": "1.643", "loss_scale": "128", "train_wall": "18", "wall": "2082"}
2021-10-23 23:09:17 | INFO | train_inner | {"epoch": 6, "update": 5.143, "loss": "2.379", "nll_loss": "0.498", "ppl": "1.41", "wps": "2652", "ups": "5.31", "wpb": "499.5", "bsz": "16", "num_updates": "6300", "lr": "4.97099e-05", "gnorm": "1.538", "loss_scale": "128", "train_wall": "19", "wall": "2101"}
2021-10-23 23:09:35 | INFO | train_inner | {"epoch": 6, "update": 5.224, "loss": "2.324", "nll_loss": "0.436", "ppl": "1.35", "wps": "2656.8", "ups": "5.33", "wpb": "498.6", "bsz": "16", "num_updates": "6400", "lr": "4.97049e-05", "gnorm": "1.512", "loss_scale": "128", "train_wall": "19", "wall": "2119"}
2021-10-23 23:09:53 | INFO | train_inner | {"epoch": 6, "update": 5.306, "loss": "2.229", "nll_loss": "0.332", "ppl": "1.26", "wps": "2267.4", "ups": "5.75", "wpb": "394.4", "bsz": "16", "num_updates": "6500", "lr": "4.96998e-05", "gnorm": "1.53", "loss_scale": "128", "train_wall": "17", "wall": "2137"}
2021-10-23 23:10:11 | INFO | train_inner | {"epoch": 6, "update": 5.388, "loss": "2.377", "nll_loss": "0.495", "ppl": "1.41", "wps": "2902.1", "ups": "5.35", "wpb": "542.3", "bsz": "16", "num_updates": "6600", "lr": "4.96948e-05", "gnorm": "1.614", "loss_scale": "128", "train_wall": "18", "wall": "2155"}
2021-10-23 23:10:30 | INFO | train_inner | {"epoch": 6, "update": 5.469, "loss": "2.278", "nll_loss": "0.386", "ppl": "1.31", "wps": "2605.4", "ups": "5.47", "wpb": "476.1", "bsz": "16", "num_updates": "6700", "lr": "4.96898e-05", "gnorm": "1.588", "loss_scale": "128", "train_wall": "18", "wall": "2174"}
2021-10-23 23:10:48 | INFO | train_inner | {"epoch": 6, "update": 5.551, "loss": "2.271", "nll_loss": "0.379", "ppl": "1.3", "wps": "2448.2", "ups": "5.39", "wpb": "454", "bsz": "16", "num_updates": "6800", "lr": "4.96848e-05", "gnorm": "1.579", "loss_scale": "128", "train_wall": "18", "wall": "2192"}
2021-10-23 23:11:08 | INFO | train_inner | {"epoch": 6, "update": 5.633, "loss": "2.27", "nll_loss": "0.376", "ppl": "1.3", "wps": "2368.6", "ups": "5.19", "wpb": "456.2", "bsz": "16", "num_updates": "6900", "lr": "4.96798e-05", "gnorm": "1.595", "loss_scale": "128", "train_wall": "19", "wall": "2212"}
2021-10-23 23:11:28 | INFO | train_inner | {"epoch": 6, "update": 5.714, "loss": "2.385", "nll_loss": "0.504", "ppl": "1.42", "wps": "2648.8", "ups": "4.96", "wpb": "534.2", "bsz": "16", "num_updates": "7000", "lr": "4.96748e-05", "gnorm": "1.586", "loss_scale": "128", "train_wall": "20", "wall": "2232"}
2021-10-23 23:11:46 | INFO | train_inner | {"epoch": 6, "update": 5.796, "loss": "2.279", "nll_loss": "0.387", "ppl": "1.31", "wps": "2306.5", "ups": "5.43", "wpb": "424.4", "bsz": "16", "num_updates": "7100", "lr": "4.96698e-05", "gnorm": "1.652", "loss_scale": "128", "train_wall": "18", "wall": "2250"}
2021-10-23 23:12:05 | INFO | train_inner | {"epoch": 6, "update": 5.878, "loss": "2.311", "nll_loss": "0.421", "ppl": "1.34", "wps": "2825.8", "ups": "5.16", "wpb": "548", "bsz": "16", "num_updates": "7200", "lr": "4.96648e-05", "gnorm": "1.554", "loss_scale": "128", "train_wall": "19", "wall": "2269"}
2021-10-23 23:12:24 | INFO | train_inner | {"epoch": 6, "update": 5.959, "loss": "2.265", "nll_loss": "0.374", "ppl": "1.3", "wps": "2154.4", "ups": "5.41", "wpb": "398.3", "bsz": "16", "num_updates": "7300", "lr": "4.96598e-05", "gnorm": "1.601", "loss_scale": "128", "train_wall": "18", "wall": "2288"}
2021-10-23 23:12:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-23 23:15:21 | INFO | valid | {"epoch": 6, "valid_loss": "3.7", "valid_nll_loss": "1.952", "valid_ppl": "3.87", "valid_bleu": "29.99", "valid_wps": "414.6", "valid_wpb": "226.2", "valid_bsz": "8", "valid_num_updates": "7350", "valid_best_bleu": "30.17"}
2021-10-23 23:15:21 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-23 23:15:27 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/scratch/unique/large/checkpoint_last.pt (epoch 6 @ 7350 updates, score 29.99) (writing took 5.913624961976893 seconds)
2021-10-23 23:15:27 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2021-10-23 23:15:27 | INFO | train | {"epoch": 6, "train_loss": "2.306", "train_nll_loss": "0.417", "train_ppl": "1.34", "train_wps": "1440.9", "train_ups": "3.04", "train_wpb": "473.3", "train_bsz": "16", "train_num_updates": "7350", "train_lr": "4.96573e-05", "train_gnorm": "1.584", "train_loss_scale": "128", "train_train_wall": "226", "train_wall": "2471"}
2021-10-23 23:15:27 | INFO | fairseq_cli.train | begin training epoch 6
2021-10-23 23:15:37 | INFO | train_inner | {"epoch": 7, "update": 6.041, "loss": "2.303", "nll_loss": "0.414", "ppl": "1.33", "wps": "251.1", "ups": "0.52", "wpb": "484.2", "bsz": "15.9", "num_updates": "7400", "lr": "4.96548e-05", "gnorm": "1.534", "loss_scale": "128", "train_wall": "19", "wall": "2481"}
2021-10-23 23:15:56 | INFO | train_inner | {"epoch": 7, "update": 6.122, "loss": "2.293", "nll_loss": "0.404", "ppl": "1.32", "wps": "2449.6", "ups": "5.31", "wpb": "461.1", "bsz": "16", "num_updates": "7500", "lr": "4.96498e-05", "gnorm": "1.517", "loss_scale": "128", "train_wall": "19", "wall": "2500"}
2021-10-23 23:16:13 | INFO | train_inner | {"epoch": 7, "update": 6.204, "loss": "2.201", "nll_loss": "0.301", "ppl": "1.23", "wps": "2289.3", "ups": "5.92", "wpb": "386.9", "bsz": "16", "num_updates": "7600", "lr": "4.96448e-05", "gnorm": "1.519", "loss_scale": "128", "train_wall": "17", "wall": "2517"}
2021-10-23 23:16:31 | INFO | train_inner | {"epoch": 7, "update": 6.286, "loss": "2.239", "nll_loss": "0.343", "ppl": "1.27", "wps": "2405.3", "ups": "5.43", "wpb": "442.8", "bsz": "16", "num_updates": "7700", "lr": "4.96398e-05", "gnorm": "1.581", "loss_scale": "128", "train_wall": "18", "wall": "2535"}
2021-10-23 23:16:50 | INFO | train_inner | {"epoch": 7, "update": 6.367, "loss": "2.261", "nll_loss": "0.367", "ppl": "1.29", "wps": "2581", "ups": "5.17", "wpb": "499.2", "bsz": "16", "num_updates": "7800", "lr": "4.96348e-05", "gnorm": "1.486", "loss_scale": "128", "train_wall": "19", "wall": "2554"}
2021-10-23 23:17:10 | INFO | train_inner | {"epoch": 7, "update": 6.449, "loss": "2.36", "nll_loss": "0.477", "ppl": "1.39", "wps": "2685.2", "ups": "5.06", "wpb": "531.1", "bsz": "16", "num_updates": "7900", "lr": "4.96298e-05", "gnorm": "1.537", "loss_scale": "128", "train_wall": "20", "wall": "2574"}
2021-10-23 23:17:29 | INFO | train_inner | {"epoch": 7, "update": 6.531, "loss": "2.302", "nll_loss": "0.413", "ppl": "1.33", "wps": "2567.1", "ups": "5.42", "wpb": "473.3", "bsz": "16", "num_updates": "8000", "lr": "4.96248e-05", "gnorm": "1.441", "loss_scale": "128", "train_wall": "18", "wall": "2593"}
2021-10-23 23:17:49 | INFO | train_inner | {"epoch": 7, "update": 6.612, "loss": "2.417", "nll_loss": "0.54", "ppl": "1.45", "wps": "2828.8", "ups": "4.92", "wpb": "575.3", "bsz": "16", "num_updates": "8100", "lr": "4.96198e-05", "gnorm": "1.526", "loss_scale": "128", "train_wall": "20", "wall": "2613"}
2021-10-23 23:18:08 | INFO | train_inner | {"epoch": 7, "update": 6.694, "loss": "2.281", "nll_loss": "0.39", "ppl": "1.31", "wps": "2480.3", "ups": "5.12", "wpb": "484.7", "bsz": "16", "num_updates": "8200", "lr": "4.96148e-05", "gnorm": "1.439", "loss_scale": "140", "train_wall": "19", "wall": "2632"}
2021-10-23 23:18:27 | INFO | train_inner | {"epoch": 7, "update": 6.776, "loss": "2.358", "nll_loss": "0.475", "ppl": "1.39", "wps": "2388.6", "ups": "5.43", "wpb": "440.3", "bsz": "16", "num_updates": "8300", "lr": "4.96098e-05", "gnorm": "1.772", "loss_scale": "256", "train_wall": "18", "wall": "2651"}
2021-10-23 23:18:46 | INFO | train_inner | {"epoch": 7, "update": 6.857, "loss": "2.251", "nll_loss": "0.354", "ppl": "1.28", "wps": "2517.7", "ups": "5.23", "wpb": "481", "bsz": "16", "num_updates": "8400", "lr": "4.96048e-05", "gnorm": "1.703", "loss_scale": "256", "train_wall": "19", "wall": "2670"}
2021-10-23 23:19:05 | INFO | train_inner | {"epoch": 7, "update": 6.939, "loss": "2.236", "nll_loss": "0.34", "ppl": "1.27", "wps": "2286.7", "ups": "5.37", "wpb": "426.2", "bsz": "16", "num_updates": "8500", "lr": "4.95998e-05", "gnorm": "1.7", "loss_scale": "256", "train_wall": "18", "wall": "2689"}
2021-10-23 23:19:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-23 23:22:08 | INFO | valid | {"epoch": 7, "valid_loss": "3.707", "valid_nll_loss": "1.956", "valid_ppl": "3.88", "valid_bleu": "29.04", "valid_wps": "410", "valid_wpb": "226.2", "valid_bsz": "8", "valid_num_updates": "8575", "valid_best_bleu": "30.17"}
2021-10-23 23:22:08 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-23 23:22:14 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/scratch/unique/large/checkpoint_last.pt (epoch 7 @ 8575 updates, score 29.04) (writing took 5.962120068958029 seconds)
2021-10-23 23:22:14 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2021-10-23 23:22:14 | INFO | train | {"epoch": 7, "train_loss": "2.3", "train_nll_loss": "0.41", "train_ppl": "1.33", "train_wps": "1425.2", "train_ups": "3.01", "train_wpb": "473.3", "train_bsz": "16", "train_num_updates": "8575", "train_lr": "4.9596e-05", "train_gnorm": "1.568", "train_loss_scale": "168", "train_train_wall": "229", "train_wall": "2878"}
2021-10-23 23:22:14 | INFO | fairseq_cli.train | begin training epoch 7
2021-10-23 23:22:18 | INFO | train_inner | {"epoch": 8, "update": 7.02, "loss": "2.316", "nll_loss": "0.426", "ppl": "1.34", "wps": "237", "ups": "0.52", "wpb": "459.4", "bsz": "15.9", "num_updates": "8600", "lr": "4.95948e-05", "gnorm": "1.66", "loss_scale": "256", "train_wall": "18", "wall": "2882"}
2021-10-23 23:22:37 | INFO | train_inner | {"epoch": 8, "update": 7.102, "loss": "2.309", "nll_loss": "0.422", "ppl": "1.34", "wps": "2733.6", "ups": "5.31", "wpb": "514.8", "bsz": "16", "num_updates": "8700", "lr": "4.95898e-05", "gnorm": "1.58", "loss_scale": "256", "train_wall": "19", "wall": "2901"}
2021-10-23 23:22:57 | INFO | train_inner | {"epoch": 8, "update": 7.184, "loss": "2.363", "nll_loss": "0.481", "ppl": "1.4", "wps": "2686.5", "ups": "5.07", "wpb": "530.1", "bsz": "16", "num_updates": "8800", "lr": "4.95848e-05", "gnorm": "1.578", "loss_scale": "256", "train_wall": "20", "wall": "2921"}
2021-10-23 23:23:13 | INFO | train_inner | {"epoch": 8, "update": 7.265, "loss": "2.294", "nll_loss": "0.405", "ppl": "1.32", "wps": "2723.4", "ups": "6.21", "wpb": "438.8", "bsz": "16", "num_updates": "8900", "lr": "4.95798e-05", "gnorm": "1.593", "loss_scale": "256", "train_wall": "16", "wall": "2937"}
2021-10-23 23:23:31 | INFO | train_inner | {"epoch": 8, "update": 7.347, "loss": "2.278", "nll_loss": "0.386", "ppl": "1.31", "wps": "2443.7", "ups": "5.51", "wpb": "443.4", "bsz": "16", "num_updates": "9000", "lr": "4.95748e-05", "gnorm": "1.585", "loss_scale": "256", "train_wall": "18", "wall": "2955"}
2021-10-23 23:23:50 | INFO | train_inner | {"epoch": 8, "update": 7.429, "loss": "2.291", "nll_loss": "0.399", "ppl": "1.32", "wps": "2621.1", "ups": "5.36", "wpb": "489.4", "bsz": "16", "num_updates": "9100", "lr": "4.95698e-05", "gnorm": "1.668", "loss_scale": "256", "train_wall": "18", "wall": "2974"}
2021-10-23 23:24:09 | INFO | train_inner | {"epoch": 8, "update": 7.51, "loss": "2.229", "nll_loss": "0.333", "ppl": "1.26", "wps": "2422.8", "ups": "5.36", "wpb": "451.8", "bsz": "16", "num_updates": "9200", "lr": "4.95648e-05", "gnorm": "1.555", "loss_scale": "256", "train_wall": "18", "wall": "2993"}
2021-10-23 23:24:27 | INFO | train_inner | {"epoch": 8, "update": 7.592, "loss": "2.301", "nll_loss": "0.413", "ppl": "1.33", "wps": "2390.3", "ups": "5.38", "wpb": "444.3", "bsz": "16", "num_updates": "9300", "lr": "4.95598e-05", "gnorm": "1.591", "loss_scale": "256", "train_wall": "18", "wall": "3011"}
2021-10-23 23:24:45 | INFO | train_inner | {"epoch": 8, "update": 7.673, "loss": "2.199", "nll_loss": "0.299", "ppl": "1.23", "wps": "2523.5", "ups": "5.74", "wpb": "439.7", "bsz": "16", "num_updates": "9400", "lr": "4.95548e-05", "gnorm": "1.654", "loss_scale": "256", "train_wall": "17", "wall": "3029"}
2021-10-23 23:25:03 | INFO | train_inner | {"epoch": 8, "update": 7.755, "loss": "2.287", "nll_loss": "0.397", "ppl": "1.32", "wps": "2547.7", "ups": "5.55", "wpb": "459.4", "bsz": "16", "num_updates": "9500", "lr": "4.95498e-05", "gnorm": "1.638", "loss_scale": "256", "train_wall": "18", "wall": "3047"}
2021-10-23 23:25:21 | INFO | train_inner | {"epoch": 8, "update": 7.837, "loss": "2.313", "nll_loss": "0.424", "ppl": "1.34", "wps": "2890.4", "ups": "5.4", "wpb": "534.9", "bsz": "16", "num_updates": "9600", "lr": "4.95448e-05", "gnorm": "1.669", "loss_scale": "256", "train_wall": "18", "wall": "3065"}
2021-10-23 23:25:39 | INFO | train_inner | {"epoch": 8, "update": 7.918, "loss": "2.352", "nll_loss": "0.471", "ppl": "1.39", "wps": "2682.8", "ups": "5.75", "wpb": "466.9", "bsz": "16", "num_updates": "9700", "lr": "4.95398e-05", "gnorm": "1.701", "loss_scale": "256", "train_wall": "17", "wall": "3083"}
2021-10-23 23:25:58 | INFO | train_inner | {"epoch": 8, "update": 8.0, "loss": "2.295", "nll_loss": "0.405", "ppl": "1.32", "wps": "2453.7", "ups": "5.16", "wpb": "475.8", "bsz": "15.9", "num_updates": "9800", "lr": "4.95348e-05", "gnorm": "1.603", "loss_scale": "256", "train_wall": "19", "wall": "3102"}
2021-10-23 23:25:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-23 23:28:53 | INFO | valid | {"epoch": 8, "valid_loss": "3.723", "valid_nll_loss": "1.979", "valid_ppl": "3.94", "valid_bleu": "29.06", "valid_wps": "397", "valid_wpb": "226.2", "valid_bsz": "8", "valid_num_updates": "9800", "valid_best_bleu": "30.17"}
2021-10-23 23:28:53 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-23 23:28:59 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/scratch/unique/large/checkpoint_last.pt (epoch 8 @ 9800 updates, score 29.06) (writing took 6.005293044028804 seconds)
2021-10-23 23:28:59 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2021-10-23 23:28:59 | INFO | train | {"epoch": 8, "train_loss": "2.293", "train_nll_loss": "0.403", "train_ppl": "1.32", "train_wps": "1430.3", "train_ups": "3.02", "train_wpb": "473.3", "train_bsz": "16", "train_num_updates": "9800", "train_lr": "4.95348e-05", "train_gnorm": "1.618", "train_loss_scale": "256", "train_train_wall": "222", "train_wall": "3283"}
2021-10-23 23:28:59 | INFO | fairseq_cli.train | begin training epoch 8
2021-10-23 23:29:16 | INFO | train_inner | {"epoch": 9, "update": 8.082, "loss": "2.308", "nll_loss": "0.422", "ppl": "1.34", "wps": "238.9", "ups": "0.5", "wpb": "474.2", "bsz": "16", "num_updates": "9900", "lr": "4.95298e-05", "gnorm": "1.593", "loss_scale": "256", "train_wall": "17", "wall": "3300"}
2021-10-23 23:29:35 | INFO | train_inner | {"epoch": 9, "update": 8.163, "loss": "2.272", "nll_loss": "0.38", "ppl": "1.3", "wps": "2493.9", "ups": "5.34", "wpb": "466.8", "bsz": "16", "num_updates": "10000", "lr": "4.95248e-05", "gnorm": "1.53", "loss_scale": "256", "train_wall": "19", "wall": "3319"}
2021-10-23 23:29:53 | INFO | train_inner | {"epoch": 9, "update": 8.245, "loss": "2.183", "nll_loss": "0.281", "ppl": "1.22", "wps": "2168.5", "ups": "5.56", "wpb": "390.3", "bsz": "16", "num_updates": "10100", "lr": "4.95198e-05", "gnorm": "1.595", "loss_scale": "256", "train_wall": "18", "wall": "3337"}
2021-10-23 23:30:11 | INFO | train_inner | {"epoch": 9, "update": 8.327, "loss": "2.283", "nll_loss": "0.393", "ppl": "1.31", "wps": "2888.9", "ups": "5.59", "wpb": "517.1", "bsz": "16", "num_updates": "10200", "lr": "4.95148e-05", "gnorm": "1.501", "loss_scale": "256", "train_wall": "18", "wall": "3355"}
2021-10-23 23:30:29 | INFO | train_inner | {"epoch": 9, "update": 8.408, "loss": "2.251", "nll_loss": "0.357", "ppl": "1.28", "wps": "2323", "ups": "5.58", "wpb": "416.2", "bsz": "16", "num_updates": "10300", "lr": "4.95098e-05", "gnorm": "1.666", "loss_scale": "256", "train_wall": "18", "wall": "3373"}
2021-10-23 23:30:47 | INFO | train_inner | {"epoch": 9, "update": 8.49, "loss": "2.188", "nll_loss": "0.288", "ppl": "1.22", "wps": "2260.5", "ups": "5.56", "wpb": "406.6", "bsz": "16", "num_updates": "10400", "lr": "4.95048e-05", "gnorm": "1.539", "loss_scale": "256", "train_wall": "18", "wall": "3391"}
2021-10-23 23:31:05 | INFO | train_inner | {"epoch": 9, "update": 8.571, "loss": "2.282", "nll_loss": "0.391", "ppl": "1.31", "wps": "2526.3", "ups": "5.51", "wpb": "458.7", "bsz": "16", "num_updates": "10500", "lr": "4.94997e-05", "gnorm": "1.644", "loss_scale": "256", "train_wall": "18", "wall": "3409"}
2021-10-23 23:31:24 | INFO | train_inner | {"epoch": 9, "update": 8.653, "loss": "2.327", "nll_loss": "0.439", "ppl": "1.36", "wps": "2879.4", "ups": "5.32", "wpb": "541.6", "bsz": "16", "num_updates": "10600", "lr": "4.94947e-05", "gnorm": "1.642", "loss_scale": "256", "train_wall": "19", "wall": "3428"}
2021-10-23 23:31:43 | INFO | train_inner | {"epoch": 9, "update": 8.735, "loss": "2.282", "nll_loss": "0.39", "ppl": "1.31", "wps": "2808.8", "ups": "5.25", "wpb": "535.1", "bsz": "16", "num_updates": "10700", "lr": "4.94897e-05", "gnorm": "1.565", "loss_scale": "256", "train_wall": "19", "wall": "3447"}
2021-10-23 23:32:00 | INFO | train_inner | {"epoch": 9, "update": 8.816, "loss": "2.325", "nll_loss": "0.44", "ppl": "1.36", "wps": "2938.5", "ups": "5.8", "wpb": "506.9", "bsz": "16", "num_updates": "10800", "lr": "4.94847e-05", "gnorm": "1.576", "loss_scale": "256", "train_wall": "17", "wall": "3464"}
2021-10-23 23:32:15 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 128.0
2021-10-23 23:32:19 | INFO | train_inner | {"epoch": 9, "update": 8.899, "loss": "2.309", "nll_loss": "0.421", "ppl": "1.34", "wps": "2450.8", "ups": "5.41", "wpb": "453.4", "bsz": "16", "num_updates": "10900", "lr": "4.94797e-05", "gnorm": "1.646", "loss_scale": "226", "train_wall": "18", "wall": "3483"}
2021-10-23 23:32:37 | INFO | train_inner | {"epoch": 9, "update": 8.98, "loss": "2.301", "nll_loss": "0.413", "ppl": "1.33", "wps": "2709.7", "ups": "5.35", "wpb": "506.2", "bsz": "16", "num_updates": "11000", "lr": "4.94747e-05", "gnorm": "1.616", "loss_scale": "128", "train_wall": "18", "wall": "3501"}
2021-10-23 23:32:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-23 23:35:29 | INFO | valid | {"epoch": 9, "valid_loss": "3.709", "valid_nll_loss": "1.966", "valid_ppl": "3.91", "valid_bleu": "29.8", "valid_wps": "413.6", "valid_wpb": "226.2", "valid_bsz": "8", "valid_num_updates": "11024", "valid_best_bleu": "30.17"}
2021-10-23 23:35:29 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-23 23:35:35 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/scratch/unique/large/checkpoint_last.pt (epoch 9 @ 11024 updates, score 29.8) (writing took 6.042407881934196 seconds)
2021-10-23 23:35:35 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2021-10-23 23:35:35 | INFO | train | {"epoch": 9, "train_loss": "2.282", "train_nll_loss": "0.391", "train_ppl": "1.31", "train_wps": "1457.7", "train_ups": "3.09", "train_wpb": "471.8", "train_bsz": "16", "train_num_updates": "11024", "train_lr": "4.94735e-05", "train_gnorm": "1.595", "train_loss_scale": "241", "train_train_wall": "219", "train_wall": "3679"}
2021-10-23 23:35:35 | INFO | fairseq_cli.train | begin training epoch 9
2021-10-23 23:35:49 | INFO | train_inner | {"epoch": 10, "update": 9.062, "loss": "2.32", "nll_loss": "0.433", "ppl": "1.35", "wps": "262.8", "ups": "0.52", "wpb": "503.2", "bsz": "15.9", "num_updates": "11100", "lr": "4.94697e-05", "gnorm": "1.555", "loss_scale": "128", "train_wall": "17", "wall": "3693"}
2021-10-23 23:36:07 | INFO | train_inner | {"epoch": 10, "update": 9.144, "loss": "2.216", "nll_loss": "0.319", "ppl": "1.25", "wps": "2270.8", "ups": "5.42", "wpb": "419", "bsz": "16", "num_updates": "11200", "lr": "4.94647e-05", "gnorm": "1.57", "loss_scale": "128", "train_wall": "18", "wall": "3711"}
2021-10-23 23:36:27 | INFO | train_inner | {"epoch": 10, "update": 9.225, "loss": "2.267", "nll_loss": "0.375", "ppl": "1.3", "wps": "2339.9", "ups": "5.16", "wpb": "453.4", "bsz": "16", "num_updates": "11300", "lr": "4.94597e-05", "gnorm": "1.59", "loss_scale": "128", "train_wall": "19", "wall": "3731"}
2021-10-23 23:36:46 | INFO | train_inner | {"epoch": 10, "update": 9.307, "loss": "2.292", "nll_loss": "0.404", "ppl": "1.32", "wps": "2703.3", "ups": "5.1", "wpb": "530", "bsz": "16", "num_updates": "11400", "lr": "4.94547e-05", "gnorm": "1.482", "loss_scale": "128", "train_wall": "19", "wall": "3750"}
2021-10-23 23:37:04 | INFO | train_inner | {"epoch": 10, "update": 9.389, "loss": "2.234", "nll_loss": "0.34", "ppl": "1.27", "wps": "2451.1", "ups": "5.64", "wpb": "434.3", "bsz": "16", "num_updates": "11500", "lr": "4.94497e-05", "gnorm": "1.511", "loss_scale": "128", "train_wall": "18", "wall": "3768"}
2021-10-23 23:37:23 | INFO | train_inner | {"epoch": 10, "update": 9.47, "loss": "2.266", "nll_loss": "0.374", "ppl": "1.3", "wps": "2698.9", "ups": "5.32", "wpb": "507.2", "bsz": "16", "num_updates": "11600", "lr": "4.94447e-05", "gnorm": "1.465", "loss_scale": "128", "train_wall": "19", "wall": "3787"}
2021-10-23 23:37:42 | INFO | train_inner | {"epoch": 10, "update": 9.552, "loss": "2.317", "nll_loss": "0.43", "ppl": "1.35", "wps": "2839.6", "ups": "5.24", "wpb": "542", "bsz": "16", "num_updates": "11700", "lr": "4.94397e-05", "gnorm": "1.575", "loss_scale": "128", "train_wall": "19", "wall": "3806"}
2021-10-23 23:37:59 | INFO | train_inner | {"epoch": 10, "update": 9.633, "loss": "2.244", "nll_loss": "0.35", "ppl": "1.27", "wps": "2539.3", "ups": "5.87", "wpb": "432.4", "bsz": "16", "num_updates": "11800", "lr": "4.94347e-05", "gnorm": "1.611", "loss_scale": "128", "train_wall": "17", "wall": "3823"}
2021-10-23 23:38:15 | INFO | train_inner | {"epoch": 10, "update": 9.715, "loss": "2.225", "nll_loss": "0.33", "ppl": "1.26", "wps": "2333.7", "ups": "6.02", "wpb": "387.7", "bsz": "16", "num_updates": "11900", "lr": "4.94297e-05", "gnorm": "1.635", "loss_scale": "128", "train_wall": "16", "wall": "3840"}
2021-10-23 23:38:34 | INFO | train_inner | {"epoch": 10, "update": 9.797, "loss": "2.229", "nll_loss": "0.334", "ppl": "1.26", "wps": "2347.3", "ups": "5.54", "wpb": "424", "bsz": "16", "num_updates": "12000", "lr": "4.94247e-05", "gnorm": "1.684", "loss_scale": "128", "train_wall": "18", "wall": "3858"}
2021-10-23 23:38:52 | INFO | train_inner | {"epoch": 10, "update": 9.878, "loss": "2.214", "nll_loss": "0.318", "ppl": "1.25", "wps": "2481.3", "ups": "5.56", "wpb": "446.5", "bsz": "16", "num_updates": "12100", "lr": "4.94197e-05", "gnorm": "1.488", "loss_scale": "128", "train_wall": "18", "wall": "3876"}
2021-10-23 23:39:12 | INFO | train_inner | {"epoch": 10, "update": 9.96, "loss": "2.439", "nll_loss": "0.566", "ppl": "1.48", "wps": "2882.2", "ups": "4.92", "wpb": "585.6", "bsz": "16", "num_updates": "12200", "lr": "4.94147e-05", "gnorm": "1.623", "loss_scale": "128", "train_wall": "20", "wall": "3896"}
2021-10-23 23:39:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-23 23:42:19 | INFO | valid | {"epoch": 10, "valid_loss": "3.717", "valid_nll_loss": "1.978", "valid_ppl": "3.94", "valid_bleu": "30.78", "valid_wps": "391.6", "valid_wpb": "226.2", "valid_bsz": "8", "valid_num_updates": "12249", "valid_best_bleu": "30.78"}
2021-10-23 23:42:19 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-23 23:42:44 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/scratch/unique/large/checkpoint_best.pt (epoch 10 @ 12249 updates, score 30.78) (writing took 25.581828035996296 seconds)
2021-10-23 23:42:44 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2021-10-23 23:42:44 | INFO | train | {"epoch": 10, "train_loss": "2.276", "train_nll_loss": "0.386", "train_ppl": "1.31", "train_wps": "1351.4", "train_ups": "2.86", "train_wpb": "473.3", "train_bsz": "16", "train_num_updates": "12249", "train_lr": "4.94123e-05", "train_gnorm": "1.567", "train_loss_scale": "128", "train_train_wall": "223", "train_wall": "4108"}
2021-10-23 23:42:44 | INFO | fairseq_cli.train | begin training epoch 10
2021-10-23 23:42:53 | INFO | train_inner | {"epoch": 11, "update": 10.042, "loss": "2.227", "nll_loss": "0.332", "ppl": "1.26", "wps": "197.6", "ups": "0.45", "wpb": "437.6", "bsz": "15.9", "num_updates": "12300", "lr": "4.94097e-05", "gnorm": "1.581", "loss_scale": "128", "train_wall": "18", "wall": "4117"}
2021-10-23 23:43:12 | INFO | train_inner | {"epoch": 11, "update": 10.123, "loss": "2.224", "nll_loss": "0.329", "ppl": "1.26", "wps": "2513.5", "ups": "5.51", "wpb": "456.3", "bsz": "16", "num_updates": "12400", "lr": "4.94047e-05", "gnorm": "1.466", "loss_scale": "128", "train_wall": "18", "wall": "4136"}
2021-10-23 23:43:31 | INFO | train_inner | {"epoch": 11, "update": 10.205, "loss": "2.306", "nll_loss": "0.419", "ppl": "1.34", "wps": "2612.3", "ups": "5.16", "wpb": "506.2", "bsz": "16", "num_updates": "12500", "lr": "4.93997e-05", "gnorm": "1.481", "loss_scale": "128", "train_wall": "19", "wall": "4155"}
2021-10-23 23:43:49 | INFO | train_inner | {"epoch": 11, "update": 10.287, "loss": "2.264", "nll_loss": "0.372", "ppl": "1.29", "wps": "2703.4", "ups": "5.4", "wpb": "500.3", "bsz": "16", "num_updates": "12600", "lr": "4.93947e-05", "gnorm": "1.418", "loss_scale": "128", "train_wall": "18", "wall": "4173"}
2021-10-23 23:44:08 | INFO | train_inner | {"epoch": 11, "update": 10.368, "loss": "2.272", "nll_loss": "0.381", "ppl": "1.3", "wps": "2600.3", "ups": "5.38", "wpb": "483.3", "bsz": "16", "num_updates": "12700", "lr": "4.93897e-05", "gnorm": "1.528", "loss_scale": "128", "train_wall": "18", "wall": "4192"}
2021-10-23 23:44:25 | INFO | train_inner | {"epoch": 11, "update": 10.45, "loss": "2.242", "nll_loss": "0.349", "ppl": "1.27", "wps": "2513.1", "ups": "5.79", "wpb": "433.8", "bsz": "16", "num_updates": "12800", "lr": "4.93847e-05", "gnorm": "1.597", "loss_scale": "128", "train_wall": "17", "wall": "4209"}
2021-10-23 23:44:44 | INFO | train_inner | {"epoch": 11, "update": 10.531, "loss": "2.254", "nll_loss": "0.362", "ppl": "1.28", "wps": "2541", "ups": "5.44", "wpb": "467", "bsz": "16", "num_updates": "12900", "lr": "4.93797e-05", "gnorm": "1.565", "loss_scale": "128", "train_wall": "18", "wall": "4228"}
2021-10-23 23:45:01 | INFO | train_inner | {"epoch": 11, "update": 10.613, "loss": "2.239", "nll_loss": "0.346", "ppl": "1.27", "wps": "2390.6", "ups": "5.63", "wpb": "424.4", "bsz": "16", "num_updates": "13000", "lr": "4.93747e-05", "gnorm": "1.607", "loss_scale": "128", "train_wall": "18", "wall": "4245"}
2021-10-23 23:45:19 | INFO | train_inner | {"epoch": 11, "update": 10.695, "loss": "2.272", "nll_loss": "0.382", "ppl": "1.3", "wps": "2623.2", "ups": "5.67", "wpb": "462.8", "bsz": "16", "num_updates": "13100", "lr": "4.93697e-05", "gnorm": "1.561", "loss_scale": "128", "train_wall": "17", "wall": "4263"}
2021-10-23 23:45:38 | INFO | train_inner | {"epoch": 11, "update": 10.776, "loss": "2.325", "nll_loss": "0.439", "ppl": "1.36", "wps": "2975.4", "ups": "5.18", "wpb": "574.4", "bsz": "16", "num_updates": "13200", "lr": "4.93647e-05", "gnorm": "1.568", "loss_scale": "128", "train_wall": "19", "wall": "4282"}
2021-10-23 23:45:57 | INFO | train_inner | {"epoch": 11, "update": 10.858, "loss": "2.293", "nll_loss": "0.406", "ppl": "1.32", "wps": "2498.9", "ups": "5.46", "wpb": "457.3", "bsz": "16", "num_updates": "13300", "lr": "4.93597e-05", "gnorm": "1.61", "loss_scale": "128", "train_wall": "18", "wall": "4301"}
2021-10-23 23:46:16 | INFO | train_inner | {"epoch": 11, "update": 10.94, "loss": "2.299", "nll_loss": "0.41", "ppl": "1.33", "wps": "2561", "ups": "5.21", "wpb": "491.8", "bsz": "16", "num_updates": "13400", "lr": "4.93547e-05", "gnorm": "1.698", "loss_scale": "128", "train_wall": "19", "wall": "4320"}
2021-10-23 23:46:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-23 23:49:21 | INFO | valid | {"epoch": 11, "valid_loss": "3.691", "valid_nll_loss": "1.95", "valid_ppl": "3.86", "valid_bleu": "30.84", "valid_wps": "404.7", "valid_wpb": "226.2", "valid_bsz": "8", "valid_num_updates": "13474", "valid_best_bleu": "30.84"}
2021-10-23 23:49:21 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-23 23:49:39 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/scratch/unique/large/checkpoint_best.pt (epoch 11 @ 13474 updates, score 30.84) (writing took 17.413757771020755 seconds)
2021-10-23 23:49:39 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2021-10-23 23:49:39 | INFO | train | {"epoch": 11, "train_loss": "2.268", "train_nll_loss": "0.377", "train_ppl": "1.3", "train_wps": "1398.4", "train_ups": "2.95", "train_wpb": "473.3", "train_bsz": "16", "train_num_updates": "13474", "train_lr": "4.9351e-05", "train_gnorm": "1.552", "train_loss_scale": "128", "train_train_wall": "223", "train_wall": "4523"}
2021-10-23 23:49:39 | INFO | fairseq_cli.train | begin training epoch 11
2021-10-23 23:49:43 | INFO | train_inner | {"epoch": 12, "update": 11.021, "loss": "2.216", "nll_loss": "0.32", "ppl": "1.25", "wps": "216.1", "ups": "0.48", "wpb": "447.8", "bsz": "15.9", "num_updates": "13500", "lr": "4.93497e-05", "gnorm": "1.55", "loss_scale": "128", "train_wall": "18", "wall": "4527"}
2021-10-23 23:50:01 | INFO | train_inner | {"epoch": 12, "update": 11.103, "loss": "2.267", "nll_loss": "0.376", "ppl": "1.3", "wps": "2539.2", "ups": "5.44", "wpb": "467.1", "bsz": "16", "num_updates": "13600", "lr": "4.93447e-05", "gnorm": "1.557", "loss_scale": "128", "train_wall": "18", "wall": "4545"}
2021-10-23 23:50:21 | INFO | train_inner | {"epoch": 12, "update": 11.184, "loss": "2.291", "nll_loss": "0.403", "ppl": "1.32", "wps": "2529.8", "ups": "5.18", "wpb": "488.6", "bsz": "16", "num_updates": "13700", "lr": "4.93397e-05", "gnorm": "1.502", "loss_scale": "128", "train_wall": "19", "wall": "4565"}
2021-10-23 23:50:40 | INFO | train_inner | {"epoch": 12, "update": 11.266, "loss": "2.306", "nll_loss": "0.419", "ppl": "1.34", "wps": "2500.7", "ups": "5.15", "wpb": "485.2", "bsz": "16", "num_updates": "13800", "lr": "4.93347e-05", "gnorm": "1.499", "loss_scale": "128", "train_wall": "19", "wall": "4584"}
2021-10-23 23:50:57 | INFO | train_inner | {"epoch": 12, "update": 11.348, "loss": "2.238", "nll_loss": "0.345", "ppl": "1.27", "wps": "2566.9", "ups": "6.04", "wpb": "424.8", "bsz": "16", "num_updates": "13900", "lr": "4.93297e-05", "gnorm": "1.588", "loss_scale": "128", "train_wall": "16", "wall": "4601"}
2021-10-23 23:51:13 | INFO | train_inner | {"epoch": 12, "update": 11.429, "loss": "2.231", "nll_loss": "0.336", "ppl": "1.26", "wps": "2808", "ups": "6.27", "wpb": "448.1", "bsz": "16", "num_updates": "14000", "lr": "4.93247e-05", "gnorm": "1.497", "loss_scale": "128", "train_wall": "16", "wall": "4617"}
2021-10-23 23:51:30 | INFO | train_inner | {"epoch": 12, "update": 11.511, "loss": "2.271", "nll_loss": "0.381", "ppl": "1.3", "wps": "2525.4", "ups": "5.61", "wpb": "450.2", "bsz": "16", "num_updates": "14100", "lr": "4.93197e-05", "gnorm": "1.635", "loss_scale": "128", "train_wall": "18", "wall": "4635"}
2021-10-23 23:51:49 | INFO | train_inner | {"epoch": 12, "update": 11.593, "loss": "2.222", "nll_loss": "0.328", "ppl": "1.26", "wps": "2615.2", "ups": "5.53", "wpb": "473.2", "bsz": "16", "num_updates": "14200", "lr": "4.93147e-05", "gnorm": "1.489", "loss_scale": "128", "train_wall": "18", "wall": "4653"}
2021-10-23 23:52:09 | INFO | train_inner | {"epoch": 12, "update": 11.674, "loss": "2.299", "nll_loss": "0.411", "ppl": "1.33", "wps": "2904.4", "ups": "5.02", "wpb": "578.7", "bsz": "16", "num_updates": "14300", "lr": "4.93097e-05", "gnorm": "1.537", "loss_scale": "128", "train_wall": "20", "wall": "4673"}
2021-10-23 23:52:27 | INFO | train_inner | {"epoch": 12, "update": 11.756, "loss": "2.223", "nll_loss": "0.329", "ppl": "1.26", "wps": "2494.1", "ups": "5.55", "wpb": "449.4", "bsz": "16", "num_updates": "14400", "lr": "4.93047e-05", "gnorm": "1.466", "loss_scale": "128", "train_wall": "18", "wall": "4691"}
2021-10-23 23:52:44 | INFO | train_inner | {"epoch": 12, "update": 11.838, "loss": "2.277", "nll_loss": "0.386", "ppl": "1.31", "wps": "2810.6", "ups": "5.89", "wpb": "477.2", "bsz": "16", "num_updates": "14500", "lr": "4.92996e-05", "gnorm": "1.558", "loss_scale": "128", "train_wall": "17", "wall": "4708"}
2021-10-23 23:53:02 | INFO | train_inner | {"epoch": 12, "update": 11.919, "loss": "2.307", "nll_loss": "0.42", "ppl": "1.34", "wps": "2740.6", "ups": "5.52", "wpb": "496.9", "bsz": "16", "num_updates": "14600", "lr": "4.92946e-05", "gnorm": "1.554", "loss_scale": "128", "train_wall": "18", "wall": "4726"}
2021-10-23 23:53:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-23 23:56:17 | INFO | valid | {"epoch": 12, "valid_loss": "3.721", "valid_nll_loss": "1.984", "valid_ppl": "3.96", "valid_bleu": "30.04", "valid_wps": "386.6", "valid_wpb": "226.2", "valid_bsz": "8", "valid_num_updates": "14699", "valid_best_bleu": "30.84"}
2021-10-23 23:56:17 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-23 23:56:23 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/scratch/unique/large/checkpoint_last.pt (epoch 12 @ 14699 updates, score 30.04) (writing took 5.884858042001724 seconds)
2021-10-23 23:56:23 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2021-10-23 23:56:23 | INFO | train | {"epoch": 12, "train_loss": "2.261", "train_nll_loss": "0.369", "train_ppl": "1.29", "train_wps": "1434", "train_ups": "3.03", "train_wpb": "473.3", "train_bsz": "16", "train_num_updates": "14699", "train_lr": "4.92897e-05", "train_gnorm": "1.533", "train_loss_scale": "128", "train_train_wall": "216", "train_wall": "4927"}
2021-10-23 23:56:23 | INFO | fairseq_cli.train | begin training epoch 12
2021-10-23 23:56:23 | INFO | train_inner | {"epoch": 13, "update": 12.001, "loss": "2.2", "nll_loss": "0.305", "ppl": "1.24", "wps": "223.2", "ups": "0.5", "wpb": "450.4", "bsz": "15.9", "num_updates": "14700", "lr": "4.92896e-05", "gnorm": "1.507", "loss_scale": "128", "train_wall": "16", "wall": "4927"}
2021-10-23 23:56:41 | INFO | train_inner | {"epoch": 13, "update": 12.082, "loss": "2.202", "nll_loss": "0.305", "ppl": "1.24", "wps": "2484.7", "ups": "5.71", "wpb": "435.4", "bsz": "16", "num_updates": "14800", "lr": "4.92846e-05", "gnorm": "1.471", "loss_scale": "128", "train_wall": "17", "wall": "4945"}
2021-10-23 23:56:58 | INFO | train_inner | {"epoch": 13, "update": 12.164, "loss": "2.177", "nll_loss": "0.277", "ppl": "1.21", "wps": "2473.8", "ups": "5.76", "wpb": "429.1", "bsz": "16", "num_updates": "14900", "lr": "4.92796e-05", "gnorm": "1.46", "loss_scale": "128", "train_wall": "17", "wall": "4962"}
2021-10-23 23:57:16 | INFO | train_inner | {"epoch": 13, "update": 12.246, "loss": "2.245", "nll_loss": "0.354", "ppl": "1.28", "wps": "2515.8", "ups": "5.69", "wpb": "442.4", "bsz": "16", "num_updates": "15000", "lr": "4.92746e-05", "gnorm": "1.48", "loss_scale": "128", "train_wall": "17", "wall": "4980"}
2021-10-23 23:57:37 | INFO | train_inner | {"epoch": 13, "update": 12.327, "loss": "2.276", "nll_loss": "0.387", "ppl": "1.31", "wps": "2431.2", "ups": "4.78", "wpb": "508.6", "bsz": "16", "num_updates": "15100", "lr": "4.92696e-05", "gnorm": "1.442", "loss_scale": "128", "train_wall": "21", "wall": "5001"}
2021-10-23 23:57:54 | INFO | train_inner | {"epoch": 13, "update": 12.409, "loss": "2.269", "nll_loss": "0.38", "ppl": "1.3", "wps": "2691.3", "ups": "5.77", "wpb": "466.8", "bsz": "16", "num_updates": "15200", "lr": "4.92646e-05", "gnorm": "1.536", "loss_scale": "128", "train_wall": "17", "wall": "5018"}
2021-10-23 23:58:11 | INFO | train_inner | {"epoch": 13, "update": 12.491, "loss": "2.213", "nll_loss": "0.319", "ppl": "1.25", "wps": "2603.4", "ups": "5.96", "wpb": "437.2", "bsz": "16", "num_updates": "15300", "lr": "4.92596e-05", "gnorm": "1.447", "loss_scale": "128", "train_wall": "17", "wall": "5035"}
2021-10-23 23:58:28 | INFO | train_inner | {"epoch": 13, "update": 12.572, "loss": "2.215", "nll_loss": "0.319", "ppl": "1.25", "wps": "2498.9", "ups": "5.81", "wpb": "430.2", "bsz": "16", "num_updates": "15400", "lr": "4.92546e-05", "gnorm": "1.574", "loss_scale": "128", "train_wall": "17", "wall": "5052"}
2021-10-23 23:58:47 | INFO | train_inner | {"epoch": 13, "update": 12.654, "loss": "2.225", "nll_loss": "0.33", "ppl": "1.26", "wps": "2471.7", "ups": "5.21", "wpb": "474", "bsz": "16", "num_updates": "15500", "lr": "4.92496e-05", "gnorm": "1.482", "loss_scale": "128", "train_wall": "19", "wall": "5071"}
2021-10-23 23:59:05 | INFO | train_inner | {"epoch": 13, "update": 12.736, "loss": "2.275", "nll_loss": "0.385", "ppl": "1.31", "wps": "2607.2", "ups": "5.53", "wpb": "471.2", "bsz": "16", "num_updates": "15600", "lr": "4.92446e-05", "gnorm": "1.547", "loss_scale": "128", "train_wall": "18", "wall": "5089"}
2021-10-23 23:59:24 | INFO | train_inner | {"epoch": 13, "update": 12.817, "loss": "2.247", "nll_loss": "0.355", "ppl": "1.28", "wps": "2478.3", "ups": "5.34", "wpb": "464.3", "bsz": "16", "num_updates": "15700", "lr": "4.92396e-05", "gnorm": "1.567", "loss_scale": "128", "train_wall": "19", "wall": "5108"}
2021-10-23 23:59:44 | INFO | train_inner | {"epoch": 13, "update": 12.899, "loss": "2.343", "nll_loss": "0.46", "ppl": "1.38", "wps": "3246.5", "ups": "5.11", "wpb": "635.9", "bsz": "16", "num_updates": "15800", "lr": "4.92346e-05", "gnorm": "1.512", "loss_scale": "128", "train_wall": "19", "wall": "5128"}
2021-10-24 00:00:01 | INFO | train_inner | {"epoch": 13, "update": 12.98, "loss": "2.277", "nll_loss": "0.389", "ppl": "1.31", "wps": "2760.5", "ups": "5.85", "wpb": "471.9", "bsz": "16", "num_updates": "15900", "lr": "4.92296e-05", "gnorm": "1.583", "loss_scale": "128", "train_wall": "17", "wall": "5145"}
2021-10-24 00:00:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-24 00:02:55 | INFO | valid | {"epoch": 13, "valid_loss": "3.696", "valid_nll_loss": "1.962", "valid_ppl": "3.9", "valid_bleu": "30.41", "valid_wps": "409.3", "valid_wpb": "226.2", "valid_bsz": "8", "valid_num_updates": "15924", "valid_best_bleu": "30.84"}
2021-10-24 00:02:55 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-24 00:03:08 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/scratch/unique/large/checkpoint_last.pt (epoch 13 @ 15924 updates, score 30.41) (writing took 12.471795947989449 seconds)
2021-10-24 00:03:08 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2021-10-24 00:03:08 | INFO | train | {"epoch": 13, "train_loss": "2.252", "train_nll_loss": "0.361", "train_ppl": "1.28", "train_wps": "1433.1", "train_ups": "3.03", "train_wpb": "473.3", "train_bsz": "16", "train_num_updates": "15924", "train_lr": "4.92284e-05", "train_gnorm": "1.509", "train_loss_scale": "128", "train_train_wall": "220", "train_wall": "5332"}
2021-10-24 00:03:08 | INFO | fairseq_cli.train | begin training epoch 13
2021-10-24 00:03:22 | INFO | train_inner | {"epoch": 14, "update": 13.062, "loss": "2.274", "nll_loss": "0.384", "ppl": "1.3", "wps": "270.8", "ups": "0.5", "wpb": "544.8", "bsz": "15.9", "num_updates": "16000", "lr": "4.92246e-05", "gnorm": "1.464", "loss_scale": "128", "train_wall": "19", "wall": "5346"}
2021-10-24 00:03:39 | INFO | train_inner | {"epoch": 14, "update": 13.144, "loss": "2.207", "nll_loss": "0.312", "ppl": "1.24", "wps": "2556.9", "ups": "5.81", "wpb": "440", "bsz": "16", "num_updates": "16100", "lr": "4.92196e-05", "gnorm": "1.437", "loss_scale": "128", "train_wall": "17", "wall": "5363"}
2021-10-24 00:03:59 | INFO | train_inner | {"epoch": 14, "update": 13.225, "loss": "2.239", "nll_loss": "0.347", "ppl": "1.27", "wps": "2469.2", "ups": "5.19", "wpb": "475.7", "bsz": "16", "num_updates": "16200", "lr": "4.92146e-05", "gnorm": "1.379", "loss_scale": "128", "train_wall": "19", "wall": "5383"}
2021-10-24 00:04:16 | INFO | train_inner | {"epoch": 14, "update": 13.307, "loss": "2.249", "nll_loss": "0.359", "ppl": "1.28", "wps": "2471.2", "ups": "5.7", "wpb": "433.2", "bsz": "16", "num_updates": "16300", "lr": "4.92096e-05", "gnorm": "1.473", "loss_scale": "128", "train_wall": "17", "wall": "5400"}
2021-10-24 00:04:35 | INFO | train_inner | {"epoch": 14, "update": 13.389, "loss": "2.279", "nll_loss": "0.39", "ppl": "1.31", "wps": "2573.6", "ups": "5.21", "wpb": "493.8", "bsz": "16", "num_updates": "16400", "lr": "4.92046e-05", "gnorm": "1.581", "loss_scale": "128", "train_wall": "19", "wall": "5419"}
2021-10-24 00:04:54 | INFO | train_inner | {"epoch": 14, "update": 13.47, "loss": "2.255", "nll_loss": "0.365", "ppl": "1.29", "wps": "2521.4", "ups": "5.4", "wpb": "467.3", "bsz": "16", "num_updates": "16500", "lr": "4.91996e-05", "gnorm": "1.538", "loss_scale": "128", "train_wall": "18", "wall": "5438"}
2021-10-24 00:05:12 | INFO | train_inner | {"epoch": 14, "update": 13.552, "loss": "2.22", "nll_loss": "0.327", "ppl": "1.25", "wps": "2508.7", "ups": "5.41", "wpb": "463.5", "bsz": "16", "num_updates": "16600", "lr": "4.91946e-05", "gnorm": "1.5", "loss_scale": "128", "train_wall": "18", "wall": "5456"}
2021-10-24 00:05:31 | INFO | train_inner | {"epoch": 14, "update": 13.633, "loss": "2.268", "nll_loss": "0.379", "ppl": "1.3", "wps": "2623", "ups": "5.28", "wpb": "496.8", "bsz": "16", "num_updates": "16700", "lr": "4.91896e-05", "gnorm": "1.464", "loss_scale": "128", "train_wall": "19", "wall": "5475"}
2021-10-24 00:05:49 | INFO | train_inner | {"epoch": 14, "update": 13.715, "loss": "2.25", "nll_loss": "0.359", "ppl": "1.28", "wps": "2614.8", "ups": "5.49", "wpb": "476.4", "bsz": "16", "num_updates": "16800", "lr": "4.91846e-05", "gnorm": "1.465", "loss_scale": "128", "train_wall": "18", "wall": "5493"}
2021-10-24 00:06:08 | INFO | train_inner | {"epoch": 14, "update": 13.797, "loss": "2.212", "nll_loss": "0.319", "ppl": "1.25", "wps": "2403.9", "ups": "5.44", "wpb": "441.7", "bsz": "16", "num_updates": "16900", "lr": "4.91796e-05", "gnorm": "1.437", "loss_scale": "128", "train_wall": "18", "wall": "5512"}
2021-10-24 00:06:26 | INFO | train_inner | {"epoch": 14, "update": 13.878, "loss": "2.259", "nll_loss": "0.368", "ppl": "1.29", "wps": "2598.3", "ups": "5.43", "wpb": "478.6", "bsz": "16", "num_updates": "17000", "lr": "4.91746e-05", "gnorm": "1.475", "loss_scale": "128", "train_wall": "18", "wall": "5530"}
2021-10-24 00:06:45 | INFO | train_inner | {"epoch": 14, "update": 13.96, "loss": "2.276", "nll_loss": "0.389", "ppl": "1.31", "wps": "2802", "ups": "5.44", "wpb": "515.4", "bsz": "16", "num_updates": "17100", "lr": "4.91696e-05", "gnorm": "1.533", "loss_scale": "128", "train_wall": "18", "wall": "5549"}
2021-10-24 00:06:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-24 00:09:51 | INFO | valid | {"epoch": 14, "valid_loss": "3.7", "valid_nll_loss": "1.961", "valid_ppl": "3.89", "valid_bleu": "31.3", "valid_wps": "390.5", "valid_wpb": "226.2", "valid_bsz": "8", "valid_num_updates": "17149", "valid_best_bleu": "31.3"}
2021-10-24 00:09:51 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-24 00:10:15 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/scratch/unique/large/checkpoint_best.pt (epoch 14 @ 17149 updates, score 31.3) (writing took 24.06878534296993 seconds)
2021-10-24 00:10:15 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2021-10-24 00:10:15 | INFO | train | {"epoch": 14, "train_loss": "2.245", "train_nll_loss": "0.354", "train_ppl": "1.28", "train_wps": "1355.5", "train_ups": "2.86", "train_wpb": "473.3", "train_bsz": "16", "train_num_updates": "17149", "train_lr": "4.91671e-05", "train_gnorm": "1.477", "train_loss_scale": "128", "train_train_wall": "223", "train_wall": "5759"}
2021-10-24 00:10:15 | INFO | fairseq_cli.train | begin training epoch 14
2021-10-24 00:10:25 | INFO | train_inner | {"epoch": 15, "update": 14.042, "loss": "2.163", "nll_loss": "0.263", "ppl": "1.2", "wps": "190.2", "ups": "0.45", "wpb": "418.3", "bsz": "15.9", "num_updates": "17200", "lr": "4.91646e-05", "gnorm": "1.433", "loss_scale": "128", "train_wall": "18", "wall": "5769"}
2021-10-24 00:10:43 | INFO | train_inner | {"epoch": 15, "update": 14.123, "loss": "2.257", "nll_loss": "0.366", "ppl": "1.29", "wps": "2836.3", "ups": "5.49", "wpb": "516.3", "bsz": "16", "num_updates": "17300", "lr": "4.91596e-05", "gnorm": "1.411", "loss_scale": "128", "train_wall": "18", "wall": "5787"}
2021-10-24 00:11:00 | INFO | train_inner | {"epoch": 15, "update": 14.205, "loss": "2.159", "nll_loss": "0.26", "ppl": "1.2", "wps": "2386.3", "ups": "5.86", "wpb": "407.3", "bsz": "16", "num_updates": "17400", "lr": "4.91546e-05", "gnorm": "1.425", "loss_scale": "128", "train_wall": "17", "wall": "5804"}
2021-10-24 00:11:18 | INFO | train_inner | {"epoch": 15, "update": 14.287, "loss": "2.247", "nll_loss": "0.356", "ppl": "1.28", "wps": "2699.2", "ups": "5.58", "wpb": "483.8", "bsz": "16", "num_updates": "17500", "lr": "4.91496e-05", "gnorm": "1.496", "loss_scale": "128", "train_wall": "18", "wall": "5822"}
2021-10-24 00:11:34 | INFO | train_inner | {"epoch": 15, "update": 14.368, "loss": "2.165", "nll_loss": "0.266", "ppl": "1.2", "wps": "2647", "ups": "5.99", "wpb": "441.9", "bsz": "16", "num_updates": "17600", "lr": "4.91446e-05", "gnorm": "1.552", "loss_scale": "128", "train_wall": "17", "wall": "5838"}
2021-10-24 00:11:54 | INFO | train_inner | {"epoch": 15, "update": 14.45, "loss": "2.232", "nll_loss": "0.338", "ppl": "1.26", "wps": "2544.1", "ups": "5.16", "wpb": "493", "bsz": "16", "num_updates": "17700", "lr": "4.91396e-05", "gnorm": "1.517", "loss_scale": "128", "train_wall": "19", "wall": "5858"}
2021-10-24 00:12:11 | INFO | train_inner | {"epoch": 15, "update": 14.531, "loss": "2.226", "nll_loss": "0.335", "ppl": "1.26", "wps": "2249.4", "ups": "5.68", "wpb": "396.4", "bsz": "16", "num_updates": "17800", "lr": "4.91346e-05", "gnorm": "1.438", "loss_scale": "128", "train_wall": "17", "wall": "5875"}
2021-10-24 00:12:31 | INFO | train_inner | {"epoch": 15, "update": 14.613, "loss": "2.223", "nll_loss": "0.331", "ppl": "1.26", "wps": "2347.5", "ups": "5.07", "wpb": "462.7", "bsz": "16", "num_updates": "17900", "lr": "4.91296e-05", "gnorm": "1.458", "loss_scale": "128", "train_wall": "19", "wall": "5895"}
2021-10-24 00:12:51 | INFO | train_inner | {"epoch": 15, "update": 14.695, "loss": "2.344", "nll_loss": "0.462", "ppl": "1.38", "wps": "2795", "ups": "5.04", "wpb": "554.9", "bsz": "16", "num_updates": "18000", "lr": "4.91246e-05", "gnorm": "1.492", "loss_scale": "128", "train_wall": "20", "wall": "5915"}
2021-10-24 00:13:10 | INFO | train_inner | {"epoch": 15, "update": 14.776, "loss": "2.287", "nll_loss": "0.403", "ppl": "1.32", "wps": "2636.2", "ups": "5.22", "wpb": "504.6", "bsz": "16", "num_updates": "18100", "lr": "4.91196e-05", "gnorm": "1.472", "loss_scale": "128", "train_wall": "19", "wall": "5934"}
2021-10-24 00:13:30 | INFO | train_inner | {"epoch": 15, "update": 14.858, "loss": "2.271", "nll_loss": "0.384", "ppl": "1.3", "wps": "2382.8", "ups": "4.95", "wpb": "481.8", "bsz": "16", "num_updates": "18200", "lr": "4.91146e-05", "gnorm": "1.512", "loss_scale": "128", "train_wall": "20", "wall": "5954"}
2021-10-24 00:13:52 | INFO | train_inner | {"epoch": 15, "update": 14.94, "loss": "2.246", "nll_loss": "0.355", "ppl": "1.28", "wps": "2239.3", "ups": "4.6", "wpb": "486.3", "bsz": "16", "num_updates": "18300", "lr": "4.91096e-05", "gnorm": "1.55", "loss_scale": "128", "train_wall": "21", "wall": "5976"}
2021-10-24 00:14:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-24 00:16:56 | INFO | valid | {"epoch": 15, "valid_loss": "3.714", "valid_nll_loss": "1.985", "valid_ppl": "3.96", "valid_bleu": "30.18", "valid_wps": "408.7", "valid_wpb": "226.2", "valid_bsz": "8", "valid_num_updates": "18374", "valid_best_bleu": "31.3"}
2021-10-24 00:16:56 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-24 00:17:10 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/scratch/unique/large/checkpoint_last.pt (epoch 15 @ 18374 updates, score 30.18) (writing took 14.13797425897792 seconds)
2021-10-24 00:17:10 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2021-10-24 00:17:10 | INFO | train | {"epoch": 15, "train_loss": "2.242", "train_nll_loss": "0.351", "train_ppl": "1.28", "train_wps": "1398.8", "train_ups": "2.96", "train_wpb": "473.3", "train_bsz": "16", "train_num_updates": "18374", "train_lr": "4.91059e-05", "train_gnorm": "1.483", "train_loss_scale": "128", "train_train_wall": "227", "train_wall": "6174"}
2021-10-24 00:17:10 | INFO | fairseq_cli.train | begin training epoch 15
2021-10-24 00:17:15 | INFO | train_inner | {"epoch": 16, "update": 15.021, "loss": "2.212", "nll_loss": "0.317", "ppl": "1.25", "wps": "219.8", "ups": "0.49", "wpb": "445", "bsz": "15.9", "num_updates": "18400", "lr": "4.91046e-05", "gnorm": "1.471", "loss_scale": "128", "train_wall": "18", "wall": "6179"}
2021-10-24 00:17:33 | INFO | train_inner | {"epoch": 16, "update": 15.103, "loss": "2.202", "nll_loss": "0.309", "ppl": "1.24", "wps": "2344.2", "ups": "5.47", "wpb": "428.2", "bsz": "16", "num_updates": "18500", "lr": "4.90995e-05", "gnorm": "1.431", "loss_scale": "128", "train_wall": "18", "wall": "6197"}
2021-10-24 00:17:53 | INFO | train_inner | {"epoch": 16, "update": 15.184, "loss": "2.307", "nll_loss": "0.422", "ppl": "1.34", "wps": "2738.1", "ups": "4.94", "wpb": "553.8", "bsz": "16", "num_updates": "18600", "lr": "4.90945e-05", "gnorm": "1.476", "loss_scale": "128", "train_wall": "20", "wall": "6217"}
2021-10-24 00:18:12 | INFO | train_inner | {"epoch": 16, "update": 15.266, "loss": "2.241", "nll_loss": "0.35", "ppl": "1.27", "wps": "2443.9", "ups": "5.3", "wpb": "460.7", "bsz": "16", "num_updates": "18700", "lr": "4.90895e-05", "gnorm": "1.447", "loss_scale": "128", "train_wall": "19", "wall": "6236"}
2021-10-24 00:18:31 | INFO | train_inner | {"epoch": 16, "update": 15.348, "loss": "2.236", "nll_loss": "0.345", "ppl": "1.27", "wps": "2340.5", "ups": "5.21", "wpb": "449.2", "bsz": "16", "num_updates": "18800", "lr": "4.90845e-05", "gnorm": "1.508", "loss_scale": "128", "train_wall": "19", "wall": "6255"}
2021-10-24 00:18:51 | INFO | train_inner | {"epoch": 16, "update": 15.429, "loss": "2.215", "nll_loss": "0.322", "ppl": "1.25", "wps": "2365.6", "ups": "5.06", "wpb": "467.6", "bsz": "16", "num_updates": "18900", "lr": "4.90795e-05", "gnorm": "1.486", "loss_scale": "128", "train_wall": "20", "wall": "6275"}
2021-10-24 00:19:10 | INFO | train_inner | {"epoch": 16, "update": 15.511, "loss": "2.207", "nll_loss": "0.312", "ppl": "1.24", "wps": "2520", "ups": "5.24", "wpb": "480.8", "bsz": "16", "num_updates": "19000", "lr": "4.90745e-05", "gnorm": "1.414", "loss_scale": "128", "train_wall": "19", "wall": "6294"}
2021-10-24 00:19:30 | INFO | train_inner | {"epoch": 16, "update": 15.593, "loss": "2.226", "nll_loss": "0.334", "ppl": "1.26", "wps": "2479.8", "ups": "5.1", "wpb": "486.1", "bsz": "16", "num_updates": "19100", "lr": "4.90695e-05", "gnorm": "1.495", "loss_scale": "169", "train_wall": "19", "wall": "6314"}
2021-10-24 00:19:48 | INFO | train_inner | {"epoch": 16, "update": 15.674, "loss": "2.269", "nll_loss": "0.381", "ppl": "1.3", "wps": "2928.2", "ups": "5.56", "wpb": "526.6", "bsz": "16", "num_updates": "19200", "lr": "4.90645e-05", "gnorm": "1.433", "loss_scale": "256", "train_wall": "18", "wall": "6332"}
2021-10-24 00:20:06 | INFO | train_inner | {"epoch": 16, "update": 15.756, "loss": "2.225", "nll_loss": "0.333", "ppl": "1.26", "wps": "2637.5", "ups": "5.52", "wpb": "478.2", "bsz": "16", "num_updates": "19300", "lr": "4.90595e-05", "gnorm": "1.412", "loss_scale": "256", "train_wall": "18", "wall": "6350"}
2021-10-24 00:20:25 | INFO | train_inner | {"epoch": 16, "update": 15.838, "loss": "2.327", "nll_loss": "0.446", "ppl": "1.36", "wps": "2512.3", "ups": "5.25", "wpb": "478.6", "bsz": "16", "num_updates": "19400", "lr": "4.90545e-05", "gnorm": "1.593", "loss_scale": "256", "train_wall": "19", "wall": "6369"}
2021-10-24 00:20:42 | INFO | train_inner | {"epoch": 16, "update": 15.919, "loss": "2.163", "nll_loss": "0.266", "ppl": "1.2", "wps": "2265", "ups": "5.68", "wpb": "399", "bsz": "16", "num_updates": "19500", "lr": "4.90495e-05", "gnorm": "1.463", "loss_scale": "256", "train_wall": "17", "wall": "6386"}
2021-10-24 00:21:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-24 00:23:51 | INFO | valid | {"epoch": 16, "valid_loss": "3.704", "valid_nll_loss": "1.97", "valid_ppl": "3.92", "valid_bleu": "31.92", "valid_wps": "409.7", "valid_wpb": "226.2", "valid_bsz": "8", "valid_num_updates": "19599", "valid_best_bleu": "31.92"}
2021-10-24 00:23:51 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-24 00:24:14 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/scratch/unique/large/checkpoint_best.pt (epoch 16 @ 19599 updates, score 31.92) (writing took 23.277597755077295 seconds)
2021-10-24 00:24:14 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2021-10-24 00:24:14 | INFO | train | {"epoch": 16, "train_loss": "2.238", "train_nll_loss": "0.347", "train_ppl": "1.27", "train_wps": "1366.2", "train_ups": "2.89", "train_wpb": "473.3", "train_bsz": "16", "train_num_updates": "19599", "train_lr": "4.90446e-05", "train_gnorm": "1.464", "train_loss_scale": "183", "train_train_wall": "229", "train_wall": "6598"}
2021-10-24 00:24:14 | INFO | fairseq_cli.train | begin training epoch 16
2021-10-24 00:24:15 | INFO | train_inner | {"epoch": 17, "update": 16.001, "loss": "2.231", "nll_loss": "0.338", "ppl": "1.26", "wps": "235.8", "ups": "0.47", "wpb": "500.3", "bsz": "15.9", "num_updates": "19600", "lr": "4.90445e-05", "gnorm": "1.459", "loss_scale": "256", "train_wall": "19", "wall": "6599"}
2021-10-24 00:24:34 | INFO | train_inner | {"epoch": 17, "update": 16.082, "loss": "2.259", "nll_loss": "0.37", "ppl": "1.29", "wps": "2760.4", "ups": "5.25", "wpb": "525.6", "bsz": "16", "num_updates": "19700", "lr": "4.90395e-05", "gnorm": "1.407", "loss_scale": "256", "train_wall": "19", "wall": "6618"}
2021-10-24 00:24:52 | INFO | train_inner | {"epoch": 17, "update": 16.164, "loss": "2.191", "nll_loss": "0.295", "ppl": "1.23", "wps": "2348.5", "ups": "5.5", "wpb": "427.3", "bsz": "16", "num_updates": "19800", "lr": "4.90345e-05", "gnorm": "1.444", "loss_scale": "256", "train_wall": "18", "wall": "6636"}
2021-10-24 00:25:10 | INFO | train_inner | {"epoch": 17, "update": 16.246, "loss": "2.22", "nll_loss": "0.327", "ppl": "1.25", "wps": "2659.1", "ups": "5.38", "wpb": "493.8", "bsz": "16", "num_updates": "19900", "lr": "4.90295e-05", "gnorm": "1.368", "loss_scale": "256", "train_wall": "18", "wall": "6654"}
2021-10-24 00:25:28 | INFO | train_inner | {"epoch": 17, "update": 16.327, "loss": "2.195", "nll_loss": "0.3", "ppl": "1.23", "wps": "2665.8", "ups": "5.77", "wpb": "461.7", "bsz": "16", "num_updates": "20000", "lr": "4.90245e-05", "gnorm": "1.403", "loss_scale": "256", "train_wall": "17", "wall": "6672"}
2021-10-24 00:25:45 | INFO | train_inner | {"epoch": 17, "update": 16.409, "loss": "2.205", "nll_loss": "0.311", "ppl": "1.24", "wps": "2633.9", "ups": "5.79", "wpb": "454.6", "bsz": "16", "num_updates": "20100", "lr": "4.90195e-05", "gnorm": "1.432", "loss_scale": "256", "train_wall": "17", "wall": "6689"}
2021-10-24 00:26:02 | INFO | train_inner | {"epoch": 17, "update": 16.491, "loss": "2.268", "nll_loss": "0.382", "ppl": "1.3", "wps": "2721.5", "ups": "5.7", "wpb": "477.5", "bsz": "16", "num_updates": "20200", "lr": "4.90145e-05", "gnorm": "1.424", "loss_scale": "256", "train_wall": "17", "wall": "6706"}
2021-10-24 00:26:20 | INFO | train_inner | {"epoch": 17, "update": 16.572, "loss": "2.242", "nll_loss": "0.352", "ppl": "1.28", "wps": "2571.4", "ups": "5.59", "wpb": "459.6", "bsz": "16", "num_updates": "20300", "lr": "4.90095e-05", "gnorm": "1.422", "loss_scale": "256", "train_wall": "18", "wall": "6724"}
2021-10-24 00:26:39 | INFO | train_inner | {"epoch": 17, "update": 16.654, "loss": "2.268", "nll_loss": "0.38", "ppl": "1.3", "wps": "2868.2", "ups": "5.36", "wpb": "535.3", "bsz": "16", "num_updates": "20400", "lr": "4.90045e-05", "gnorm": "1.504", "loss_scale": "256", "train_wall": "18", "wall": "6743"}
2021-10-24 00:26:57 | INFO | train_inner | {"epoch": 17, "update": 16.736, "loss": "2.189", "nll_loss": "0.293", "ppl": "1.23", "wps": "2464.7", "ups": "5.53", "wpb": "446.1", "bsz": "16", "num_updates": "20500", "lr": "4.89995e-05", "gnorm": "1.534", "loss_scale": "256", "train_wall": "18", "wall": "6761"}
2021-10-24 00:27:15 | INFO | train_inner | {"epoch": 17, "update": 16.817, "loss": "2.262", "nll_loss": "0.374", "ppl": "1.3", "wps": "2676.8", "ups": "5.46", "wpb": "490.4", "bsz": "16", "num_updates": "20600", "lr": "4.89945e-05", "gnorm": "1.491", "loss_scale": "256", "train_wall": "18", "wall": "6779"}
2021-10-24 00:27:34 | INFO | train_inner | {"epoch": 17, "update": 16.899, "loss": "2.227", "nll_loss": "0.335", "ppl": "1.26", "wps": "2585", "ups": "5.32", "wpb": "485.6", "bsz": "16", "num_updates": "20700", "lr": "4.89895e-05", "gnorm": "1.471", "loss_scale": "256", "train_wall": "19", "wall": "6798"}
2021-10-24 00:27:53 | INFO | train_inner | {"epoch": 17, "update": 16.98, "loss": "2.239", "nll_loss": "0.35", "ppl": "1.27", "wps": "2395.4", "ups": "5.47", "wpb": "438", "bsz": "16", "num_updates": "20800", "lr": "4.89845e-05", "gnorm": "1.436", "loss_scale": "256", "train_wall": "18", "wall": "6817"}
2021-10-24 00:27:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-24 00:30:52 | INFO | valid | {"epoch": 17, "valid_loss": "3.704", "valid_nll_loss": "1.97", "valid_ppl": "3.92", "valid_bleu": "30.81", "valid_wps": "397.3", "valid_wpb": "226.2", "valid_bsz": "8", "valid_num_updates": "20824", "valid_best_bleu": "31.92"}
2021-10-24 00:30:52 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-24 00:30:58 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/scratch/unique/large/checkpoint_last.pt (epoch 17 @ 20824 updates, score 30.81) (writing took 5.919887903961353 seconds)
2021-10-24 00:30:58 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2021-10-24 00:30:58 | INFO | train | {"epoch": 17, "train_loss": "2.231", "train_nll_loss": "0.34", "train_ppl": "1.27", "train_wps": "1435.8", "train_ups": "3.03", "train_wpb": "473.3", "train_bsz": "16", "train_num_updates": "20824", "train_lr": "4.89833e-05", "train_gnorm": "1.446", "train_loss_scale": "256", "train_train_wall": "220", "train_wall": "7002"}
2021-10-24 00:30:58 | INFO | fairseq_cli.train | begin training epoch 17
2021-10-24 00:31:11 | INFO | train_inner | {"epoch": 18, "update": 17.062, "loss": "2.249", "nll_loss": "0.358", "ppl": "1.28", "wps": "226.5", "ups": "0.5", "wpb": "450.8", "bsz": "15.9", "num_updates": "20900", "lr": "4.89795e-05", "gnorm": "1.5", "loss_scale": "256", "train_wall": "18", "wall": "7016"}
2021-10-24 00:31:30 | INFO | train_inner | {"epoch": 18, "update": 17.144, "loss": "2.251", "nll_loss": "0.362", "ppl": "1.29", "wps": "2916.9", "ups": "5.54", "wpb": "526.6", "bsz": "16", "num_updates": "21000", "lr": "4.89745e-05", "gnorm": "1.504", "loss_scale": "256", "train_wall": "18", "wall": "7034"}
2021-10-24 00:31:48 | INFO | train_inner | {"epoch": 18, "update": 17.225, "loss": "2.188", "nll_loss": "0.293", "ppl": "1.22", "wps": "2347", "ups": "5.38", "wpb": "436.3", "bsz": "16", "num_updates": "21100", "lr": "4.89695e-05", "gnorm": "1.348", "loss_scale": "256", "train_wall": "18", "wall": "7052"}
2021-10-24 00:32:06 | INFO | train_inner | {"epoch": 18, "update": 17.307, "loss": "2.207", "nll_loss": "0.313", "ppl": "1.24", "wps": "2766.9", "ups": "5.7", "wpb": "485.1", "bsz": "16", "num_updates": "21200", "lr": "4.89645e-05", "gnorm": "1.361", "loss_scale": "256", "train_wall": "17", "wall": "7070"}
2021-10-24 00:32:23 | INFO | train_inner | {"epoch": 18, "update": 17.389, "loss": "2.187", "nll_loss": "0.291", "ppl": "1.22", "wps": "2759.5", "ups": "5.76", "wpb": "479", "bsz": "16", "num_updates": "21300", "lr": "4.89595e-05", "gnorm": "1.379", "loss_scale": "256", "train_wall": "17", "wall": "7087"}
2021-10-24 00:32:40 | INFO | train_inner | {"epoch": 18, "update": 17.47, "loss": "2.225", "nll_loss": "0.335", "ppl": "1.26", "wps": "2763.7", "ups": "5.85", "wpb": "472.1", "bsz": "16", "num_updates": "21400", "lr": "4.89545e-05", "gnorm": "1.355", "loss_scale": "256", "train_wall": "17", "wall": "7104"}
2021-10-24 00:32:59 | INFO | train_inner | {"epoch": 18, "update": 17.552, "loss": "2.216", "nll_loss": "0.324", "ppl": "1.25", "wps": "2486.1", "ups": "5.42", "wpb": "458.4", "bsz": "16", "num_updates": "21500", "lr": "4.89495e-05", "gnorm": "1.377", "loss_scale": "256", "train_wall": "18", "wall": "7123"}
2021-10-24 00:33:17 | INFO | train_inner | {"epoch": 18, "update": 17.633, "loss": "2.233", "nll_loss": "0.342", "ppl": "1.27", "wps": "2658", "ups": "5.39", "wpb": "493.4", "bsz": "16", "num_updates": "21600", "lr": "4.89445e-05", "gnorm": "1.44", "loss_scale": "256", "train_wall": "18", "wall": "7141"}
2021-10-24 00:33:36 | INFO | train_inner | {"epoch": 18, "update": 17.715, "loss": "2.203", "nll_loss": "0.309", "ppl": "1.24", "wps": "2599.4", "ups": "5.28", "wpb": "492", "bsz": "16", "num_updates": "21700", "lr": "4.89395e-05", "gnorm": "1.457", "loss_scale": "256", "train_wall": "19", "wall": "7160"}
2021-10-24 00:33:54 | INFO | train_inner | {"epoch": 18, "update": 17.797, "loss": "2.238", "nll_loss": "0.348", "ppl": "1.27", "wps": "2617.5", "ups": "5.45", "wpb": "480.5", "bsz": "16", "num_updates": "21800", "lr": "4.89345e-05", "gnorm": "1.459", "loss_scale": "256", "train_wall": "18", "wall": "7178"}
2021-10-24 00:34:13 | INFO | train_inner | {"epoch": 18, "update": 17.878, "loss": "2.272", "nll_loss": "0.385", "ppl": "1.31", "wps": "2657.8", "ups": "5.49", "wpb": "483.8", "bsz": "16", "num_updates": "21900", "lr": "4.89295e-05", "gnorm": "1.473", "loss_scale": "256", "train_wall": "18", "wall": "7197"}
2021-10-24 00:34:30 | INFO | train_inner | {"epoch": 18, "update": 17.96, "loss": "2.238", "nll_loss": "0.35", "ppl": "1.27", "wps": "2306.1", "ups": "5.64", "wpb": "409.2", "bsz": "16", "num_updates": "22000", "lr": "4.89245e-05", "gnorm": "1.495", "loss_scale": "256", "train_wall": "18", "wall": "7214"}
2021-10-24 00:34:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-24 00:37:25 | INFO | valid | {"epoch": 18, "valid_loss": "3.723", "valid_nll_loss": "1.992", "valid_ppl": "3.98", "valid_bleu": "29.09", "valid_wps": "420.7", "valid_wpb": "226.2", "valid_bsz": "8", "valid_num_updates": "22049", "valid_best_bleu": "31.92"}
2021-10-24 00:37:25 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-24 00:37:45 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/scratch/unique/large/checkpoint_last.pt (epoch 18 @ 22049 updates, score 29.09) (writing took 19.777041518012993 seconds)
2021-10-24 00:37:45 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2021-10-24 00:37:45 | INFO | train | {"epoch": 18, "train_loss": "2.226", "train_nll_loss": "0.334", "train_ppl": "1.26", "train_wps": "1423.4", "train_ups": "3.01", "train_wpb": "473.3", "train_bsz": "16", "train_num_updates": "22049", "train_lr": "4.8922e-05", "train_gnorm": "1.428", "train_loss_scale": "256", "train_train_wall": "220", "train_wall": "7409"}
2021-10-24 00:37:45 | INFO | fairseq_cli.train | begin training epoch 18
2021-10-24 00:37:55 | INFO | train_inner | {"epoch": 19, "update": 18.042, "loss": "2.21", "nll_loss": "0.317", "ppl": "1.25", "wps": "224.5", "ups": "0.49", "wpb": "459.2", "bsz": "15.9", "num_updates": "22100", "lr": "4.89195e-05", "gnorm": "1.411", "loss_scale": "256", "train_wall": "19", "wall": "7419"}
2021-10-24 00:38:13 | INFO | train_inner | {"epoch": 19, "update": 18.123, "loss": "2.236", "nll_loss": "0.348", "ppl": "1.27", "wps": "2617.7", "ups": "5.4", "wpb": "484.6", "bsz": "16", "num_updates": "22200", "lr": "4.89145e-05", "gnorm": "1.342", "loss_scale": "256", "train_wall": "18", "wall": "7437"}
2021-10-24 00:38:32 | INFO | train_inner | {"epoch": 19, "update": 18.205, "loss": "2.203", "nll_loss": "0.308", "ppl": "1.24", "wps": "2423.4", "ups": "5.25", "wpb": "461.6", "bsz": "16", "num_updates": "22300", "lr": "4.89095e-05", "gnorm": "1.357", "loss_scale": "256", "train_wall": "19", "wall": "7456"}
2021-10-24 00:38:52 | INFO | train_inner | {"epoch": 19, "update": 18.287, "loss": "2.176", "nll_loss": "0.282", "ppl": "1.22", "wps": "2361.7", "ups": "5.2", "wpb": "454.1", "bsz": "16", "num_updates": "22400", "lr": "4.89045e-05", "gnorm": "1.362", "loss_scale": "256", "train_wall": "19", "wall": "7476"}
2021-10-24 00:39:11 | INFO | train_inner | {"epoch": 19, "update": 18.368, "loss": "2.253", "nll_loss": "0.363", "ppl": "1.29", "wps": "2698.3", "ups": "5.09", "wpb": "529.6", "bsz": "16", "num_updates": "22500", "lr": "4.88994e-05", "gnorm": "1.439", "loss_scale": "256", "train_wall": "19", "wall": "7495"}
2021-10-24 00:39:30 | INFO | train_inner | {"epoch": 19, "update": 18.45, "loss": "2.188", "nll_loss": "0.293", "ppl": "1.23", "wps": "2350.2", "ups": "5.42", "wpb": "433.7", "bsz": "16", "num_updates": "22600", "lr": "4.88944e-05", "gnorm": "1.359", "loss_scale": "256", "train_wall": "18", "wall": "7514"}
2021-10-24 00:39:48 | INFO | train_inner | {"epoch": 19, "update": 18.531, "loss": "2.232", "nll_loss": "0.342", "ppl": "1.27", "wps": "2406", "ups": "5.36", "wpb": "448.9", "bsz": "16", "num_updates": "22700", "lr": "4.88894e-05", "gnorm": "1.438", "loss_scale": "256", "train_wall": "18", "wall": "7532"}
2021-10-24 00:40:07 | INFO | train_inner | {"epoch": 19, "update": 18.613, "loss": "2.211", "nll_loss": "0.32", "ppl": "1.25", "wps": "2358.4", "ups": "5.44", "wpb": "433.6", "bsz": "16", "num_updates": "22800", "lr": "4.88844e-05", "gnorm": "1.477", "loss_scale": "256", "train_wall": "18", "wall": "7551"}
2021-10-24 00:40:26 | INFO | train_inner | {"epoch": 19, "update": 18.695, "loss": "2.297", "nll_loss": "0.414", "ppl": "1.33", "wps": "2698.7", "ups": "5.19", "wpb": "520", "bsz": "16", "num_updates": "22900", "lr": "4.88794e-05", "gnorm": "1.464", "loss_scale": "256", "train_wall": "19", "wall": "7570"}
2021-10-24 00:40:45 | INFO | train_inner | {"epoch": 19, "update": 18.776, "loss": "2.219", "nll_loss": "0.327", "ppl": "1.25", "wps": "2601", "ups": "5.31", "wpb": "490", "bsz": "16", "num_updates": "23000", "lr": "4.88744e-05", "gnorm": "1.408", "loss_scale": "256", "train_wall": "19", "wall": "7589"}
2021-10-24 00:41:02 | INFO | train_inner | {"epoch": 19, "update": 18.858, "loss": "2.183", "nll_loss": "0.288", "ppl": "1.22", "wps": "2760.5", "ups": "5.71", "wpb": "483.6", "bsz": "16", "num_updates": "23100", "lr": "4.88694e-05", "gnorm": "1.451", "loss_scale": "256", "train_wall": "17", "wall": "7606"}
2021-10-24 00:41:19 | INFO | train_inner | {"epoch": 19, "update": 18.94, "loss": "2.197", "nll_loss": "0.303", "ppl": "1.23", "wps": "2720.8", "ups": "6.05", "wpb": "449.9", "bsz": "16", "num_updates": "23200", "lr": "4.88644e-05", "gnorm": "1.443", "loss_scale": "256", "train_wall": "16", "wall": "7623"}
2021-10-24 00:41:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-24 00:44:14 | INFO | valid | {"epoch": 19, "valid_loss": "3.706", "valid_nll_loss": "1.981", "valid_ppl": "3.95", "valid_bleu": "30.81", "valid_wps": "432.4", "valid_wpb": "226.2", "valid_bsz": "8", "valid_num_updates": "23274", "valid_best_bleu": "31.92"}
2021-10-24 00:44:14 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-24 00:44:29 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/scratch/unique/large/checkpoint_last.pt (epoch 19 @ 23274 updates, score 30.81) (writing took 14.503467644914053 seconds)
2021-10-24 00:44:29 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2021-10-24 00:44:29 | INFO | train | {"epoch": 19, "train_loss": "2.221", "train_nll_loss": "0.33", "train_ppl": "1.26", "train_wps": "1436.1", "train_ups": "3.03", "train_wpb": "473.3", "train_bsz": "16", "train_num_updates": "23274", "train_lr": "4.88607e-05", "train_gnorm": "1.419", "train_loss_scale": "256", "train_train_wall": "226", "train_wall": "7813"}
2021-10-24 00:44:29 | INFO | fairseq_cli.train | begin training epoch 19
2021-10-24 00:44:34 | INFO | train_inner | {"epoch": 20, "update": 19.021, "loss": "2.253", "nll_loss": "0.364", "ppl": "1.29", "wps": "246.1", "ups": "0.51", "wpb": "479.4", "bsz": "15.9", "num_updates": "23300", "lr": "4.88594e-05", "gnorm": "1.484", "loss_scale": "256", "train_wall": "19", "wall": "7818"}
2021-10-24 00:44:36 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 128.0
2021-10-24 00:44:53 | INFO | train_inner | {"epoch": 20, "update": 19.104, "loss": "2.162", "nll_loss": "0.267", "ppl": "1.2", "wps": "2151.9", "ups": "5.21", "wpb": "412.7", "bsz": "16", "num_updates": "23400", "lr": "4.88544e-05", "gnorm": "1.195", "loss_scale": "141", "train_wall": "19", "wall": "7837"}
2021-10-24 00:45:12 | INFO | train_inner | {"epoch": 20, "update": 19.185, "loss": "2.21", "nll_loss": "0.319", "ppl": "1.25", "wps": "2475.6", "ups": "5.19", "wpb": "476.7", "bsz": "16", "num_updates": "23500", "lr": "4.88494e-05", "gnorm": "1.293", "loss_scale": "128", "train_wall": "19", "wall": "7856"}
2021-10-24 00:45:29 | INFO | train_inner | {"epoch": 20, "update": 19.267, "loss": "2.2", "nll_loss": "0.306", "ppl": "1.24", "wps": "2793.1", "ups": "5.84", "wpb": "478.4", "bsz": "16", "num_updates": "23600", "lr": "4.88444e-05", "gnorm": "1.265", "loss_scale": "128", "train_wall": "17", "wall": "7873"}
2021-10-24 00:45:48 | INFO | train_inner | {"epoch": 20, "update": 19.349, "loss": "2.18", "nll_loss": "0.285", "ppl": "1.22", "wps": "2568.5", "ups": "5.35", "wpb": "480.5", "bsz": "16", "num_updates": "23700", "lr": "4.88394e-05", "gnorm": "1.249", "loss_scale": "128", "train_wall": "18", "wall": "7892"}
2021-10-24 00:46:07 | INFO | train_inner | {"epoch": 20, "update": 19.43, "loss": "2.235", "nll_loss": "0.346", "ppl": "1.27", "wps": "2581.2", "ups": "5.17", "wpb": "499.2", "bsz": "16", "num_updates": "23800", "lr": "4.88344e-05", "gnorm": "1.287", "loss_scale": "128", "train_wall": "19", "wall": "7911"}
2021-10-24 00:46:25 | INFO | train_inner | {"epoch": 20, "update": 19.512, "loss": "2.185", "nll_loss": "0.293", "ppl": "1.23", "wps": "2404", "ups": "5.52", "wpb": "435.2", "bsz": "16", "num_updates": "23900", "lr": "4.88294e-05", "gnorm": "1.322", "loss_scale": "128", "train_wall": "18", "wall": "7929"}
2021-10-24 00:46:45 | INFO | train_inner | {"epoch": 20, "update": 19.593, "loss": "2.199", "nll_loss": "0.307", "ppl": "1.24", "wps": "2735.3", "ups": "5.15", "wpb": "531", "bsz": "16", "num_updates": "24000", "lr": "4.88244e-05", "gnorm": "1.255", "loss_scale": "128", "train_wall": "19", "wall": "7949"}
2021-10-24 00:47:03 | INFO | train_inner | {"epoch": 20, "update": 19.675, "loss": "2.18", "nll_loss": "0.285", "ppl": "1.22", "wps": "2746.8", "ups": "5.53", "wpb": "496.4", "bsz": "16", "num_updates": "24100", "lr": "4.88194e-05", "gnorm": "1.213", "loss_scale": "128", "train_wall": "18", "wall": "7967"}
2021-10-24 00:47:21 | INFO | train_inner | {"epoch": 20, "update": 19.757, "loss": "2.252", "nll_loss": "0.367", "ppl": "1.29", "wps": "2776.1", "ups": "5.56", "wpb": "499.1", "bsz": "16", "num_updates": "24200", "lr": "4.88144e-05", "gnorm": "1.326", "loss_scale": "128", "train_wall": "18", "wall": "7985"}
2021-10-24 00:47:39 | INFO | train_inner | {"epoch": 20, "update": 19.838, "loss": "2.187", "nll_loss": "0.295", "ppl": "1.23", "wps": "2338.9", "ups": "5.49", "wpb": "425.9", "bsz": "16", "num_updates": "24300", "lr": "4.88094e-05", "gnorm": "1.275", "loss_scale": "128", "train_wall": "18", "wall": "8003"}
2021-10-24 00:47:56 | INFO | train_inner | {"epoch": 20, "update": 19.92, "loss": "2.191", "nll_loss": "0.297", "ppl": "1.23", "wps": "2697", "ups": "5.95", "wpb": "453.1", "bsz": "16", "num_updates": "24400", "lr": "4.88044e-05", "gnorm": "1.286", "loss_scale": "128", "train_wall": "17", "wall": "8020"}
2021-10-24 00:48:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-24 00:51:06 | INFO | valid | {"epoch": 20, "valid_loss": "3.71", "valid_nll_loss": "1.989", "valid_ppl": "3.97", "valid_bleu": "31.4", "valid_wps": "407.4", "valid_wpb": "226.2", "valid_bsz": "8", "valid_num_updates": "24498", "valid_best_bleu": "31.92"}
2021-10-24 00:51:06 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-24 00:51:19 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/scratch/unique/large/checkpoint_last.pt (epoch 20 @ 24498 updates, score 31.4) (writing took 13.33904789108783 seconds)
2021-10-24 00:51:19 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2021-10-24 00:51:19 | INFO | train | {"epoch": 20, "train_loss": "2.201", "train_nll_loss": "0.309", "train_ppl": "1.24", "train_wps": "1408.8", "train_ups": "2.99", "train_wpb": "471.9", "train_bsz": "16", "train_num_updates": "24498", "train_lr": "4.87995e-05", "train_gnorm": "1.267", "train_loss_scale": "132", "train_train_wall": "223", "train_wall": "8223"}
2021-10-24 00:51:19 | INFO | fairseq_cli.train | begin training epoch 20
2021-10-24 00:51:19 | INFO | train_inner | {"epoch": 21, "update": 20.002, "loss": "2.214", "nll_loss": "0.323", "ppl": "1.25", "wps": "238.6", "ups": "0.49", "wpb": "485.8", "bsz": "15.9", "num_updates": "24500", "lr": "4.87994e-05", "gnorm": "1.226", "loss_scale": "128", "train_wall": "19", "wall": "8224"}
2021-10-24 00:51:39 | INFO | train_inner | {"epoch": 21, "update": 20.083, "loss": "2.215", "nll_loss": "0.323", "ppl": "1.25", "wps": "2714.4", "ups": "5.06", "wpb": "536.7", "bsz": "16", "num_updates": "24600", "lr": "4.87944e-05", "gnorm": "1.119", "loss_scale": "128", "train_wall": "20", "wall": "8243"}
2021-10-24 00:51:58 | INFO | train_inner | {"epoch": 21, "update": 20.165, "loss": "2.201", "nll_loss": "0.311", "ppl": "1.24", "wps": "2588.7", "ups": "5.37", "wpb": "481.9", "bsz": "16", "num_updates": "24700", "lr": "4.87894e-05", "gnorm": "1.215", "loss_scale": "128", "train_wall": "18", "wall": "8262"}
2021-10-24 00:52:17 | INFO | train_inner | {"epoch": 21, "update": 20.247, "loss": "2.205", "nll_loss": "0.314", "ppl": "1.24", "wps": "2365.2", "ups": "5.15", "wpb": "459.4", "bsz": "16", "num_updates": "24800", "lr": "4.87844e-05", "gnorm": "1.337", "loss_scale": "128", "train_wall": "19", "wall": "8281"}
2021-10-24 00:52:34 | INFO | train_inner | {"epoch": 21, "update": 20.328, "loss": "2.201", "nll_loss": "0.31", "ppl": "1.24", "wps": "2882.7", "ups": "5.91", "wpb": "487.5", "bsz": "16", "num_updates": "24900", "lr": "4.87794e-05", "gnorm": "1.22", "loss_scale": "128", "train_wall": "17", "wall": "8298"}
2021-10-24 00:52:51 | INFO | train_inner | {"epoch": 21, "update": 20.41, "loss": "2.219", "nll_loss": "0.33", "ppl": "1.26", "wps": "2805.2", "ups": "5.87", "wpb": "477.8", "bsz": "16", "num_updates": "25000", "lr": "4.87744e-05", "gnorm": "1.194", "loss_scale": "128", "train_wall": "17", "wall": "8315"}
2021-10-24 00:53:12 | INFO | train_inner | {"epoch": 21, "update": 20.491, "loss": "2.252", "nll_loss": "0.365", "ppl": "1.29", "wps": "2583.2", "ups": "4.91", "wpb": "526.2", "bsz": "16", "num_updates": "25100", "lr": "4.87694e-05", "gnorm": "1.31", "loss_scale": "128", "train_wall": "20", "wall": "8336"}
2021-10-24 00:53:30 | INFO | train_inner | {"epoch": 21, "update": 20.573, "loss": "2.167", "nll_loss": "0.273", "ppl": "1.21", "wps": "2291.1", "ups": "5.33", "wpb": "429.7", "bsz": "16", "num_updates": "25200", "lr": "4.87644e-05", "gnorm": "1.209", "loss_scale": "128", "train_wall": "19", "wall": "8354"}
2021-10-24 00:53:50 | INFO | train_inner | {"epoch": 21, "update": 20.655, "loss": "2.178", "nll_loss": "0.284", "ppl": "1.22", "wps": "2305.2", "ups": "5.06", "wpb": "455.3", "bsz": "16", "num_updates": "25300", "lr": "4.87594e-05", "gnorm": "1.29", "loss_scale": "128", "train_wall": "20", "wall": "8374"}
2021-10-24 00:54:09 | INFO | train_inner | {"epoch": 21, "update": 20.736, "loss": "2.223", "nll_loss": "0.335", "ppl": "1.26", "wps": "2605.5", "ups": "5.37", "wpb": "485.4", "bsz": "16", "num_updates": "25400", "lr": "4.87544e-05", "gnorm": "1.257", "loss_scale": "128", "train_wall": "18", "wall": "8393"}
2021-10-24 00:54:27 | INFO | train_inner | {"epoch": 21, "update": 20.818, "loss": "2.205", "nll_loss": "0.314", "ppl": "1.24", "wps": "2533.9", "ups": "5.48", "wpb": "462.5", "bsz": "16", "num_updates": "25500", "lr": "4.87494e-05", "gnorm": "1.292", "loss_scale": "128", "train_wall": "18", "wall": "8411"}
2021-10-24 00:54:44 | INFO | train_inner | {"epoch": 21, "update": 20.9, "loss": "2.172", "nll_loss": "0.278", "ppl": "1.21", "wps": "2471.6", "ups": "5.79", "wpb": "426.7", "bsz": "16", "num_updates": "25600", "lr": "4.87444e-05", "gnorm": "1.291", "loss_scale": "128", "train_wall": "17", "wall": "8428"}
2021-10-24 00:55:02 | INFO | train_inner | {"epoch": 21, "update": 20.981, "loss": "2.176", "nll_loss": "0.282", "ppl": "1.22", "wps": "2574.7", "ups": "5.76", "wpb": "446.9", "bsz": "16", "num_updates": "25700", "lr": "4.87394e-05", "gnorm": "1.287", "loss_scale": "128", "train_wall": "17", "wall": "8446"}
2021-10-24 00:55:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-24 00:58:01 | INFO | valid | {"epoch": 21, "valid_loss": "3.716", "valid_nll_loss": "1.998", "valid_ppl": "3.99", "valid_bleu": "30.57", "valid_wps": "398.4", "valid_wpb": "226.2", "valid_bsz": "8", "valid_num_updates": "25723", "valid_best_bleu": "31.92"}
2021-10-24 00:58:01 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-24 00:58:13 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/scratch/unique/large/checkpoint_last.pt (epoch 21 @ 25723 updates, score 30.57) (writing took 12.541770120034926 seconds)
2021-10-24 00:58:13 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2021-10-24 00:58:13 | INFO | train | {"epoch": 21, "train_loss": "2.203", "train_nll_loss": "0.312", "train_ppl": "1.24", "train_wps": "1399.6", "train_ups": "2.96", "train_wpb": "473.3", "train_bsz": "16", "train_num_updates": "25723", "train_lr": "4.87382e-05", "train_gnorm": "1.251", "train_loss_scale": "128", "train_train_wall": "225", "train_wall": "8637"}
2021-10-24 00:58:13 | INFO | fairseq_cli.train | begin training epoch 21
2021-10-24 00:58:28 | INFO | train_inner | {"epoch": 22, "update": 21.063, "loss": "2.201", "nll_loss": "0.309", "ppl": "1.24", "wps": "234.2", "ups": "0.48", "wpb": "483.6", "bsz": "15.9", "num_updates": "25800", "lr": "4.87344e-05", "gnorm": "1.206", "loss_scale": "128", "train_wall": "19", "wall": "8652"}
2021-10-24 00:58:48 | INFO | train_inner | {"epoch": 22, "update": 21.144, "loss": "2.183", "nll_loss": "0.291", "ppl": "1.22", "wps": "2278.4", "ups": "5.15", "wpb": "442.4", "bsz": "16", "num_updates": "25900", "lr": "4.87294e-05", "gnorm": "1.142", "loss_scale": "128", "train_wall": "19", "wall": "8672"}
2021-10-24 00:59:07 | INFO | train_inner | {"epoch": 22, "update": 21.226, "loss": "2.189", "nll_loss": "0.298", "ppl": "1.23", "wps": "2451.8", "ups": "5.13", "wpb": "477.7", "bsz": "16", "num_updates": "26000", "lr": "4.87244e-05", "gnorm": "1.29", "loss_scale": "128", "train_wall": "19", "wall": "8691"}
2021-10-24 00:59:27 | INFO | train_inner | {"epoch": 22, "update": 21.308, "loss": "2.231", "nll_loss": "0.343", "ppl": "1.27", "wps": "2566.6", "ups": "5.06", "wpb": "506.9", "bsz": "16", "num_updates": "26100", "lr": "4.87194e-05", "gnorm": "1.262", "loss_scale": "128", "train_wall": "20", "wall": "8711"}
2021-10-24 00:59:45 | INFO | train_inner | {"epoch": 22, "update": 21.389, "loss": "2.21", "nll_loss": "0.32", "ppl": "1.25", "wps": "2675.7", "ups": "5.43", "wpb": "492.5", "bsz": "16", "num_updates": "26200", "lr": "4.87144e-05", "gnorm": "1.226", "loss_scale": "128", "train_wall": "18", "wall": "8729"}
2021-10-24 01:00:04 | INFO | train_inner | {"epoch": 22, "update": 21.471, "loss": "2.162", "nll_loss": "0.268", "ppl": "1.2", "wps": "2497", "ups": "5.34", "wpb": "467.7", "bsz": "16", "num_updates": "26300", "lr": "4.87094e-05", "gnorm": "1.241", "loss_scale": "128", "train_wall": "19", "wall": "8748"}
2021-10-24 01:00:25 | INFO | train_inner | {"epoch": 22, "update": 21.553, "loss": "2.167", "nll_loss": "0.272", "ppl": "1.21", "wps": "2204.7", "ups": "4.76", "wpb": "463.6", "bsz": "16", "num_updates": "26400", "lr": "4.87044e-05", "gnorm": "1.235", "loss_scale": "128", "train_wall": "21", "wall": "8769"}
2021-10-24 01:00:46 | INFO | train_inner | {"epoch": 22, "update": 21.634, "loss": "2.207", "nll_loss": "0.317", "ppl": "1.25", "wps": "2339.1", "ups": "4.73", "wpb": "495", "bsz": "16", "num_updates": "26500", "lr": "4.86993e-05", "gnorm": "1.264", "loss_scale": "128", "train_wall": "21", "wall": "8790"}
2021-10-24 01:01:06 | INFO | train_inner | {"epoch": 22, "update": 21.716, "loss": "2.189", "nll_loss": "0.3", "ppl": "1.23", "wps": "2243.3", "ups": "5.1", "wpb": "439.9", "bsz": "16", "num_updates": "26600", "lr": "4.86943e-05", "gnorm": "1.306", "loss_scale": "128", "train_wall": "19", "wall": "8810"}
2021-10-24 01:01:23 | INFO | train_inner | {"epoch": 22, "update": 21.798, "loss": "2.199", "nll_loss": "0.308", "ppl": "1.24", "wps": "2671.2", "ups": "5.87", "wpb": "454.8", "bsz": "16", "num_updates": "26700", "lr": "4.86893e-05", "gnorm": "1.353", "loss_scale": "128", "train_wall": "17", "wall": "8827"}
2021-10-24 01:01:42 | INFO | train_inner | {"epoch": 22, "update": 21.879, "loss": "2.251", "nll_loss": "0.364", "ppl": "1.29", "wps": "2745.3", "ups": "5.32", "wpb": "516.2", "bsz": "16", "num_updates": "26800", "lr": "4.86843e-05", "gnorm": "1.319", "loss_scale": "128", "train_wall": "19", "wall": "8846"}
2021-10-24 01:02:00 | INFO | train_inner | {"epoch": 22, "update": 21.961, "loss": "2.22", "nll_loss": "0.331", "ppl": "1.26", "wps": "2603.5", "ups": "5.5", "wpb": "473", "bsz": "16", "num_updates": "26900", "lr": "4.86793e-05", "gnorm": "1.254", "loss_scale": "128", "train_wall": "18", "wall": "8864"}
2021-10-24 01:02:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-24 01:05:03 | INFO | valid | {"epoch": 22, "valid_loss": "3.715", "valid_nll_loss": "1.987", "valid_ppl": "3.97", "valid_bleu": "31.07", "valid_wps": "398.2", "valid_wpb": "226.2", "valid_bsz": "8", "valid_num_updates": "26948", "valid_best_bleu": "31.92"}
2021-10-24 01:05:03 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-24 01:05:09 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/scratch/unique/large/checkpoint_last.pt (epoch 22 @ 26948 updates, score 31.07) (writing took 5.963694017962553 seconds)
2021-10-24 01:05:09 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2021-10-24 01:05:09 | INFO | train | {"epoch": 22, "train_loss": "2.199", "train_nll_loss": "0.308", "train_ppl": "1.24", "train_wps": "1394.1", "train_ups": "2.95", "train_wpb": "473.3", "train_bsz": "16", "train_num_updates": "26948", "train_lr": "4.86769e-05", "train_gnorm": "1.258", "train_loss_scale": "128", "train_train_wall": "232", "train_wall": "9053"}
2021-10-24 01:05:09 | INFO | fairseq_cli.train | begin training epoch 22
2021-10-24 01:05:18 | INFO | train_inner | {"epoch": 23, "update": 22.042, "loss": "2.197", "nll_loss": "0.306", "ppl": "1.24", "wps": "228.7", "ups": "0.5", "wpb": "453.7", "bsz": "15.9", "num_updates": "27000", "lr": "4.86743e-05", "gnorm": "1.25", "loss_scale": "128", "train_wall": "17", "wall": "9062"}
2021-10-24 01:05:37 | INFO | train_inner | {"epoch": 23, "update": 22.124, "loss": "2.164", "nll_loss": "0.27", "ppl": "1.21", "wps": "2395.2", "ups": "5.36", "wpb": "447.1", "bsz": "16", "num_updates": "27100", "lr": "4.86693e-05", "gnorm": "1.189", "loss_scale": "128", "train_wall": "18", "wall": "9081"}
2021-10-24 01:05:55 | INFO | train_inner | {"epoch": 23, "update": 22.206, "loss": "2.191", "nll_loss": "0.3", "ppl": "1.23", "wps": "2355.8", "ups": "5.57", "wpb": "423", "bsz": "16", "num_updates": "27200", "lr": "4.86643e-05", "gnorm": "1.256", "loss_scale": "128", "train_wall": "18", "wall": "9099"}
2021-10-24 01:06:13 | INFO | train_inner | {"epoch": 23, "update": 22.287, "loss": "2.183", "nll_loss": "0.29", "ppl": "1.22", "wps": "2630.2", "ups": "5.44", "wpb": "483.8", "bsz": "16", "num_updates": "27300", "lr": "4.86593e-05", "gnorm": "1.263", "loss_scale": "128", "train_wall": "18", "wall": "9117"}
2021-10-24 01:06:31 | INFO | train_inner | {"epoch": 23, "update": 22.369, "loss": "2.173", "nll_loss": "0.28", "ppl": "1.21", "wps": "2676.7", "ups": "5.67", "wpb": "472.4", "bsz": "16", "num_updates": "27400", "lr": "4.86543e-05", "gnorm": "1.213", "loss_scale": "128", "train_wall": "17", "wall": "9135"}
2021-10-24 01:06:49 | INFO | train_inner | {"epoch": 23, "update": 22.451, "loss": "2.19", "nll_loss": "0.299", "ppl": "1.23", "wps": "2670.2", "ups": "5.39", "wpb": "495", "bsz": "16", "num_updates": "27500", "lr": "4.86493e-05", "gnorm": "1.212", "loss_scale": "128", "train_wall": "18", "wall": "9153"}
2021-10-24 01:07:08 | INFO | train_inner | {"epoch": 23, "update": 22.532, "loss": "2.216", "nll_loss": "0.328", "ppl": "1.26", "wps": "2547.6", "ups": "5.47", "wpb": "465.4", "bsz": "16", "num_updates": "27600", "lr": "4.86443e-05", "gnorm": "1.199", "loss_scale": "128", "train_wall": "18", "wall": "9172"}
2021-10-24 01:07:27 | INFO | train_inner | {"epoch": 23, "update": 22.614, "loss": "2.228", "nll_loss": "0.339", "ppl": "1.26", "wps": "2561.5", "ups": "5.07", "wpb": "505.4", "bsz": "16", "num_updates": "27700", "lr": "4.86393e-05", "gnorm": "1.315", "loss_scale": "128", "train_wall": "19", "wall": "9191"}
2021-10-24 01:07:46 | INFO | train_inner | {"epoch": 23, "update": 22.696, "loss": "2.138", "nll_loss": "0.241", "ppl": "1.18", "wps": "2358.3", "ups": "5.25", "wpb": "449.4", "bsz": "16", "num_updates": "27800", "lr": "4.86343e-05", "gnorm": "1.33", "loss_scale": "128", "train_wall": "19", "wall": "9210"}
2021-10-24 01:08:05 | INFO | train_inner | {"epoch": 23, "update": 22.777, "loss": "2.167", "nll_loss": "0.276", "ppl": "1.21", "wps": "2234.2", "ups": "5.52", "wpb": "404.8", "bsz": "16", "num_updates": "27900", "lr": "4.86293e-05", "gnorm": "1.285", "loss_scale": "128", "train_wall": "18", "wall": "9229"}
2021-10-24 01:08:24 | INFO | train_inner | {"epoch": 23, "update": 22.859, "loss": "2.213", "nll_loss": "0.323", "ppl": "1.25", "wps": "2945", "ups": "5.2", "wpb": "565.8", "bsz": "16", "num_updates": "28000", "lr": "4.86243e-05", "gnorm": "1.328", "loss_scale": "128", "train_wall": "19", "wall": "9248"}
2021-10-24 01:08:42 | INFO | train_inner | {"epoch": 23, "update": 22.94, "loss": "2.199", "nll_loss": "0.31", "ppl": "1.24", "wps": "2623.3", "ups": "5.5", "wpb": "477.2", "bsz": "16", "num_updates": "28100", "lr": "4.86193e-05", "gnorm": "1.271", "loss_scale": "128", "train_wall": "18", "wall": "9266"}
2021-10-24 01:08:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-24 01:11:43 | INFO | valid | {"epoch": 23, "valid_loss": "3.755", "valid_nll_loss": "2.042", "valid_ppl": "4.12", "valid_bleu": "30.13", "valid_wps": "415.7", "valid_wpb": "226.2", "valid_bsz": "8", "valid_num_updates": "28173", "valid_best_bleu": "31.92"}
2021-10-24 01:11:43 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-24 01:11:49 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/scratch/unique/large/checkpoint_last.pt (epoch 23 @ 28173 updates, score 30.13) (writing took 5.714689115062356 seconds)
2021-10-24 01:11:49 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2021-10-24 01:11:49 | INFO | train | {"epoch": 23, "train_loss": "2.192", "train_nll_loss": "0.301", "train_ppl": "1.23", "train_wps": "1449", "train_ups": "3.06", "train_wpb": "473.3", "train_bsz": "16", "train_num_updates": "28173", "train_lr": "4.86157e-05", "train_gnorm": "1.263", "train_loss_scale": "128", "train_train_wall": "224", "train_wall": "9453"}
2021-10-24 01:11:49 | INFO | fairseq_cli.train | begin training epoch 23
2021-10-24 01:11:54 | INFO | train_inner | {"epoch": 24, "update": 23.022, "loss": "2.189", "nll_loss": "0.298", "ppl": "1.23", "wps": "245.7", "ups": "0.52", "wpb": "472.1", "bsz": "15.9", "num_updates": "28200", "lr": "4.86143e-05", "gnorm": "1.295", "loss_scale": "128", "train_wall": "19", "wall": "9458"}
2021-10-24 01:12:12 | INFO | train_inner | {"epoch": 24, "update": 23.104, "loss": "2.158", "nll_loss": "0.265", "ppl": "1.2", "wps": "2351.6", "ups": "5.47", "wpb": "430.1", "bsz": "16", "num_updates": "28300", "lr": "4.86093e-05", "gnorm": "1.231", "loss_scale": "128", "train_wall": "18", "wall": "9476"}
2021-10-24 01:12:31 | INFO | train_inner | {"epoch": 24, "update": 23.185, "loss": "2.176", "nll_loss": "0.283", "ppl": "1.22", "wps": "2239.2", "ups": "5.42", "wpb": "413.1", "bsz": "16", "num_updates": "28400", "lr": "4.86043e-05", "gnorm": "1.239", "loss_scale": "128", "train_wall": "18", "wall": "9495"}
2021-10-24 01:12:49 | INFO | train_inner | {"epoch": 24, "update": 23.267, "loss": "2.175", "nll_loss": "0.282", "ppl": "1.22", "wps": "2534.9", "ups": "5.35", "wpb": "473.6", "bsz": "16", "num_updates": "28500", "lr": "4.85993e-05", "gnorm": "1.205", "loss_scale": "128", "train_wall": "18", "wall": "9514"}
2021-10-24 01:13:09 | INFO | train_inner | {"epoch": 24, "update": 23.349, "loss": "2.19", "nll_loss": "0.299", "ppl": "1.23", "wps": "2706.1", "ups": "5.22", "wpb": "518.2", "bsz": "16", "num_updates": "28600", "lr": "4.85943e-05", "gnorm": "1.197", "loss_scale": "128", "train_wall": "19", "wall": "9533"}
2021-10-24 01:13:28 | INFO | train_inner | {"epoch": 24, "update": 23.43, "loss": "2.206", "nll_loss": "0.316", "ppl": "1.24", "wps": "2696.4", "ups": "5.13", "wpb": "525.1", "bsz": "16", "num_updates": "28700", "lr": "4.85893e-05", "gnorm": "1.133", "loss_scale": "128", "train_wall": "19", "wall": "9552"}
2021-10-24 01:13:47 | INFO | train_inner | {"epoch": 24, "update": 23.512, "loss": "2.142", "nll_loss": "0.247", "ppl": "1.19", "wps": "2234.7", "ups": "5.36", "wpb": "416.9", "bsz": "16", "num_updates": "28800", "lr": "4.85843e-05", "gnorm": "1.17", "loss_scale": "128", "train_wall": "18", "wall": "9571"}
2021-10-24 01:14:07 | INFO | train_inner | {"epoch": 24, "update": 23.593, "loss": "2.215", "nll_loss": "0.326", "ppl": "1.25", "wps": "2754.8", "ups": "5.01", "wpb": "549.6", "bsz": "16", "num_updates": "28900", "lr": "4.85793e-05", "gnorm": "1.331", "loss_scale": "128", "train_wall": "20", "wall": "9591"}
2021-10-24 01:14:26 | INFO | train_inner | {"epoch": 24, "update": 23.675, "loss": "2.209", "nll_loss": "0.32", "ppl": "1.25", "wps": "2451.3", "ups": "5.17", "wpb": "474", "bsz": "16", "num_updates": "29000", "lr": "4.85743e-05", "gnorm": "1.266", "loss_scale": "128", "train_wall": "19", "wall": "9610"}
2021-10-24 01:14:46 | INFO | train_inner | {"epoch": 24, "update": 23.757, "loss": "2.208", "nll_loss": "0.32", "ppl": "1.25", "wps": "2430.5", "ups": "5.04", "wpb": "482.2", "bsz": "16", "num_updates": "29100", "lr": "4.85693e-05", "gnorm": "1.273", "loss_scale": "128", "train_wall": "20", "wall": "9630"}
2021-10-24 01:15:05 | INFO | train_inner | {"epoch": 24, "update": 23.838, "loss": "2.2", "nll_loss": "0.31", "ppl": "1.24", "wps": "2450.1", "ups": "5.11", "wpb": "479.6", "bsz": "16", "num_updates": "29200", "lr": "4.85643e-05", "gnorm": "1.272", "loss_scale": "128", "train_wall": "19", "wall": "9650"}
2021-10-24 01:15:24 | INFO | train_inner | {"epoch": 24, "update": 23.92, "loss": "2.182", "nll_loss": "0.291", "ppl": "1.22", "wps": "2449", "ups": "5.27", "wpb": "465", "bsz": "16", "num_updates": "29300", "lr": "4.85593e-05", "gnorm": "1.262", "loss_scale": "128", "train_wall": "19", "wall": "9668"}
2021-10-24 01:15:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-24 01:18:36 | INFO | valid | {"epoch": 24, "valid_loss": "3.727", "valid_nll_loss": "2.004", "valid_ppl": "4.01", "valid_bleu": "31.57", "valid_wps": "401.1", "valid_wpb": "226.2", "valid_bsz": "8", "valid_num_updates": "29398", "valid_best_bleu": "31.92"}
2021-10-24 01:18:36 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-24 01:18:49 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/scratch/unique/large/checkpoint_last.pt (epoch 24 @ 29398 updates, score 31.57) (writing took 12.74737014202401 seconds)
2021-10-24 01:18:49 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2021-10-24 01:18:49 | INFO | train | {"epoch": 24, "train_loss": "2.189", "train_nll_loss": "0.298", "train_ppl": "1.23", "train_wps": "1380.7", "train_ups": "2.92", "train_wpb": "473.3", "train_bsz": "16", "train_num_updates": "29398", "train_lr": "4.85544e-05", "train_gnorm": "1.237", "train_loss_scale": "128", "train_train_wall": "231", "train_wall": "9873"}
2021-10-24 01:18:49 | INFO | fairseq_cli.train | begin training epoch 24
2021-10-24 01:18:50 | INFO | train_inner | {"epoch": 25, "update": 24.002, "loss": "2.199", "nll_loss": "0.31", "ppl": "1.24", "wps": "224.9", "ups": "0.49", "wpb": "461.3", "bsz": "15.9", "num_updates": "29400", "lr": "4.85543e-05", "gnorm": "1.277", "loss_scale": "128", "train_wall": "19", "wall": "9874"}
2021-10-24 01:19:10 | INFO | train_inner | {"epoch": 25, "update": 24.083, "loss": "2.272", "nll_loss": "0.386", "ppl": "1.31", "wps": "3029.9", "ups": "4.95", "wpb": "612", "bsz": "16", "num_updates": "29500", "lr": "4.85493e-05", "gnorm": "1.324", "loss_scale": "128", "train_wall": "20", "wall": "9894"}
2021-10-24 01:19:30 | INFO | train_inner | {"epoch": 25, "update": 24.165, "loss": "2.22", "nll_loss": "0.33", "ppl": "1.26", "wps": "2630.1", "ups": "4.91", "wpb": "535.9", "bsz": "16", "num_updates": "29600", "lr": "4.85443e-05", "gnorm": "1.252", "loss_scale": "128", "train_wall": "20", "wall": "9914"}
2021-10-24 01:19:51 | INFO | train_inner | {"epoch": 25, "update": 24.247, "loss": "2.193", "nll_loss": "0.302", "ppl": "1.23", "wps": "2330.9", "ups": "4.89", "wpb": "476.7", "bsz": "16", "num_updates": "29700", "lr": "4.85393e-05", "gnorm": "1.408", "loss_scale": "128", "train_wall": "20", "wall": "9935"}
2021-10-24 01:20:09 | INFO | train_inner | {"epoch": 25, "update": 24.328, "loss": "2.221", "nll_loss": "0.333", "ppl": "1.26", "wps": "2578.5", "ups": "5.36", "wpb": "481.2", "bsz": "16", "num_updates": "29800", "lr": "4.85343e-05", "gnorm": "1.406", "loss_scale": "128", "train_wall": "18", "wall": "9953"}
2021-10-24 01:20:28 | INFO | train_inner | {"epoch": 25, "update": 24.41, "loss": "2.163", "nll_loss": "0.27", "ppl": "1.21", "wps": "2419.7", "ups": "5.24", "wpb": "462.1", "bsz": "16", "num_updates": "29900", "lr": "4.85293e-05", "gnorm": "1.336", "loss_scale": "128", "train_wall": "19", "wall": "9972"}
2021-10-24 01:20:47 | INFO | train_inner | {"epoch": 25, "update": 24.491, "loss": "2.192", "nll_loss": "0.3", "ppl": "1.23", "wps": "2291.2", "ups": "5.41", "wpb": "423.8", "bsz": "16", "num_updates": "30000", "lr": "4.85243e-05", "gnorm": "1.476", "loss_scale": "128", "train_wall": "18", "wall": "9991"}
2021-10-24 01:21:04 | INFO | train_inner | {"epoch": 25, "update": 24.573, "loss": "2.149", "nll_loss": "0.254", "ppl": "1.19", "wps": "2472.1", "ups": "5.9", "wpb": "418.8", "bsz": "16", "num_updates": "30100", "lr": "4.85193e-05", "gnorm": "1.385", "loss_scale": "128", "train_wall": "17", "wall": "10008"}
2021-10-24 01:21:22 | INFO | train_inner | {"epoch": 25, "update": 24.655, "loss": "2.16", "nll_loss": "0.267", "ppl": "1.2", "wps": "2417.6", "ups": "5.52", "wpb": "437.6", "bsz": "16", "num_updates": "30200", "lr": "4.85143e-05", "gnorm": "1.339", "loss_scale": "128", "train_wall": "18", "wall": "10026"}
2021-10-24 01:21:40 | INFO | train_inner | {"epoch": 25, "update": 24.736, "loss": "2.161", "nll_loss": "0.267", "ppl": "1.2", "wps": "2481.2", "ups": "5.44", "wpb": "456.4", "bsz": "16", "num_updates": "30300", "lr": "4.85093e-05", "gnorm": "1.308", "loss_scale": "128", "train_wall": "18", "wall": "10044"}
2021-10-24 01:21:59 | INFO | train_inner | {"epoch": 25, "update": 24.818, "loss": "2.164", "nll_loss": "0.271", "ppl": "1.21", "wps": "2293.7", "ups": "5.31", "wpb": "432.2", "bsz": "16", "num_updates": "30400", "lr": "4.85043e-05", "gnorm": "1.428", "loss_scale": "128", "train_wall": "19", "wall": "10063"}
2021-10-24 01:22:18 | INFO | train_inner | {"epoch": 25, "update": 24.9, "loss": "2.212", "nll_loss": "0.323", "ppl": "1.25", "wps": "2574.6", "ups": "5.16", "wpb": "498.8", "bsz": "16", "num_updates": "30500", "lr": "4.84992e-05", "gnorm": "1.405", "loss_scale": "128", "train_wall": "19", "wall": "10083"}
2021-10-24 01:22:37 | INFO | train_inner | {"epoch": 25, "update": 24.981, "loss": "2.184", "nll_loss": "0.294", "ppl": "1.23", "wps": "2425.4", "ups": "5.35", "wpb": "453.6", "bsz": "16", "num_updates": "30600", "lr": "4.84942e-05", "gnorm": "1.363", "loss_scale": "128", "train_wall": "18", "wall": "10101"}
2021-10-24 01:22:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-24 01:25:35 | INFO | valid | {"epoch": 25, "valid_loss": "3.724", "valid_nll_loss": "2", "valid_ppl": "4", "valid_bleu": "31.61", "valid_wps": "401.5", "valid_wpb": "226.2", "valid_bsz": "8", "valid_num_updates": "30623", "valid_best_bleu": "31.92"}
2021-10-24 01:25:35 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-24 01:25:41 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/scratch/unique/large/checkpoint_last.pt (epoch 25 @ 30623 updates, score 31.61) (writing took 5.923879613983445 seconds)
2021-10-24 01:25:41 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2021-10-24 01:25:41 | INFO | train | {"epoch": 25, "train_loss": "2.193", "train_nll_loss": "0.302", "train_ppl": "1.23", "train_wps": "1408.5", "train_ups": "2.98", "train_wpb": "473.3", "train_bsz": "16", "train_num_updates": "30623", "train_lr": "4.84931e-05", "train_gnorm": "1.372", "train_loss_scale": "128", "train_train_wall": "230", "train_wall": "10285"}
2021-10-24 01:25:41 | INFO | fairseq_cli.train | begin training epoch 25
2021-10-24 01:25:55 | INFO | train_inner | {"epoch": 26, "update": 25.063, "loss": "2.137", "nll_loss": "0.241", "ppl": "1.18", "wps": "208.2", "ups": "0.51", "wpb": "411.5", "bsz": "15.9", "num_updates": "30700", "lr": "4.84892e-05", "gnorm": "1.371", "loss_scale": "128", "train_wall": "18", "wall": "10299"}
2021-10-24 01:26:14 | INFO | train_inner | {"epoch": 26, "update": 25.144, "loss": "2.184", "nll_loss": "0.292", "ppl": "1.22", "wps": "2567.2", "ups": "5.32", "wpb": "482.5", "bsz": "16", "num_updates": "30800", "lr": "4.84842e-05", "gnorm": "1.334", "loss_scale": "128", "train_wall": "19", "wall": "10318"}
2021-10-24 01:26:33 | INFO | train_inner | {"epoch": 26, "update": 25.226, "loss": "2.188", "nll_loss": "0.297", "ppl": "1.23", "wps": "2374.2", "ups": "5.19", "wpb": "457.5", "bsz": "16", "num_updates": "30900", "lr": "4.84792e-05", "gnorm": "1.399", "loss_scale": "128", "train_wall": "19", "wall": "10337"}
2021-10-24 01:26:52 | INFO | train_inner | {"epoch": 26, "update": 25.308, "loss": "2.172", "nll_loss": "0.28", "ppl": "1.21", "wps": "2228.2", "ups": "5.22", "wpb": "427", "bsz": "16", "num_updates": "31000", "lr": "4.84742e-05", "gnorm": "1.367", "loss_scale": "128", "train_wall": "19", "wall": "10356"}
2021-10-24 01:27:10 | INFO | train_inner | {"epoch": 26, "update": 25.389, "loss": "2.159", "nll_loss": "0.264", "ppl": "1.2", "wps": "2609.4", "ups": "5.58", "wpb": "467.4", "bsz": "16", "num_updates": "31100", "lr": "4.84692e-05", "gnorm": "1.255", "loss_scale": "128", "train_wall": "18", "wall": "10374"}
2021-10-24 01:27:28 | INFO | train_inner | {"epoch": 26, "update": 25.471, "loss": "2.28", "nll_loss": "0.397", "ppl": "1.32", "wps": "2872.1", "ups": "5.4", "wpb": "532.2", "bsz": "16", "num_updates": "31200", "lr": "4.84642e-05", "gnorm": "1.331", "loss_scale": "128", "train_wall": "18", "wall": "10392"}
2021-10-24 01:27:45 | INFO | train_inner | {"epoch": 26, "update": 25.553, "loss": "2.156", "nll_loss": "0.261", "ppl": "1.2", "wps": "2713.7", "ups": "5.89", "wpb": "461.1", "bsz": "16", "num_updates": "31300", "lr": "4.84592e-05", "gnorm": "1.301", "loss_scale": "128", "train_wall": "17", "wall": "10409"}
2021-10-24 01:28:04 | INFO | train_inner | {"epoch": 26, "update": 25.634, "loss": "2.218", "nll_loss": "0.328", "ppl": "1.26", "wps": "2533.9", "ups": "5.33", "wpb": "475.3", "bsz": "16", "num_updates": "31400", "lr": "4.84542e-05", "gnorm": "1.398", "loss_scale": "128", "train_wall": "19", "wall": "10428"}
2021-10-24 01:28:24 | INFO | train_inner | {"epoch": 26, "update": 25.716, "loss": "2.219", "nll_loss": "0.33", "ppl": "1.26", "wps": "2939.2", "ups": "4.98", "wpb": "590.7", "bsz": "16", "num_updates": "31500", "lr": "4.84492e-05", "gnorm": "1.368", "loss_scale": "128", "train_wall": "20", "wall": "10448"}
2021-10-24 01:28:43 | INFO | train_inner | {"epoch": 26, "update": 25.798, "loss": "2.193", "nll_loss": "0.301", "ppl": "1.23", "wps": "2699.5", "ups": "5.29", "wpb": "510", "bsz": "16", "num_updates": "31600", "lr": "4.84442e-05", "gnorm": "1.246", "loss_scale": "255", "train_wall": "19", "wall": "10467"}
2021-10-24 01:29:03 | INFO | train_inner | {"epoch": 26, "update": 25.879, "loss": "2.168", "nll_loss": "0.277", "ppl": "1.21", "wps": "2243.7", "ups": "4.99", "wpb": "449.6", "bsz": "16", "num_updates": "31700", "lr": "4.84392e-05", "gnorm": "1.293", "loss_scale": "256", "train_wall": "20", "wall": "10487"}
2021-10-24 01:29:22 | INFO | train_inner | {"epoch": 26, "update": 25.961, "loss": "2.149", "nll_loss": "0.256", "ppl": "1.19", "wps": "2213.9", "ups": "5.45", "wpb": "406.4", "bsz": "16", "num_updates": "31800", "lr": "4.84342e-05", "gnorm": "1.365", "loss_scale": "256", "train_wall": "18", "wall": "10506"}
2021-10-24 01:29:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-24 01:32:22 | INFO | valid | {"epoch": 26, "valid_loss": "3.729", "valid_nll_loss": "2.006", "valid_ppl": "4.02", "valid_bleu": "29.88", "valid_wps": "406.3", "valid_wpb": "226.2", "valid_bsz": "8", "valid_num_updates": "31848", "valid_best_bleu": "31.92"}
2021-10-24 01:32:22 | INFO | fairseq_cli.train | early stop since valid performance hasn't improved for last 10 runs
2021-10-24 01:32:22 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-24 01:32:28 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/scratch/unique/large/checkpoint_last.pt (epoch 26 @ 31848 updates, score 29.88) (writing took 5.927896800916642 seconds)
2021-10-24 01:32:28 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2021-10-24 01:32:28 | INFO | train | {"epoch": 26, "train_loss": "2.191", "train_nll_loss": "0.3", "train_ppl": "1.23", "train_wps": "1423.2", "train_ups": "3.01", "train_wpb": "473.3", "train_bsz": "16", "train_num_updates": "31848", "train_lr": "4.84318e-05", "train_gnorm": "1.34", "train_loss_scale": "164", "train_train_wall": "228", "train_wall": "10692"}
2021-10-24 01:32:28 | INFO | fairseq_cli.train | done training in 10687.0 seconds
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
Source: source Target: target


2021-10-24 12:50:42 | INFO | fairseq_cli.train | Namespace(activation_fn='gelu', adam_betas='(0.9, 0.98)', adam_eps=1e-06, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='mbart_base', attention_dropout=0.1, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_suffix='', clip_norm=0.0, cpu=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='../processed_data/large/data-bin', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', decoder_attention_heads=12, decoder_embed_dim=768, decoder_embed_path=None, decoder_ffn_embed_dim=3072, decoder_input_dim=768, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=True, decoder_normalize_before=False, decoder_output_dim=768, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', dropout=0.1, empty_cache_freq=0, encoder_attention_heads=12, encoder_embed_dim=768, encoder_embed_path=None, encoder_ffn_embed_dim=3072, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=False, end_learning_rate=0.0, eval_bleu=True, eval_bleu_args='{"beam": 5}', eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=True, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.1, langs='java,python,en_XX', layernorm_embedding=True, left_pad_source='True', left_pad_target='False', load_alignments=False, localsgd_frequency=3, log_format='json', log_interval=100, lr=[5e-05], lr_scheduler='polynomial_decay', max_epoch=3000, max_sentences=8, max_sentences_valid=8, max_source_positions=1024, max_target_positions=1024, max_tokens=None, max_tokens_valid=None, max_update=200000, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=-1.0, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_workers=1, optimizer='adam', optimizer_overrides='{}', patience=10, pooler_activation_fn='tanh', pooler_dropout=0.0, power=1.0, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, relu_dropout=0.0, required_batch_size_multiple=8, reset_dataloader=True, reset_lr_scheduler=True, reset_meters=True, reset_optimizer=True, restore_file='../plbart/checkpoint_11_100000.pt', save_dir='../models/scratch/unique/large', save_interval=1, save_interval_updates=0, seed=1234, sentence_avg=False, share_all_embeddings=True, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='source', stop_time_hours=0, target_lang='target', task='translation_without_lang_token', tensorboard_logdir='', threshold_loss_scale=None, tokenizer=None, total_num_update=1000000, tpu=False, train_subset='train', truncate_source=True, update_freq=[2], upsample_primary=1, use_bmuf=False, use_old_adam=False, user_dir='../user_dir', valid_subset='valid', validate_interval=1, warmup_updates=500, weight_decay=0.0)
2021-10-24 12:50:42 | INFO | fairseq.tasks.translation | [source] dictionary: 50001 types
2021-10-24 12:50:42 | INFO | fairseq.tasks.translation | [target] dictionary: 50001 types
2021-10-24 12:50:42 | INFO | fairseq.data.data_utils | loaded 2449 examples from: ../processed_data/large/data-bin/valid.source-target.source
2021-10-24 12:50:42 | INFO | fairseq.data.data_utils | loaded 2449 examples from: ../processed_data/large/data-bin/valid.source-target.target
2021-10-24 12:50:42 | INFO | fairseq.tasks.translation | ../processed_data/large/data-bin valid source-target 2449 examples
2021-10-24 12:50:47 | INFO | fairseq_cli.train | BARTModel(
  (encoder): TransformerEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(50005, 768, padding_idx=1)
    (embed_positions): LearnedPositionalEmbedding(1026, 768, padding_idx=1)
    (layernorm_embedding): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(50005, 768, padding_idx=1)
    (embed_positions): LearnedPositionalEmbedding(1026, 768, padding_idx=1)
    (layernorm_embedding): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=768, out_features=50005, bias=False)
  )
  (classification_heads): ModuleDict()
)
2021-10-24 12:50:47 | INFO | fairseq_cli.train | model mbart_base, criterion LabelSmoothedCrossEntropyCriterion
2021-10-24 12:50:47 | INFO | fairseq_cli.train | num. model params: 139220736 (num. trained: 139220736)
2021-10-24 12:50:50 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight
2021-10-24 12:50:50 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight
2021-10-24 12:50:50 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2021-10-24 12:50:50 | INFO | fairseq.utils | rank   0: capabilities =  6.1  ; total memory = 12.000 GB ; name = GRID P40-12Q                            
2021-10-24 12:50:50 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2021-10-24 12:50:50 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2021-10-24 12:50:50 | INFO | fairseq_cli.train | max tokens per GPU = None and max sentences per GPU = 8
2021-10-24 12:50:54 | INFO | fairseq.trainer | loaded checkpoint ../plbart/checkpoint_11_100000.pt (epoch 11 @ 0 updates)
2021-10-24 12:50:54 | INFO | fairseq.trainer | NOTE: your device does NOT support faster training with --fp16, please switch to FP32 which is likely to be faster
2021-10-24 12:50:54 | INFO | fairseq.optim.adam | using FusedAdam
2021-10-24 12:50:54 | INFO | fairseq.trainer | loading train data for epoch 1
2021-10-24 12:50:54 | INFO | fairseq.data.data_utils | loaded 19590 examples from: ../processed_data/large/data-bin/train.source-target.source
2021-10-24 12:50:54 | INFO | fairseq.data.data_utils | loaded 19590 examples from: ../processed_data/large/data-bin/train.source-target.target
2021-10-24 12:50:54 | INFO | fairseq.tasks.translation | ../processed_data/large/data-bin train source-target 19590 examples
2021-10-24 12:50:55 | INFO | fairseq_cli.train | begin training epoch 1
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
2021-10-24 12:50:55 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 64.0
2021-10-24 12:50:56 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2021-10-24 12:50:56 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2021-10-24 12:50:56 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2021-10-24 12:50:58 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4.0
2021-10-24 12:51:13 | INFO | train_inner | {"epoch": 1, "update": 0.086, "loss": "6.883", "nll_loss": "4.95", "ppl": "30.91", "wps": "1395", "ups": "5.56", "wpb": "249.8", "bsz": "16", "num_updates": "100", "lr": "1e-05", "gnorm": "49.485", "loss_scale": "6", "train_wall": "18", "wall": "23"}
Source: source Target: target


2021-10-24 12:55:20 | INFO | fairseq_cli.train | Namespace(activation_fn='gelu', adam_betas='(0.9, 0.98)', adam_eps=1e-06, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='mbart_base', attention_dropout=0.1, best_checkpoint_metric='bleu', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_suffix='', clip_norm=0.0, cpu=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='../processed_data/large/data-bin', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', decoder_attention_heads=12, decoder_embed_dim=768, decoder_embed_path=None, decoder_ffn_embed_dim=3072, decoder_input_dim=768, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=True, decoder_normalize_before=False, decoder_output_dim=768, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', dropout=0.1, empty_cache_freq=0, encoder_attention_heads=12, encoder_embed_dim=768, encoder_embed_path=None, encoder_ffn_embed_dim=3072, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=False, end_learning_rate=0.0, eval_bleu=True, eval_bleu_args='{"beam": 5}', eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=True, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.1, langs='java,python,en_XX', layernorm_embedding=True, left_pad_source='True', left_pad_target='False', load_alignments=False, localsgd_frequency=3, log_format='json', log_interval=100, lr=[5e-05], lr_scheduler='polynomial_decay', max_epoch=3000, max_sentences=8, max_sentences_valid=8, max_source_positions=1024, max_target_positions=1024, max_tokens=None, max_tokens_valid=None, max_update=200000, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=-1.0, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_workers=1, optimizer='adam', optimizer_overrides='{}', patience=10, pooler_activation_fn='tanh', pooler_dropout=0.0, power=1.0, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, relu_dropout=0.0, required_batch_size_multiple=8, reset_dataloader=True, reset_lr_scheduler=True, reset_meters=True, reset_optimizer=True, restore_file='../plbart/checkpoint_11_100000.pt', save_dir='../models/plbart/unique/large', save_interval=1, save_interval_updates=0, seed=1234, sentence_avg=False, share_all_embeddings=True, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='source', stop_time_hours=0, target_lang='target', task='translation_without_lang_token', tensorboard_logdir='', threshold_loss_scale=None, tokenizer=None, total_num_update=1000000, tpu=False, train_subset='train', truncate_source=True, update_freq=[2], upsample_primary=1, use_bmuf=False, use_old_adam=False, user_dir='../user_dir', valid_subset='valid', validate_interval=1, warmup_updates=500, weight_decay=0.0)
2021-10-24 12:55:20 | INFO | fairseq.tasks.translation | [source] dictionary: 50001 types
2021-10-24 12:55:20 | INFO | fairseq.tasks.translation | [target] dictionary: 50001 types
2021-10-24 12:55:20 | INFO | fairseq.data.data_utils | loaded 2449 examples from: ../processed_data/large/data-bin/valid.source-target.source
2021-10-24 12:55:20 | INFO | fairseq.data.data_utils | loaded 2449 examples from: ../processed_data/large/data-bin/valid.source-target.target
2021-10-24 12:55:20 | INFO | fairseq.tasks.translation | ../processed_data/large/data-bin valid source-target 2449 examples
2021-10-24 12:55:25 | INFO | fairseq_cli.train | BARTModel(
  (encoder): TransformerEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(50005, 768, padding_idx=1)
    (embed_positions): LearnedPositionalEmbedding(1026, 768, padding_idx=1)
    (layernorm_embedding): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(50005, 768, padding_idx=1)
    (embed_positions): LearnedPositionalEmbedding(1026, 768, padding_idx=1)
    (layernorm_embedding): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([768]), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=768, out_features=50005, bias=False)
  )
  (classification_heads): ModuleDict()
)
2021-10-24 12:55:25 | INFO | fairseq_cli.train | model mbart_base, criterion LabelSmoothedCrossEntropyCriterion
2021-10-24 12:55:25 | INFO | fairseq_cli.train | num. model params: 139220736 (num. trained: 139220736)
2021-10-24 12:55:27 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight
2021-10-24 12:55:27 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight
2021-10-24 12:55:27 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2021-10-24 12:55:27 | INFO | fairseq.utils | rank   0: capabilities =  6.1  ; total memory = 12.000 GB ; name = GRID P40-12Q                            
2021-10-24 12:55:27 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2021-10-24 12:55:27 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2021-10-24 12:55:27 | INFO | fairseq_cli.train | max tokens per GPU = None and max sentences per GPU = 8
2021-10-24 12:55:31 | INFO | fairseq.trainer | loaded checkpoint ../plbart/checkpoint_11_100000.pt (epoch 11 @ 0 updates)
2021-10-24 12:55:31 | INFO | fairseq.trainer | NOTE: your device does NOT support faster training with --fp16, please switch to FP32 which is likely to be faster
2021-10-24 12:55:31 | INFO | fairseq.optim.adam | using FusedAdam
2021-10-24 12:55:31 | INFO | fairseq.trainer | loading train data for epoch 1
2021-10-24 12:55:31 | INFO | fairseq.data.data_utils | loaded 19590 examples from: ../processed_data/large/data-bin/train.source-target.source
2021-10-24 12:55:31 | INFO | fairseq.data.data_utils | loaded 19590 examples from: ../processed_data/large/data-bin/train.source-target.target
2021-10-24 12:55:31 | INFO | fairseq.tasks.translation | ../processed_data/large/data-bin train source-target 19590 examples
2021-10-24 12:55:31 | INFO | fairseq_cli.train | begin training epoch 1
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
2021-10-24 12:55:32 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 64.0
2021-10-24 12:55:32 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2021-10-24 12:55:33 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2021-10-24 12:55:33 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2021-10-24 12:55:35 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4.0
2021-10-24 12:55:51 | INFO | train_inner | {"epoch": 1, "update": 0.086, "loss": "6.883", "nll_loss": "4.95", "ppl": "30.91", "wps": "1331.9", "ups": "5.31", "wpb": "249.8", "bsz": "16", "num_updates": "100", "lr": "1e-05", "gnorm": "49.485", "loss_scale": "6", "train_wall": "19", "wall": "23"}
2021-10-24 12:56:07 | INFO | train_inner | {"epoch": 1, "update": 0.167, "loss": "4.039", "nll_loss": "1.996", "ppl": "3.99", "wps": "1703.5", "ups": "6.14", "wpb": "277.3", "bsz": "16", "num_updates": "200", "lr": "2e-05", "gnorm": "12.036", "loss_scale": "4", "train_wall": "16", "wall": "40"}
2021-10-24 12:56:24 | INFO | train_inner | {"epoch": 1, "update": 0.249, "loss": "3.399", "nll_loss": "1.4", "ppl": "2.64", "wps": "1715.3", "ups": "5.84", "wpb": "293.9", "bsz": "16", "num_updates": "300", "lr": "3e-05", "gnorm": "6.603", "loss_scale": "4", "train_wall": "17", "wall": "57"}
2021-10-24 12:56:41 | INFO | train_inner | {"epoch": 1, "update": 0.331, "loss": "3.3", "nll_loss": "1.365", "ppl": "2.58", "wps": "1544.3", "ups": "5.88", "wpb": "262.6", "bsz": "16", "num_updates": "400", "lr": "4e-05", "gnorm": "5.409", "loss_scale": "4", "train_wall": "17", "wall": "74"}
2021-10-24 12:56:59 | INFO | train_inner | {"epoch": 1, "update": 0.412, "loss": "3.034", "nll_loss": "1.094", "ppl": "2.13", "wps": "1841.8", "ups": "5.72", "wpb": "322.1", "bsz": "16", "num_updates": "500", "lr": "5e-05", "gnorm": "4.011", "loss_scale": "4", "train_wall": "17", "wall": "91"}
2021-10-24 12:57:17 | INFO | train_inner | {"epoch": 1, "update": 0.494, "loss": "2.971", "nll_loss": "1.041", "ppl": "2.06", "wps": "1651.6", "ups": "5.49", "wpb": "300.7", "bsz": "16", "num_updates": "600", "lr": "4.9995e-05", "gnorm": "4.302", "loss_scale": "4", "train_wall": "18", "wall": "109"}
2021-10-24 12:57:34 | INFO | train_inner | {"epoch": 1, "update": 0.576, "loss": "2.94", "nll_loss": "1.016", "ppl": "2.02", "wps": "1923.5", "ups": "5.92", "wpb": "325.1", "bsz": "16", "num_updates": "700", "lr": "4.999e-05", "gnorm": "4.073", "loss_scale": "4", "train_wall": "17", "wall": "126"}
2021-10-24 12:57:51 | INFO | train_inner | {"epoch": 1, "update": 0.657, "loss": "3.017", "nll_loss": "1.113", "ppl": "2.16", "wps": "1706.2", "ups": "5.78", "wpb": "295.4", "bsz": "16", "num_updates": "800", "lr": "4.9985e-05", "gnorm": "3.814", "loss_scale": "4", "train_wall": "17", "wall": "144"}
2021-10-24 12:58:10 | INFO | train_inner | {"epoch": 1, "update": 0.739, "loss": "2.847", "nll_loss": "0.929", "ppl": "1.9", "wps": "1741.8", "ups": "5.32", "wpb": "327.3", "bsz": "16", "num_updates": "900", "lr": "4.998e-05", "gnorm": "3.619", "loss_scale": "4", "train_wall": "19", "wall": "162"}
2021-10-24 12:58:26 | INFO | train_inner | {"epoch": 1, "update": 0.82, "loss": "3.02", "nll_loss": "1.128", "ppl": "2.19", "wps": "1667.2", "ups": "6.06", "wpb": "274.9", "bsz": "16", "num_updates": "1000", "lr": "4.9975e-05", "gnorm": "3.769", "loss_scale": "4", "train_wall": "16", "wall": "179"}
2021-10-24 12:58:44 | INFO | train_inner | {"epoch": 1, "update": 0.902, "loss": "2.856", "nll_loss": "0.947", "ppl": "1.93", "wps": "1707.7", "ups": "5.55", "wpb": "307.7", "bsz": "16", "num_updates": "1100", "lr": "4.997e-05", "gnorm": "3.547", "loss_scale": "4", "train_wall": "18", "wall": "197"}
2021-10-24 12:59:03 | INFO | train_inner | {"epoch": 1, "update": 0.984, "loss": "2.813", "nll_loss": "0.907", "ppl": "1.87", "wps": "1652.9", "ups": "5.43", "wpb": "304.4", "bsz": "16", "num_updates": "1200", "lr": "4.9965e-05", "gnorm": "3.781", "loss_scale": "4", "train_wall": "18", "wall": "215"}
2021-10-24 12:59:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-24 13:01:02 | INFO | valid | {"epoch": 1, "valid_loss": "2.929", "valid_nll_loss": "0.902", "valid_ppl": "1.87", "valid_bleu": "66.1", "valid_wps": "375.4", "valid_wpb": "140.1", "valid_bsz": "8", "valid_num_updates": "1220"}
2021-10-24 13:01:02 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-24 13:01:19 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/plbart/unique/large/checkpoint_best.pt (epoch 1 @ 1220 updates, score 66.1) (writing took 17.111229272093624 seconds)
2021-10-24 13:01:19 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2021-10-24 13:01:19 | INFO | train | {"epoch": 1, "train_loss": "3.363", "train_nll_loss": "1.429", "train_ppl": "2.69", "train_wps": "1032.3", "train_ups": "3.51", "train_wpb": "294", "train_bsz": "16", "train_num_updates": "1220", "train_lr": "4.9964e-05", "train_gnorm": "8.625", "train_loss_scale": "4", "train_train_wall": "213", "train_wall": "352"}
2021-10-24 13:01:19 | INFO | fairseq_cli.train | begin training epoch 1
2021-10-24 13:01:35 | INFO | train_inner | {"epoch": 2, "update": 1.065, "loss": "2.765", "nll_loss": "0.853", "ppl": "1.81", "wps": "216.9", "ups": "0.66", "wpb": "330.6", "bsz": "15.9", "num_updates": "1300", "lr": "4.996e-05", "gnorm": "3.25", "loss_scale": "4", "train_wall": "19", "wall": "368"}
2021-10-24 13:01:53 | INFO | train_inner | {"epoch": 2, "update": 1.147, "loss": "2.718", "nll_loss": "0.797", "ppl": "1.74", "wps": "1766.6", "ups": "5.65", "wpb": "312.4", "bsz": "16", "num_updates": "1400", "lr": "4.9955e-05", "gnorm": "3.021", "loss_scale": "4", "train_wall": "17", "wall": "386"}
2021-10-24 13:02:11 | INFO | train_inner | {"epoch": 2, "update": 1.229, "loss": "2.787", "nll_loss": "0.877", "ppl": "1.84", "wps": "1513.8", "ups": "5.47", "wpb": "276.6", "bsz": "16", "num_updates": "1500", "lr": "4.995e-05", "gnorm": "3.415", "loss_scale": "4", "train_wall": "18", "wall": "404"}
2021-10-24 13:02:30 | INFO | train_inner | {"epoch": 2, "update": 1.31, "loss": "2.813", "nll_loss": "0.913", "ppl": "1.88", "wps": "1433.5", "ups": "5.4", "wpb": "265.5", "bsz": "16", "num_updates": "1600", "lr": "4.9945e-05", "gnorm": "3.295", "loss_scale": "4", "train_wall": "18", "wall": "422"}
2021-10-24 13:02:48 | INFO | train_inner | {"epoch": 2, "update": 1.392, "loss": "2.731", "nll_loss": "0.817", "ppl": "1.76", "wps": "1705", "ups": "5.46", "wpb": "312.1", "bsz": "16", "num_updates": "1700", "lr": "4.994e-05", "gnorm": "3.271", "loss_scale": "4", "train_wall": "18", "wall": "441"}
2021-10-24 13:03:05 | INFO | train_inner | {"epoch": 2, "update": 1.473, "loss": "2.673", "nll_loss": "0.759", "ppl": "1.69", "wps": "1840.4", "ups": "5.71", "wpb": "322.1", "bsz": "16", "num_updates": "1800", "lr": "4.9935e-05", "gnorm": "2.769", "loss_scale": "4", "train_wall": "17", "wall": "458"}
2021-10-24 13:03:23 | INFO | train_inner | {"epoch": 2, "update": 1.555, "loss": "2.903", "nll_loss": "1.023", "ppl": "2.03", "wps": "1401.8", "ups": "5.66", "wpb": "247.5", "bsz": "16", "num_updates": "1900", "lr": "4.993e-05", "gnorm": "3.364", "loss_scale": "4", "train_wall": "17", "wall": "476"}
2021-10-24 13:03:40 | INFO | train_inner | {"epoch": 2, "update": 1.637, "loss": "2.851", "nll_loss": "0.963", "ppl": "1.95", "wps": "1590.9", "ups": "6.01", "wpb": "264.8", "bsz": "16", "num_updates": "2000", "lr": "4.9925e-05", "gnorm": "3.443", "loss_scale": "4", "train_wall": "16", "wall": "492"}
2021-10-24 13:03:56 | INFO | train_inner | {"epoch": 2, "update": 1.718, "loss": "2.749", "nll_loss": "0.849", "ppl": "1.8", "wps": "1746.7", "ups": "6.04", "wpb": "289.4", "bsz": "16", "num_updates": "2100", "lr": "4.992e-05", "gnorm": "3.308", "loss_scale": "4", "train_wall": "16", "wall": "509"}
2021-10-24 13:04:15 | INFO | train_inner | {"epoch": 2, "update": 1.8, "loss": "2.667", "nll_loss": "0.758", "ppl": "1.69", "wps": "1899.9", "ups": "5.23", "wpb": "363", "bsz": "16", "num_updates": "2200", "lr": "4.9915e-05", "gnorm": "3.158", "loss_scale": "4", "train_wall": "19", "wall": "528"}
2021-10-24 13:04:34 | INFO | train_inner | {"epoch": 2, "update": 1.882, "loss": "2.721", "nll_loss": "0.825", "ppl": "1.77", "wps": "1684.9", "ups": "5.39", "wpb": "312.7", "bsz": "16", "num_updates": "2300", "lr": "4.991e-05", "gnorm": "3.136", "loss_scale": "4", "train_wall": "18", "wall": "547"}
2021-10-24 13:04:51 | INFO | train_inner | {"epoch": 2, "update": 1.963, "loss": "2.834", "nll_loss": "0.949", "ppl": "1.93", "wps": "1635.6", "ups": "6.01", "wpb": "272.1", "bsz": "16", "num_updates": "2400", "lr": "4.9905e-05", "gnorm": "3.427", "loss_scale": "4", "train_wall": "16", "wall": "563"}
2021-10-24 13:04:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-24 13:06:47 | INFO | valid | {"epoch": 2, "valid_loss": "2.892", "valid_nll_loss": "0.867", "valid_ppl": "1.82", "valid_bleu": "68.43", "valid_wps": "394.6", "valid_wpb": "140.1", "valid_bsz": "8", "valid_num_updates": "2445", "valid_best_bleu": "68.43"}
2021-10-24 13:06:47 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-24 13:07:06 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/plbart/unique/large/checkpoint_best.pt (epoch 2 @ 2445 updates, score 68.43) (writing took 19.69334121106658 seconds)
2021-10-24 13:07:06 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2021-10-24 13:07:06 | INFO | train | {"epoch": 2, "train_loss": "2.76", "train_nll_loss": "0.857", "train_ppl": "1.81", "train_wps": "1044.4", "train_ups": "3.53", "train_wpb": "295.9", "train_bsz": "16", "train_num_updates": "2445", "train_lr": "4.99027e-05", "train_gnorm": "3.237", "train_loss_scale": "4", "train_train_wall": "215", "train_wall": "699"}
2021-10-24 13:07:06 | INFO | fairseq_cli.train | begin training epoch 2
2021-10-24 13:07:15 | INFO | train_inner | {"epoch": 3, "update": 2.045, "loss": "2.773", "nll_loss": "0.881", "ppl": "1.84", "wps": "168.7", "ups": "0.69", "wpb": "244.1", "bsz": "15.9", "num_updates": "2500", "lr": "4.98999e-05", "gnorm": "3.194", "loss_scale": "4", "train_wall": "15", "wall": "708"}
2021-10-24 13:07:32 | INFO | train_inner | {"epoch": 3, "update": 2.127, "loss": "2.57", "nll_loss": "0.642", "ppl": "1.56", "wps": "1738.2", "ups": "5.83", "wpb": "298", "bsz": "16", "num_updates": "2600", "lr": "4.98949e-05", "gnorm": "3.197", "loss_scale": "4", "train_wall": "17", "wall": "725"}
2021-10-24 13:07:49 | INFO | train_inner | {"epoch": 3, "update": 2.208, "loss": "2.591", "nll_loss": "0.675", "ppl": "1.6", "wps": "1749.3", "ups": "6.07", "wpb": "288.2", "bsz": "16", "num_updates": "2700", "lr": "4.98899e-05", "gnorm": "3.112", "loss_scale": "4", "train_wall": "16", "wall": "742"}
2021-10-24 13:08:05 | INFO | train_inner | {"epoch": 3, "update": 2.29, "loss": "2.597", "nll_loss": "0.679", "ppl": "1.6", "wps": "2055.8", "ups": "6.11", "wpb": "336.3", "bsz": "16", "num_updates": "2800", "lr": "4.98849e-05", "gnorm": "3.233", "loss_scale": "4", "train_wall": "16", "wall": "758"}
2021-10-24 13:08:23 | INFO | train_inner | {"epoch": 3, "update": 2.371, "loss": "2.651", "nll_loss": "0.742", "ppl": "1.67", "wps": "1497.8", "ups": "5.71", "wpb": "262.2", "bsz": "16", "num_updates": "2900", "lr": "4.98799e-05", "gnorm": "3.254", "loss_scale": "4", "train_wall": "17", "wall": "775"}
2021-10-24 13:08:40 | INFO | train_inner | {"epoch": 3, "update": 2.453, "loss": "2.578", "nll_loss": "0.662", "ppl": "1.58", "wps": "1856.4", "ups": "5.8", "wpb": "320.3", "bsz": "16", "num_updates": "3000", "lr": "4.98749e-05", "gnorm": "3.42", "loss_scale": "4", "train_wall": "17", "wall": "793"}
2021-10-24 13:08:57 | INFO | train_inner | {"epoch": 3, "update": 2.535, "loss": "2.662", "nll_loss": "0.761", "ppl": "1.69", "wps": "1481.3", "ups": "5.75", "wpb": "257.8", "bsz": "16", "num_updates": "3100", "lr": "4.98699e-05", "gnorm": "3.178", "loss_scale": "4", "train_wall": "17", "wall": "810"}
2021-10-24 13:09:15 | INFO | train_inner | {"epoch": 3, "update": 2.616, "loss": "2.558", "nll_loss": "0.642", "ppl": "1.56", "wps": "1802.3", "ups": "5.77", "wpb": "312.3", "bsz": "16", "num_updates": "3200", "lr": "4.98649e-05", "gnorm": "3.197", "loss_scale": "4", "train_wall": "17", "wall": "827"}
2021-10-24 13:09:31 | INFO | train_inner | {"epoch": 3, "update": 2.698, "loss": "2.654", "nll_loss": "0.75", "ppl": "1.68", "wps": "1822.1", "ups": "6.27", "wpb": "290.6", "bsz": "16", "num_updates": "3300", "lr": "4.98599e-05", "gnorm": "3.163", "loss_scale": "4", "train_wall": "16", "wall": "843"}
2021-10-24 13:09:47 | INFO | train_inner | {"epoch": 3, "update": 2.78, "loss": "2.625", "nll_loss": "0.718", "ppl": "1.65", "wps": "1555.3", "ups": "6", "wpb": "259.2", "bsz": "16", "num_updates": "3400", "lr": "4.98549e-05", "gnorm": "3.324", "loss_scale": "4", "train_wall": "16", "wall": "860"}
2021-10-24 13:10:04 | INFO | train_inner | {"epoch": 3, "update": 2.861, "loss": "2.564", "nll_loss": "0.65", "ppl": "1.57", "wps": "2072.6", "ups": "6.08", "wpb": "340.8", "bsz": "16", "num_updates": "3500", "lr": "4.98499e-05", "gnorm": "3.267", "loss_scale": "4", "train_wall": "16", "wall": "877"}
2021-10-24 13:10:22 | INFO | train_inner | {"epoch": 3, "update": 2.943, "loss": "2.557", "nll_loss": "0.646", "ppl": "1.56", "wps": "1746.2", "ups": "5.51", "wpb": "316.9", "bsz": "16", "num_updates": "3600", "lr": "4.98449e-05", "gnorm": "3.295", "loss_scale": "4", "train_wall": "18", "wall": "895"}
2021-10-24 13:10:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-24 13:12:21 | INFO | valid | {"epoch": 3, "valid_loss": "2.891", "valid_nll_loss": "0.865", "valid_ppl": "1.82", "valid_bleu": "69.28", "valid_wps": "399", "valid_wpb": "140.1", "valid_bsz": "8", "valid_num_updates": "3670", "valid_best_bleu": "69.28"}
2021-10-24 13:12:21 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-24 13:12:43 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/plbart/unique/large/checkpoint_best.pt (epoch 3 @ 3670 updates, score 69.28) (writing took 21.84388185001444 seconds)
2021-10-24 13:12:43 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2021-10-24 13:12:43 | INFO | train | {"epoch": 3, "train_loss": "2.603", "train_nll_loss": "0.69", "train_ppl": "1.61", "train_wps": "1075.7", "train_ups": "3.64", "train_wpb": "295.9", "train_bsz": "16", "train_num_updates": "3670", "train_lr": "4.98414e-05", "train_gnorm": "3.243", "train_loss_scale": "4", "train_train_wall": "204", "train_wall": "1036"}
2021-10-24 13:12:43 | INFO | fairseq_cli.train | begin training epoch 3
2021-10-24 13:12:48 | INFO | train_inner | {"epoch": 4, "update": 3.024, "loss": "2.586", "nll_loss": "0.677", "ppl": "1.6", "wps": "188.7", "ups": "0.68", "wpb": "276.2", "bsz": "15.9", "num_updates": "3700", "lr": "4.98399e-05", "gnorm": "3.425", "loss_scale": "4", "train_wall": "16", "wall": "1041"}
2021-10-24 13:13:05 | INFO | train_inner | {"epoch": 4, "update": 3.106, "loss": "2.453", "nll_loss": "0.519", "ppl": "1.43", "wps": "1628.2", "ups": "5.94", "wpb": "274", "bsz": "16", "num_updates": "3800", "lr": "4.98349e-05", "gnorm": "3.042", "loss_scale": "4", "train_wall": "17", "wall": "1058"}
2021-10-24 13:13:22 | INFO | train_inner | {"epoch": 4, "update": 3.188, "loss": "2.473", "nll_loss": "0.546", "ppl": "1.46", "wps": "1567.7", "ups": "5.87", "wpb": "267", "bsz": "16", "num_updates": "3900", "lr": "4.98299e-05", "gnorm": "3.116", "loss_scale": "4", "train_wall": "17", "wall": "1075"}
2021-10-24 13:13:41 | INFO | train_inner | {"epoch": 4, "update": 3.269, "loss": "2.462", "nll_loss": "0.531", "ppl": "1.45", "wps": "1690.2", "ups": "5.23", "wpb": "323.4", "bsz": "16", "num_updates": "4000", "lr": "4.98249e-05", "gnorm": "3.162", "loss_scale": "4", "train_wall": "19", "wall": "1094"}
2021-10-24 13:14:00 | INFO | train_inner | {"epoch": 4, "update": 3.351, "loss": "2.506", "nll_loss": "0.583", "ppl": "1.5", "wps": "1678.5", "ups": "5.37", "wpb": "312.7", "bsz": "16", "num_updates": "4100", "lr": "4.98199e-05", "gnorm": "3.018", "loss_scale": "4", "train_wall": "18", "wall": "1113"}
2021-10-24 13:14:17 | INFO | train_inner | {"epoch": 4, "update": 3.433, "loss": "2.449", "nll_loss": "0.525", "ppl": "1.44", "wps": "2037.5", "ups": "5.87", "wpb": "346.9", "bsz": "16", "num_updates": "4200", "lr": "4.98149e-05", "gnorm": "3.199", "loss_scale": "4", "train_wall": "17", "wall": "1130"}
2021-10-24 13:14:35 | INFO | train_inner | {"epoch": 4, "update": 3.514, "loss": "2.451", "nll_loss": "0.522", "ppl": "1.44", "wps": "1792.8", "ups": "5.47", "wpb": "327.6", "bsz": "16", "num_updates": "4300", "lr": "4.98099e-05", "gnorm": "3.107", "loss_scale": "4", "train_wall": "18", "wall": "1148"}
2021-10-24 13:14:54 | INFO | train_inner | {"epoch": 4, "update": 3.596, "loss": "2.539", "nll_loss": "0.62", "ppl": "1.54", "wps": "1415", "ups": "5.29", "wpb": "267.5", "bsz": "16", "num_updates": "4400", "lr": "4.98049e-05", "gnorm": "3.08", "loss_scale": "4", "train_wall": "19", "wall": "1167"}
2021-10-24 13:15:12 | INFO | train_inner | {"epoch": 4, "update": 3.678, "loss": "2.529", "nll_loss": "0.611", "ppl": "1.53", "wps": "1452.2", "ups": "5.48", "wpb": "265", "bsz": "16", "num_updates": "4500", "lr": "4.97999e-05", "gnorm": "3.115", "loss_scale": "4", "train_wall": "18", "wall": "1185"}
2021-10-24 13:15:30 | INFO | train_inner | {"epoch": 4, "update": 3.759, "loss": "2.539", "nll_loss": "0.624", "ppl": "1.54", "wps": "1587.4", "ups": "5.83", "wpb": "272.1", "bsz": "16", "num_updates": "4600", "lr": "4.97949e-05", "gnorm": "3.355", "loss_scale": "4", "train_wall": "17", "wall": "1202"}
2021-10-24 13:15:46 | INFO | train_inner | {"epoch": 4, "update": 3.841, "loss": "2.522", "nll_loss": "0.607", "ppl": "1.52", "wps": "1699", "ups": "6.05", "wpb": "280.7", "bsz": "16", "num_updates": "4700", "lr": "4.97899e-05", "gnorm": "3.099", "loss_scale": "4", "train_wall": "16", "wall": "1219"}
2021-10-24 13:16:03 | INFO | train_inner | {"epoch": 4, "update": 3.922, "loss": "2.5", "nll_loss": "0.584", "ppl": "1.5", "wps": "1615.7", "ups": "5.82", "wpb": "277.6", "bsz": "16", "num_updates": "4800", "lr": "4.97849e-05", "gnorm": "3.372", "loss_scale": "4", "train_wall": "17", "wall": "1236"}
2021-10-24 13:16:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-24 13:18:11 | INFO | valid | {"epoch": 4, "valid_loss": "2.889", "valid_nll_loss": "0.871", "valid_ppl": "1.83", "valid_bleu": "69.4", "valid_wps": "387.6", "valid_wpb": "140.1", "valid_bsz": "8", "valid_num_updates": "4895", "valid_best_bleu": "69.4"}
2021-10-24 13:18:11 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-24 13:18:36 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/plbart/unique/large/checkpoint_best.pt (epoch 4 @ 4895 updates, score 69.4) (writing took 25.120668857940473 seconds)
2021-10-24 13:18:36 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2021-10-24 13:18:36 | INFO | train | {"epoch": 4, "train_loss": "2.489", "train_nll_loss": "0.566", "train_ppl": "1.48", "train_wps": "1027.4", "train_ups": "3.47", "train_wpb": "295.9", "train_bsz": "16", "train_num_updates": "4895", "train_lr": "4.97801e-05", "train_gnorm": "3.138", "train_loss_scale": "4", "train_train_wall": "214", "train_wall": "1389"}
2021-10-24 13:18:36 | INFO | fairseq_cli.train | begin training epoch 4
2021-10-24 13:18:37 | INFO | train_inner | {"epoch": 5, "update": 4.004, "loss": "2.472", "nll_loss": "0.553", "ppl": "1.47", "wps": "223.8", "ups": "0.65", "wpb": "344.5", "bsz": "15.9", "num_updates": "4900", "lr": "4.97799e-05", "gnorm": "3.214", "loss_scale": "4", "train_wall": "17", "wall": "1390"}
2021-10-24 13:18:55 | INFO | train_inner | {"epoch": 5, "update": 4.086, "loss": "2.372", "nll_loss": "0.432", "ppl": "1.35", "wps": "1780.2", "ups": "5.67", "wpb": "314.1", "bsz": "16", "num_updates": "5000", "lr": "4.97749e-05", "gnorm": "3.045", "loss_scale": "4", "train_wall": "17", "wall": "1408"}
2021-10-24 13:19:12 | INFO | train_inner | {"epoch": 5, "update": 4.167, "loss": "2.408", "nll_loss": "0.476", "ppl": "1.39", "wps": "1667.2", "ups": "5.82", "wpb": "286.3", "bsz": "16", "num_updates": "5100", "lr": "4.97699e-05", "gnorm": "2.914", "loss_scale": "4", "train_wall": "17", "wall": "1425"}
2021-10-24 13:19:31 | INFO | train_inner | {"epoch": 5, "update": 4.249, "loss": "2.405", "nll_loss": "0.467", "ppl": "1.38", "wps": "1365", "ups": "5.2", "wpb": "262.4", "bsz": "16", "num_updates": "5200", "lr": "4.97649e-05", "gnorm": "3.124", "loss_scale": "4", "train_wall": "19", "wall": "1444"}
2021-10-24 13:19:49 | INFO | train_inner | {"epoch": 5, "update": 4.331, "loss": "2.386", "nll_loss": "0.449", "ppl": "1.37", "wps": "1858.3", "ups": "5.62", "wpb": "330.8", "bsz": "16", "num_updates": "5300", "lr": "4.97599e-05", "gnorm": "3.178", "loss_scale": "4", "train_wall": "18", "wall": "1462"}
2021-10-24 13:20:07 | INFO | train_inner | {"epoch": 5, "update": 4.412, "loss": "2.383", "nll_loss": "0.451", "ppl": "1.37", "wps": "1675.3", "ups": "5.6", "wpb": "298.9", "bsz": "16", "num_updates": "5400", "lr": "4.97549e-05", "gnorm": "3.14", "loss_scale": "4", "train_wall": "18", "wall": "1480"}
2021-10-24 13:20:23 | INFO | train_inner | {"epoch": 5, "update": 4.494, "loss": "2.417", "nll_loss": "0.485", "ppl": "1.4", "wps": "1537.3", "ups": "6.13", "wpb": "250.8", "bsz": "16", "num_updates": "5500", "lr": "4.97499e-05", "gnorm": "3.097", "loss_scale": "4", "train_wall": "16", "wall": "1496"}
2021-10-24 13:20:41 | INFO | train_inner | {"epoch": 5, "update": 4.576, "loss": "2.415", "nll_loss": "0.485", "ppl": "1.4", "wps": "1782.8", "ups": "5.69", "wpb": "313.3", "bsz": "16", "num_updates": "5600", "lr": "4.97449e-05", "gnorm": "3.07", "loss_scale": "4", "train_wall": "17", "wall": "1513"}
2021-10-24 13:20:58 | INFO | train_inner | {"epoch": 5, "update": 4.657, "loss": "2.424", "nll_loss": "0.5", "ppl": "1.41", "wps": "1613.3", "ups": "5.82", "wpb": "277.4", "bsz": "16", "num_updates": "5700", "lr": "4.97399e-05", "gnorm": "3.239", "loss_scale": "4", "train_wall": "17", "wall": "1531"}
2021-10-24 13:21:15 | INFO | train_inner | {"epoch": 5, "update": 4.739, "loss": "2.406", "nll_loss": "0.479", "ppl": "1.39", "wps": "1717.9", "ups": "5.79", "wpb": "296.7", "bsz": "16", "num_updates": "5800", "lr": "4.97349e-05", "gnorm": "3.166", "loss_scale": "4", "train_wall": "17", "wall": "1548"}
2021-10-24 13:21:33 | INFO | train_inner | {"epoch": 5, "update": 4.82, "loss": "2.373", "nll_loss": "0.442", "ppl": "1.36", "wps": "1877.1", "ups": "5.57", "wpb": "337.1", "bsz": "16", "num_updates": "5900", "lr": "4.97299e-05", "gnorm": "3.059", "loss_scale": "4", "train_wall": "18", "wall": "1566"}
2021-10-24 13:21:52 | INFO | train_inner | {"epoch": 5, "update": 4.902, "loss": "2.392", "nll_loss": "0.464", "ppl": "1.38", "wps": "1470.2", "ups": "5.34", "wpb": "275.4", "bsz": "16", "num_updates": "6000", "lr": "4.97249e-05", "gnorm": "3.235", "loss_scale": "4", "train_wall": "19", "wall": "1585"}
2021-10-24 13:22:10 | INFO | train_inner | {"epoch": 5, "update": 4.984, "loss": "2.402", "nll_loss": "0.479", "ppl": "1.39", "wps": "1761", "ups": "5.62", "wpb": "313.4", "bsz": "16", "num_updates": "6100", "lr": "4.97199e-05", "gnorm": "3.388", "loss_scale": "4", "train_wall": "18", "wall": "1602"}
2021-10-24 13:22:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-24 13:24:03 | INFO | valid | {"epoch": 5, "valid_loss": "2.93", "valid_nll_loss": "0.905", "valid_ppl": "1.87", "valid_bleu": "69.44", "valid_wps": "391.2", "valid_wpb": "140.1", "valid_bsz": "8", "valid_num_updates": "6120", "valid_best_bleu": "69.44"}
2021-10-24 13:24:03 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-24 13:24:29 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/plbart/unique/large/checkpoint_best.pt (epoch 5 @ 6120 updates, score 69.44) (writing took 25.980412286007777 seconds)
2021-10-24 13:24:29 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2021-10-24 13:24:29 | INFO | train | {"epoch": 5, "train_loss": "2.399", "train_nll_loss": "0.468", "train_ppl": "1.38", "train_wps": "1025.9", "train_ups": "3.47", "train_wpb": "295.9", "train_bsz": "16", "train_num_updates": "6120", "train_lr": "4.97189e-05", "train_gnorm": "3.162", "train_loss_scale": "4", "train_train_wall": "214", "train_wall": "1742"}
2021-10-24 13:24:29 | INFO | fairseq_cli.train | begin training epoch 5
2021-10-24 13:24:42 | INFO | train_inner | {"epoch": 6, "update": 5.065, "loss": "2.382", "nll_loss": "0.443", "ppl": "1.36", "wps": "184", "ups": "0.66", "wpb": "280.6", "bsz": "15.9", "num_updates": "6200", "lr": "4.97149e-05", "gnorm": "2.976", "loss_scale": "4", "train_wall": "16", "wall": "1755"}
2021-10-24 13:24:59 | INFO | train_inner | {"epoch": 6, "update": 5.147, "loss": "2.298", "nll_loss": "0.357", "ppl": "1.28", "wps": "2026.4", "ups": "6.16", "wpb": "329", "bsz": "16", "num_updates": "6300", "lr": "4.97099e-05", "gnorm": "2.957", "loss_scale": "4", "train_wall": "16", "wall": "1771"}
2021-10-24 13:25:18 | INFO | train_inner | {"epoch": 6, "update": 5.229, "loss": "2.312", "nll_loss": "0.373", "ppl": "1.29", "wps": "1582.3", "ups": "5.12", "wpb": "308.7", "bsz": "16", "num_updates": "6400", "lr": "4.97049e-05", "gnorm": "2.713", "loss_scale": "4", "train_wall": "19", "wall": "1791"}
2021-10-24 13:25:38 | INFO | train_inner | {"epoch": 6, "update": 5.31, "loss": "2.364", "nll_loss": "0.426", "ppl": "1.34", "wps": "1261.5", "ups": "5.03", "wpb": "250.8", "bsz": "16", "num_updates": "6500", "lr": "4.96998e-05", "gnorm": "3.255", "loss_scale": "4", "train_wall": "20", "wall": "1811"}
2021-10-24 13:25:57 | INFO | train_inner | {"epoch": 6, "update": 5.392, "loss": "2.305", "nll_loss": "0.365", "ppl": "1.29", "wps": "1925.2", "ups": "5.34", "wpb": "360.2", "bsz": "16", "num_updates": "6600", "lr": "4.96948e-05", "gnorm": "2.764", "loss_scale": "4", "train_wall": "18", "wall": "1829"}
2021-10-24 13:26:14 | INFO | train_inner | {"epoch": 6, "update": 5.473, "loss": "2.324", "nll_loss": "0.386", "ppl": "1.31", "wps": "1655.7", "ups": "5.82", "wpb": "284.7", "bsz": "16", "num_updates": "6700", "lr": "4.96898e-05", "gnorm": "3.055", "loss_scale": "4", "train_wall": "17", "wall": "1847"}
2021-10-24 13:26:30 | INFO | train_inner | {"epoch": 6, "update": 5.555, "loss": "2.35", "nll_loss": "0.416", "ppl": "1.33", "wps": "1746.1", "ups": "6.1", "wpb": "286.1", "bsz": "16", "num_updates": "6800", "lr": "4.96848e-05", "gnorm": "3.306", "loss_scale": "4", "train_wall": "16", "wall": "1863"}
2021-10-24 13:26:46 | INFO | train_inner | {"epoch": 6, "update": 5.637, "loss": "2.332", "nll_loss": "0.394", "ppl": "1.31", "wps": "1852.7", "ups": "6.32", "wpb": "293.2", "bsz": "16", "num_updates": "6900", "lr": "4.96798e-05", "gnorm": "2.983", "loss_scale": "4", "train_wall": "16", "wall": "1879"}
2021-10-24 13:27:04 | INFO | train_inner | {"epoch": 6, "update": 5.718, "loss": "2.343", "nll_loss": "0.412", "ppl": "1.33", "wps": "1863.6", "ups": "5.68", "wpb": "328.3", "bsz": "16", "num_updates": "7000", "lr": "4.96748e-05", "gnorm": "2.841", "loss_scale": "4", "train_wall": "17", "wall": "1896"}
2021-10-24 13:27:19 | INFO | train_inner | {"epoch": 6, "update": 5.8, "loss": "2.355", "nll_loss": "0.424", "ppl": "1.34", "wps": "1755.1", "ups": "6.57", "wpb": "267.3", "bsz": "16", "num_updates": "7100", "lr": "4.96698e-05", "gnorm": "3.184", "loss_scale": "4", "train_wall": "15", "wall": "1912"}
2021-10-24 13:27:37 | INFO | train_inner | {"epoch": 6, "update": 5.882, "loss": "2.309", "nll_loss": "0.377", "ppl": "1.3", "wps": "1753.2", "ups": "5.59", "wpb": "313.5", "bsz": "16", "num_updates": "7200", "lr": "4.96648e-05", "gnorm": "2.858", "loss_scale": "4", "train_wall": "18", "wall": "1929"}
2021-10-24 13:27:54 | INFO | train_inner | {"epoch": 6, "update": 5.963, "loss": "2.414", "nll_loss": "0.483", "ppl": "1.4", "wps": "1420.2", "ups": "5.93", "wpb": "239.4", "bsz": "16", "num_updates": "7300", "lr": "4.96598e-05", "gnorm": "3.468", "loss_scale": "4", "train_wall": "17", "wall": "1946"}
2021-10-24 13:28:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-24 13:29:56 | INFO | valid | {"epoch": 6, "valid_loss": "2.95", "valid_nll_loss": "0.937", "valid_ppl": "1.91", "valid_bleu": "68.79", "valid_wps": "376.6", "valid_wpb": "140.1", "valid_bsz": "8", "valid_num_updates": "7345", "valid_best_bleu": "69.44"}
2021-10-24 13:29:56 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-24 13:30:08 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/plbart/unique/large/checkpoint_last.pt (epoch 6 @ 7345 updates, score 68.79) (writing took 12.861061607021838 seconds)
2021-10-24 13:30:08 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2021-10-24 13:30:08 | INFO | train | {"epoch": 6, "train_loss": "2.337", "train_nll_loss": "0.401", "train_ppl": "1.32", "train_wps": "1069.3", "train_ups": "3.61", "train_wpb": "295.9", "train_bsz": "16", "train_num_updates": "7345", "train_lr": "4.96576e-05", "train_gnorm": "3.031", "train_loss_scale": "4", "train_train_wall": "209", "train_wall": "2081"}
2021-10-24 13:30:08 | INFO | fairseq_cli.train | begin training epoch 6
2021-10-24 13:30:18 | INFO | train_inner | {"epoch": 7, "update": 6.045, "loss": "2.306", "nll_loss": "0.369", "ppl": "1.29", "wps": "215.8", "ups": "0.69", "wpb": "312.4", "bsz": "15.9", "num_updates": "7400", "lr": "4.96548e-05", "gnorm": "2.84", "loss_scale": "4", "train_wall": "17", "wall": "2091"}
2021-10-24 13:30:36 | INFO | train_inner | {"epoch": 7, "update": 6.127, "loss": "2.272", "nll_loss": "0.329", "ppl": "1.26", "wps": "1622.8", "ups": "5.69", "wpb": "285.4", "bsz": "16", "num_updates": "7500", "lr": "4.96498e-05", "gnorm": "2.599", "loss_scale": "4", "train_wall": "17", "wall": "2109"}
2021-10-24 13:30:53 | INFO | train_inner | {"epoch": 7, "update": 6.208, "loss": "2.294", "nll_loss": "0.353", "ppl": "1.28", "wps": "1357.2", "ups": "5.73", "wpb": "236.9", "bsz": "16", "num_updates": "7600", "lr": "4.96448e-05", "gnorm": "2.611", "loss_scale": "4", "train_wall": "17", "wall": "2126"}
2021-10-24 13:31:11 | INFO | train_inner | {"epoch": 7, "update": 6.29, "loss": "2.28", "nll_loss": "0.338", "ppl": "1.26", "wps": "1567.6", "ups": "5.73", "wpb": "273.7", "bsz": "16", "num_updates": "7700", "lr": "4.96398e-05", "gnorm": "2.754", "loss_scale": "4", "train_wall": "17", "wall": "2144"}
2021-10-24 13:31:28 | INFO | train_inner | {"epoch": 7, "update": 6.371, "loss": "2.296", "nll_loss": "0.357", "ppl": "1.28", "wps": "1650.2", "ups": "5.7", "wpb": "289.4", "bsz": "16", "num_updates": "7800", "lr": "4.96348e-05", "gnorm": "2.842", "loss_scale": "4", "train_wall": "17", "wall": "2161"}
2021-10-24 13:31:46 | INFO | train_inner | {"epoch": 7, "update": 6.453, "loss": "2.277", "nll_loss": "0.339", "ppl": "1.26", "wps": "1937.1", "ups": "5.72", "wpb": "338.7", "bsz": "16", "num_updates": "7900", "lr": "4.96298e-05", "gnorm": "2.857", "loss_scale": "4", "train_wall": "17", "wall": "2179"}
2021-10-24 13:32:04 | INFO | train_inner | {"epoch": 7, "update": 6.535, "loss": "2.288", "nll_loss": "0.352", "ppl": "1.28", "wps": "1726.9", "ups": "5.63", "wpb": "306.5", "bsz": "16", "num_updates": "8000", "lr": "4.96248e-05", "gnorm": "2.65", "loss_scale": "4", "train_wall": "18", "wall": "2196"}
2021-10-24 13:32:22 | INFO | train_inner | {"epoch": 7, "update": 6.616, "loss": "2.273", "nll_loss": "0.333", "ppl": "1.26", "wps": "2081.6", "ups": "5.53", "wpb": "376.5", "bsz": "16", "num_updates": "8100", "lr": "4.96198e-05", "gnorm": "2.809", "loss_scale": "4", "train_wall": "18", "wall": "2214"}
2021-10-24 13:32:39 | INFO | train_inner | {"epoch": 7, "update": 6.698, "loss": "2.314", "nll_loss": "0.379", "ppl": "1.3", "wps": "1762", "ups": "5.84", "wpb": "301.8", "bsz": "16", "num_updates": "8200", "lr": "4.96148e-05", "gnorm": "2.754", "loss_scale": "4", "train_wall": "17", "wall": "2232"}
2021-10-24 13:32:56 | INFO | train_inner | {"epoch": 7, "update": 6.78, "loss": "2.305", "nll_loss": "0.371", "ppl": "1.29", "wps": "1643.8", "ups": "5.86", "wpb": "280.4", "bsz": "16", "num_updates": "8300", "lr": "4.96098e-05", "gnorm": "3.384", "loss_scale": "8", "train_wall": "17", "wall": "2249"}
2021-10-24 13:33:14 | INFO | train_inner | {"epoch": 7, "update": 6.861, "loss": "2.313", "nll_loss": "0.381", "ppl": "1.3", "wps": "1660.8", "ups": "5.6", "wpb": "296.4", "bsz": "16", "num_updates": "8400", "lr": "4.96048e-05", "gnorm": "2.997", "loss_scale": "8", "train_wall": "18", "wall": "2267"}
2021-10-24 13:33:30 | INFO | train_inner | {"epoch": 7, "update": 6.943, "loss": "2.301", "nll_loss": "0.368", "ppl": "1.29", "wps": "1705.2", "ups": "6.19", "wpb": "275.5", "bsz": "16", "num_updates": "8500", "lr": "4.95998e-05", "gnorm": "2.743", "loss_scale": "8", "train_wall": "16", "wall": "2283"}
2021-10-24 13:33:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-24 13:35:35 | INFO | valid | {"epoch": 7, "valid_loss": "3.003", "valid_nll_loss": "0.991", "valid_ppl": "1.99", "valid_bleu": "68.23", "valid_wps": "378.4", "valid_wpb": "140.1", "valid_bsz": "8", "valid_num_updates": "8570", "valid_best_bleu": "69.44"}
2021-10-24 13:35:35 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-24 13:35:47 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/plbart/unique/large/checkpoint_last.pt (epoch 7 @ 8570 updates, score 68.23) (writing took 12.843946377979591 seconds)
2021-10-24 13:35:47 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2021-10-24 13:35:47 | INFO | train | {"epoch": 7, "train_loss": "2.289", "train_nll_loss": "0.351", "train_ppl": "1.28", "train_wps": "1069.2", "train_ups": "3.61", "train_wpb": "295.9", "train_bsz": "16", "train_num_updates": "8570", "train_lr": "4.95963e-05", "train_gnorm": "2.812", "train_loss_scale": "5", "train_train_wall": "210", "train_wall": "2420"}
2021-10-24 13:35:47 | INFO | fairseq_cli.train | begin training epoch 7
2021-10-24 13:35:52 | INFO | train_inner | {"epoch": 8, "update": 7.024, "loss": "2.27", "nll_loss": "0.326", "ppl": "1.25", "wps": "186.9", "ups": "0.7", "wpb": "266", "bsz": "15.9", "num_updates": "8600", "lr": "4.95948e-05", "gnorm": "2.676", "loss_scale": "8", "train_wall": "15", "wall": "2425"}
2021-10-24 13:36:10 | INFO | train_inner | {"epoch": 8, "update": 7.106, "loss": "2.256", "nll_loss": "0.317", "ppl": "1.25", "wps": "1893.2", "ups": "5.78", "wpb": "327.4", "bsz": "16", "num_updates": "8700", "lr": "4.95898e-05", "gnorm": "2.732", "loss_scale": "8", "train_wall": "17", "wall": "2442"}
2021-10-24 13:36:26 | INFO | train_inner | {"epoch": 8, "update": 7.188, "loss": "2.225", "nll_loss": "0.285", "ppl": "1.22", "wps": "2017", "ups": "5.96", "wpb": "338.2", "bsz": "16", "num_updates": "8800", "lr": "4.95848e-05", "gnorm": "2.383", "loss_scale": "8", "train_wall": "17", "wall": "2459"}
2021-10-24 13:36:44 | INFO | train_inner | {"epoch": 8, "update": 7.269, "loss": "2.253", "nll_loss": "0.312", "ppl": "1.24", "wps": "1635.5", "ups": "5.7", "wpb": "287", "bsz": "16", "num_updates": "8900", "lr": "4.95798e-05", "gnorm": "2.667", "loss_scale": "8", "train_wall": "17", "wall": "2477"}
2021-10-24 13:37:01 | INFO | train_inner | {"epoch": 8, "update": 7.351, "loss": "2.256", "nll_loss": "0.317", "ppl": "1.25", "wps": "1689.3", "ups": "5.98", "wpb": "282.5", "bsz": "16", "num_updates": "9000", "lr": "4.95748e-05", "gnorm": "2.745", "loss_scale": "8", "train_wall": "17", "wall": "2493"}
2021-10-24 13:37:18 | INFO | train_inner | {"epoch": 8, "update": 7.433, "loss": "2.26", "nll_loss": "0.325", "ppl": "1.25", "wps": "1754.9", "ups": "5.7", "wpb": "308.1", "bsz": "16", "num_updates": "9100", "lr": "4.95698e-05", "gnorm": "2.785", "loss_scale": "8", "train_wall": "17", "wall": "2511"}
2021-10-24 13:37:35 | INFO | train_inner | {"epoch": 8, "update": 7.514, "loss": "2.274", "nll_loss": "0.337", "ppl": "1.26", "wps": "1608.4", "ups": "6", "wpb": "268", "bsz": "16", "num_updates": "9200", "lr": "4.95648e-05", "gnorm": "2.991", "loss_scale": "8", "train_wall": "16", "wall": "2528"}
2021-10-24 13:37:53 | INFO | train_inner | {"epoch": 8, "update": 7.596, "loss": "2.283", "nll_loss": "0.349", "ppl": "1.27", "wps": "1456.7", "ups": "5.52", "wpb": "264.1", "bsz": "16", "num_updates": "9300", "lr": "4.95598e-05", "gnorm": "3.849", "loss_scale": "8", "train_wall": "18", "wall": "2546"}
2021-10-24 13:38:09 | INFO | train_inner | {"epoch": 8, "update": 7.678, "loss": "2.268", "nll_loss": "0.333", "ppl": "1.26", "wps": "1754.9", "ups": "6.42", "wpb": "273.2", "bsz": "16", "num_updates": "9400", "lr": "4.95548e-05", "gnorm": "2.869", "loss_scale": "8", "train_wall": "15", "wall": "2561"}
2021-10-24 13:38:24 | INFO | train_inner | {"epoch": 8, "update": 7.759, "loss": "2.262", "nll_loss": "0.326", "ppl": "1.25", "wps": "1925.6", "ups": "6.35", "wpb": "303.1", "bsz": "16", "num_updates": "9500", "lr": "4.95498e-05", "gnorm": "2.968", "loss_scale": "8", "train_wall": "16", "wall": "2577"}
2021-10-24 13:38:41 | INFO | train_inner | {"epoch": 8, "update": 7.841, "loss": "2.29", "nll_loss": "0.357", "ppl": "1.28", "wps": "1787.6", "ups": "5.98", "wpb": "299", "bsz": "16", "num_updates": "9600", "lr": "4.95448e-05", "gnorm": "2.948", "loss_scale": "8", "train_wall": "17", "wall": "2594"}
2021-10-24 13:38:59 | INFO | train_inner | {"epoch": 8, "update": 7.922, "loss": "2.275", "nll_loss": "0.341", "ppl": "1.27", "wps": "1702.4", "ups": "5.59", "wpb": "304.6", "bsz": "16", "num_updates": "9700", "lr": "4.95398e-05", "gnorm": "3.215", "loss_scale": "8", "train_wall": "18", "wall": "2612"}
2021-10-24 13:39:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-24 13:41:10 | INFO | valid | {"epoch": 8, "valid_loss": "3.01", "valid_nll_loss": "1.013", "valid_ppl": "2.02", "valid_bleu": "67.89", "valid_wps": "379.3", "valid_wpb": "140.1", "valid_bsz": "8", "valid_num_updates": "9795", "valid_best_bleu": "69.44"}
2021-10-24 13:41:10 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-24 13:41:16 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/plbart/unique/large/checkpoint_last.pt (epoch 8 @ 9795 updates, score 67.89) (writing took 6.398680023965426 seconds)
2021-10-24 13:41:16 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2021-10-24 13:41:16 | INFO | train | {"epoch": 8, "train_loss": "2.262", "train_nll_loss": "0.325", "train_ppl": "1.25", "train_wps": "1103.2", "train_ups": "3.73", "train_wpb": "295.9", "train_bsz": "16", "train_num_updates": "9795", "train_lr": "4.9535e-05", "train_gnorm": "2.912", "train_loss_scale": "8", "train_train_wall": "206", "train_wall": "2749"}
2021-10-24 13:41:16 | INFO | fairseq_cli.train | begin training epoch 8
2021-10-24 13:41:17 | INFO | train_inner | {"epoch": 9, "update": 8.004, "loss": "2.257", "nll_loss": "0.324", "ppl": "1.25", "wps": "224.6", "ups": "0.73", "wpb": "309.6", "bsz": "15.9", "num_updates": "9800", "lr": "4.95348e-05", "gnorm": "2.98", "loss_scale": "8", "train_wall": "18", "wall": "2750"}
2021-10-24 13:41:33 | INFO | train_inner | {"epoch": 9, "update": 8.086, "loss": "2.226", "nll_loss": "0.287", "ppl": "1.22", "wps": "1799.9", "ups": "6.07", "wpb": "296.5", "bsz": "16", "num_updates": "9900", "lr": "4.95298e-05", "gnorm": "2.413", "loss_scale": "8", "train_wall": "16", "wall": "2766"}
2021-10-24 13:41:50 | INFO | train_inner | {"epoch": 9, "update": 8.167, "loss": "2.228", "nll_loss": "0.293", "ppl": "1.22", "wps": "1794.5", "ups": "6.13", "wpb": "292.7", "bsz": "16", "num_updates": "10000", "lr": "4.95248e-05", "gnorm": "2.519", "loss_scale": "8", "train_wall": "16", "wall": "2782"}
2021-10-24 13:42:06 | INFO | train_inner | {"epoch": 9, "update": 8.249, "loss": "2.241", "nll_loss": "0.305", "ppl": "1.24", "wps": "1537.9", "ups": "6.12", "wpb": "251.1", "bsz": "16", "num_updates": "10100", "lr": "4.95198e-05", "gnorm": "2.733", "loss_scale": "8", "train_wall": "16", "wall": "2799"}
2021-10-24 13:42:22 | INFO | train_inner | {"epoch": 9, "update": 8.331, "loss": "2.22", "nll_loss": "0.284", "ppl": "1.22", "wps": "1855.7", "ups": "6.06", "wpb": "306.1", "bsz": "16", "num_updates": "10200", "lr": "4.95148e-05", "gnorm": "2.396", "loss_scale": "8", "train_wall": "16", "wall": "2815"}
2021-10-24 13:42:40 | INFO | train_inner | {"epoch": 9, "update": 8.412, "loss": "2.243", "nll_loss": "0.307", "ppl": "1.24", "wps": "1467.8", "ups": "5.72", "wpb": "256.8", "bsz": "16", "num_updates": "10300", "lr": "4.95098e-05", "gnorm": "2.6", "loss_scale": "8", "train_wall": "17", "wall": "2833"}
2021-10-24 13:42:56 | INFO | train_inner | {"epoch": 9, "update": 8.494, "loss": "2.24", "nll_loss": "0.303", "ppl": "1.23", "wps": "1536.3", "ups": "6.1", "wpb": "252", "bsz": "16", "num_updates": "10400", "lr": "4.95048e-05", "gnorm": "2.699", "loss_scale": "8", "train_wall": "16", "wall": "2849"}
2021-10-24 13:43:13 | INFO | train_inner | {"epoch": 9, "update": 8.576, "loss": "2.236", "nll_loss": "0.301", "ppl": "1.23", "wps": "1764.7", "ups": "5.97", "wpb": "295.5", "bsz": "16", "num_updates": "10500", "lr": "4.94997e-05", "gnorm": "2.766", "loss_scale": "8", "train_wall": "17", "wall": "2866"}
2021-10-24 13:43:30 | INFO | train_inner | {"epoch": 9, "update": 8.657, "loss": "2.25", "nll_loss": "0.315", "ppl": "1.24", "wps": "1822.9", "ups": "5.87", "wpb": "310.3", "bsz": "16", "num_updates": "10600", "lr": "4.94947e-05", "gnorm": "2.516", "loss_scale": "8", "train_wall": "17", "wall": "2883"}
2021-10-24 13:43:46 | INFO | train_inner | {"epoch": 9, "update": 8.739, "loss": "2.252", "nll_loss": "0.321", "ppl": "1.25", "wps": "2100.2", "ups": "6.19", "wpb": "339.3", "bsz": "16", "num_updates": "10700", "lr": "4.94897e-05", "gnorm": "2.413", "loss_scale": "8", "train_wall": "16", "wall": "2899"}
2021-10-24 13:44:04 | INFO | train_inner | {"epoch": 9, "update": 8.82, "loss": "2.252", "nll_loss": "0.32", "ppl": "1.25", "wps": "1848.6", "ups": "5.73", "wpb": "322.7", "bsz": "16", "num_updates": "10800", "lr": "4.94847e-05", "gnorm": "2.825", "loss_scale": "8", "train_wall": "17", "wall": "2916"}
2021-10-24 13:44:21 | INFO | train_inner | {"epoch": 9, "update": 8.902, "loss": "2.258", "nll_loss": "0.325", "ppl": "1.25", "wps": "1871.8", "ups": "5.84", "wpb": "320.4", "bsz": "16", "num_updates": "10900", "lr": "4.94797e-05", "gnorm": "2.97", "loss_scale": "8", "train_wall": "17", "wall": "2934"}
2021-10-24 13:44:38 | INFO | train_inner | {"epoch": 9, "update": 8.984, "loss": "2.251", "nll_loss": "0.32", "ppl": "1.25", "wps": "1785.8", "ups": "5.85", "wpb": "305.4", "bsz": "16", "num_updates": "11000", "lr": "4.94747e-05", "gnorm": "2.683", "loss_scale": "8", "train_wall": "17", "wall": "2951"}
2021-10-24 13:44:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-24 13:46:38 | INFO | valid | {"epoch": 9, "valid_loss": "3.027", "valid_nll_loss": "1.039", "valid_ppl": "2.06", "valid_bleu": "65.36", "valid_wps": "369.9", "valid_wpb": "140.1", "valid_bsz": "8", "valid_num_updates": "11020", "valid_best_bleu": "69.44"}
2021-10-24 13:46:38 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-24 13:46:45 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/plbart/unique/large/checkpoint_last.pt (epoch 9 @ 11020 updates, score 65.36) (writing took 6.430502776987851 seconds)
2021-10-24 13:46:45 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2021-10-24 13:46:45 | INFO | train | {"epoch": 9, "train_loss": "2.242", "train_nll_loss": "0.307", "train_ppl": "1.24", "train_wps": "1102.3", "train_ups": "3.73", "train_wpb": "295.9", "train_bsz": "16", "train_num_updates": "11020", "train_lr": "4.94737e-05", "train_gnorm": "2.627", "train_loss_scale": "8", "train_train_wall": "203", "train_wall": "3077"}
2021-10-24 13:46:45 | INFO | fairseq_cli.train | begin training epoch 9
2021-10-24 13:46:59 | INFO | train_inner | {"epoch": 10, "update": 9.065, "loss": "2.221", "nll_loss": "0.287", "ppl": "1.22", "wps": "225.2", "ups": "0.71", "wpb": "316.6", "bsz": "15.9", "num_updates": "11100", "lr": "4.94697e-05", "gnorm": "2.708", "loss_scale": "8", "train_wall": "17", "wall": "3091"}
2021-10-24 13:47:14 | INFO | train_inner | {"epoch": 10, "update": 9.147, "loss": "2.218", "nll_loss": "0.281", "ppl": "1.22", "wps": "1696.9", "ups": "6.65", "wpb": "255.2", "bsz": "16", "num_updates": "11200", "lr": "4.94647e-05", "gnorm": "2.452", "loss_scale": "8", "train_wall": "15", "wall": "3106"}
2021-10-24 13:47:30 | INFO | train_inner | {"epoch": 10, "update": 9.229, "loss": "2.215", "nll_loss": "0.278", "ppl": "1.21", "wps": "1682.2", "ups": "5.91", "wpb": "284.6", "bsz": "16", "num_updates": "11300", "lr": "4.94597e-05", "gnorm": "2.457", "loss_scale": "8", "train_wall": "17", "wall": "3123"}
2021-10-24 13:47:48 | INFO | train_inner | {"epoch": 10, "update": 9.31, "loss": "2.205", "nll_loss": "0.272", "ppl": "1.21", "wps": "1807.1", "ups": "5.56", "wpb": "324.9", "bsz": "16", "num_updates": "11400", "lr": "4.94547e-05", "gnorm": "2.58", "loss_scale": "8", "train_wall": "18", "wall": "3141"}
2021-10-24 13:48:06 | INFO | train_inner | {"epoch": 10, "update": 9.392, "loss": "2.226", "nll_loss": "0.288", "ppl": "1.22", "wps": "1654.7", "ups": "5.74", "wpb": "288.2", "bsz": "16", "num_updates": "11500", "lr": "4.94497e-05", "gnorm": "2.701", "loss_scale": "8", "train_wall": "17", "wall": "3159"}
2021-10-24 13:48:22 | INFO | train_inner | {"epoch": 10, "update": 9.473, "loss": "2.218", "nll_loss": "0.286", "ppl": "1.22", "wps": "1982.2", "ups": "6.39", "wpb": "310.1", "bsz": "16", "num_updates": "11600", "lr": "4.94447e-05", "gnorm": "2.267", "loss_scale": "8", "train_wall": "15", "wall": "3174"}
2021-10-24 13:48:38 | INFO | train_inner | {"epoch": 10, "update": 9.555, "loss": "2.217", "nll_loss": "0.288", "ppl": "1.22", "wps": "1958.9", "ups": "6.23", "wpb": "314.5", "bsz": "16", "num_updates": "11700", "lr": "4.94397e-05", "gnorm": "2.672", "loss_scale": "8", "train_wall": "16", "wall": "3190"}
2021-10-24 13:48:54 | INFO | train_inner | {"epoch": 10, "update": 9.637, "loss": "2.24", "nll_loss": "0.307", "ppl": "1.24", "wps": "1598.9", "ups": "6.05", "wpb": "264.1", "bsz": "16", "num_updates": "11800", "lr": "4.94347e-05", "gnorm": "2.729", "loss_scale": "8", "train_wall": "16", "wall": "3207"}
2021-10-24 13:49:11 | INFO | train_inner | {"epoch": 10, "update": 9.718, "loss": "2.254", "nll_loss": "0.319", "ppl": "1.25", "wps": "1550.6", "ups": "5.93", "wpb": "261.4", "bsz": "16", "num_updates": "11900", "lr": "4.94297e-05", "gnorm": "2.836", "loss_scale": "8", "train_wall": "17", "wall": "3224"}
2021-10-24 13:49:28 | INFO | train_inner | {"epoch": 10, "update": 9.8, "loss": "2.238", "nll_loss": "0.305", "ppl": "1.24", "wps": "1610.5", "ups": "5.96", "wpb": "270.4", "bsz": "16", "num_updates": "12000", "lr": "4.94247e-05", "gnorm": "2.735", "loss_scale": "8", "train_wall": "17", "wall": "3240"}
2021-10-24 13:49:46 | INFO | train_inner | {"epoch": 10, "update": 9.882, "loss": "2.25", "nll_loss": "0.319", "ppl": "1.25", "wps": "1496.5", "ups": "5.55", "wpb": "269.4", "bsz": "16", "num_updates": "12100", "lr": "4.94197e-05", "gnorm": "2.601", "loss_scale": "8", "train_wall": "18", "wall": "3258"}
2021-10-24 13:50:04 | INFO | train_inner | {"epoch": 10, "update": 9.963, "loss": "2.225", "nll_loss": "0.296", "ppl": "1.23", "wps": "2156.3", "ups": "5.49", "wpb": "392.5", "bsz": "16", "num_updates": "12200", "lr": "4.94147e-05", "gnorm": "2.793", "loss_scale": "8", "train_wall": "18", "wall": "3277"}
2021-10-24 13:50:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-24 13:52:08 | INFO | valid | {"epoch": 10, "valid_loss": "3.069", "valid_nll_loss": "1.094", "valid_ppl": "2.13", "valid_bleu": "65.27", "valid_wps": "367.7", "valid_wpb": "140.1", "valid_bsz": "8", "valid_num_updates": "12245", "valid_best_bleu": "69.44"}
2021-10-24 13:52:08 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-24 13:52:15 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/plbart/unique/large/checkpoint_last.pt (epoch 10 @ 12245 updates, score 65.27) (writing took 6.500704720965587 seconds)
2021-10-24 13:52:15 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2021-10-24 13:52:15 | INFO | train | {"epoch": 10, "train_loss": "2.226", "train_nll_loss": "0.294", "train_ppl": "1.23", "train_wps": "1098.6", "train_ups": "3.71", "train_wpb": "295.9", "train_bsz": "16", "train_num_updates": "12245", "train_lr": "4.94125e-05", "train_gnorm": "2.618", "train_loss_scale": "8", "train_train_wall": "204", "train_wall": "3407"}
2021-10-24 13:52:15 | INFO | fairseq_cli.train | begin training epoch 10
2021-10-24 13:52:23 | INFO | train_inner | {"epoch": 11, "update": 10.045, "loss": "2.222", "nll_loss": "0.291", "ppl": "1.22", "wps": "198.9", "ups": "0.72", "wpb": "275.5", "bsz": "15.9", "num_updates": "12300", "lr": "4.94097e-05", "gnorm": "2.317", "loss_scale": "8", "train_wall": "15", "wall": "3415"}
2021-10-24 13:52:41 | INFO | train_inner | {"epoch": 11, "update": 10.127, "loss": "2.205", "nll_loss": "0.271", "ppl": "1.21", "wps": "1665.5", "ups": "5.45", "wpb": "305.7", "bsz": "16", "num_updates": "12400", "lr": "4.94047e-05", "gnorm": "2.28", "loss_scale": "8", "train_wall": "18", "wall": "3434"}
2021-10-24 13:52:59 | INFO | train_inner | {"epoch": 11, "update": 10.208, "loss": "2.198", "nll_loss": "0.262", "ppl": "1.2", "wps": "1819.1", "ups": "5.39", "wpb": "337.4", "bsz": "16", "num_updates": "12500", "lr": "4.93997e-05", "gnorm": "2.268", "loss_scale": "8", "train_wall": "18", "wall": "3452"}
2021-10-24 13:53:17 | INFO | train_inner | {"epoch": 11, "update": 10.29, "loss": "2.198", "nll_loss": "0.268", "ppl": "1.2", "wps": "1596", "ups": "5.68", "wpb": "281", "bsz": "16", "num_updates": "12600", "lr": "4.93947e-05", "gnorm": "2.294", "loss_scale": "8", "train_wall": "17", "wall": "3470"}
2021-10-24 13:53:34 | INFO | train_inner | {"epoch": 11, "update": 10.371, "loss": "2.209", "nll_loss": "0.278", "ppl": "1.21", "wps": "1806.4", "ups": "6.04", "wpb": "299.2", "bsz": "16", "num_updates": "12700", "lr": "4.93897e-05", "gnorm": "2.53", "loss_scale": "8", "train_wall": "16", "wall": "3486"}
2021-10-24 13:53:50 | INFO | train_inner | {"epoch": 11, "update": 10.453, "loss": "2.213", "nll_loss": "0.281", "ppl": "1.21", "wps": "1640.6", "ups": "6.17", "wpb": "265.7", "bsz": "16", "num_updates": "12800", "lr": "4.93847e-05", "gnorm": "2.682", "loss_scale": "8", "train_wall": "16", "wall": "3502"}
2021-10-24 13:54:06 | INFO | train_inner | {"epoch": 11, "update": 10.535, "loss": "2.213", "nll_loss": "0.281", "ppl": "1.22", "wps": "1756.6", "ups": "6.09", "wpb": "288.6", "bsz": "16", "num_updates": "12900", "lr": "4.93797e-05", "gnorm": "2.459", "loss_scale": "8", "train_wall": "16", "wall": "3519"}
2021-10-24 13:54:22 | INFO | train_inner | {"epoch": 11, "update": 10.616, "loss": "2.225", "nll_loss": "0.294", "ppl": "1.23", "wps": "1646", "ups": "6.3", "wpb": "261.3", "bsz": "16", "num_updates": "13000", "lr": "4.93747e-05", "gnorm": "2.715", "loss_scale": "8", "train_wall": "16", "wall": "3535"}
2021-10-24 13:54:41 | INFO | train_inner | {"epoch": 11, "update": 10.698, "loss": "2.23", "nll_loss": "0.301", "ppl": "1.23", "wps": "1533.8", "ups": "5.34", "wpb": "287.5", "bsz": "16", "num_updates": "13100", "lr": "4.93697e-05", "gnorm": "2.743", "loss_scale": "8", "train_wall": "19", "wall": "3554"}
2021-10-24 13:54:58 | INFO | train_inner | {"epoch": 11, "update": 10.78, "loss": "2.213", "nll_loss": "0.286", "ppl": "1.22", "wps": "2099.1", "ups": "5.84", "wpb": "359.3", "bsz": "16", "num_updates": "13200", "lr": "4.93647e-05", "gnorm": "2.562", "loss_scale": "8", "train_wall": "17", "wall": "3571"}
2021-10-24 13:55:14 | INFO | train_inner | {"epoch": 11, "update": 10.861, "loss": "2.246", "nll_loss": "0.321", "ppl": "1.25", "wps": "1760.8", "ups": "6.06", "wpb": "290.5", "bsz": "16", "num_updates": "13300", "lr": "4.93597e-05", "gnorm": "2.731", "loss_scale": "8", "train_wall": "16", "wall": "3587"}
2021-10-24 13:55:33 | INFO | train_inner | {"epoch": 11, "update": 10.943, "loss": "2.23", "nll_loss": "0.303", "ppl": "1.23", "wps": "1789", "ups": "5.49", "wpb": "325.6", "bsz": "16", "num_updates": "13400", "lr": "4.93547e-05", "gnorm": "2.99", "loss_scale": "8", "train_wall": "18", "wall": "3605"}
2021-10-24 13:55:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-24 13:57:38 | INFO | valid | {"epoch": 11, "valid_loss": "3.07", "valid_nll_loss": "1.111", "valid_ppl": "2.16", "valid_bleu": "63.04", "valid_wps": "375.4", "valid_wpb": "140.1", "valid_bsz": "8", "valid_num_updates": "13470", "valid_best_bleu": "69.44"}
2021-10-24 13:57:38 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-24 13:57:45 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/plbart/unique/large/checkpoint_last.pt (epoch 11 @ 13470 updates, score 63.04) (writing took 6.307106673950329 seconds)
2021-10-24 13:57:45 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2021-10-24 13:57:45 | INFO | train | {"epoch": 11, "train_loss": "2.216", "train_nll_loss": "0.286", "train_ppl": "1.22", "train_wps": "1098.3", "train_ups": "3.71", "train_wpb": "295.9", "train_bsz": "16", "train_num_updates": "13470", "train_lr": "4.93512e-05", "train_gnorm": "2.566", "train_loss_scale": "8", "train_train_wall": "206", "train_wall": "3737"}
2021-10-24 13:57:45 | INFO | fairseq_cli.train | begin training epoch 11
2021-10-24 13:57:50 | INFO | train_inner | {"epoch": 12, "update": 11.024, "loss": "2.218", "nll_loss": "0.293", "ppl": "1.22", "wps": "200.2", "ups": "0.73", "wpb": "274.8", "bsz": "15.9", "num_updates": "13500", "lr": "4.93497e-05", "gnorm": "2.558", "loss_scale": "8", "train_wall": "16", "wall": "3743"}
2021-10-24 13:58:06 | INFO | train_inner | {"epoch": 12, "update": 11.106, "loss": "2.196", "nll_loss": "0.261", "ppl": "1.2", "wps": "1710.1", "ups": "6.15", "wpb": "277.9", "bsz": "16", "num_updates": "13600", "lr": "4.93447e-05", "gnorm": "2.398", "loss_scale": "8", "train_wall": "16", "wall": "3759"}
2021-10-24 13:58:24 | INFO | train_inner | {"epoch": 12, "update": 11.188, "loss": "2.193", "nll_loss": "0.261", "ppl": "1.2", "wps": "1706.5", "ups": "5.52", "wpb": "309.4", "bsz": "16", "num_updates": "13700", "lr": "4.93397e-05", "gnorm": "2.044", "loss_scale": "8", "train_wall": "18", "wall": "3777"}
2021-10-24 13:58:43 | INFO | train_inner | {"epoch": 12, "update": 11.269, "loss": "2.208", "nll_loss": "0.277", "ppl": "1.21", "wps": "1631.1", "ups": "5.33", "wpb": "306.2", "bsz": "16", "num_updates": "13800", "lr": "4.93347e-05", "gnorm": "2.358", "loss_scale": "8", "train_wall": "19", "wall": "3796"}
2021-10-24 13:58:59 | INFO | train_inner | {"epoch": 12, "update": 11.351, "loss": "2.214", "nll_loss": "0.284", "ppl": "1.22", "wps": "1709.4", "ups": "6.31", "wpb": "271", "bsz": "16", "num_updates": "13900", "lr": "4.93297e-05", "gnorm": "2.55", "loss_scale": "8", "train_wall": "16", "wall": "3812"}
2021-10-24 13:59:15 | INFO | train_inner | {"epoch": 12, "update": 11.433, "loss": "2.216", "nll_loss": "0.29", "ppl": "1.22", "wps": "1718.9", "ups": "6.13", "wpb": "280.4", "bsz": "16", "num_updates": "14000", "lr": "4.93247e-05", "gnorm": "2.568", "loss_scale": "8", "train_wall": "16", "wall": "3828"}
2021-10-24 13:59:32 | INFO | train_inner | {"epoch": 12, "update": 11.514, "loss": "2.207", "nll_loss": "0.279", "ppl": "1.21", "wps": "1694.2", "ups": "5.9", "wpb": "287", "bsz": "16", "num_updates": "14100", "lr": "4.93197e-05", "gnorm": "2.67", "loss_scale": "8", "train_wall": "17", "wall": "3845"}
2021-10-24 13:59:49 | INFO | train_inner | {"epoch": 12, "update": 11.596, "loss": "2.207", "nll_loss": "0.279", "ppl": "1.21", "wps": "1738.9", "ups": "6.02", "wpb": "288.8", "bsz": "16", "num_updates": "14200", "lr": "4.93147e-05", "gnorm": "2.35", "loss_scale": "8", "train_wall": "16", "wall": "3861"}
2021-10-24 14:00:07 | INFO | train_inner | {"epoch": 12, "update": 11.678, "loss": "2.211", "nll_loss": "0.286", "ppl": "1.22", "wps": "1962.7", "ups": "5.52", "wpb": "355.5", "bsz": "16", "num_updates": "14300", "lr": "4.93097e-05", "gnorm": "2.544", "loss_scale": "8", "train_wall": "18", "wall": "3880"}
2021-10-24 14:00:23 | INFO | train_inner | {"epoch": 12, "update": 11.759, "loss": "2.224", "nll_loss": "0.3", "ppl": "1.23", "wps": "1650.4", "ups": "6.13", "wpb": "269.4", "bsz": "16", "num_updates": "14400", "lr": "4.93047e-05", "gnorm": "2.501", "loss_scale": "8", "train_wall": "16", "wall": "3896"}
2021-10-24 14:00:41 | INFO | train_inner | {"epoch": 12, "update": 11.841, "loss": "2.226", "nll_loss": "0.302", "ppl": "1.23", "wps": "1744.9", "ups": "5.7", "wpb": "306.1", "bsz": "16", "num_updates": "14500", "lr": "4.92996e-05", "gnorm": "3.97", "loss_scale": "8", "train_wall": "17", "wall": "3913"}
2021-10-24 14:00:59 | INFO | train_inner | {"epoch": 12, "update": 11.922, "loss": "2.238", "nll_loss": "0.318", "ppl": "1.25", "wps": "1856.3", "ups": "5.59", "wpb": "331.9", "bsz": "16", "num_updates": "14600", "lr": "4.92946e-05", "gnorm": "2.785", "loss_scale": "8", "train_wall": "18", "wall": "3931"}
2021-10-24 14:01:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-24 14:03:08 | INFO | valid | {"epoch": 12, "valid_loss": "3.107", "valid_nll_loss": "1.14", "valid_ppl": "2.2", "valid_bleu": "61.26", "valid_wps": "379.5", "valid_wpb": "140.1", "valid_bsz": "8", "valid_num_updates": "14695", "valid_best_bleu": "69.44"}
2021-10-24 14:03:08 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-24 14:03:14 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/plbart/unique/large/checkpoint_last.pt (epoch 12 @ 14695 updates, score 61.26) (writing took 6.155253060976975 seconds)
2021-10-24 14:03:14 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2021-10-24 14:03:14 | INFO | train | {"epoch": 12, "train_loss": "2.213", "train_nll_loss": "0.286", "train_ppl": "1.22", "train_wps": "1100.2", "train_ups": "3.72", "train_wpb": "295.9", "train_bsz": "16", "train_num_updates": "14695", "train_lr": "4.92899e-05", "train_gnorm": "2.586", "train_loss_scale": "8", "train_train_wall": "207", "train_wall": "4067"}
2021-10-24 14:03:14 | INFO | fairseq_cli.train | begin training epoch 12
2021-10-24 14:03:15 | INFO | train_inner | {"epoch": 13, "update": 12.004, "loss": "2.216", "nll_loss": "0.288", "ppl": "1.22", "wps": "190.7", "ups": "0.73", "wpb": "260.3", "bsz": "15.9", "num_updates": "14700", "lr": "4.92896e-05", "gnorm": "2.428", "loss_scale": "8", "train_wall": "16", "wall": "4068"}
2021-10-24 14:03:31 | INFO | train_inner | {"epoch": 13, "update": 12.086, "loss": "2.189", "nll_loss": "0.258", "ppl": "1.2", "wps": "1633.1", "ups": "6.18", "wpb": "264.1", "bsz": "16", "num_updates": "14800", "lr": "4.92846e-05", "gnorm": "2.293", "loss_scale": "8", "train_wall": "16", "wall": "4084"}
2021-10-24 14:03:49 | INFO | train_inner | {"epoch": 13, "update": 12.167, "loss": "2.185", "nll_loss": "0.257", "ppl": "1.19", "wps": "1434.4", "ups": "5.79", "wpb": "247.7", "bsz": "16", "num_updates": "14900", "lr": "4.92796e-05", "gnorm": "2.536", "loss_scale": "8", "train_wall": "17", "wall": "4101"}
2021-10-24 14:04:05 | INFO | train_inner | {"epoch": 13, "update": 12.249, "loss": "2.202", "nll_loss": "0.276", "ppl": "1.21", "wps": "1662.9", "ups": "5.92", "wpb": "281", "bsz": "16", "num_updates": "15000", "lr": "4.92746e-05", "gnorm": "2.358", "loss_scale": "8", "train_wall": "17", "wall": "4118"}
2021-10-24 14:04:22 | INFO | train_inner | {"epoch": 13, "update": 12.331, "loss": "2.196", "nll_loss": "0.269", "ppl": "1.2", "wps": "1960.9", "ups": "6.21", "wpb": "315.9", "bsz": "16", "num_updates": "15100", "lr": "4.92696e-05", "gnorm": "2.541", "loss_scale": "8", "train_wall": "16", "wall": "4134"}
2021-10-24 14:04:39 | INFO | train_inner | {"epoch": 13, "update": 12.412, "loss": "2.204", "nll_loss": "0.275", "ppl": "1.21", "wps": "1774.5", "ups": "5.85", "wpb": "303.3", "bsz": "16", "num_updates": "15200", "lr": "4.92646e-05", "gnorm": "2.364", "loss_scale": "8", "train_wall": "17", "wall": "4151"}
2021-10-24 14:04:56 | INFO | train_inner | {"epoch": 13, "update": 12.494, "loss": "2.197", "nll_loss": "0.271", "ppl": "1.21", "wps": "1499.6", "ups": "5.64", "wpb": "265.9", "bsz": "16", "num_updates": "15300", "lr": "4.92596e-05", "gnorm": "2.364", "loss_scale": "8", "train_wall": "18", "wall": "4169"}
2021-10-24 14:05:14 | INFO | train_inner | {"epoch": 13, "update": 12.576, "loss": "2.211", "nll_loss": "0.284", "ppl": "1.22", "wps": "1511.9", "ups": "5.59", "wpb": "270.5", "bsz": "16", "num_updates": "15400", "lr": "4.92546e-05", "gnorm": "2.655", "loss_scale": "8", "train_wall": "18", "wall": "4187"}
2021-10-24 14:05:31 | INFO | train_inner | {"epoch": 13, "update": 12.657, "loss": "2.223", "nll_loss": "0.301", "ppl": "1.23", "wps": "1810.5", "ups": "6.08", "wpb": "297.9", "bsz": "16", "num_updates": "15500", "lr": "4.92496e-05", "gnorm": "2.443", "loss_scale": "8", "train_wall": "16", "wall": "4203"}
2021-10-24 14:05:48 | INFO | train_inner | {"epoch": 13, "update": 12.739, "loss": "2.219", "nll_loss": "0.295", "ppl": "1.23", "wps": "1693.6", "ups": "5.91", "wpb": "286.5", "bsz": "16", "num_updates": "15600", "lr": "4.92446e-05", "gnorm": "2.521", "loss_scale": "8", "train_wall": "17", "wall": "4220"}
2021-10-24 14:06:04 | INFO | train_inner | {"epoch": 13, "update": 12.82, "loss": "2.21", "nll_loss": "0.287", "ppl": "1.22", "wps": "1751.2", "ups": "6.16", "wpb": "284.1", "bsz": "16", "num_updates": "15700", "lr": "4.92396e-05", "gnorm": "2.676", "loss_scale": "8", "train_wall": "16", "wall": "4237"}
2021-10-24 14:06:22 | INFO | train_inner | {"epoch": 13, "update": 12.902, "loss": "2.229", "nll_loss": "0.313", "ppl": "1.24", "wps": "2467.1", "ups": "5.5", "wpb": "448.3", "bsz": "16", "num_updates": "15800", "lr": "4.92346e-05", "gnorm": "2.546", "loss_scale": "8", "train_wall": "18", "wall": "4255"}
2021-10-24 14:06:39 | INFO | train_inner | {"epoch": 13, "update": 12.984, "loss": "2.209", "nll_loss": "0.291", "ppl": "1.22", "wps": "1649.6", "ups": "5.82", "wpb": "283.2", "bsz": "16", "num_updates": "15900", "lr": "4.92296e-05", "gnorm": "2.612", "loss_scale": "8", "train_wall": "17", "wall": "4272"}
2021-10-24 14:06:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-24 14:08:35 | INFO | valid | {"epoch": 13, "valid_loss": "3.127", "valid_nll_loss": "1.172", "valid_ppl": "2.25", "valid_bleu": "60.64", "valid_wps": "383.8", "valid_wpb": "140.1", "valid_bsz": "8", "valid_num_updates": "15920", "valid_best_bleu": "69.44"}
2021-10-24 14:08:35 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-24 14:08:41 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/plbart/unique/large/checkpoint_last.pt (epoch 13 @ 15920 updates, score 60.64) (writing took 6.183524255990051 seconds)
2021-10-24 14:08:41 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2021-10-24 14:08:41 | INFO | train | {"epoch": 13, "train_loss": "2.207", "train_nll_loss": "0.283", "train_ppl": "1.22", "train_wps": "1110", "train_ups": "3.75", "train_wpb": "295.9", "train_bsz": "16", "train_num_updates": "15920", "train_lr": "4.92286e-05", "train_gnorm": "2.494", "train_loss_scale": "8", "train_train_wall": "206", "train_wall": "4393"}
2021-10-24 14:08:41 | INFO | fairseq_cli.train | begin training epoch 13
2021-10-24 14:08:54 | INFO | train_inner | {"epoch": 14, "update": 13.065, "loss": "2.191", "nll_loss": "0.266", "ppl": "1.2", "wps": "246.5", "ups": "0.74", "wpb": "332.4", "bsz": "15.9", "num_updates": "16000", "lr": "4.92246e-05", "gnorm": "2.313", "loss_scale": "8", "train_wall": "16", "wall": "4407"}
2021-10-24 14:09:09 | INFO | train_inner | {"epoch": 14, "update": 13.147, "loss": "2.185", "nll_loss": "0.261", "ppl": "1.2", "wps": "1897.5", "ups": "6.91", "wpb": "274.8", "bsz": "16", "num_updates": "16100", "lr": "4.92196e-05", "gnorm": "2.3", "loss_scale": "8", "train_wall": "14", "wall": "4421"}
2021-10-24 14:09:26 | INFO | train_inner | {"epoch": 14, "update": 13.229, "loss": "2.192", "nll_loss": "0.268", "ppl": "1.2", "wps": "1749.3", "ups": "5.62", "wpb": "311.1", "bsz": "16", "num_updates": "16200", "lr": "4.92146e-05", "gnorm": "2.131", "loss_scale": "8", "train_wall": "18", "wall": "4439"}
2021-10-24 14:09:44 | INFO | train_inner | {"epoch": 14, "update": 13.31, "loss": "2.191", "nll_loss": "0.262", "ppl": "1.2", "wps": "1595.4", "ups": "5.83", "wpb": "273.6", "bsz": "16", "num_updates": "16300", "lr": "4.92096e-05", "gnorm": "2.565", "loss_scale": "8", "train_wall": "17", "wall": "4456"}
2021-10-24 14:10:00 | INFO | train_inner | {"epoch": 14, "update": 13.392, "loss": "2.208", "nll_loss": "0.288", "ppl": "1.22", "wps": "1859.4", "ups": "6.18", "wpb": "300.7", "bsz": "16", "num_updates": "16400", "lr": "4.92046e-05", "gnorm": "2.616", "loss_scale": "8", "train_wall": "16", "wall": "4472"}
2021-10-24 14:10:17 | INFO | train_inner | {"epoch": 14, "update": 13.473, "loss": "2.196", "nll_loss": "0.273", "ppl": "1.21", "wps": "1737.4", "ups": "5.86", "wpb": "296.7", "bsz": "16", "num_updates": "16500", "lr": "4.91996e-05", "gnorm": "2.777", "loss_scale": "16", "train_wall": "17", "wall": "4489"}
2021-10-24 14:10:34 | INFO | train_inner | {"epoch": 14, "update": 13.555, "loss": "2.198", "nll_loss": "0.276", "ppl": "1.21", "wps": "1649", "ups": "5.65", "wpb": "292", "bsz": "16", "num_updates": "16600", "lr": "4.91946e-05", "gnorm": "2.409", "loss_scale": "16", "train_wall": "17", "wall": "4507"}
2021-10-24 14:10:52 | INFO | train_inner | {"epoch": 14, "update": 13.637, "loss": "2.196", "nll_loss": "0.276", "ppl": "1.21", "wps": "1706.1", "ups": "5.55", "wpb": "307.2", "bsz": "16", "num_updates": "16700", "lr": "4.91896e-05", "gnorm": "2.202", "loss_scale": "16", "train_wall": "18", "wall": "4525"}
2021-10-24 14:11:10 | INFO | train_inner | {"epoch": 14, "update": 13.718, "loss": "2.207", "nll_loss": "0.285", "ppl": "1.22", "wps": "1637.3", "ups": "5.78", "wpb": "283.5", "bsz": "16", "num_updates": "16800", "lr": "4.91846e-05", "gnorm": "2.833", "loss_scale": "16", "train_wall": "17", "wall": "4542"}
2021-10-24 14:11:26 | INFO | train_inner | {"epoch": 14, "update": 13.8, "loss": "2.21", "nll_loss": "0.287", "ppl": "1.22", "wps": "1783.3", "ups": "6.33", "wpb": "281.6", "bsz": "16", "num_updates": "16900", "lr": "4.91796e-05", "gnorm": "2.583", "loss_scale": "16", "train_wall": "16", "wall": "4558"}
2021-10-24 14:11:44 | INFO | train_inner | {"epoch": 14, "update": 13.882, "loss": "2.215", "nll_loss": "0.299", "ppl": "1.23", "wps": "1749.9", "ups": "5.49", "wpb": "318.7", "bsz": "16", "num_updates": "17000", "lr": "4.91746e-05", "gnorm": "2.681", "loss_scale": "16", "train_wall": "18", "wall": "4576"}
2021-10-24 14:12:01 | INFO | train_inner | {"epoch": 14, "update": 13.963, "loss": "2.232", "nll_loss": "0.32", "ppl": "1.25", "wps": "1825.5", "ups": "5.9", "wpb": "309.6", "bsz": "16", "num_updates": "17100", "lr": "4.91696e-05", "gnorm": "2.601", "loss_scale": "16", "train_wall": "17", "wall": "4593"}
2021-10-24 14:12:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-24 14:14:06 | INFO | valid | {"epoch": 14, "valid_loss": "3.142", "valid_nll_loss": "1.188", "valid_ppl": "2.28", "valid_bleu": "59.26", "valid_wps": "364.6", "valid_wpb": "140.1", "valid_bsz": "8", "valid_num_updates": "17145", "valid_best_bleu": "69.44"}
2021-10-24 14:14:06 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-24 14:14:12 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/plbart/unique/large/checkpoint_last.pt (epoch 14 @ 17145 updates, score 59.26) (writing took 6.1205069969873875 seconds)
2021-10-24 14:14:12 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2021-10-24 14:14:12 | INFO | train | {"epoch": 14, "train_loss": "2.203", "train_nll_loss": "0.281", "train_ppl": "1.21", "train_wps": "1093.5", "train_ups": "3.7", "train_wpb": "295.9", "train_bsz": "16", "train_num_updates": "17145", "train_lr": "4.91673e-05", "train_gnorm": "2.502", "train_loss_scale": "13", "train_train_wall": "205", "train_wall": "4725"}
2021-10-24 14:14:12 | INFO | fairseq_cli.train | begin training epoch 14
2021-10-24 14:14:21 | INFO | train_inner | {"epoch": 15, "update": 14.045, "loss": "2.205", "nll_loss": "0.282", "ppl": "1.22", "wps": "177.8", "ups": "0.71", "wpb": "249.4", "bsz": "15.9", "num_updates": "17200", "lr": "4.91646e-05", "gnorm": "2.436", "loss_scale": "16", "train_wall": "16", "wall": "4734"}
2021-10-24 14:14:38 | INFO | train_inner | {"epoch": 15, "update": 14.127, "loss": "2.18", "nll_loss": "0.258", "ppl": "1.2", "wps": "1866.3", "ups": "5.89", "wpb": "317.1", "bsz": "16", "num_updates": "17300", "lr": "4.91596e-05", "gnorm": "2.126", "loss_scale": "16", "train_wall": "17", "wall": "4751"}
2021-10-24 14:14:53 | INFO | train_inner | {"epoch": 15, "update": 14.208, "loss": "2.183", "nll_loss": "0.257", "ppl": "1.2", "wps": "1647.9", "ups": "6.73", "wpb": "244.9", "bsz": "16", "num_updates": "17400", "lr": "4.91546e-05", "gnorm": "2.314", "loss_scale": "16", "train_wall": "15", "wall": "4766"}
2021-10-24 14:15:09 | INFO | train_inner | {"epoch": 15, "update": 14.29, "loss": "2.187", "nll_loss": "0.266", "ppl": "1.2", "wps": "1896.8", "ups": "6.07", "wpb": "312.4", "bsz": "16", "num_updates": "17500", "lr": "4.91496e-05", "gnorm": "2.351", "loss_scale": "16", "train_wall": "16", "wall": "4782"}
2021-10-24 14:15:25 | INFO | train_inner | {"epoch": 15, "update": 14.371, "loss": "2.184", "nll_loss": "0.261", "ppl": "1.2", "wps": "1622.3", "ups": "6.21", "wpb": "261.4", "bsz": "16", "num_updates": "17600", "lr": "4.91446e-05", "gnorm": "2.206", "loss_scale": "16", "train_wall": "16", "wall": "4798"}
2021-10-24 14:15:43 | INFO | train_inner | {"epoch": 15, "update": 14.453, "loss": "2.195", "nll_loss": "0.275", "ppl": "1.21", "wps": "1766.2", "ups": "5.71", "wpb": "309.2", "bsz": "16", "num_updates": "17700", "lr": "4.91396e-05", "gnorm": "2.261", "loss_scale": "16", "train_wall": "17", "wall": "4816"}
2021-10-24 14:16:00 | INFO | train_inner | {"epoch": 15, "update": 14.535, "loss": "2.207", "nll_loss": "0.286", "ppl": "1.22", "wps": "1446.3", "ups": "6.03", "wpb": "239.9", "bsz": "16", "num_updates": "17800", "lr": "4.91346e-05", "gnorm": "2.201", "loss_scale": "16", "train_wall": "16", "wall": "4832"}
2021-10-24 14:16:16 | INFO | train_inner | {"epoch": 15, "update": 14.616, "loss": "2.207", "nll_loss": "0.287", "ppl": "1.22", "wps": "1836.7", "ups": "6.23", "wpb": "294.7", "bsz": "16", "num_updates": "17900", "lr": "4.91296e-05", "gnorm": "2.406", "loss_scale": "16", "train_wall": "16", "wall": "4848"}
2021-10-24 14:16:34 | INFO | train_inner | {"epoch": 15, "update": 14.698, "loss": "2.217", "nll_loss": "0.302", "ppl": "1.23", "wps": "1998.8", "ups": "5.49", "wpb": "363.9", "bsz": "16", "num_updates": "18000", "lr": "4.91246e-05", "gnorm": "2.33", "loss_scale": "16", "train_wall": "18", "wall": "4867"}
2021-10-24 14:16:52 | INFO | train_inner | {"epoch": 15, "update": 14.78, "loss": "2.214", "nll_loss": "0.296", "ppl": "1.23", "wps": "1835.1", "ups": "5.65", "wpb": "324.6", "bsz": "16", "num_updates": "18100", "lr": "4.91196e-05", "gnorm": "2.38", "loss_scale": "16", "train_wall": "17", "wall": "4884"}
2021-10-24 14:17:08 | INFO | train_inner | {"epoch": 15, "update": 14.861, "loss": "2.203", "nll_loss": "0.287", "ppl": "1.22", "wps": "1885.7", "ups": "6.16", "wpb": "306", "bsz": "16", "num_updates": "18200", "lr": "4.91146e-05", "gnorm": "2.55", "loss_scale": "16", "train_wall": "16", "wall": "4900"}
2021-10-24 14:17:25 | INFO | train_inner | {"epoch": 15, "update": 14.943, "loss": "2.224", "nll_loss": "0.309", "ppl": "1.24", "wps": "1670.1", "ups": "5.89", "wpb": "283.8", "bsz": "16", "num_updates": "18300", "lr": "4.91096e-05", "gnorm": "2.352", "loss_scale": "16", "train_wall": "17", "wall": "4917"}
2021-10-24 14:17:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-10-24 14:19:34 | INFO | valid | {"epoch": 15, "valid_loss": "3.16", "valid_nll_loss": "1.216", "valid_ppl": "2.32", "valid_bleu": "60.34", "valid_wps": "368.9", "valid_wpb": "140.1", "valid_bsz": "8", "valid_num_updates": "18370", "valid_best_bleu": "69.44"}
2021-10-24 14:19:34 | INFO | fairseq_cli.train | early stop since valid performance hasn't improved for last 10 runs
2021-10-24 14:19:34 | INFO | fairseq_cli.train | begin save checkpoint
2021-10-24 14:19:47 | INFO | fairseq.checkpoint_utils | saved checkpoint ../models/plbart/unique/large/checkpoint_last.pt (epoch 15 @ 18370 updates, score 60.34) (writing took 13.400165228056721 seconds)
2021-10-24 14:19:47 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2021-10-24 14:19:47 | INFO | train | {"epoch": 15, "train_loss": "2.202", "train_nll_loss": "0.283", "train_ppl": "1.22", "train_wps": "1081.5", "train_ups": "3.66", "train_wpb": "295.9", "train_bsz": "16", "train_num_updates": "18370", "train_lr": "4.91061e-05", "train_gnorm": "2.35", "train_loss_scale": "16", "train_train_wall": "202", "train_wall": "5060"}
2021-10-24 14:19:47 | INFO | fairseq_cli.train | done training in 5056.2 seconds
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/mahim/miniconda3/envs/python36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
Traceback (most recent call last):
  File "match_files.py", line 22, in <module>
    main()
  File "match_files.py", line 10, in main
    with open(args.file1) as f1 , open(args.file2) as f2:
FileNotFoundError: [Errno 2] No such file or directory: '../data/unique/split/large/tgt-test.txt'
